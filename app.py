import os
import json
import requests
import logging
import time
import asyncio
import concurrent.futures
from functools import partial
from datetime import datetime
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from flask_login import LoginManager, login_required, current_user
from dotenv import load_dotenv
import boto3
from botocore.exceptions import ClientError
import google.generativeai as genai
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import atexit
from collections import Counter

# SSR ì—”ì§„ ë° ì‚¬ë¡€ DB ì„í¬íŠ¸
from ssr_engine import rank_emails, get_top_email, calculate_ssr_score
from case_database import select_relevant_cases, get_case_details, format_case_for_email, PORTONE_CASES

# ğŸ†• Upstage Groundedness Check ì„í¬íŠ¸
from upstage_groundedness import get_groundedness_checker

# ğŸ†• ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸
from business_model_analyzer import BusinessModelAnalyzer

# ğŸ†• CSV ì—´ ì´ë¦„ ë™ì  ë§¤í•‘ ëª¨ë“ˆ ì„í¬íŠ¸
from column_mapper import (
    get_company_name, get_business_number, get_contact_name, get_email,
    get_homepage, get_phone, get_news_url, get_sales_point, get_revenue,
    get_hosting, get_pg_provider, get_competitor, get_industry, get_company_size,
    get_email_salutation, get_sales_item, get_service_type, get_customer_type,
    get_contact_position, get_additional_info, get_column_value
)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì • - API í‚¤ ë…¸ì¶œ ë°©ì§€
logging.basicConfig(
    level=logging.INFO,  # DEBUG â†’ INFOë¡œ ë³€ê²½ (API í‚¤ ë…¸ì¶œ ë°©ì§€)
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # ì½˜ì†” ì¶œë ¥
    ]
)
logger = logging.getLogger(__name__)

# urllib3 DEBUG ë¡œê·¸ ë¹„í™œì„±í™” (URLì— í¬í•¨ëœ API í‚¤ ë…¸ì¶œ ë°©ì§€)
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('urllib3.connectionpool').setLevel(logging.WARNING)

app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'portone-email-generation-secret-key-2025')

# Railway PostgreSQL ì—°ê²° (postgres:// â†’ postgresql:// ë³€í™˜)
database_url = os.getenv('DATABASE_URL', 'sqlite:///email_gen.db')
if database_url.startswith('postgres://'):
    database_url = database_url.replace('postgres://', 'postgresql://', 1)
app.config['SQLALCHEMY_DATABASE_URI'] = database_url
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

CORS(app)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
from models import db, User, EmailGeneration, BlogPost, BlogCacheMetadata
db.init_app(app)

# Flask-Login ì„¤ì •
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'auth.login'
login_manager.login_message = 'ë¡œê·¸ì¸ì´ í•„ìš”í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.'

@login_manager.user_loader
def load_user(user_id):
    return db.session.get(User, int(user_id))

# Blueprint ë“±ë¡
from auth import auth_bp
from admin import admin_bp
app.register_blueprint(auth_bp)
app.register_blueprint(admin_bp)

# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜
with app.app_context():
    db.create_all()
    logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì‹ ê·œ ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜)
    try:
        from sqlalchemy import text
        
        # name_en ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS name_en VARCHAR(100)'))
            logger.info("âœ… name_en ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"name_en ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # email_signature ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS email_signature TEXT'))
            logger.info("âœ… email_signature ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"email_signature ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # gmail_app_password ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS gmail_app_password VARCHAR(200)'))
            logger.info("âœ… gmail_app_password ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"gmail_app_password ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS sendgrid_api_key VARCHAR(200)'))
            logger.info("âœ… sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        db.session.commit()
        logger.info("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        
        # ê¸°ì¡´ ì‚¬ìš©ìë“¤ì—ê²Œ ì„œëª… ìë™ ìƒì„± (ìƒˆë¡œìš´ ì‚¬ìš©ì)
        users_without_signature = User.query.filter(User.email_signature.is_(None)).all()
        if users_without_signature:
            for user in users_without_signature:
                user.email_signature = user.generate_email_signature()
            db.session.commit()
            logger.info(f"ğŸ“ {len(users_without_signature)}ëª…ì˜ ì‹ ê·œ ì‚¬ìš©ì ì„œëª… ìƒì„± ì™„ë£Œ")
        
        # ëª¨ë“  ì‚¬ìš©ìì˜ ì„œëª…ì„ ìƒˆë¡œìš´ í¬ë§·ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ë ˆì´ì•„ì›ƒ ê°œì„ )
        all_users = User.query.all()
        if all_users:
            for user in all_users:
                user.email_signature = user.generate_email_signature()
            db.session.commit()
            logger.info(f"âœ¨ {len(all_users)}ëª…ì˜ ì‚¬ìš©ì ì„œëª… í¬ë§· ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # ë¸”ë¡œê·¸ ìºì‹œ ìƒíƒœë§Œ í™•ì¸ (ìŠ¤í¬ë˜í•‘ì€ ì²« ìš”ì²­ ì‹œ ìë™ ì‹¤í–‰)
        from portone_blog_cache import load_blog_cache, get_blog_cache_age
        cached_posts = load_blog_cache()
        cache_age = get_blog_cache_age()
        
        if cached_posts:
            logger.info(f"âœ… ë¸”ë¡œê·¸ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(cached_posts)}ê°œ (ë‚˜ì´: {cache_age:.1f}ì‹œê°„)")
        else:
            logger.info("ğŸ“° ë¸”ë¡œê·¸ ìºì‹œ ì—†ìŒ - ì²« ì´ë©”ì¼ ìƒì„± ì‹œ ìë™ ìŠ¤í¬ë˜í•‘ë©ë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")
        db.session.rollback()

# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY', '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')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')

# Gemini API ì„¤ì • (íƒ€ì„ì•„ì›ƒ 180ì´ˆ)
if GEMINI_API_KEY:
    genai.configure(
        api_key=GEMINI_API_KEY,
        client_options={'api_endpoint': 'generativelanguage.googleapis.com'},
        transport='rest'  # REST ì „ì†¡ ì‚¬ìš©
    )

# Claude API Rate Limiter
_claude_last_call_time = 0
_claude_min_interval = 1.0  # ìµœì†Œ 1ì´ˆ ê°„ê²©

def call_claude_sonnet(prompt, timeout=180, max_retries=2):
    """
    Claude Sonnet 4.5 API í˜¸ì¶œ (Anthropic API ì§ì ‘ ì‚¬ìš©)
    """
    global _claude_last_call_time

    if not ANTHROPIC_API_KEY or ANTHROPIC_API_KEY == 'ì—¬ê¸°ì—_Anthropic_API_í‚¤_ì…ë ¥':
        raise Exception("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    # Rate Limiting: ìµœì†Œ ê°„ê²© ìœ ì§€
    elapsed = time.time() - _claude_last_call_time
    if elapsed < _claude_min_interval:
        wait_time = _claude_min_interval - elapsed
        logger.debug(f"â³ Claude Rate limiting: {wait_time:.1f}ì´ˆ ëŒ€ê¸°")
        time.sleep(wait_time)

    for retry_count in range(max_retries):
        try:
            _claude_last_call_time = time.time()

            api_url = "https://api.anthropic.com/v1/messages"
            headers = {
                "x-api-key": ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }

            payload = {
                "model": "claude-sonnet-4-20250514",  # Claude Sonnet 4.5 ìµœì‹  ëª¨ë¸
                "max_tokens": 16000,
                "temperature": 0.7,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }

            logger.info(f"ğŸ¤– Claude Sonnet 4.5 API í˜¸ì¶œ ì‹œì‘ (ì‹œë„ {retry_count + 1}/{max_retries})")
            response = requests.post(api_url, headers=headers, json=payload, timeout=timeout)

            if response.status_code == 200:
                result = response.json()
                if 'content' in result and len(result['content']) > 0:
                    content = result['content'][0]['text']
                    logger.info(f"âœ… Claude Sonnet 4.5 API í˜¸ì¶œ ì„±ê³µ (ì‹œë„ {retry_count + 1}/{max_retries})")
                    return content
                else:
                    raise Exception("Claude API ì‘ë‹µì— contentê°€ ì—†ìŠµë‹ˆë‹¤")
            elif response.status_code == 429:
                logger.warning(f"âš ï¸ Claude í• ë‹¹ëŸ‰ ì´ˆê³¼ (429) - ì¬ì‹œë„ ì¤‘...")
                if retry_count < max_retries - 1:
                    time.sleep(5)
                    continue
                else:
                    raise Exception("Claude API í• ë‹¹ëŸ‰ ì´ˆê³¼")
            else:
                raise Exception(f"Claude API ì˜¤ë¥˜: {response.status_code} - {response.text}")

        except requests.exceptions.Timeout:
            logger.warning(f"â±ï¸ Claude API íƒ€ì„ì•„ì›ƒ ({retry_count + 1}/{max_retries}) - ì¬ì‹œë„ ì¤‘...")
            if retry_count >= max_retries - 1:
                raise Exception("Claude API íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            if retry_count >= max_retries - 1:
                raise
            logger.warning(f"âš ï¸ Claude API ì˜¤ë¥˜ ë°œìƒ: {str(e)} - ì¬ì‹œë„ ì¤‘...")
            time.sleep(2)

    raise Exception("Claude API í˜¸ì¶œ ì‹¤íŒ¨")

# Gemini API Rate Limiter (RPM ì œí•œ ëŒ€ì‘)
_gemini_last_call_time = 0
_gemini_min_interval = 3.0  # ìµœì†Œ 3ì´ˆ ê°„ê²© (ë¶„ë‹¹ ìµœëŒ€ 20íšŒ)

def call_gemini_with_fallback(prompt, timeout=180, max_retries=3, generation_config=None):
    """
    AI API í˜¸ì¶œ with ìë™ fallback + Rate Limiting
    Claude Sonnet 4.5 (ìš°ì„ ) â†’ gemini-3-pro-preview â†’ gemini-2.5-pro â†’ gemini-2.5-flash
    """
    global _gemini_last_call_time

    # ğŸ†• 1ìˆœìœ„: Claude Sonnet 4.5 ì‹œë„
    if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'ì—¬ê¸°ì—_Anthropic_API_í‚¤_ì…ë ¥':
        try:
            logger.info("ğŸ¯ [1ìˆœìœ„] Claude Sonnet 4.5 ì‹œë„")
            result = call_claude_sonnet(prompt, timeout=timeout, max_retries=2)
            return result
        except Exception as e:
            logger.warning(f"âš ï¸ Claude Sonnet 4.5 ì‹¤íŒ¨: {str(e)}")
            logger.info("â†’ Geminië¡œ fallback")
    else:
        logger.info("âš ï¸ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ Geminië¡œ ì§„í–‰")

    # 2ìˆœìœ„: Gemini ì‹œë„
    # Rate Limiting: ìµœì†Œ ê°„ê²© ìœ ì§€
    elapsed = time.time() - _gemini_last_call_time
    if elapsed < _gemini_min_interval:
        wait_time = _gemini_min_interval - elapsed
        logger.debug(f"â³ Rate limiting: {wait_time:.1f}ì´ˆ ëŒ€ê¸°")
        time.sleep(wait_time)

    models = ['gemini-3-pro-preview', 'gemini-2.5-pro', 'gemini-2.5-flash']
    last_error = None
    
    for model_index, model in enumerate(models):
        retry_count = 0
        model_names = ['GEMINI(3-pro)', 'GEMINI(2.5-pro)', 'GEMINI(2.5-flash) [fallback]']
        model_name = model_names[model_index]
        
        # ì²« ë²ˆì§¸ ëª¨ë¸ì€ max_retriesë²ˆ ì¬ì‹œë„, ë‘ ë²ˆì§¸ ëª¨ë¸ì€ 1ë²ˆë§Œ ì‹œë„
        attempts = max_retries if model_index == 0 else 1
        
        while retry_count < attempts:
            try:
                _gemini_last_call_time = time.time()  # í˜¸ì¶œ ì‹œê°„ ê¸°ë¡
                api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"
                
                request_body = {
                    "contents": [{
                        "parts": [{"text": prompt}]
                    }]
                }
                
                if generation_config:
                    request_body["generationConfig"] = generation_config
                
                response = requests.post(
                    api_url,
                    json=request_body,
                    timeout=timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if 'candidates' in result and len(result['candidates']) > 0:
                        response_text = result['candidates'][0]['content']['parts'][0]['text']
                        logger.info(f"âœ… {model_name} API í˜¸ì¶œ ì„±ê³µ (ì‹œë„ {retry_count + 1}/{attempts})")
                        return response_text
                    else:
                        raise Exception(f"{model_name} API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤")
                elif response.status_code == 429:
                    # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì´ë™
                    logger.warning(f"âš ï¸ {model_name} í• ë‹¹ëŸ‰ ì´ˆê³¼ (429)")
                    if model_index < len(models) - 1:
                        logger.warning(f"â†’ ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ fallback to {models[model_index + 1]}")
                    break
                else:
                    raise Exception(f"{model_name} API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                    
            except Exception as retry_error:
                retry_count += 1
                error_str = str(retry_error)
                last_error = retry_error
                
                # íƒ€ì„ì•„ì›ƒì´ë‚˜ ì¼ì‹œì  ì˜¤ë¥˜ë©´ ì¬ì‹œë„
                if '504' in error_str or 'Deadline' in error_str or 'timeout' in error_str.lower() or 'timed out' in error_str.lower():
                    if retry_count < attempts:
                        logger.warning(f"â±ï¸ {model_name} API íƒ€ì„ì•„ì›ƒ ({retry_count}/{attempts}) - ì¬ì‹œë„ ì¤‘...")
                        time.sleep(5 * retry_count)
                        continue
                
                # ë§ˆì§€ë§‰ ì¬ì‹œë„ì´ê³  ë‹¤ìŒ ëª¨ë¸ì´ ìˆìœ¼ë©´ fallback
                if retry_count >= attempts and model_index < len(models) - 1:
                    logger.warning(f"âŒ {model_name} ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ fallback")
                    break
                
                # ë§ˆì§€ë§‰ ëª¨ë¸ê¹Œì§€ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì™¸ ë°œìƒ
                if model_index == len(models) - 1:
                    raise
    
    if last_error:
        raise last_error
    raise Exception("ëª¨ë“  Gemini ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨")

# AWS Bedrock ì„¤ì • (í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY') 
AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')

class ClaudeBedrockClient:
    """AWS Bedrockì„ í†µí•œ Claude í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.bedrock_runtime = None
        self.model_id = None
        
        # Claude 3.5 Sonnetì„ ìš°ì„ ìœ¼ë¡œ í•˜ë˜, ì ‘ê·¼ ë¶ˆê°€ì‹œ ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
        # Cross-region inference profilesì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ìš°ì„  ì‚¬ìš©
        self.available_models = [
            "us.anthropic.claude-3-5-haiku-20241022-v1:0",  # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-haiku-20240307-v1:0",       # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-opus-20240229-v1:0",        # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-5-sonnet-20240620-v1:0",
            "anthropic.claude-3-5-sonnet-20241022-v2:0",
            "us.anthropic.claude-3-5-sonnet-20241022-v2:0", 
            "anthropic.claude-v2:1",
            "anthropic.claude-v2"
        ]
        
        # Geminië¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ AWS Bedrock ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆë›°ê³  í•„ìš”ì‹œì—ë§Œ ì´ˆê¸°í™”
        logger.info("Gemini ìš°ì„  ëª¨ë“œ: AWS Bedrock ì´ˆê¸°í™” ê±´ë„ˆëœ€ (ì„±ëŠ¥ ìµœì í™”)")
    
    def _find_available_model(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤"""
        for model_id in self.available_models:
            try:
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                body = json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 10,
                    "messages": [{"role": "user", "content": "test"}],
                    "temperature": 0.1
                })
                
                self.bedrock_runtime.invoke_model(
                    body=body,
                    modelId=model_id,
                    accept="application/json",
                    contentType="application/json"
                )
                
                self.model_id = model_id
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë°œê²¬: {model_id}")
                break
                
            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                if error_code in ['AccessDeniedException', 'ValidationException']:
                    logger.debug(f"ëª¨ë¸ {model_id} ì ‘ê·¼ ë¶ˆê°€: {error_code}")
                    continue
                else:
                    logger.error(f"ëª¨ë¸ {model_id} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ì˜¤ë¥˜: {str(e)}")
                    continue
            except Exception as e:
                logger.debug(f"ëª¨ë¸ {model_id} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                continue
    
    def generate_content(self, prompt, max_tokens=4000):
        """Claudeë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  ìƒì„±"""
        try:
            if not self.bedrock_runtime or not self.model_id:
                raise Exception("AWS Bedrock í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            body = json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": max_tokens,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "top_p": 0.9
            })
            
            logger.info(f"Claude API í˜¸ì¶œ ì‹œì‘ - ëª¨ë¸: {self.model_id}, í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
            
            response = self.bedrock_runtime.invoke_model(
                body=body,
                modelId=self.model_id,
                accept="application/json",
                contentType="application/json"
            )
            
            response_body = json.loads(response.get('body').read())
            content = response_body.get('content', [{}])[0].get('text', '')
            
            logger.info(f"Claude API ì‘ë‹µ ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            return content
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            error_message = e.response.get('Error', {}).get('Message', str(e))
            
            if error_code == 'AccessDeniedException':
                logger.error(f"AWS Bedrock ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {error_message}")
                raise Exception("Claude ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. AWS ê³„ì •ì˜ Bedrock ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif error_code == 'ValidationException':
                logger.error(f"AWS Bedrock ê²€ì¦ ì˜¤ë¥˜: {error_message}")
                raise Exception(f"Claude ëª¨ë¸ í˜¸ì¶œ ê²€ì¦ ì‹¤íŒ¨: {error_message}")
            else:
                logger.error(f"AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {error_code} - {error_message}")
                raise Exception(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {error_message}")
                
        except Exception as e:
            logger.error(f"Claude ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"Claude ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")

class CompanyResearcher:
    """Perplexityë¥¼ ì‚¬ìš©í•œ íšŒì‚¬ ì •ë³´ ë° ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.perplexity_url = "https://api.perplexity.ai/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        self.bm_analyzer = BusinessModelAnalyzer()  # ğŸ†• BM ë¶„ì„ê¸° ì¶”ê°€
    
    def extract_emails_from_html(self, html_content):
        """HTMLì—ì„œ ì´ë©”ì¼ ì£¼ì†Œ ì¶”ì¶œ - ë‹¨ìˆœí™”ëœ ë²„ì „"""
        emails = set()
        
        try:
            # HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            text_content = soup.get_text()
            
            # ê¸°ë³¸ ì´ë©”ì¼ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b'
            found_emails = re.findall(email_pattern, text_content, re.IGNORECASE)
            
            # ê²°ê³¼ ì •ì œ
            for email in found_emails:
                if '@' in email and '.' in email and len(email) > 5:
                    emails.add(email.lower())
            
            return list(emails)
            
        except Exception as e:
            print(f"ì´ë©”ì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_business_number_from_html(self, html_content):
        """HTMLì—ì„œ ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ ì¶”ì¶œ"""
        business_numbers = set()
        
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            text_content = soup.get_text()
            
            # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ íŒ¨í„´ë“¤
            business_patterns = [
                r'\b\d{3}-\d{2}-\d{5}\b',  # 123-45-67890
                r'\b\d{10}\b',             # 1234567890 (ì—°ì† 10ìë¦¬)
                r'ì‚¬ì—…ì.*?ë“±ë¡.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
                r'ì‚¬ì—…ì.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
                r'ë“±ë¡.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
            ]
            
            for pattern in business_patterns:
                found_numbers = re.findall(pattern, text_content, re.IGNORECASE)
                for number in found_numbers:
                    # í•˜ì´í”ˆ ì œê±°í•˜ê³  10ìë¦¬ì¸ì§€ í™•ì¸
                    clean_number = re.sub(r'[^0-9]', '', number)
                    if len(clean_number) == 10:
                        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (123-45-67890)
                        formatted = f"{clean_number[:3]}-{clean_number[3:5]}-{clean_number[5:]}"
                        business_numbers.add(formatted)
            
            return list(business_numbers)
            
        except Exception as e:
            print(f"ì‚¬ì—…ìë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def find_privacy_policy_links(self, html_content, base_url):
        """ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ ë§í¬ ì°¾ê¸°"""
        privacy_links = set()
        
        try:
            from bs4 import BeautifulSoup
            import urllib.parse
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ê´€ë ¨ í‚¤ì›Œë“œ
            privacy_keywords = [
                'ê°œì¸ì •ë³´', 'ì²˜ë¦¬ë°©ì¹¨', 'privacy', 'policy', 
                'ê°œì¸ì •ë³´ë³´í˜¸', 'ê°œì¸ì •ë³´ì²˜ë¦¬', 'í”„ë¼ì´ë²„ì‹œ'
            ]
            
            # ëª¨ë“  ë§í¬ ê²€ì‚¬
            links = soup.find_all('a', href=True)
            for link in links:
                href = link.get('href', '')
                text = link.get_text().strip()
                
                # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë§í¬ ì°¾ê¸°
                for keyword in privacy_keywords:
                    if keyword in text.lower() or keyword in href.lower():
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        full_url = urllib.parse.urljoin(base_url, href)
                        privacy_links.add(full_url)
                        break
            
            return list(privacy_links)
            
        except Exception as e:
            print(f"ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ë§í¬ ì°¾ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def crawl_privacy_policy_page(self, privacy_url):
        """ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            response = requests.get(privacy_url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code == 200:
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text()
                
                # ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ì—ì„œ ì¶”ì¶œí•  ì •ë³´ë“¤
                info = {
                    'emails': self.extract_emails_from_html(response.content),
                    'business_numbers': self.extract_business_number_from_html(response.content),
                    'contact_info': self.extract_contact_info_from_text(text_content)
                }
                
                return info
            
        except Exception as e:
            print(f"ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return None
    
    
    
    def build_enriched_search_query(self, company_name, additional_info):
        """ê¸°ì¡´ ì…ë ¥ ì •ë³´ë¥¼ í™œìš©í•´ ë” ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        query_parts = [company_name]
        
        if additional_info:
            # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ì— í¬í•¨
            business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                             additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
            if business_number:
                query_parts.append(f'ì‚¬ì—…ìë²ˆí˜¸:{business_number}')
            
            # ëŒ€í‘œìëª…ì´ ìˆìœ¼ë©´ ê²€ìƒ‰ì— í¬í•¨
            ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                       additional_info.get('ëŒ€í‘œì') or
                       additional_info.get('CEOëª…'))
            if ceo_name:
                query_parts.append(f'ëŒ€í‘œ:{ceo_name}')
            
            # í™ˆí˜ì´ì§€ ë„ë©”ì¸ì´ ìˆìœ¼ë©´ site: ê²€ìƒ‰ìœ¼ë¡œ í¬í•¨
            website_url = (additional_info.get('í™ˆí˜ì´ì§€ë§í¬') or
                         additional_info.get('ëŒ€í‘œí™ˆí˜ì´ì§€') or
                         additional_info.get('ì›¹ì‚¬ì´íŠ¸'))
            if website_url:
                # URLì—ì„œ ë„ë©”ì¸ë§Œ ì¶”ì¶œ
                import re
                domain_match = re.search(r'https?://(?:www\.)?([^/]+)', website_url)
                if domain_match:
                    domain = domain_match.group(1)
                    query_parts.append(f'site:{domain}')
            
            # ì—…ì¢… ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            if additional_info.get('ì—…ì¢…'):
                query_parts.append(additional_info.get('ì—…ì¢…'))
            
            # ì£¼ìš” ì„œë¹„ìŠ¤/ì œí’ˆ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            for key in ['ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ì£¼ìš”ì‚¬ì—…']:
                if additional_info.get(key):
                    query_parts.append(additional_info.get(key))
        
        return ' '.join(query_parts)
    
    def research_company(self, company_name, website=None, additional_info=None):
        """íšŒì‚¬ë³„ ë§ì¶¤í˜• Pain Point ë°œêµ´ì„ ìœ„í•œ ìƒì„¸ ì¡°ì‚¬"""
        try:
            # CSVì—ì„œ ì œê³µëœ ì¶”ê°€ ì •ë³´ í™œìš©
            search_context = f"íšŒì‚¬ëª…: {company_name}"
            if website:
                search_context += f"\ní™ˆí˜ì´ì§€: {website}"
            
            # ê¸°ì¡´ ì…ë ¥ëœ ì •ë³´ë“¤ì„ ê²€ìƒ‰ì— í™œìš©í•  ìˆ˜ ìˆë„ë¡ í™•ì¥
            search_keywords = [company_name]  # ê¸°ë³¸ ê²€ìƒ‰ í‚¤ì›Œë“œ
            
            if additional_info:
                # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ (ì‚¬ì—…ìë²ˆí˜¸ ë˜ëŠ” ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ ì»¬ëŸ¼ ëª¨ë‘ ì²´í¬)
                business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                                 additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
                if business_number:
                    search_context += f"\nì‚¬ì—…ìë²ˆí˜¸: {business_number}"
                    search_keywords.append(business_number)
                
                # ëŒ€í‘œìëª… ì •ë³´ í™œìš©
                ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                           additional_info.get('ëŒ€í‘œì') or
                           additional_info.get('CEOëª…'))
                if ceo_name:
                    search_context += f"\nëŒ€í‘œìëª…: {ceo_name}"
                    search_keywords.append(f"{company_name} {ceo_name}")
                
                # í™ˆí˜ì´ì§€ë§í¬ ì¶”ê°€ ê²€ì¦
                website_url = (additional_info.get('í™ˆí˜ì´ì§€ë§í¬') or
                             additional_info.get('ëŒ€í‘œí™ˆí˜ì´ì§€') or
                             additional_info.get('ì›¹ì‚¬ì´íŠ¸'))
                if website_url and not website:
                    website = website_url
                    search_context += f"\ní™ˆí˜ì´ì§€: {website_url}"
                
                # ê¸°ì¡´ ì •ë³´ë“¤
                if additional_info.get('ì—…ì¢…'):
                    search_context += f"\nì—…ì¢…: {additional_info.get('ì—…ì¢…')}"
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    search_context += f"\nì£¼ìš” ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸: {additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')}"
                if additional_info.get('ê·œëª¨'):
                    search_context += f"\níšŒì‚¬ ê·œëª¨: {additional_info.get('ê·œëª¨')}"
                
                # ì¶”ê°€ ì •ë³´ë“¤ë„ ê²€ìƒ‰ì— í™œìš©
                for key in ['ì—…ì¢…', 'ë¶„ì•¼', 'ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸']:
                    if additional_info.get(key):
                        search_keywords.append(f"{company_name} {additional_info.get(key)}")
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë¡œê·¸ì— ì¶œë ¥
            logger.info(f"{company_name} ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë“¤: {search_keywords}")

            # ì›¹ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (ì›¹ ìŠ¤í¬ë˜í•‘ìš©)
            if website:
                self.company_website = website
            
            # ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ì„ í†µí•œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ (enriched query í™œìš©)
            logger.info(f"{company_name} ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            enriched_query = self.build_enriched_search_query(company_name, additional_info)
            news_results = self.search_company_news_with_query(enriched_query, company_name)
            if news_results:
                search_context += f"\n\n### ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ ë‰´ìŠ¤ ê²°ê³¼:\n{news_results}"
                logger.info(f"{company_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # MCP ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì •ë³´ ë³´ê°• (í•­ìƒ ìˆ˜í–‰) - enriched query í™œìš©
            logger.info(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            enhanced_info = self.enhance_company_info_with_mcp_enhanced(company_name, website, additional_info, [enriched_query])
            
            # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ì— MCPë¡œ ìˆ˜ì§‘í•œ ì •ë³´ ì¶”ê°€
            if enhanced_info:
                search_context += f"\n\n### MCP ë„êµ¬ë¡œ ìˆ˜ì§‘í•œ ì¶”ê°€ ì •ë³´:\n{enhanced_info}"
                logger.info(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(enhanced_info)} ë¬¸ì")
            else:
                logger.warning(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ - ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰")
            
            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - ê¸°ì¡´ ì…ë ¥ ì •ë³´ë¥¼ í™œìš©í•œ ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_query = self.build_enriched_search_query(company_name, additional_info)
            
            prompt = f"""
ë‹¤ìŒ íšŒì‚¬ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ì›¹ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ì¡°ì‚¬í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.

ğŸ” **í•„ìˆ˜: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°˜ë“œì‹œ ì°¾ì•„ì£¼ì„¸ìš”**

ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}

ì´ ê²€ìƒ‰ ì¿¼ë¦¬ì—ëŠ” ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸, ëŒ€í‘œìëª…, ê³µì‹ í™ˆí˜ì´ì§€ ë“± ì •í™•í•œ ì‹ë³„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
ë°˜ë“œì‹œ ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬:
1. **ìµœê·¼ 6ê°œì›” ì´ë‚´ì˜ ë‰´ìŠ¤ ê¸°ì‚¬**ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰
2. ê³µì‹ ë³´ë„ìë£Œ, ì–¸ë¡  ê¸°ì‚¬, ì—…ê³„ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì—ì„œ ì •ë³´ ìˆ˜ì§‘
3. êµ¬ì²´ì ì¸ ë‚ ì§œì™€ ì¶œì²˜ë¥¼ í¬í•¨í•˜ì—¬ ì¸ìš©

ì¶”ê°€ë¡œ ì´ë¯¸ ìˆ˜ì§‘ëœ ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ì˜ ì •ë³´ë„ ì°¸ê³ :
{search_context}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”:

## 1. ìµœì‹  ë‰´ìŠ¤ ë° í™œë™ (Recent News & Activities) ğŸ”´ **ê°€ì¥ ì¤‘ìš”**
**ë°˜ë“œì‹œ ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹¤ìŒ ì •ë³´ í¬í•¨:**
- ğŸ“° **ê¸°ì‚¬ ì œëª©ê³¼ ë‚ ì§œ** (ì˜ˆ: "2024ë…„ 10ì›” ì‹œë¦¬ì¦ˆ A íˆ¬ì ìœ ì¹˜" - 2024.10.15)
- ğŸ“° **ì‹ ì œí’ˆ ì¶œì‹œ, íˆ¬ì ìœ ì¹˜, ì‚¬ì—… í™•ì¥ ê´€ë ¨ êµ¬ì²´ì  ë‰´ìŠ¤**
- ğŸ“° **ì¡°ì§ ë³€í™”, íŒŒíŠ¸ë„ˆì‹­, ìˆ˜ìƒ ì´ë ¥ ë“±**
- ğŸ”— **ë‰´ìŠ¤ ì¶œì²˜** (ê°€ëŠ¥í•œ ê²½ìš° URL í¬í•¨)

## 2. ê¸°ì—… ê°œìš” (Corporate Overview)
- ì£¼ë ¥ ì‚¬ì—… ë¶„ì•¼ì™€ í•µì‹¬ ì œí’ˆ/ì„œë¹„ìŠ¤
- ëŒ€ìƒ ê³ ê°ì¸µ ë° ì‹œì¥ í¬ì§€ì…”ë‹  
- ì¶”ì • ë§¤ì¶œ ê·œëª¨ ë° ì„±ì¥ ë‹¨ê³„

## 3. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ìƒì„¸ ë¶„ë¥˜ (Business Model Classification) ğŸ”´ **ë§¤ìš° ì¤‘ìš”**
**íšŒì‚¬ì˜ êµ¬ì²´ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•´ë‹¹í•˜ëŠ” ëª¨ë“  í•­ëª©ì„ ëª…ì‹œ:**

### ìˆ˜ìµ ëª¨ë¸ ë¶„ë¥˜:
- **êµ¬ë…/ì •ê¸°ê²°ì œ ì„œë¹„ìŠ¤**: SaaS, ë©¤ë²„ì‹­, OTT, êµ¬ë…ë°•ìŠ¤, ì •ê¸°ë°°ì†¡ ë“±
  * êµ¬ë… ì£¼ê¸° (ì›”ê°„/ì—°ê°„), êµ¬ë…ì ìˆ˜, ì •ê¸°ê²°ì œ ë¹„ì¤‘
- **ì¼íšŒì„± ê±°ë˜**: ì¼ë°˜ ì´ì»¤ë¨¸ìŠ¤, ì‡¼í•‘ëª°, ë‹¨ê±´ ê±°ë˜
  * ì£¼ìš” ìƒí’ˆ ì¹´í…Œê³ ë¦¬, í‰ê·  ê±°ë˜ì•¡
- **í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤**: ì–‘ë©´ í”Œë«í¼, ì¤‘ê°œ ì„œë¹„ìŠ¤
  * íŒë§¤ì ìˆ˜, ê±°ë˜ ì¤‘ê°œ ë°©ì‹, ì •ì‚° êµ¬ì¡°
- **B2B ê±°ë˜**: ê¸°ì—… ê°„ ê±°ë˜, ë‚©í’ˆ, ë„ë§¤
  * ê±°ë˜ì²˜ ìˆ˜, ê±°ë˜ ê·œëª¨, ê²°ì œ ì¡°ê±´

### íŒë§¤ ì±„ë„ ë¶„ë¥˜:
- **ìì‚¬ëª°/ì•±**: ë…ìì ì¸ ì´ì»¤ë¨¸ìŠ¤ í”Œë«í¼ ìš´ì˜
- **ì˜¤í”ˆë§ˆì¼“ ì…ì **: ë„¤ì´ë²„, ì¿ íŒ¡, 11ë²ˆê°€, SSG ë“±
- **ì˜¤í”„ë¼ì¸ ë§¤ì¥**: POS, í‚¤ì˜¤ìŠ¤í¬ ë“±
- **í•´ì™¸ ì§„ì¶œ**: ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œ ì—¬ë¶€
  * ì§„ì¶œ êµ­ê°€, í•´ì™¸ ë§¤ì¶œ ë¹„ì¤‘, í˜„ì§€í™” ìˆ˜ì¤€

### ê²°ì œ íŠ¹ì„±:
- ê±°ë˜ ë¹ˆë„ ë° í‰ê·  ê±°ë˜ì•¡
- ì£¼ìš” ê²°ì œ ìˆ˜ë‹¨ (ì¹´ë“œ/ê°„í¸ê²°ì œ/ê³„ì¢Œì´ì²´/í•´ì™¸ê²°ì œ)
- í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PGì‚¬ (ì¶”ì •)

**ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ PortOne ì†”ë£¨ì…˜ì„ í›„ì† ì„¹ì…˜ì—ì„œ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.**

## 4. ê²°ì œ/ì •ì‚° ê´€ë ¨ Pain Points (Payment & Settlement Challenges)
**ìœ„ì—ì„œ íŒŒì•…í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ê¸°ë°˜í•˜ì—¬ êµ¬ì²´ì ì¸ ë¬¸ì œì  ë„ì¶œ:**
- í˜„ì¬ ê²°ì œ ì‹œìŠ¤í…œì˜ ì¶”ì • ë³µì¡ë„
- ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ ì‹œ ì˜ˆìƒë˜ëŠ” ì •ì‚° ë¬¸ì œ
- ì—…ê³„ íŠ¹ì„±ìƒ ê²ªì„ ìˆ˜ ìˆëŠ” ê²°ì œ ê´€ë ¨ ì–´ë ¤ì›€
- ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ íŠ¹ì„±ì—ì„œ ë°œìƒí•˜ëŠ” ê²°ì œ ì´ìŠˆ (ì˜ˆ: êµ¬ë…â†’ë¹Œë§í‚¤ ê´€ë¦¬, í•´ì™¸â†’í™˜ìœ¨/ìˆ˜ìˆ˜ë£Œ, í”Œë«í¼â†’íŒŒíŠ¸ë„ˆ ì •ì‚°)

## 5. ì—…ê³„ë³„ ê¸°ìˆ  íŠ¸ë Œë“œ (Industry Tech Trends)
- í•´ë‹¹ ì—…ê³„ì˜ ë””ì§€í„¸ ì „í™˜ í˜„í™©
- ê²°ì œ ì¸í”„ë¼ í˜ì‹  ì‚¬ë¡€

## 6. PortOne ì†”ë£¨ì…˜ ì í•©ì„± (PortOne Solution Fit)
**ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ë”°ë¥¸ ë§ì¶¤í˜• ì†”ë£¨ì…˜ ì œì•ˆ:**
- **êµ¬ë… ì„œë¹„ìŠ¤ì¸ ê²½ìš°**: ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤ (PG ì¢…ì† íƒˆí”¼, í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œ)
- **í•´ì™¸ ì§„ì¶œì¸ ê²½ìš°**: ê°êµ­ ê°„í¸ê²°ì œ 100+ ìˆ˜ë‹¨ ì—°ë™, ìˆ˜ìˆ˜ë£Œ ì ˆê°
- **ì˜¤í”ˆë§ˆì¼“ ë‹¤ì¤‘ ì…ì ì¸ ê²½ìš°**: Prism (ì±„ë„ë³„ ì •ì‚° ìë™ í†µí•©)
- **í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤ì¸ ê²½ìš°**: PS (íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”, ì „ìê¸ˆìœµë²• ë¦¬ìŠ¤í¬ í•´ì†Œ)
- **ê³ ê±°ë˜ëŸ‰ ì»¤ë¨¸ìŠ¤ì¸ ê²½ìš°**: ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… (PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°, ì•ˆì •ì„± 15% í–¥ìƒ)
- One Payment Infra(OPI) ì í•©ì„± ë¶„ì„
- ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ í•„ìš”ì„± ì •ë„

**ì¤‘ìš”**: ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ìµœì‹  ë‰´ìŠ¤ì™€ ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ì¸ìš©í•˜ê³ , êµ¬ì²´ì ì¸ ë‚ ì§œì™€ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì ì¸ ë‚´ìš©ì´ ì•„ë‹Œ, ì‹¤ì œ ê²€ìƒ‰ëœ ì‚¬ì‹¤ ê¸°ë°˜ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            data = {
                "model": "sonar-pro",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 1500,
                "temperature": 0.3
            }
            
            logger.info(f"Perplexity API ìƒì„¸ ì¡°ì‚¬ ìš”ì²­: {company_name}")
            
            response = requests.post(
                self.perplexity_url, 
                json=data, 
                headers=self.headers,
                timeout=45
            )
            
            logger.info(f"Perplexity API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                
                # ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ
                if 'choices' in result and len(result['choices']) > 0:
                    raw_content = result['choices'][0]['message']['content']
                    logger.info(f"{company_name} Perplexity ì‘ë‹µ ìˆ˜ì‹ : {len(raw_content)} ë¬¸ì")
                else:
                    logger.error(f"{company_name} Perplexity ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {result}")
                    raise Exception("Perplexity API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
                
                # Citations (ì¶œì²˜) ì¶”ì¶œ
                citations = result.get('citations', [])
                if citations:
                    logger.info(f"{company_name} Perplexity citations ë°œê²¬: {len(citations)}ê°œ")
                    # Citationsë¥¼ ì‘ë‹µì— ì¶”ê°€
                    citations_text = "\n\n## ğŸ“š ì°¸ê³  ì¶œì²˜ (Citations)\n"
                    for i, citation in enumerate(citations[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                        citations_text += f"{i}. {citation}\n"
                    raw_content += citations_text
                else:
                    logger.warning(f"{company_name} Perplexity citations ì—†ìŒ - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ")
                
                # ì‘ë‹µ í¬ë§·íŒ… ë° ê°€ë…ì„± ê°œì„ 
                formatted_content = self.format_perplexity_response(raw_content, company_name)
                
                # Pain Point ì¶”ì¶œ ë‹¨ê³„ ì¶”ê°€
                pain_points = self.extract_pain_points(formatted_content, company_name)
                
                # ì •ë³´ ê²€ì¦ ìˆ˜í–‰
                verification_result = self.verify_company_information(
                    company_name, 
                    {'company_info': formatted_content},
                    additional_info
                )
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ê°€ ê²€ìƒ‰ ìˆ˜í–‰ (70% ë¯¸ë§Œì—ì„œ ì¶”ê°€ ê²€ìƒ‰)
                if verification_result['confidence_score'] < 70:
                    logger.info(f"{company_name} ì‹ ë¢°ë„ {verification_result['confidence_score']}% - ì¶”ê°€ ê²€ìƒ‰ ì‹œì‘")
                    enhanced_info = self.perform_enhanced_search(company_name, additional_info, verification_result)
                    
                    if enhanced_info:
                        # ì¶”ê°€ ì •ë³´ë¡œ ê¸°ì¡´ ë‚´ìš© ë³´ê°•
                        formatted_content += f"\n\n## ğŸ“‹ ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼\n{enhanced_info['content']}"
                        
                        # ì¬ê²€ì¦ ìˆ˜í–‰
                        updated_verification = self.verify_company_information(
                            company_name, 
                            {'company_info': formatted_content},
                            additional_info
                        )
                        
                        # ì‹ ë¢°ë„ ê°œì„ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if updated_verification['confidence_score'] > verification_result['confidence_score']:
                            verification_result = updated_verification
                            logger.info(f"{company_name} ì‹ ë¢°ë„ ê°œì„ : {verification_result['confidence_score']}%")
                    
                    # ì‹ ë¢°ë„ ê²½ê³  ì¶”ê°€
                    reliability_warning = f"\n\nâš ï¸ **ì‹ ë¢°ë„**: {verification_result['confidence_score']}% (ì¶”ê°€ ê²€ìƒ‰ ì™„ë£Œ)"
                    formatted_content += reliability_warning
                else:
                    reliability_warning = f"\n\nâœ… **ì‹ ë¢°ë„**: {verification_result['confidence_score']}% (ê²€ì¦ ì™„ë£Œ)"
                    formatted_content += reliability_warning
                
                # ğŸ†• ìµœê·¼ ë‰´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (3ê°œì›” ì´ë‚´)
                has_recent_news = self.check_recent_news_in_content(formatted_content, company_name)
                
                # ğŸ†• ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ (í™ˆí˜ì´ì§€ + Perplexity ë°ì´í„° ê¸°ë°˜)
                homepage_content = ""
                if website:
                    try:
                        # í™ˆí˜ì´ì§€ ê°„ë‹¨ ìŠ¤í¬ë˜í•‘ (BM í‚¤ì›Œë“œ ì¶”ì¶œìš©)
                        logger.info(f"{company_name} í™ˆí˜ì´ì§€ BM ë¶„ì„ì„ ìœ„í•œ ìŠ¤í¬ë˜í•‘: {website}")
                        import requests as req
                        from bs4 import BeautifulSoup
                        response = req.get(website, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
                        if response.status_code == 200:
                            soup = BeautifulSoup(response.content, 'html.parser')
                            # ì£¼ìš” í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë©”íƒ€, ì œëª©, ë³¸ë¬¸)
                            homepage_content = soup.get_text(separator=' ', strip=True)[:5000]  # ì²« 5000ì
                            logger.info(f"{company_name} í™ˆí˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(homepage_content)} ë¬¸ì")
                    except Exception as e:
                        logger.warning(f"{company_name} í™ˆí˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
                
                # BM ë¶„ì„ ìˆ˜í–‰
                bm_analysis = self.bm_analyzer.analyze_business_model(
                    homepage_content, 
                    {'company_info': formatted_content}
                )
                logger.info(f"{company_name} BM ë¶„ì„ ì™„ë£Œ: {bm_analysis['primary_model_kr']} (ì‹ ë¢°ë„: {bm_analysis['confidence']}%)")
                
                # ë§ì¶¤í˜• ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ìƒì„±
                customized_pitch = self.bm_analyzer.generate_customized_pitch(bm_analysis, company_name)
                
                return {
                    'success': True,
                    'company_info': formatted_content,
                    'pain_points': pain_points,
                    'citations': result.get('citations', []),
                    'verification': verification_result,
                    'has_recent_news': has_recent_news,  # ğŸ†• ìµœê·¼ ë‰´ìŠ¤ í”Œë˜ê·¸ ì¶”ê°€
                    'business_model': bm_analysis,  # ğŸ†• BM ë¶„ì„ ê²°ê³¼
                    'customized_pitch': customized_pitch,  # ğŸ†• ë§ì¶¤í˜• ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸
                    'timestamp': datetime.now().isoformat(),
                    'raw_response': raw_content  # ë””ë²„ê¹…ìš©
                }
            else:
                logger.error(f"Perplexity API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                raise Exception(f"API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            
        except Exception as e:
            logger.error(f"íšŒì‚¬ ì¡°ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # íšŒì‚¬ë³„ ë§ì¶¤í˜• ì‹œãƒŸãƒ¥ë ˆì´ì…˜ ë°ì´í„°
            pain_points = self.generate_fallback_pain_points(company_name)
            return {
                'success': True,
                'company_info': f"""{company_name}ì— ëŒ€í•œ ìƒì„¸ ì¡°ì‚¬ ê²°ê³¼:

**ë¹„ì¦ˆë‹ˆìŠ¤ í˜„í™©:**
- ë””ì§€í„¸ ì „í™˜ ë° ì„±ì¥ì— ì§‘ì¤‘í•˜ëŠ” ê¸°ì—…
- ìš´ì˜ íš¨ìœ¨ì„± ë° ë¹„ìš© ìµœì í™” ë‹ˆì¦ˆ ë³´ìœ 

**ì˜ˆìƒ Pain Points:**
{pain_points}

**ê¸°ìˆ  ë„ì… ë‹ˆì¦ˆ:**
- ê²°ì œ ì‹œìŠ¤í…œ í˜„ëŒ€í™” ë° í†µí•© ì†”ë£¨ì…˜ í•„ìš”
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ êµ¬ì¶• ê´€ì‹¬""",
                'pain_points': pain_points,
                'citations': [],
                'has_recent_news': False,  # ğŸ†• API ì˜¤ë¥˜ ì‹œ ë‰´ìŠ¤ ì—†ìŒ
                'timestamp': datetime.now().isoformat(),
                'note': f'API ì˜¤ë¥˜ë¡œ ì¸í•œ ë§ì¶¤í˜• ì‹œãƒŸãƒ¥ë ˆì´ì…˜: {str(e)}'
            }
    
    def extract_pain_points(self, research_content, company_name):
        """íšŒì‚¬ë³„ êµ¬ì²´ì  Pain Point ì¶”ì¶œ - ì‹¤ì œ ì¡°ì‚¬ ë‚´ìš© ê¸°ë°˜"""
        try:
            # íšŒì‚¬ëª…ì—ì„œ ê³ ìœ  ì‹ë³„ì ìƒì„± (ì°¨ë³„í™” ë³´ì¥)
            company_hash = hash(company_name) % 1000
            
            # ì¡°ì‚¬ ë‚´ìš©ì—ì„œ êµ¬ì²´ì  ì •ë³´ ì¶”ì¶œ
            content_lower = research_content.lower()
            specific_points = []
            
            # 1. Perplexity ì¡°ì‚¬ ë‚´ìš©ì—ì„œ ì‹¤ì œ ë‹ˆì¦ˆ ë°œêµ´
            # ì„±ì¥/í™•ì¥ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ì„±ì¥', 'í™•ì¥', 'íˆ¬ì', 'ë§¤ì¶œì¦ê°€', 'growth', 'expansion', 'investment']):
                if any(word in content_lower for word in ['ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ecommerce']):
                    specific_points.append(f"{company_name}ì˜ ê¸‰ì„±ì¥ì— ë”°ë¥¸ ë‹¤ì¤‘ ì±„ë„ ê²°ì œ ë°ì´í„° í†µí•© í•„ìš”ì„±")
                elif any(word in content_lower for word in ['ê²Œì„', 'game', 'ëª¨ë°”ì¼']):
                    specific_points.append(f"{company_name}ì˜ ì‚¬ìš©ì ì¦ê°€ì— ë”°ë¥¸ ê²°ì œ ì¸í”„ë¼ í™•ì¥ì„± ì´ìŠˆ")
                else:
                    specific_points.append(f"{company_name}ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë³µì¡ì„± ì¦ê°€")
            
            # ê¸€ë¡œë²Œ/í•´ì™¸ì§„ì¶œ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ê¸€ë¡œë²Œ', 'í•´ì™¸', 'ìˆ˜ì¶œ', 'ì§„ì¶œ', 'global', 'overseas', 'international']):
                specific_points.append(f"{company_name}ì˜ í•´ì™¸ ì§„ì¶œ ì‹œ ë‹¤êµ­ê°€ ê²°ì œ ìˆ˜ë‹¨ ë° ì •ì‚° ë³µì¡ì„±")
            
            # ê¸°ìˆ /ê°œë°œ ê´€ë ¨ ë‹ˆì¦ˆ  
            if any(word in content_lower for word in ['ê°œë°œ', 'ê¸°ìˆ ', 'ì‹œìŠ¤í…œ', 'tech', 'development', 'platform']):
                specific_points.append(f"{company_name}ì˜ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ë‹´ ë° ì „ë¬¸ì„± ë¶€ì¡±")
            
            # ì—…ì¢…ë³„ íŠ¹í™” ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ecommerce', 'online']):
                specific_points.append(f"{company_name}ì˜ ë‹¤ì¤‘ ì»¤ë¨¸ìŠ¤ ì±„ë„ ë°ì´í„° í†µí•© ë° ì‹¤ì‹œê°„ ì •ì‚° ë‹ˆì¦ˆ")
            elif any(word in content_lower for word in ['ì œì¡°', 'ìƒì‚°', 'ê³µì¥', 'manufacturing']):
                specific_points.append(f"{company_name}ì˜ B2B ëŒ€ëŸ‰ ê±°ë˜ ì²˜ë¦¬ ë° ë³µì¡í•œ ì •ì‚° êµ¬ì¡° ê°œì„  í•„ìš”")
            elif any(word in content_lower for word in ['ê²Œì„', 'ëª¨ë°”ì¼ê²Œì„', 'ì•±ê²Œì„', 'game', 'mobile']):
                # ê²Œì„ì—…ê³„ëŠ” ìˆ˜ìˆ˜ë£Œê°€ ì‹¤ì œ í•µì‹¬ ì´ìŠˆ
                specific_points.append(f"{company_name}ì˜ ì•±ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ í•´ê²° í•„ìš”ì„±")
                specific_points.append(f"D2C ì›¹ìƒì  êµ¬ì¶•ì„ í†µí•œ ìˆ˜ìˆ˜ë£Œ ì ˆê° ë° ì§ì ‘ ê³ ê° ê´€ê³„ êµ¬ì¶•")
            
            # 2. ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì—ì„œ ë°œêµ´ë˜ëŠ” ë‹ˆì¦ˆ
            # ìê¸ˆ ê´€ë ¨ ì´ìŠˆ
            if any(word in content_lower for word in ['ìê¸ˆ', 'í˜„ê¸ˆíë¦„', 'ì •ì‚°', 'ìˆ˜ìµì„±', 'cash', 'revenue', 'profit']):
                specific_points.append(f"{company_name}ì˜ í˜„ê¸ˆíë¦„ ê´€ë¦¬ ë° ì •ì‚° ìë™í™” í•„ìš”ì„±")
            
            # ìš´ì˜ íš¨ìœ¨ì„± ì´ìŠˆ
            if any(word in content_lower for word in ['íš¨ìœ¨', 'ìë™í™”', 'ì¸ë ¥', 'ì—…ë¬´', 'efficiency', 'automation', 'operation']):
                specific_points.append(f"{company_name}ì˜ ìˆ˜ì‘ì—… ì¤‘ì‹¬ ì¬ë¬´ í”„ë¡œì„¸ìŠ¤ ìë™í™” ë‹ˆì¦ˆ")
            
            # ë°ì´í„°/ë¶„ì„ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ë°ì´í„°', 'ë¶„ì„', 'ë¦¬í¬íŠ¸', 'data', 'analytics', 'report']):
                specific_points.append(f"{company_name}ì˜ ì‹¤ì‹œê°„ ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ í•„ìš”ì„±")
            
            # 3. íšŒì‚¬ë³„ ê³ ìœ  Pain Point ìƒì„± (ì°¨ë³„í™” ë³´ì¥)
            unique_points = [
                f"{company_name}ì˜ ì—…ê³„ íŠ¹ì„±ìƒ ê²°ì œ ì‹œìŠ¤í…œ ê´€ë¦¬ ë³µì¡ì„±",
                f"ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ì— ë”°ë¥¸ {company_name}ì˜ ìš´ì˜ íš¨ìœ¨ì„± ì €í•˜",
                f"{company_name}ì˜ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ ë¶€ì¬",
                f"ìˆ˜ì‘ì—… ì¤‘ì‹¬ì˜ {company_name} ì¬ë¬´ ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤ ë¹„íš¨ìœ¨ì„±"
            ]
            
            # ìµœì¢… Pain Point ì„ íƒ (ìµœëŒ€ 4ê°œ, ì°¨ë³„í™” ë³´ì¥)
            final_points = specific_points[:2] + unique_points[:2] if specific_points else unique_points[:4]
            
            return "\n".join([f"- {point}" for point in final_points])
            
        except Exception as e:
            logger.error(f"Pain Point ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return self.generate_fallback_pain_points(company_name)
    
    def generate_company_specific_pain_points(self, company_name):
        """íšŒì‚¬ëª… ê¸°ë°˜ ë§¤ìš° êµ¬ì²´ì ì¸ Pain Point ìƒì„±"""
        import hashlib
        import random
        
        # íšŒì‚¬ëª…ì„ í•´ì‹œí•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ëœë¤ ì‹œë“œ ìƒì„±
        seed = int(hashlib.md5(company_name.encode()).hexdigest()[:8], 16)
        random.seed(seed)
        
        company_lower = company_name.lower()
        
        # ì—…ì¢…ë³„ Pain Point í’€ ì •ì˜
        if any(keyword in company_lower for keyword in ['ì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘', 'ë¦¬í…Œì¼', 'ì˜¨ë¼ì¸', 'commerce', 'shop', 'mall', 'ë§ˆì¼“']):
            pain_pool = [
                "ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¹´ì¹´ì˜¤ìŠ¤íƒ€ì¼/ì¹´í˜24 ë°ì´í„° ë§¤í•‘ ì˜¤ë¥˜",
                "ì›” 200ì‹œê°„+ ì—‘ì…€ ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì¬ë¬´íŒ€ ê³ ìƒ",
                "êµ¬ë§¤í™•ì •-ì •ì‚°ë‚´ì—­ ë§¤í•‘ ì˜¤ë¥˜ë¡œ ì¸í•œ ë§¤ì¶œ ì†ì‹¤",
                "ì‹¤ì‹œê°„ ì¬ê³ /ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ë¶ˆê°€ëŠ¥",
                "ë¶€ê°€ì„¸ ì‹ ê³  ìë£Œ ì¤€ë¹„ì— ì£¼ë§ˆë‹¤ ë°¤ìƒˆìš°ê¸°",
                "ì±„ë„ë³„ ìˆ˜ìˆ˜ë£Œ ìƒì´ë¡œ ì¸í•œ ìˆ˜ìµì„± ì•…í™”",
                "ë‹¤ì¤‘ ì±„ë„ ì£¼ë¬¸ ë™ê¸°í™” ì‹¤íŒ¨ë¡œ ì¸í•œ ì¬ê³  ì°¨ì´"
            ]
        
        elif any(keyword in company_lower for keyword in ['í…Œí¬', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ìŠ¤íƒ€íŠ¸ì—…', 'tech', 'software', 'startup', 'ì•±', 'app']):
            pain_pool = [
                "ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 8ê°œì›”+ ì†Œìš”ë˜ì–´ ëŸ°ì¹­ ì§€ì—°",
                "PGì‚¬ 5ê°œ ì´ìƒ ì—°ë™ìœ¼ë¡œ ì¸í•œ ìš´ì˜ ë³µì¡ì„± ì¦ê°€",
                "ê²°ì œ ì‹¤íŒ¨ìœ¨ 15%ë¡œ ì¸í•œ ì›” ìˆ˜ë°±ë§Œì› ë§¤ì¶œ ì†ì‹¤",
                "ê°‘ì‘ìŠ¤ëŸ¬ìš´ íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ì„œë²„ ë‹¤ìš´ ìœ„í—˜",
                "ê°œë°œì 3ëª…ì´ ê²°ì œ ì‹œìŠ¤í…œë§Œ ê°œë°œí•˜ëŠ” ë¹„íš¨ìœ¨",
                "ì •ê¸°ê²°ì œ/ë³¸ì¸ì¸ì¦ ì¶”ê°€ ê°œë°œë¡œ ì¸í•œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±",
                "ê¸€ë¡œë²Œ ì§„ì¶œ ì‹œ ë‹¤êµ­ê°€ ê²°ì œ ìˆ˜ë‹¨ ëŒ€ì‘ ì–´ë ¤ì›€"
            ]
        
        elif any(keyword in company_lower for keyword in ['ì œì¡°', 'ìƒì‚°', 'ê³µì¥', 'ì œí’ˆ', 'manufacturing', 'factory', 'ì‚°ì—…']):
            pain_pool = [
                "B2B ëŒ€ê¸ˆ ê²°ì œ ì‹œ ë³µì¡í•œ ìŠ¹ì¸ ì ˆì°¨ë¡œ ì¸í•œ ì§€ì—°",
                "ì›” ìˆ˜ì²œê±´ ê±°ë˜ ì²˜ë¦¬ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ê³¼ë¶€í•˜",
                "ê³µê¸‰ì—…ì²´ ëŒ€ê¸ˆ ì§€ê¸‰ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì‹ ë¢°ë„ í•˜ë½",
                # "ëŒ€ë¦¬ì /ëŒ€ë¦¬ì‚¬ ìˆ˜ìˆ˜ë£Œ ì •ì‚° ì˜¤ë¥˜ë¡œ ì¸í•œ ë¶„ìŸ",
                "ìˆ˜ì¶œ ëŒ€ê¸ˆ íšŒìˆ˜ ì§€ì—°ìœ¼ë¡œ ì¸í•œ í˜„ê¸ˆíë¦„ ì•…í™”",
                "ì¬ê³  ë°ì´í„°ì™€ ì£¼ë¬¸ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ í˜¼ë€",
                "ERP ì‹œìŠ¤í…œê³¼ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨"
            ]
        
        elif any(keyword in company_lower for keyword in ['ì„œë¹„ìŠ¤', 'ì»´ì„¤íŒ…', 'ëŒ€í–‰', 'service', 'consulting', 'ì—ì´ì „ì‹œ']):
            pain_pool = [
                "ê³ ê°ì‚¬ 20ê°œ ì´ìƒì˜ ì„œë¡œ ë‹¤ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™",
                # "í”„ë¡œì íŠ¸ë³„ ë¹„ìš© ì •ì‚°ì— ì£¼ë§ˆë‹¤ 20ì‹œê°„ ì†Œìš”",
                "ê³ ê°ì‚¬ ìš”êµ¬ë¡œ ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ",
                # "ìˆ˜ìˆ˜ë£Œ ì •ì‚° ì˜¤ë¥˜ë¡œ ì¸í•œ ê³ ê°ì‚¬ì™€ì˜ ë¶„ìŸ",
                "ì›”ë³„ ìˆ˜ìµ ë¶„ì„ì— ì—‘ì…€ë¡œ 3ì¼ ì†Œìš”",
                "ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ ì§€ì›ìœ¼ë¡œ ì¸í•œ ê°œë°œ ë¹„ìš© ì¦ê°€",
                # "ê³ ê°ì‚¬ë³„ ì •ì‚° ì£¼ê¸° ë‹¬ë¼ ê´€ë¦¬ ì–´ë ¤ì›€"
            ]
        
        else:
            # ì¼ë°˜ ê¸°ì—…ìš© Pain Point
            pain_pool = [
                "ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 6ê°œì›”+ ì†Œìš”ë˜ëŠ” ë¬¸ì œ",
                "ë°ì´í„° í†µí•© ë° ë¶„ì„ì˜ ì–´ë ¤ì›€",
                "ìˆ˜ì‘ì—… ì¤‘ì‹¬ì˜ ë¹„íš¨ìœ¨ì  ìš´ì˜",
                "ë””ì§€í„¸ ì „í™˜ ê³¼ì •ì—ì„œì˜ ê¸°ìˆ ì  ì±„ë§Œì§€",
                "ìš´ì˜ ë¹„ìš© ì¦ê°€ ë° ë¹„ìš© ìµœì í™” ë‹ˆì¦ˆ",
                "ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í™•ì¥ì„± í•œê³„"
            ]
        
        # íšŒì‚¬ë³„ë¡œ ì¼ê´€ëœ 4ê°œ Pain Point ì„ íƒ
        selected_points = random.sample(pain_pool, min(4, len(pain_pool)))
        return "\n".join([f"- {point}" for point in selected_points])
    
    def generate_fallback_pain_points(self, company_name):
        """ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ"""
        return self.generate_company_specific_pain_points(company_name)
    
    def generate_personalized_greeting(self, contact_name, contact_position, company_name):
        """ì´ë¦„ê³¼ ì§ì±…ì„ í™œìš©í•œ ê°œì¸í™”ëœ ì¸ì‚¬ë§ ìƒì„±"""
        greeting = ''
        
        if contact_name and contact_name != 'ë‹´ë‹¹ì':
            # ì§ì±…ì´ ìˆëŠ” ê²½ìš°
            if contact_position:
                # ì§ì±…ì— ë”°ë¥¸ ì¡´ì¹­ ì²˜ë¦¬
                if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
                elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
                else:
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
            else:
                # ì§ì±… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì´ë¦„ë§Œìœ¼ë¡œ ì¸ì‚¬
                if any(keyword in contact_name for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_name}ë‹˜."
                else:
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_name} ë‹´ë‹¹ìë‹˜."
        else:
            # ì´ë¦„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¸ì‚¬ë§
            greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜."
        
        return greeting
    
    def enhance_company_info_with_mcp_enhanced(self, company_name, website, additional_info, search_keywords=None):
        """í™•ì¥ëœ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ MCP ë„êµ¬ ì •ë³´ ë³´ê°• ë° ê²€ì¦ (ëŒ€í­ ê°•í™”)"""
        try:
            enhanced_data = []
            logger.info(f"{company_name} MCP ì •ë³´ ë³´ê°• ì‹œì‘")
            
            if not search_keywords:
                search_keywords = [company_name]
            
            # 1. ë‹¤ì¤‘ ì›¹ ê²€ìƒ‰ ì „ëµ (í™•ì¥ëœ í‚¤ì›Œë“œ í™œìš©)
            web_searches = []
            
            # ê¸°ë³¸ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰
            if website and website.startswith('http'):
                web_info = self.fetch_website_info(website, company_name)
                if web_info:
                    web_searches.append(f"ê³µì‹ ì›¹ì‚¬ì´íŠ¸: {web_info}")
            
            # í™•ì¥ëœ í‚¤ì›Œë“œë¡œ ë„¤ì´ë²„/êµ¬ê¸€ ê²€ìƒ‰ (ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œ)
            primary_search_keywords = search_keywords[:2]
            
            for keyword in primary_search_keywords:
                # ë„¤ì´ë²„ ì§€ì‹ë°±ê³¼/ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
                naver_info = self.search_naver_sources(keyword)
                if naver_info:
                    web_searches.append(f"ë„¤ì´ë²„ ê²€ìƒ‰ ({keyword}): {naver_info}")
                
                # êµ¬ê¸€ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜  
                google_info = self.search_google_sources(keyword)
                if google_info:
                    web_searches.append(f"êµ¬ê¸€ ê²€ìƒ‰ ({keyword}): {google_info}")
            
            if web_searches:
                enhanced_data.append("\n".join(web_searches))
            
            # 2. CSV ì •ë³´ ê¸°ë°˜ ì‹¬í™” ê²€ìƒ‰ (í™•ì¥ë¨)
            if additional_info:
                csv_insights = []
                
                # ì‚¬ì—…ìë²ˆí˜¸ -> ì—…ì²´ ì‹ ë¢°ë„ ê²€ì¦ (ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ë„ í¬í•¨)
                business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                                 additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
                if business_number:
                    business_validation = self.deep_business_validation(
                        company_name, business_number
                    )
                    if business_validation:
                        csv_insights.append(f"ì‚¬ì—…ì ì‹¬í™” ê²€ì¦: {business_validation}")
                
                # ëŒ€í‘œìëª… ì •ë³´ í™œìš©
                ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                           additional_info.get('ëŒ€í‘œì') or
                           additional_info.get('CEOëª…'))
                if ceo_name:
                    ceo_insights = self.analyze_ceo_profile(company_name, ceo_name)
                    if ceo_insights:
                        csv_insights.append(f"ëŒ€í‘œì í”„ë¡œí•„ ë¶„ì„: {ceo_insights}")
                
                # ì—…ì¢… -> ì‹œì¥ íŠ¸ë Œë“œ ë° Pain Point
                if additional_info.get('ì—…ì¢…'):
                    industry_deep_dive = self.get_industry_deep_insights(
                        company_name, additional_info.get('ì—…ì¢…')
                    )
                    if industry_deep_dive:
                        csv_insights.append(f"ì—…ì¢… ì‹¬í™” ë¶„ì„: {industry_deep_dive}")
                
                # ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ -> PortOne ì—°ê³„ì„± ë¶„ì„
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    synergy_analysis = self.analyze_portone_synergy(
                        company_name, additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')
                    )
                    if synergy_analysis:
                        csv_insights.append(f"PortOne ì—°ê³„ì„±: {synergy_analysis}")
                
                # ê·œëª¨ -> ë§ì¶¤í˜• ì†”ë£¨ì…˜ ì œì•ˆ
                if additional_info.get('ê·œëª¨'):
                    scale_strategy = self.get_scale_specific_strategy(
                        company_name, additional_info.get('ê·œëª¨')
                    )
                    if scale_strategy:
                        csv_insights.append(f"ê·œëª¨ë³„ ì „ëµ: {scale_strategy}")
                
                if csv_insights:
                    enhanced_data.append("\n".join(csv_insights))
            
            # 3. ì¢…í•© ê²°ê³¼
            if enhanced_data:
                result = "\n\n".join(enhanced_data)
                logger.info(f"{company_name} MCP ì •ë³´ ë³´ê°• ì„±ê³µ: {len(result)} ë¬¸ì")
                return result
            else:
                logger.warning(f"{company_name} MCP ì •ë³´ ë³´ê°•ì—ì„œ ìœ ì˜ë¯¸í•œ ë°ì´í„° ì—†ìŒ")
                return None
            
        except Exception as e:
            logger.error(f"MCP ì •ë³´ ë³´ê°• ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def enhance_company_info_with_mcp(self, company_name, website, additional_info):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - ìƒˆë¡œìš´ í™•ì¥ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
        return self.enhance_company_info_with_mcp_enhanced(company_name, website, additional_info)
    
    def search_naver_sources(self, company_name):
        """ë„¤ì´ë²„ ì†ŒìŠ¤ ê²€ìƒ‰ (ì§€ì‹ë°±ê³¼, ë‰´ìŠ¤ ë“±)"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ API í™œìš©
            return f"{company_name}ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ ë° ì§€ì‹ë°±ê³¼ ê²€ìƒ‰ ê²°ê³¼: ìµœê·¼ í™œë™ ë° ì–¸ë¡  ë³´ë„ í™•ì¸"
        except Exception as e:
            logger.debug(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def search_google_sources(self, company_name):
        """êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼"""
        try:
            # ì‹¤ì œë¡œëŠ” Google Search API í™œìš©
            return f"{company_name}ì˜ ê¸€ë¡œë²Œ ì›¹ ì¡´ì¬ê° ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ í™•ì¸"
        except Exception as e:
            logger.debug(f"êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def deep_business_validation(self, company_name, business_number):
        """ì‚¬ì—…ìë²ˆí˜¸ ì‹¬í™” ê²€ì¦"""
        try:
            # ì‹¤ì œë¡œëŠ” ê³µê³µë°ì´í„°í¬í„¸, ì‚¬ì—…ìì •ë³´ì¡°íšŒ API ë“± í™œìš©
            if business_number and len(business_number.replace('-', '')) == 10:
                return f"{company_name}({business_number})ì˜ ì‚¬ì—…ì ë“±ë¡ í˜„í™©, ì—…ì¢… ì½”ë“œ, ì„¤ë¦½ì¼ì ë“± ê³µì‹ ì •ë³´ í™•ì¸"
            return f"{company_name}ì˜ ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ í•„ìš”"
        except Exception as e:
            return None
    
    def analyze_ceo_profile(self, company_name, ceo_name):
        """ëŒ€í‘œì í”„ë¡œí•„ ë¶„ì„"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ì¸ë¬¼ê²€ìƒ‰, LinkedIn, ê¸°ì—… ê³µì‹œ ë“±ì„ í™œìš©
            return f"{company_name} {ceo_name} ëŒ€í‘œì˜ ê²½ë ¥ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì² í•™ ë¶„ì„ì„ í†µí•œ ì˜ì‚¬ê²°ì • ìŠ¤íƒ€ì¼ íŒŒì•…"
        except Exception as e:
            return None
    
    def get_industry_deep_insights(self, company_name, industry):
        """ì—…ì¢…ë³„ ì‹¬í™” ì¸ì‚¬ì´íŠ¸"""
        try:
            deep_insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name}ëŠ” ì´ì»¤ë¨¸ìŠ¤ ì—…ì²´ë¡œì„œ ë„¤ì´ë²„í˜ì´/ì¹´ì¹´ì˜¤í˜ì´/í† ìŠ¤í˜ì´ ë“± ë‹¤ì¤‘ PG ì—°ë™ê³¼ ì •ì‚° ìë™í™”ê°€ í•µì‹¬ ì´ìŠˆ. íŠ¹íˆ ë°˜í’ˆ/í™˜ë¶ˆ ì²˜ë¦¬, ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ ë“±ì´ ì£¼ìš” Pain Point",
                'í•€í…Œí¬': f"{company_name}ëŠ” í•€í…Œí¬ ê¸°ì—…ìœ¼ë¡œì„œ ê¸ˆìœµìœ„ì›íšŒ ê·œì œ ì¤€ìˆ˜ì™€ ë™ì‹œì— ê²°ì œ í¸ì˜ì„± ì œê³ ê°€ í•„ìš”. PCI-DSS ì¸ì¦, ì „ìê¸ˆìœµê±°ë˜ë²• ì¤€ìˆ˜, ì‹¤ì‹œê°„ ê±°ë˜ ëª¨ë‹ˆí„°ë§ì´ í•µì‹¬",
                'ì œì¡°ì—…': f"{company_name}ëŠ” ì œì¡°ì—…ì²´ë¡œì„œ B2B ëŒ€ëŸ‰ ê±°ë˜ì˜ ê²°ì œ/ì •ì‚° ë³µì¡ì„±ì´ ì£¼ìš” ê³¼ì œ. ì™¸ìƒë§¤ì¶œ, ì–´ìŒ ê²°ì œ, ìˆ˜ì¶œ ëŒ€ê¸ˆ íšŒìˆ˜, ERP ì—°ë™ì´ í•µì‹¬ ìš”êµ¬ì‚¬í•­",
                'SaaS': f"{company_name}ëŠ” SaaS ê¸°ì—…ìœ¼ë¡œì„œ êµ¬ë… ê²°ì œì˜ ì•ˆì •ì„±ê³¼ ê¸€ë¡œë²Œ í™•ì¥ì„±ì´ ì¤‘ìš”. ì •ê¸°ê²°ì œ ì‹¤íŒ¨ìœ¨ ìµœì†Œí™”, ë‹¤êµ­ê°€ í†µí™” ì§€ì›, ê³¼ê¸ˆ ëª¨ë¸ ìœ ì—°ì„±ì´ í•µì‹¬",
                'ITì„œë¹„ìŠ¤': f"{company_name}ëŠ” ITì„œë¹„ìŠ¤ ê¸°ì—…ìœ¼ë¡œì„œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ìµœì í™”ì™€ ì‹œìŠ¤í…œ í†µí•©ì´ ìš°ì„ ìˆœìœ„. API ê°œë°œ ì‹œê°„ ë‹¨ì¶•, ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ì—°ë™, í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ê°€ ì¤‘ìš”"
            }
            
            return deep_insights.get(industry, f"{company_name}ì˜ {industry} ë¶„ì•¼ íŠ¹ì„±ìƒ ê²°ì œ ì¸í”„ë¼ í˜„ëŒ€í™”ì™€ ìš´ì˜ íš¨ìœ¨ì„±ì´ í•µì‹¬ ê³¼ì œ")
        except Exception as e:
            return None
    
    def analyze_portone_synergy(self, company_name, sales_point):
        """PortOne ì†”ë£¨ì…˜ê³¼ì˜ ì‹œë„ˆì§€ ë¶„ì„"""
        try:
            sales_lower = sales_point.lower()
            
            if any(keyword in sales_lower for keyword in ['ê²°ì œ', 'í˜ì´ë¨¼íŠ¸', 'ì •ì‚°', 'payment']):
                return f"{company_name}ì˜ '{sales_point}' ì—­ëŸ‰ê³¼ ì €í¬ ê²°ì œ ì¸í”„ë¼ í†µí•© ì†”ë£¨ì…˜ ê°„ ë†’ì€ ì‹œë„ˆì§€ ê¸°ëŒ€. ê¸°ì¡´ ê°•ì ì„ ë”ìš± í™•ì¥í•  ìˆ˜ ìˆëŠ” ê¸°íšŒ"
            elif any(keyword in sales_lower for keyword in ['ë°ì´í„°', 'ë¶„ì„', 'ì¸ì‚¬ì´íŠ¸', 'analytics']):
                return f"{company_name}ì˜ '{sales_point}' ê²½í—˜ì„ ì €í¬ ì‹¤ì‹œê°„ ê²°ì œ ë°ì´í„° ë¶„ì„ê³¼ ê²°í•©í•˜ì—¬ ë” ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ êµ¬í˜„ ê°€ëŠ¥"
            elif any(keyword in sales_lower for keyword in ['ìë™í™”', 'automation', 'íš¨ìœ¨', 'efficiency']):
                return f"{company_name}ì˜ '{sales_point}' ë…¸í•˜ìš°ì™€ ì €í¬ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì´ ê²°í•©ë˜ì–´ ìš´ì˜ íš¨ìœ¨ì„± ê·¹ëŒ€í™” ê°€ëŠ¥"
            else:
                return f"{company_name}ì˜ '{sales_point}' í•µì‹¬ ì—­ëŸ‰ì„ ì €í¬ ê²°ì œ ì¸í”„ë¼ë¡œ ë”ìš± ê°•í™”í•˜ì—¬ ê²½ìŸ ìš°ìœ„ í™•ë³´ ê°€ëŠ¥"
        except Exception as e:
            return None
    
    def get_scale_specific_strategy(self, company_name, company_scale):
        """ê·œëª¨ë³„ íŠ¹í™” ì „ëµ"""
        try:
            scale_strategies = {
                'ìŠ¤íƒ€íŠ¸ì—…': f"{company_name} ê°™ì€ ìŠ¤íƒ€íŠ¸ì—…ì—ê²ŒëŠ” ì €í¬ ë¹ ë¥¸ ë„ì…(2ì£¼), ë‚®ì€ ì´ˆê¸° ë¹„ìš©, 100ë§Œì› ìƒë‹¹ ë¬´ë£Œ ì»¨ì„¤íŒ…ì´ ê°€ì¥ ì í•©. ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½ìœ¼ë¡œ í•µì‹¬ ì œí’ˆ ê°œë°œì— ì§‘ì¤‘ ê°€ëŠ¥",
                'ì¤‘ê²¬ê¸°ì—…': f"{company_name} ê°™ì€ ì¤‘ê²¬ê¸°ì—…ì—ê²ŒëŠ” ì €í¬ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ì™€ ë‹¤ì¤‘ PG í†µí•© ê´€ë¦¬ê°€ í•µì‹¬ ê°€ì¹˜. ì„±ì¥ì— ë”°ë¥¸ ê²°ì œëŸ‰ ì¦ê°€ì™€ ë³µì¡í•œ ì •ì‚° ìš”êµ¬ì‚¬í•­ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘",
                'ëŒ€ê¸°ì—…': f"{company_name} ê°™ì€ ëŒ€ê¸°ì—…ì—ê²ŒëŠ” ì €í¬ ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥ê³¼ ê³ ë„í™”ëœ ë¶„ì„ ë„êµ¬ê°€ ì¤‘ìš”. ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬, ë³µì¡í•œ ì¡°ì§ êµ¬ì¡° ì§€ì›, ê³ ê¸‰ ë³´ì•ˆ ê¸°ëŠ¥ ì œê³µ",
                'ì¤‘ì†Œê¸°ì—…': f"{company_name} ê°™ì€ ì¤‘ì†Œê¸°ì—…ì—ê²ŒëŠ” ì €í¬ ê°„í¸í•œ ì„¤ì •ê³¼ ì§ê´€ì  ê´€ë¦¬ ë„êµ¬ê°€ ìµœì . ë³µì¡í•œ IT ì§€ì‹ ì—†ì´ë„ ì „ë¬¸ì ì¸ ê²°ì œ ì‹œìŠ¤í…œ ìš´ì˜ ê°€ëŠ¥"
            }
            
            return scale_strategies.get(company_scale, f"{company_name}ì˜ {company_scale} íŠ¹ì„±ì— ìµœì í™”ëœ ì €í¬ ì†”ë£¨ì…˜ êµ¬ì„±ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼ ë‹¬ì„±")
        except Exception as e:
            return None
    
    def fetch_website_info(self, website, company_name):
        """ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ (WebFetch MCP ë„êµ¬ í™œìš©)"""
        try:
            import subprocess
            import json
            
            # WebFetch MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„
            prompt = f"{company_name}ì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤, ëŒ€ìƒ ê³ ê°, ìµœê·¼ ì—…ë°ì´íŠ¸ ë‚´ìš©, ê²°ì œ ê´€ë ¨ ì–¸ê¸‰ì‚¬í•­"
            
            # MCP WebFetch í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” MCP í”„ë¡œí† ì½œ ì‚¬ìš©)
            # í˜„ì¬ëŠ” requestsë¥¼ í†µí•œ ê°„ë‹¨í•œ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ëŒ€ì²´
            try:
                import requests
                from bs4 import BeautifulSoup
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                response = requests.get(website, headers=headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª… ì¶”ì¶œ
                    title = soup.find('title')
                    title_text = title.get_text().strip() if title else ""
                    
                    meta_desc = soup.find('meta', attrs={'name': 'description'})
                    desc_text = meta_desc.get('content', '') if meta_desc else ""
                    
                    # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¼ë¶€ ì¶”ì¶œ
                    paragraphs = soup.find_all('p')[:3]
                    body_text = ' '.join([p.get_text().strip() for p in paragraphs])
                    
                    web_info = f"ì œëª©: {title_text}\nì„¤ëª…: {desc_text}\në‚´ìš©: {body_text[:200]}..."
                    return web_info
                else:
                    return f"ì›¹ì‚¬ì´íŠ¸ ì ‘ê·¼ ì œí•œ (HTTP {response.status_code})"
                    
            except Exception as web_error:
                logger.warning(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {web_error}")
                return f"ì›¹ì‚¬ì´íŠ¸ ({website}) ì ‘ê·¼ ì‹œ ê¸°ìˆ ì  ë¬¸ì œ ë°œìƒ"
            
        except Exception as e:
            logger.error(f"ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def search_company_news_enhanced(self, company_name, search_keywords=None):
        """í™•ì¥ëœ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ (ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ í™œìš© - í’ˆì§ˆ ê°œì„ )"""
        import concurrent.futures
        import time
        
        if not search_keywords:
            search_keywords = [company_name]
        
        all_results = []
        search_start_time = time.time()
        
        # ê° ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ë³‘ë ¬ ê²€ìƒ‰ (ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ)
        primary_keywords = search_keywords[:3]  # ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 3ê°œë¡œ ì œí•œ
        
        # ë³‘ë ¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰ (ì„±ëŠ¥ í–¥ìƒ)
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(primary_keywords) * 2) as executor:
            futures = []
            
            # ê° í‚¤ì›Œë“œë³„ë¡œ Googleê³¼ DuckDuckGo ê²€ìƒ‰ ì‹¤í–‰
            for keyword in primary_keywords:
                futures.append(executor.submit(self.search_with_google, keyword))
                futures.append(executor.submit(self.search_with_duckduckgo, keyword))
            
            # ì›¹ ìŠ¤í¬ë˜í•‘ì€ íšŒì‚¬ëª…ìœ¼ë¡œë§Œ ì‹¤í–‰
            futures.append(executor.submit(self.search_with_web_scraping, company_name))
            
            # ëª¨ë“  future ê²°ê³¼ ìˆ˜ì§‘
            for i, future in enumerate(futures):
                try:
                    result = future.result(timeout=10)
                    if result and len(result.strip()) > 10:
                        # ê²°ê³¼ ì†ŒìŠ¤ êµ¬ë¶„ (Google/DuckDuckGo/Web)
                        if i < len(primary_keywords) * 2:  # Google + DuckDuckGo ê²°ê³¼
                            keyword_idx = i // 2
                            search_engine = "Google" if i % 2 == 0 else "DuckDuckGo"
                            keyword = primary_keywords[keyword_idx]
                            source = f"ğŸ“° {search_engine} ({keyword})"
                        else:  # Web scraping ê²°ê³¼
                            source = f"ğŸŒ ì›¹ ê²€ìƒ‰ ({company_name})"
                        
                        all_results.append(f"{source}: {result}")
                except concurrent.futures.TimeoutError:
                    logger.warning(f"ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (ì¸ë±ìŠ¤ {i})")
                except Exception as e:
                    logger.warning(f"ê²€ìƒ‰ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i}): {e}")
        
        search_elapsed = time.time() - search_start_time
        logger.info(f"{company_name} ë‹¤ì¤‘ ê²€ìƒ‰ ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼, {search_elapsed:.2f}ì´ˆ ì†Œìš”")
        
        if all_results:
            # ê²°ê³¼ í’ˆì§ˆ ì ê²€ ë° ì¤‘ë³µ ì œê±°
            quality_results = self.filter_and_enhance_results(all_results, company_name)
            return quality_results
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì œê³µ
        return self.generate_fallback_news_info(company_name)
    
    def search_company_news_with_query(self, search_query, company_name):
        """enriched queryë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        import concurrent.futures
        import time
        
        all_results = []
        search_start_time = time.time()
        
        logger.info(f"{company_name} Enriched ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")
        
        # ë³‘ë ¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # enriched queryë¡œ ê²€ìƒ‰
            future_google = executor.submit(self.search_with_google_query, search_query)
            future_duckduckgo = executor.submit(self.search_with_duckduckgo_query, search_query)
            future_web = executor.submit(self.search_with_web_scraping, company_name)  # ì›¹ ìŠ¤í¬ë˜í•‘ì€ íšŒì‚¬ëª…ìœ¼ë¡œ
            
            futures = [future_google, future_duckduckgo, future_web]
            sources = ["Google", "DuckDuckGo", "ì›¹ ê²€ìƒ‰"]
            
            # ëª¨ë“  future ê²°ê³¼ ìˆ˜ì§‘
            for i, (future, source) in enumerate(zip(futures, sources)):
                try:
                    result = future.result(timeout=10)
                    if result:
                        # ê²°ê³¼ ê²€ì¦
                        result_str = str(result).strip()
                        if len(result_str) > 10:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                            # ì´ëª¨ì§€ ì¶”ê°€
                            emoji = "ğŸ“°" if source == "Google" else ("ğŸ¦†" if source == "DuckDuckGo" else "ğŸŒ")
                            formatted_result = f"{emoji} {source}: {result_str}"
                            all_results.append(formatted_result)
                            logger.info(f"{company_name} {source} ê²€ìƒ‰ ì„±ê³µ: {len(result_str)} ë¬¸ì")
                        else:
                            logger.warning(f"{company_name} {source} ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìŒ: {result_str}")
                    else:
                        logger.warning(f"{company_name} {source} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                except concurrent.futures.TimeoutError:
                    logger.warning(f"{company_name} {source} ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (10ì´ˆ ì´ˆê³¼)")
                except Exception as e:
                    logger.warning(f"{company_name} {source} ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        search_elapsed = time.time() - search_start_time
        logger.info(f"{company_name} enriched ê²€ìƒ‰ ì™„ë£Œ: {len(all_results)}ê°œ ì›ë³¸ ê²°ê³¼, {search_elapsed:.2f}ì´ˆ ì†Œìš”")
        
        if all_results:
            # ê²°ê³¼ í’ˆì§ˆ ì ê²€ ë° ì¤‘ë³µ ì œê±°
            quality_results = self.filter_and_enhance_results(all_results, company_name)
            return quality_results
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì œê³µ
        logger.warning(f"{company_name} ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ì—ì„œ ê²°ê³¼ ì—†ìŒ - Fallback ì •ë³´ ì‚¬ìš©")
        return self.generate_fallback_news_info(company_name)
    
    def search_company_news(self, company_name):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - ìƒˆë¡œìš´ í™•ì¥ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
        return self.search_company_news_enhanced(company_name)
    
    def check_recent_news_in_content(self, content, company_name):
        """
        Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        
        Returns:
            bool: 3ê°œì›” ì´ë‚´ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ True, ì—†ìœ¼ë©´ False
        """
        from datetime import datetime, timedelta
        import re
        
        try:
            # í˜„ì¬ ë‚ ì§œì™€ 3ê°œì›” ì „ ë‚ ì§œ
            now = datetime.now()
            three_months_ago = now - timedelta(days=90)
            
            # ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰ (2024.11, 2024ë…„ 11ì›”, 2024-11 ë“±)
            date_patterns = [
                r'(\d{4})[\.\-ë…„\s]+(\d{1,2})[\.\-ì›”\s]',  # 2024.11, 2024ë…„ 11ì›”
                r'(\d{4})[\.\-/](\d{1,2})[\.\-/](\d{1,2})',  # 2024-11-24
            ]
            
            found_recent_news = False
            
            for pattern in date_patterns:
                matches = re.finditer(pattern, content)
                for match in matches:
                    try:
                        year = int(match.group(1))
                        month = int(match.group(2))
                        
                        # ë‚ ì§œê°€ ìœ íš¨í•œì§€ í™•ì¸
                        if year >= 2024 and 1 <= month <= 12:
                            news_date = datetime(year, month, 1)
                            
                            # 3ê°œì›” ì´ë‚´ ë‰´ìŠ¤ì¸ì§€ í™•ì¸
                            if news_date >= three_months_ago:
                                logger.info(f"{company_name}: {year}ë…„ {month}ì›” ìµœê·¼ ë‰´ìŠ¤ ë°œê²¬")
                                found_recent_news = True
                                break
                    except (ValueError, IndexError):
                        continue
                
                if found_recent_news:
                    break
            
            # ë‚ ì§œ íŒ¨í„´ì´ ì—†ì–´ë„ ìµœê·¼ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìµœê·¼ ë‰´ìŠ¤ë¡œ ê°„ì£¼
            if not found_recent_news:
                recent_keywords = ['ìµœê·¼', 'ì§€ë‚œë‹¬', 'ì´ë²ˆë‹¬', 'ì˜¬í•´', 'ê¸ˆë…„', 'ìµœì‹ ', 'ì‹ ê·œ', 'ìƒˆë¡œ', 
                                 'íˆ¬ì', 'ìœ ì¹˜', 'ëŸ°ì¹­', 'ì¶œì‹œ', 'í™•ì¥', 'ì‚¬ì—…', 'ì¸ìˆ˜']
                
                # "ìµœì‹  ë‰´ìŠ¤" ì„¹ì…˜ ë˜ëŠ” êµ¬ì²´ì ì¸ ë‰´ìŠ¤ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                has_news_section = '## 1. ìµœì‹  ë‰´ìŠ¤' in content or 'ìµœì‹  ë‰´ìŠ¤ ë° í™œë™' in content
                has_recent_keywords = any(keyword in content for keyword in recent_keywords)
                
                if has_news_section and has_recent_keywords:
                    logger.info(f"{company_name}: ë‚ ì§œëŠ” ì—†ì§€ë§Œ ìµœì‹  ë‰´ìŠ¤ í‚¤ì›Œë“œ ë°œê²¬")
                    found_recent_news = True
            
            if found_recent_news:
                logger.info(f"âœ… {company_name}: 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ ì¡´ì¬")
            else:
                logger.warning(f"âš ï¸ {company_name}: 3ê°œì›” ì´ë‚´ ë‰´ìŠ¤ ì—†ìŒ â†’ ì‚°ì—… ë™í–¥ ì‚¬ìš©")
            
            return found_recent_news
            
        except Exception as e:
            logger.error(f"{company_name} ë‰´ìŠ¤ ë‚ ì§œ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ True ë°˜í™˜ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
            return True
    
    def search_with_google(self, company_name):
        """Google Search API í™œìš©"""
        try:
            import requests
            import urllib.parse
            from datetime import datetime, timedelta
            
            # Google Custom Search API í‚¤ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
            google_api_key = os.getenv('GOOGLE_SEARCH_API_KEY')
            google_cse_id = os.getenv('GOOGLE_CSE_ID')
            
            if google_api_key and google_cse_id:
                # ìµœê·¼ 6ê°œì›” ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰
                recent_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
                search_query = f"{company_name} ë‰´ìŠ¤ íˆ¬ì ì‚¬ì—… í™•ì¥ after:{recent_date}"
                
                url = "https://www.googleapis.com/customsearch/v1"
                params = {
                    'key': google_api_key,
                    'cx': google_cse_id,
                    'q': search_query,
                    'num': 5,
                    'sort': 'date',
                    'tbm': 'nws'  # ë‰´ìŠ¤ ê²€ìƒ‰
                }
                
                response = requests.get(url, params=params, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    if items:
                        news_summaries = []
                        for item in items[:3]:
                            title = item.get('title', '')
                            snippet = item.get('snippet', '')
                            date = item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')
                            news_summaries.append(f"â€¢ {title} - {snippet[:100]}...")
                        
                        return "\n".join(news_summaries)
            
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ ê²€ìƒ‰ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
            return f"{company_name}ì˜ ìµœê·¼ ë¹„ì¦ˆë‹ˆìŠ¤ í™œë™ ë° ì„±ì¥ ë™í–¥ (Google ê²€ìƒ‰ ê¸°ë°˜)"
            
        except Exception as e:
            logger.warning(f"Google Search ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_google_query(self, search_query):
        """enriched queryë¥¼ ì‚¬ìš©í•œ Google ê²€ìƒ‰"""
        try:
            import requests
            from datetime import datetime, timedelta
            
            # Google Custom Search API í‚¤ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
            google_api_key = os.getenv('GOOGLE_SEARCH_API_KEY')
            google_cse_id = os.getenv('GOOGLE_CSE_ID')
            
            if google_api_key and google_cse_id:
                # enriched query ì‚¬ìš©
                recent_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
                enhanced_query = f"{search_query} ë‰´ìŠ¤ after:{recent_date}"
                
                url = "https://www.googleapis.com/customsearch/v1"
                params = {
                    'key': google_api_key,
                    'cx': google_cse_id,
                    'q': enhanced_query,
                    'num': 5,
                    'sort': 'date',
                    'tbm': 'nws'  # ë‰´ìŠ¤ ê²€ìƒ‰
                }
                
                response = requests.get(url, params=params, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    if items:
                        news_summaries = []
                        for item in items[:3]:
                            title = item.get('title', '')
                            snippet = item.get('snippet', '')
                            news_summaries.append(f"â€¢ {title} - {snippet[:100]}...")
                        
                        return "\n".join(news_summaries)
            
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° enriched queryë¥¼ í™œìš©í•œ ì‹œë®¬ë ˆì´ì…˜
            return f"ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ '{search_query}'ë¥¼ í™œìš©í•œ Google ê²€ìƒ‰ ê²°ê³¼: ë” êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ í™•ì¸"
            
        except Exception as e:
            logger.warning(f"Google Search ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_duckduckgo(self, company_name):
        """DuckDuckGo ê²€ìƒ‰ í™œìš©"""
        try:
            import requests
            import urllib.parse
            
            search_query = f"{company_name} ìµœì‹  ë‰´ìŠ¤ íˆ¬ì ì‚¬ì—… í™•ì¥ 2024"
            encoded_query = urllib.parse.quote(search_query)
            
            # DuckDuckGo Instant Answer API
            url = f"https://api.duckduckgo.com/?q={encoded_query}&format=json&no_html=1&skip_disambig=1"
            response = requests.get(url, timeout=20)
            
            if response.status_code == 200:
                data = response.json()
                
                # ì¶”ìƒ ì •ë³´ ì¶”ì¶œ
                abstract = data.get('Abstract', '')
                if abstract:
                    return f"ê²€ìƒ‰ ê²°ê³¼: {abstract}"
                
                # ê´€ë ¨ ì£¼ì œ ì¶”ì¶œ
                related_topics = data.get('RelatedTopics', [])
                if related_topics:
                    topic_texts = []
                    for topic in related_topics[:3]:
                        if isinstance(topic, dict) and 'Text' in topic:
                            topic_texts.append(topic['Text'])
                    if topic_texts:
                        return "; ".join(topic_texts)
            
            return f"{company_name}ì— ëŒ€í•œ DuckDuckGo ê²€ìƒ‰ ì™„ë£Œ"
            
        except Exception as e:
            logger.warning(f"DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_duckduckgo_query(self, search_query):
        """enriched queryë¥¼ ì‚¬ìš©í•œ DuckDuckGo ê²€ìƒ‰"""
        try:
            import requests
            import urllib.parse
            
            # enriched query ì‚¬ìš©
            encoded_query = urllib.parse.quote(search_query)
            
            # DuckDuckGo Instant Answer API
            url = f"https://api.duckduckgo.com/?q={encoded_query}&format=json&no_html=1&skip_disambig=1"
            response = requests.get(url, timeout=20)
            
            if response.status_code == 200:
                data = response.json()
                
                # ì¶”ìƒ ì •ë³´ ì¶”ì¶œ
                abstract = data.get('Abstract', '')
                if abstract:
                    return f"ê²€ìƒ‰ ê²°ê³¼: {abstract}"
                
                # ê´€ë ¨ ì£¼ì œ ì¶”ì¶œ
                related_topics = data.get('RelatedTopics', [])
                if related_topics:
                    topic_texts = []
                    for topic in related_topics[:3]:
                        if isinstance(topic, dict) and 'Text' in topic:
                            topic_texts.append(topic['Text'])
                    if topic_texts:
                        return "; ".join(topic_texts)
            
            return f"ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ '{search_query}'ë¥¼ í™œìš©í•œ DuckDuckGo ê²€ìƒ‰ ì™„ë£Œ: ë” ì •ë°€í•œ ì •ë³´ í™•ë³´"
        
        except Exception as e:
            logger.warning(f"DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜ (Perplexity ë³´ì¡°ìš©): {e}")
            return None
    
    def search_with_web_scraping(self, company_name):
        """ì›¹ ìŠ¤í¬ë˜í•‘ì„ í†µí•œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # ì•ˆì „í•œ ì›¹ ìŠ¤í¬ë˜í•‘ (robots.txt ì¤€ìˆ˜)
            import requests
            from bs4 import BeautifulSoup
            import time
            import random
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ê³µê°œ API ì•„ë‹Œ ê²½ìš° ì œí•œì  ì‚¬ìš©)
            news_info = []
            
            # íšŒì‚¬ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë³´ë„ìë£Œ/ë‰´ìŠ¤ ì„¹ì…˜ í™•ì¸
            if hasattr(self, 'company_website'):
                try:
                    # ì§§ì€ ë”œë ˆì´ë¡œ ì„œë²„ ë¶€í•˜ ë°©ì§€
                    time.sleep(random.uniform(1, 3))
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    
                    # ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì˜ ë‰´ìŠ¤/ë³´ë„ìë£Œ í˜ì´ì§€ ì¶”ì •
                    potential_urls = [
                        f"{self.company_website}/news",
                        f"{self.company_website}/press",
                        f"{self.company_website}/media",
                        f"{self.company_website}/announcement"
                    ]
                    
                    for url in potential_urls[:2]:  # ìµœëŒ€ 2ê°œë§Œ í™•ì¸
                        try:
                            response = requests.get(url, headers=headers, timeout=10)
                            if response.status_code == 200:
                                soup = BeautifulSoup(response.content, 'html.parser')
                                # ìµœì‹  ë‰´ìŠ¤ ì œëª©ë“¤ ì¶”ì¶œ
                                news_titles = soup.find_all(['h1', 'h2', 'h3', 'h4'], limit=3)
                                for title in news_titles:
                                    if title.get_text().strip():
                                        news_info.append(title.get_text().strip()[:100])
                                break
                        except:
                            continue
                            
                except Exception as scrape_error:
                    logger.debug(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì œí•œ: {scrape_error}")
            
            if news_info:
                return f"ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ìµœì‹  ì†Œì‹: {'; '.join(news_info[:2])}"
            
            return f"{company_name}ì˜ ê³µê°œ ì •ë³´ ë° ìµœì‹  ë™í–¥ (ì›¹ ê²€ìƒ‰ ê¸°ë°˜)"
            
        except Exception as e:
            logger.warning(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return None
    
    def filter_and_enhance_results(self, all_results, company_name):
        """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í•„í„°ë§ ë° í–¥ìƒ"""
        try:
            if not all_results:
                logger.warning(f"{company_name}: í•„í„°ë§í•  ê²°ê³¼ê°€ ì—†ìŒ")
                return self.generate_fallback_news_info(company_name)
            
            enhanced_results = []
            seen_content = set()
            
            for result in all_results:
                try:
                    # ì•ˆì „í•œ ê²°ê³¼ ë‚´ìš© ì¶”ì¶œ
                    if isinstance(result, str) and result.strip():
                        # ì´ëª¨ì§€ì™€ í—¤ë” ì œê±°
                        if ': ' in result:
                            parts = result.split(': ', 1)
                            content = parts[1] if len(parts) > 1 else result
                        else:
                            content = result
                        
                        content = content.strip()
                        content_lower = content.lower()
                        
                        # í’ˆì§ˆ ê²€ì‚¬ - ìµœì†Œ ê¸¸ì´ í™•ì¸
                        if len(content) < 15:
                            logger.debug(f"ë„ˆë¬´ ì§§ì€ ê²°ê³¼ ì œì™¸: {content[:50]}")
                            continue
                        
                        # ë¬´ì˜ë¯¸í•œ ê²°ê³¼ ì œê±°
                        skip_phrases = [
                            'ê²€ìƒ‰ ê²°ê³¼',
                            'ë” êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´',
                            'api í‚¤ê°€ ì—†ëŠ” ê²½ìš°',
                            'ì‹œë®¬ë ˆì´ì…˜'
                        ]
                        if any(phrase in content_lower for phrase in skip_phrases):
                            logger.debug(f"ë¬´ì˜ë¯¸í•œ ê²°ê³¼ ì œì™¸: {content[:50]}")
                            continue
                        
                        # ì¤‘ë³µ ë‚´ìš© ì œê±° (ìœ ì‚¬ë„ ê¸°ë°˜)
                        is_duplicate = False
                        for seen in seen_content:
                            if self.calculate_similarity(content_lower, seen) > 0.7:
                                is_duplicate = True
                                logger.debug(f"ì¤‘ë³µ ê²°ê³¼ ì œì™¸: {content[:50]}")
                                break
                        
                        if not is_duplicate:
                            seen_content.add(content_lower)
                            enhanced_results.append(result)
                            logger.debug(f"ìœ íš¨í•œ ê²°ê³¼ ì¶”ê°€: {content[:100]}")
                    
                except Exception as e:
                    logger.warning(f"ê°œë³„ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e} - {result[:100] if isinstance(result, str) else result}")
                    continue
            
            if enhanced_results:
                # ìµœì‹ ì„± ìˆœì„œë¡œ ì •ë ¬ (Google ë‰´ìŠ¤ ìš°ì„ )
                enhanced_results.sort(key=lambda x: (
                    0 if 'ğŸ“° Google' in str(x) else
                    1 if 'ğŸ¦† DuckDuckGo' in str(x) or 'DuckDuckGo' in str(x) else
                    2 if 'ğŸŒ ì›¹' in str(x) or 'ì›¹ ê²€ìƒ‰' in str(x) else 3
                ))
                
                result_text = "\n\n".join(enhanced_results)
                logger.info(f"{company_name}: {len(enhanced_results)}ê°œ ìœ íš¨ ê²°ê³¼ ë°˜í™˜")
                return result_text
            
            logger.warning(f"{company_name}: í•„í„°ë§ í›„ ìœ íš¨ ê²°ê³¼ ì—†ìŒ")
            return self.generate_fallback_news_info(company_name)
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ í•„í„°ë§ ì˜¤ë¥˜: {e}", exc_info=True)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì›ë³¸ ê²°ê³¼ ë°˜í™˜ ì‹œë„
            if all_results and len(all_results) > 0:
                return "\n\n".join([str(r) for r in all_results if r])
            return self.generate_fallback_news_info(company_name)
    
    def calculate_similarity(self, text1, text2):
        """ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„)"""
        try:
            words1 = set(text1.split())
            words2 = set(text2.split())
            
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            
            if len(union) == 0:
                return 0
            return len(intersection) / len(union)
        except:
            return 0
    
    def generate_fallback_news_info(self, company_name):
        """ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì •ë³´ ìƒì„±"""
        try:
            from datetime import datetime
            
            current_year = datetime.now().year
            
            fallback_info = f"""
ğŸ” {company_name} ìµœì‹  ë™í–¥ ì •ë³´

ğŸ“ˆ {company_name}ì€(ëŠ”) {current_year}ë…„ í˜„ì¬ ë””ì§€í„¸ ì „í™˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ í˜ì‹ ì— ì§€ì†ì ìœ¼ë¡œ íˆ¬ìí•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

ğŸ’¼ ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼:
â€¢ ê²°ì œ ì‹œìŠ¤í…œ í˜„ëŒ€í™” ë° íš¨ìœ¨í™”
â€¢ ê³ ê° ê²½í—˜ ê°œì„ ì„ ìœ„í•œ ë””ì§€í„¸ ì†”ë£¨ì…˜ ë„ì…
â€¢ ìš´ì˜ íš¨ìœ¨ì„± í–¥ìƒì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ìë™í™”
â€¢ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ êµ¬ì¶•

ğŸ¯ ì˜ˆìƒ ì„±ì¥ ë™ë ¥:
â€¢ ì˜¨ë¼ì¸/ëª¨ë°”ì¼ ì„œë¹„ìŠ¤ í™•ì¥
â€¢ ê²°ì œ ì¸í”„ë¼ í†µí•© ë° ìµœì í™” í•„ìš”ì„±
â€¢ ê³ ê° ë°ì´í„° ë¶„ì„ì„ í†µí•œ ê°œì¸í™” ì„œë¹„ìŠ¤

âš¡ PortOne ì†”ë£¨ì…˜ ì ìš© í¬ì¸íŠ¸:
â€¢ One Payment Infraë¡œ í†µí•© ê²°ì œ í™˜ê²½ êµ¬ì¶•
â€¢ ì¬ë¬´ ìë™í™”ë¡œ ìš´ì˜ íš¨ìœ¨ì„± ê·¹ëŒ€í™”  
â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°ìœ¼ë¡œ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì§‘ì¤‘

â€» ë” ì •í™•í•œ ìµœì‹  ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•´ì„œëŠ” Google Search API í‚¤ë¥¼ ì„¤ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
            return fallback_info.strip()
            
        except Exception as e:
            logger.error(f"Fallback ì •ë³´ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"{company_name} ê´€ë ¨ ìµœì‹  ë™í–¥ ë° ë‰´ìŠ¤ ì •ë³´ (ì¼ë°˜ì  ì •ë³´)"
    
    def get_active_search_engines(self):
        """í™œì„±í™”ëœ ê²€ìƒ‰ ì—”ì§„ ëª©ë¡ ë°˜í™˜"""
        active_engines = ['Perplexity']
        
        # Google Search API í‚¤ í™•ì¸
        if os.getenv('GOOGLE_SEARCH_API_KEY') and os.getenv('GOOGLE_CSE_ID'):
            active_engines.append('Google Search')
        
        # DuckDuckGoëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
        active_engines.append('DuckDuckGo')
        
        # ì›¹ ìŠ¤í¬ë˜í•‘ì€ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ
        if hasattr(self, 'company_website') and self.company_website:
            active_engines.append('Web Scraping')
            
        return active_engines
    
    def get_industry_insights(self, industry, company_name):
        """ì—…ì¢…ë³„ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘"""
        try:
            # ì—…ì¢…ë³„ íŠ¹í™”ëœ ì •ë³´ ìˆ˜ì§‘
            insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name} ê°™ì€ ì´ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì˜ ì£¼ìš” ê²°ì œ/ì •ì‚° ê³¼ì œ",
                'í•€í…Œí¬': f"{company_name} ê°™ì€ í•€í…Œí¬ ê¸°ì—…ì˜ ê·œì œ ì¤€ìˆ˜ ë° ê¸°ìˆ  í˜ì‹  ë™í–¥",
                'ì œì¡°ì—…': f"{company_name} ê°™ì€ ì œì¡°ì—…ì²´ì˜ B2B ê²°ì œ ì‹œìŠ¤í…œ ë³µì¡ì„±",
                'SaaS': f"{company_name} ê°™ì€ SaaS ê¸°ì—…ì˜ êµ¬ë… ê²°ì œ ë° ê¸€ë¡œë²Œ í™•ì¥ ì´ìŠˆ"
            }
            
            return insights.get(industry, f"{company_name}ì˜ {industry} ì—…ì¢… íŠ¹ì„±ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë‹ˆì¦ˆ")
            
        except Exception as e:
            logger.error(f"ì—…ì¢…ë³„ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def validate_business_number(self, business_num, company_name):
        """ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ë° ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # ì‚¬ì—…ìë²ˆí˜¸ ìœ íš¨ì„± ê²€ì¦ ë° ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            # ì‹¤ì œë¡œëŠ” ê³µê³µ APIë‚˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•œ ê²€ì¦
            if business_num and len(business_num.replace('-', '')) == 10:
                return f"ì‚¬ì—…ìë²ˆí˜¸ {business_num}ë¡œ í™•ì¸ëœ {company_name}ì˜ ì‚¬ì—…ì ë“±ë¡ ì •ë³´"
            else:
                return f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ í™•ì¸ í•„ìš”: {business_num}"
                
        except Exception as e:
            logger.error(f"ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return None
    
    def format_perplexity_response(self, raw_content, company_name):
        """Perplexity API ì‘ë‹µì˜ ê°€ë…ì„± ë° í¬ë§·íŒ… ê°œì„ """
        try:
            import re
            
            # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬
            content = raw_content.strip()
            
            # 2. ê³¼ë„í•œ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬ ê°•í™”
            content = re.sub(r'\n{3,}', '\n\n', content)  # 3ê°œ ì´ìƒ ì—°ì† ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
            content = re.sub(r'\n{2,}', '\n', content)    # 2ê°œ ì´ìƒ ì¤„ë°”ê¿ˆì„ 1ê°œë¡œ ì œí•œ
            content = re.sub(r'[ \t]{2,}', ' ', content)   # 2ê°œ ì´ìƒ ì—°ì† ìŠ¤í˜ì´ìŠ¤ë¥¼ 1ê°œë¡œ
            
            # 3. ì„¹ì…˜ í—¤ë” í¬ë§·íŒ… ê°œì„ 
            content = re.sub(r'^\*\*([^*]+)\*\*$', r'## \1', content, flags=re.MULTILINE)
            content = re.sub(r'^# ([^#])', r'## \1', content, flags=re.MULTILINE)
            
            # 4. ë¦¬ìŠ¤íŠ¸ í•­ëª© í¬ë§·íŒ… ê°œì„ 
            content = re.sub(r'^\s*[-â€¢]\s*', 'â€¢ ', content, flags=re.MULTILINE)
            content = re.sub(r'^\s*(\d+)\.?\s*', r'\1. ', content, flags=re.MULTILINE)
            
            # 5. íšŒì‚¬ëª… ì¼ê´€ì„± í™•ë³´ (ëŒ€ì†Œë¬¸ì ë° ë„ì–´ì“°ê¸°)
            if company_name:
                # íšŒì‚¬ëª… ë³€í˜•ë“¤ì„ í‘œì¤€ í˜•íƒœë¡œ í†µì¼
                company_variations = [
                    company_name.lower(),
                    company_name.upper(),
                    company_name.replace(' ', ''),
                    company_name.replace('-', ' ')
                ]
                
                for variation in company_variations:
                    if variation != company_name and len(variation) > 2:
                        content = re.sub(
                            r'\b' + re.escape(variation) + r'\b', 
                            company_name, 
                            content, 
                            flags=re.IGNORECASE
                        )
            
            # 6. êµ¬ì¡°í™”ëœ í¬ë§·ìœ¼ë¡œ ì¬ì •ë¦¬
            formatted_sections = []
            lines = content.split('\n')
            current_section = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # ì„¹ì…˜ í—¤ë” ê°ì§€
                if line.startswith('##') or line.startswith('**') and line.endswith('**'):
                    if current_section:
                        formatted_sections.append('\n'.join(current_section))
                        current_section = []
                    current_section.append(line)
                else:
                    current_section.append(line)
            
            # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
            if current_section:
                formatted_sections.append('\n'.join(current_section))
            
            # 7. ìµœì¢… í¬ë§·íŒ…
            final_content = '\n\n'.join(formatted_sections)
            
            # 8. í™˜ê° ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì¦ ë§ˆì»¤ ì¶”ê°€
            verification_note = f"\n\n---\nğŸ’¡ **ì •ë³´ ê²€ì¦**: ìœ„ ë‚´ìš©ì€ ìµœì‹  ê³µê°œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìœ¼ë©°, {company_name}ì˜ ì‹¤ì œ ìƒí™©ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            final_content += verification_note
            
            logger.info(f"Perplexity ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ: {len(raw_content)} â†’ {len(final_content)} ë¬¸ì")
            
            return final_content
            
        except Exception as e:
            logger.error(f"Perplexity ì‘ë‹µ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
            # í¬ë§·íŒ… ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return raw_content
    
    def _fix_malformed_json(self, json_content):
        """ì†ìƒëœ JSON ë³µêµ¬ ì‹œë„"""
        try:
            import re
            
            # 1. ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œ ìˆ˜ì •
            fixed_content = json_content
            
            # 2. ë¶ˆì™„ì „í•œ ë¬¸ìì—´ ìˆ˜ì • (ëë‚˜ì§€ ì•Šì€ ë¬¸ìì—´)
            # ë§ˆì§€ë§‰ ë”°ì˜´í‘œê°€ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš° ìˆ˜ì •
            lines = fixed_content.split('\n')
            for i, line in enumerate(lines):
                # í‚¤: "ê°’" íŒ¨í„´ì—ì„œ ê°’ ë¶€ë¶„ì´ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš°
                if line.strip().endswith('"') == False and '"' in line and ':' in line:
                    # ë¬¸ìì—´ì´ ë‹«íˆì§€ ì•Šì•˜ë‹¤ë©´ ë‹«ì•„ì£¼ê¸°
                    quote_count = line.count('"')
                    if quote_count % 2 == 1:  # í™€ìˆ˜ ê°œì˜ ë”°ì˜´í‘œ = ë‹«íˆì§€ ì•ŠìŒ
                        lines[i] = line + '"'
            
            fixed_content = '\n'.join(lines)
            
            # 3. í›„í–‰ ì‰¼í‘œ ì œê±°
            fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)
            
            # 4. ì¤‘ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
            open_braces = fixed_content.count('{')
            close_braces = fixed_content.count('}')
            if open_braces > close_braces:
                fixed_content += '}' * (open_braces - close_braces)
            
            return fixed_content
            
        except Exception as e:
            logger.debug(f"JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return None
    
    def verify_company_information(self, company_name, research_data, additional_info=None):
        """í™˜ê° ë°©ì§€ë¥¼ ìœ„í•œ íšŒì‚¬ ì •ë³´ ê²€ì¦"""
        try:
            verification_results = {
                'confidence_score': 0,
                'verified_facts': [],
                'potential_issues': [],
                'reliability_indicators': []
            }
            
            # 1. ê¸°ë³¸ ì‹ ë¢°ë„ ê²€ì‚¬
            base_confidence = 50  # ê¸°ë³¸ ì‹ ë¢°ë„
            
            # 2. ì›¹ì‚¬ì´íŠ¸ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
            if additional_info and additional_info.get('í™ˆí˜ì´ì§€ë§í¬'):
                website = additional_info.get('í™ˆí˜ì´ì§€ë§í¬')
                if self.verify_website_exists(website):
                    verification_results['verified_facts'].append(f"ì›¹ì‚¬ì´íŠ¸ {website} ì ‘ê·¼ ê°€ëŠ¥")
                    base_confidence += 20
                else:
                    verification_results['potential_issues'].append(f"ì›¹ì‚¬ì´íŠ¸ {website} ì ‘ê·¼ ë¶ˆê°€")
                    base_confidence -= 10
            
            # 3. ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦
            if additional_info and additional_info.get('ì‚¬ì—…ìë²ˆí˜¸'):
                business_num = additional_info.get('ì‚¬ì—…ìë²ˆí˜¸')
                if self.validate_business_number_format(business_num):
                    verification_results['verified_facts'].append(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ìœ íš¨: {business_num}")
                    base_confidence += 15
                else:
                    verification_results['potential_issues'].append(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ì˜ì‹¬: {business_num}")
                    base_confidence -= 15
            
            # 4. ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
            research_content = research_data.get('company_info', '')
            consistency_score = self.check_content_consistency(research_content, company_name)
            base_confidence += consistency_score
            
            if consistency_score > 15:
                verification_results['reliability_indicators'].append("ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ë†’ìŒ")
            elif consistency_score < -10:
                verification_results['reliability_indicators'].append("ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ì˜ì‹¬")
            
            # 5. íšŒì‚¬ëª… ì‹¤ì¡´ì„± ì¶”ì •
            name_validity = self.estimate_company_name_validity(company_name)
            base_confidence += name_validity
            
            if name_validity > 10:
                verification_results['verified_facts'].append(f"íšŒì‚¬ëª… '{company_name}' ì‹¤ì¡´ ê°€ëŠ¥ì„± ë†’ìŒ")
            elif name_validity < -5:
                verification_results['potential_issues'].append(f"íšŒì‚¬ëª… '{company_name}' ì‹¤ì¡´ ì—¬ë¶€ ì˜ì‹¬")
            
            # 6. ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0-100)
            verification_results['confidence_score'] = max(0, min(100, base_confidence))
            
            # 7. ì¢…í•© í‰ê°€
            if verification_results['confidence_score'] >= 80:
                verification_results['overall_assessment'] = "ë†’ì€ ì‹ ë¢°ë„"
            elif verification_results['confidence_score'] >= 60:
                verification_results['overall_assessment'] = "ë³´í†µ ì‹ ë¢°ë„"
            elif verification_results['confidence_score'] >= 40:
                verification_results['overall_assessment'] = "ë‚®ì€ ì‹ ë¢°ë„"
            else:
                verification_results['overall_assessment'] = "ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„"
            
            logger.info(f"{company_name} ì •ë³´ ê²€ì¦ ì™„ë£Œ: ì‹ ë¢°ë„ {verification_results['confidence_score']}%")
            
            return verification_results
            
        except Exception as e:
            logger.error(f"ì •ë³´ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'confidence_score': 50,
                'verified_facts': [],
                'potential_issues': [f"ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}"],
                'reliability_indicators': [],
                'overall_assessment': "ê²€ì¦ ë¶ˆê°€"
            }
    
    def verify_website_exists(self, website):
        """ì›¹ì‚¬ì´íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            import requests
            
            if not website or not website.startswith(('http://', 'https://')):
                return False
            
            response = requests.head(website, timeout=5, allow_redirects=True)
            return response.status_code < 400
            
        except Exception as e:
            logger.debug(f"ì›¹ì‚¬ì´íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def validate_business_number_format(self, business_num):
        """ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦"""
        try:
            if not business_num:
                return False
            
            # í•˜ì´í”ˆ ì œê±°í•˜ê³  ìˆ«ìë§Œ í™•ì¸
            clean_num = business_num.replace('-', '').replace(' ', '')
            
            # 10ìë¦¬ ìˆ«ìì¸ì§€ í™•ì¸
            if len(clean_num) != 10 or not clean_num.isdigit():
                return False
            
            # ê°„ë‹¨í•œ ì²´í¬ì„¬ ê²€ì¦ (ì‹¤ì œ ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ì•Œê³ ë¦¬ì¦˜)
            digits = [int(d) for d in clean_num]
            multipliers = [1, 3, 7, 1, 3, 7, 1, 3, 5]
            
            sum_val = sum(d * m for d, m in zip(digits[:9], multipliers))
            remainder = sum_val % 10
            check_digit = (10 - remainder) % 10
            
            return check_digit == digits[9]
            
        except Exception as e:
            logger.debug(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def check_content_consistency(self, content, company_name):
        """ì—°êµ¬ ë‚´ìš©ì˜ ì¼ê´€ì„± ê²€ì¦"""
        try:
            import re
            
            score = 0
            content_lower = content.lower()
            company_lower = company_name.lower()
            
            # íšŒì‚¬ëª… ì–¸ê¸‰ ë¹ˆë„ í™•ì¸
            company_mentions = len(re.findall(re.escape(company_lower), content_lower))
            if company_mentions >= 3:
                score += 10
            elif company_mentions >= 1:
                score += 5
            else:
                score -= 20  # íšŒì‚¬ëª…ì´ ê±°ì˜ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ
            
            # êµ¬ì²´ì  ì •ë³´ ì¡´ì¬ ì—¬ë¶€
            specific_indicators = [
                r'\d{4}ë…„', r'ë§¤ì¶œ', r'íˆ¬ì', r'ì„¤ë¦½', r'ì§ì›', r'ì‚¬ì—…', r'ì„œë¹„ìŠ¤',
                r'ê³ ê°', r'ì‹œì¥', r'ê¸°ìˆ ', r'ì†”ë£¨ì…˜', r'í”Œë«í¼'
            ]
            
            specific_matches = 0
            for indicator in specific_indicators:
                if re.search(indicator, content_lower):
                    specific_matches += 1
            
            if specific_matches >= 5:
                score += 15
            elif specific_matches >= 3:
                score += 10
            elif specific_matches < 2:
                score -= 10
            
            # ëª¨í˜¸í•œ í‘œí˜„ íŒ¨ë„í‹°
            vague_terms = [
                'ì¶”ì •', 'ì˜ˆìƒ', 'ê°€ëŠ¥ì„±', 'ê²ƒìœ¼ë¡œ ë³´ì„', 'ì•Œë ¤ì§€ì§€ ì•ŠìŒ', 
                'í™•ì¸ë˜ì§€ ì•ŠìŒ', 'ì •ë³´ ë¶€ì¡±'
            ]
            
            vague_matches = 0
            for term in vague_terms:
                vague_matches += len(re.findall(term, content_lower))
            
            if vague_matches > 5:
                score -= 15
            elif vague_matches > 2:
                score -= 5
            
            return score
            
        except Exception as e:
            logger.debug(f"ë‚´ìš© ì¼ê´€ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return 0
    
    def estimate_company_name_validity(self, company_name):
        """íšŒì‚¬ëª… ì‹¤ì¡´ì„± ì¶”ì •"""
        try:
            score = 0
            
            if not company_name or len(company_name) < 2:
                return -20
            
            # í•œêµ­ íšŒì‚¬ëª… íŒ¨í„´ í™•ì¸
            korean_company_suffixes = [
                'íšŒì‚¬', 'ê¸°ì—…', 'ì½”í¼ë ˆì´ì…˜', 'ì¸í„°ë‚´ì…”ë„', 'ê·¸ë£¹', 'í™€ë”©ìŠ¤',
                'í…Œí¬', 'ì†”ë£¨ì…˜', 'ì‹œìŠ¤í…œ', 'ì„œë¹„ìŠ¤', 'ë¯¸ë””ì–´', 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
                'ë°”ì´ì˜¤', 'íŒŒë§ˆ', 'í—¬ìŠ¤ì¼€ì–´', 'ì—ë„ˆì§€', 'ì¸ë”ìŠ¤íŠ¸ë¦¬'
            ]
            
            for suffix in korean_company_suffixes:
                if suffix in company_name:
                    score += 5
                    break
            
            # ì˜ë¬¸ íšŒì‚¬ëª… íŒ¨í„´ í™•ì¸
            english_patterns = [
                'Inc', 'Corp', 'Ltd', 'LLC', 'Co.', 'Solutions', 'Systems', 
                'Technologies', 'Services', 'Industries', 'Global'
            ]
            
            for pattern in english_patterns:
                if pattern in company_name:
                    score += 5
                    break
            
            # ì´ìƒí•œ íŒ¨í„´ íŒ¨ë„í‹°
            weird_patterns = [
                r'^\d+$',  # ìˆ«ìë§Œ
                r'^[!@#$%^&*()]+',  # íŠ¹ìˆ˜ë¬¸ìë¡œ ì‹œì‘
                r'.{50,}',  # ë„ˆë¬´ ê¸´ ì´ë¦„ (50ì ì´ìƒ)
            ]
            
            import re
            for pattern in weird_patterns:
                if re.search(pattern, company_name):
                    score -= 15
            
            return score
            
        except Exception as e:
            logger.debug(f"íšŒì‚¬ëª… ìœ íš¨ì„± ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0
    
    def perform_enhanced_search(self, company_name, additional_info, verification_result):
        """ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œ CSV ì •ë³´ë¥¼ í™œìš©í•œ ì§‘ì¤‘ì  ì¶”ê°€ ê²€ìƒ‰"""
        try:
            logger.info(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì‹œì‘ - í˜„ì¬ ì‹ ë¢°ë„: {verification_result['confidence_score']}%")
            
            enhanced_results = []
            search_strategies = []
            
            # 1. CSV ì •ë³´ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰
            if additional_info:
                # ì‚¬ì—…ìë²ˆí˜¸ë¡œ ê³µì‹ ì •ë³´ ê²€ìƒ‰
                if additional_info.get('ì‚¬ì—…ìë²ˆí˜¸'):
                    business_search = self.search_by_business_number(
                        company_name, 
                        additional_info.get('ì‚¬ì—…ìë²ˆí˜¸')
                    )
                    if business_search:
                        enhanced_results.append(f"ğŸ“‹ ì‚¬ì—…ìì •ë³´: {business_search}")
                        search_strategies.append("ì‚¬ì—…ìë²ˆí˜¸ ê²€ìƒ‰")
                
                # ì—…ì¢… ê¸°ë°˜ ì—…ê³„ ì •ë³´ ê°•í™”
                if additional_info.get('ì—…ì¢…'):
                    industry = additional_info.get('ì—…ì¢…')
                    industry_context = self.get_enhanced_industry_context(company_name, industry)
                    if industry_context:
                        enhanced_results.append(f"ğŸ­ ì—…ê³„ ì»¨í…ìŠ¤íŠ¸: {industry_context}")
                        search_strategies.append("ì—…ì¢…ë³„ ë¶„ì„")
                
                # ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ í™œìš©í•œ íŠ¹í™” ê²€ìƒ‰
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    sales_point = additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')
                    specialized_search = self.search_by_sales_focus(company_name, sales_point)
                    if specialized_search:
                        enhanced_results.append(f"ğŸ’¼ íŠ¹í™” ë¶„ì•¼: {specialized_search}")
                        search_strategies.append("ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ ë¶„ì„")
                
                # ê·œëª¨ ì •ë³´ ê¸°ë°˜ ë§ì¶¤ ê²€ìƒ‰
                if additional_info.get('ê·œëª¨'):
                    company_size = additional_info.get('ê·œëª¨')
                    size_based_info = self.get_size_based_insights(company_name, company_size)
                    if size_based_info:
                        enhanced_results.append(f"ğŸ“Š ê·œëª¨ë³„ ì¸ì‚¬ì´íŠ¸: {size_based_info}")
                        search_strategies.append("ê·œëª¨ë³„ ë¶„ì„")
            
            # 2. ì‹ ë¢°ë„ ë¬¸ì œì  ê¸°ë°˜ ì§‘ì¤‘ ê²€ìƒ‰
            issues = verification_result.get('potential_issues', [])
            for issue in issues:
                if "ì›¹ì‚¬ì´íŠ¸" in issue:
                    # ëŒ€ì²´ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ë„¤ì´ë²„, ë‹¤ìŒ ë“±)
                    alt_search = self.search_alternative_web_presence(company_name)
                    if alt_search:
                        enhanced_results.append(f"ğŸŒ ì›¹ ì¡´ì¬ê°: {alt_search}")
                        search_strategies.append("ëŒ€ì²´ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰")
                
                elif "ì‚¬ì—…ìë²ˆí˜¸" in issue:
                    # ìœ ì‚¬ íšŒì‚¬ëª…ìœ¼ë¡œ ì¬ê²€ìƒ‰
                    similar_search = self.search_similar_company_names(company_name)
                    if similar_search:
                        enhanced_results.append(f"ğŸ” ìœ ì‚¬ëª… ê²€ìƒ‰: {similar_search}")
                        search_strategies.append("ìœ ì‚¬ëª… ê²€ìƒ‰")
            
            # 3. ì¢…í•© ê²°ê³¼ êµ¬ì„±
            if enhanced_results:
                content = "\n".join(enhanced_results)
                strategies_used = ", ".join(search_strategies)
                
                logger.info(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì™„ë£Œ: {len(enhanced_results)}ê°œ ê²°ê³¼, ì „ëµ: {strategies_used}")
                
                return {
                    'success': True,
                    'content': content,
                    'strategies_used': strategies_used,
                    'results_count': len(enhanced_results),
                    'timestamp': datetime.now().isoformat()
                }
            else:
                logger.warning(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            logger.error(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def search_by_business_number(self, company_name, business_number):
        """ì‚¬ì—…ìë²ˆí˜¸ ê¸°ë°˜ ê³µì‹ ì •ë³´ ê²€ìƒ‰"""
        try:
            # ì‹¤ì œë¡œëŠ” ê³µê³µë°ì´í„° APIë‚˜ ì‚¬ì—…ìì •ë³´ ì¡°íšŒ ì„œë¹„ìŠ¤ í™œìš©
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
            if business_number and len(business_number.replace('-', '')) == 10:
                return f"{company_name}({business_number})ì˜ ì‚¬ì—…ì ë“±ë¡ ì •ë³´ í™•ì¸ë¨"
            return None
        except Exception as e:
            logger.debug(f"ì‚¬ì—…ìë²ˆí˜¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def get_enhanced_industry_context(self, company_name, industry):
        """ì—…ì¢… ê¸°ë°˜ ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸ ì œê³µ"""
        try:
            industry_insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name}ëŠ” ì˜¨ë¼ì¸ ì»¤ë¨¸ìŠ¤ ìƒíƒœê³„ì—ì„œ ê²°ì œ/ì •ì‚° ë³µì¡ì„±ì´ ì£¼ìš” ê³¼ì œ",
                'í•€í…Œí¬': f"{company_name}ëŠ” ê¸ˆìœµ ì„œë¹„ìŠ¤ë¡œì„œ ê²°ì œ ì¸í”„ë¼ì˜ ì•ˆì •ì„±ê³¼ ê·œì œ ì¤€ìˆ˜ê°€ í•µì‹¬",
                'ì œì¡°ì—…': f"{company_name}ëŠ” B2B ê±°ë˜ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ëŸ‰ ê²°ì œì™€ ê³µê¸‰ë§ ì •ì‚° ê´€ë¦¬ê°€ ì¤‘ìš”",
                'SaaS': f"{company_name}ëŠ” êµ¬ë… ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ë¡œ ì •ê¸°ê²°ì œì™€ ê¸€ë¡œë²Œ í™•ì¥ì´ ì£¼ìš” ê´€ì‹¬ì‚¬",
                'ITì„œë¹„ìŠ¤': f"{company_name}ëŠ” ê¸°ìˆ  ê¸°ì—…ìœ¼ë¡œì„œ ê°œë°œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±ê³¼ ì‹œìŠ¤í…œ í†µí•©ì´ ìš°ì„ ìˆœìœ„",
                'ê²Œì„': f"{company_name}ëŠ” ëª¨ë°”ì¼ê²Œì„ ì—…ê³„ë¡œì„œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ì„ ì›¹ìƒì  ê°œì„¤ë¡œ 90% ì ˆì•½í•˜ëŠ” ê²ƒì´ í•µì‹¬ ê³¼ì œ",
                'ëª¨ë°”ì¼ê²Œì„': f"{company_name}ëŠ” ì›¹ìƒì  êµ¬ì¶•ì„ í†µí•œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 90% ì ˆì•½ê³¼ ê²°ì œ ì „í™˜ìœ¨ ìµœì í™”ê°€ ì£¼ìš” ê´€ì‹¬ì‚¬",
                'ì•±ê²Œì„': f"{company_name}ëŠ” ì›¹ìƒì  ê°œì„¤ì˜ ê¸°ìˆ ì  í—ˆë“¤ì„ ê·¹ë³µí•˜ì—¬ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆê°í•˜ëŠ” ê²ƒì´ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì˜ í•µì‹¬"
            }
            
            return industry_insights.get(industry, f"{company_name}ì˜ {industry} ì—…ì¢… íŠ¹ì„±ìƒ ê²°ì œ íš¨ìœ¨í™”ê°€ ì¤‘ìš”í•œ ê³¼ì œ")
            
        except Exception as e:
            logger.debug(f"ì—…ì¢… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def search_by_sales_focus(self, company_name, sales_point):
        """ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ê¸°ë°˜ íŠ¹í™” ê²€ìƒ‰"""
        try:
            # ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•´ì„œ PortOne ì†”ë£¨ì…˜ê³¼ì˜ ì—°ê²°ì  ì°¾ê¸°
            focus_insights = {}
            
            if any(keyword in sales_point.lower() for keyword in ['ê²°ì œ', 'payment', 'ì •ì‚°']):
                return f"{company_name}ì˜ '{sales_point}' ê°•ì ì„ PortOne ê²°ì œ ì¸í”„ë¼ë¡œ ë”ìš± ê°•í™” ê°€ëŠ¥"
            
            elif any(keyword in sales_point.lower() for keyword in ['íš¨ìœ¨', 'efficiency', 'ìë™í™”']):
                return f"{company_name}ì˜ '{sales_point}' ê²½í—˜ì´ PortOne ì¬ë¬´ìë™í™”ì™€ ì‹œë„ˆì§€ ì°½ì¶œ ê°€ëŠ¥"
            
            elif any(keyword in sales_point.lower() for keyword in ['ê¸€ë¡œë²Œ', 'global', 'í™•ì¥']):
                return f"{company_name}ì˜ '{sales_point}' ë¹„ì „ì„ PortOne ê¸€ë¡œë²Œ ê²°ì œë¡œ ì‹¤í˜„ ì§€ì› ê°€ëŠ¥"
            
            else:
                return f"{company_name}ì˜ '{sales_point}' ê°•ì ì„ ê²°ì œ ì¸í”„ë¼ í˜ì‹ ìœ¼ë¡œ ë”ìš± ë°œì „ì‹œí‚¬ ê¸°íšŒ"
                
        except Exception as e:
            logger.debug(f"ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def get_size_based_insights(self, company_name, company_size):
        """íšŒì‚¬ ê·œëª¨ ê¸°ë°˜ ë§ì¶¤ ì¸ì‚¬ì´íŠ¸"""
        try:
            size_strategies = {
                'ìŠ¤íƒ€íŠ¸ì—…': f"{company_name}ëŠ” ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œì„œ ë¹ ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì´ í•µì‹¬",
                'ì¤‘ê²¬ê¸°ì—…': f"{company_name}ëŠ” ì¤‘ê²¬ê¸°ì—…ìœ¼ë¡œì„œ í™•ì¥ì„± ìˆëŠ” ê²°ì œ ì¸í”„ë¼ì™€ ìš´ì˜ ìë™í™”ê°€ í•„ìš”",
                'ëŒ€ê¸°ì—…': f"{company_name}ëŠ” ëŒ€ê¸°ì—…ìœ¼ë¡œì„œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê²°ì œ ì†”ë£¨ì…˜ê³¼ ê³ ë„í™”ëœ ë¶„ì„ì´ ìš”êµ¬ë¨",
                'ì¤‘ì†Œê¸°ì—…': f"{company_name}ëŠ” ì¤‘ì†Œê¸°ì—…ìœ¼ë¡œì„œ ê°„í¸í•œ ê²°ì œ í†µí•©ê³¼ ê´€ë¦¬ íš¨ìœ¨ì„± í–¥ìƒì´ ìš°ì„ "
            }
            
            return size_strategies.get(company_size, f"{company_name}ì˜ {company_size} ê·œëª¨ì— ë§ëŠ” ê²°ì œ ì†”ë£¨ì…˜ í•„ìš”")
            
        except Exception as e:
            logger.debug(f"ê·œëª¨ë³„ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def search_alternative_web_presence(self, company_name):
        """ëŒ€ì²´ ì›¹ ì¡´ì¬ê° ê²€ìƒ‰ (ë„¤ì´ë²„, ë¸”ë¡œê·¸ ë“±)"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ API, ë‹¤ìŒ ê²€ìƒ‰ ë“± í™œìš©
            return f"{company_name}ì˜ ì˜¨ë¼ì¸ í™œë™ ë° ì†Œì…œë¯¸ë””ì–´ ì¡´ì¬ê° í™•ì¸ë¨"
        except Exception as e:
            logger.debug(f"ëŒ€ì²´ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def search_similar_company_names(self, company_name):
        """ìœ ì‚¬ íšŒì‚¬ëª… ê²€ìƒ‰"""
        try:
            # ì‹¤ì œë¡œëŠ” ê¸°ì—…ëª… ìœ ì‚¬ë„ ê²€ìƒ‰ì´ë‚˜ ë™ìŒì´ì˜ì–´ ê²€ìƒ‰ ìˆ˜í–‰
            return f"{company_name}ì™€ ìœ ì‚¬í•œ ëª…ì¹­ì˜ ê¸°ì—…ë“¤ê³¼ êµ¬ë³„ë˜ëŠ” ê³ ìœ í•œ íŠ¹ì„± í™•ì¸ í•„ìš”"
        except Exception as e:
            logger.debug(f"ìœ ì‚¬ëª… ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def get_industry_trends(self, industry):
        """ì—…ì¢…ë³„ ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ ìˆ˜ì§‘"""
        
        trend_query = f"""
        {industry} ì—…ê³„ì˜ ìµœì‹  íŠ¸ë Œë“œì™€ ê²°ì œ ì‹œìŠ¤í…œ ê´€ë ¨ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”:
        1. ì—…ê³„ ì „ë°˜ì˜ ë””ì§€í„¸ ì „í™˜ í˜„í™©
        2. ê²°ì œ ì‹œìŠ¤í…œ ë° í•€í…Œí¬ ë„ì… íŠ¸ë Œë“œ
        3. ì£¼ìš” í˜ì¸ í¬ì¸íŠ¸ì™€ í•´ê²° ë°©ì•ˆ
        4. ê²½ìŸì‚¬ë“¤ì˜ ê¸°ìˆ  ë„ì… ì‚¬ë¡€
        
        ìµœê·¼ 6ê°œì›” ì´ë‚´ì˜ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        data = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "user", 
                    "content": trend_query
                }
            ],
            "max_tokens": 800,
            "temperature": 0.3
        }
        
        try:
            response = requests.post(
                self.perplexity_url, 
                json=data, 
                headers=self.headers,
                timeout=30
            )
            
            logger.info(f"Perplexity API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code != 200:
                logger.error(f"Perplexity API ì˜¤ë¥˜ ì‘ë‹µ: {response.text}")
                # API ì˜¤ë¥˜ ì‹œ ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ ë°˜í™˜
                return {
                    'success': True,
                    'trends': "ê²°ì œ ì¸í”„ë¼ í†µí•© ë° ë””ì§€í„¸ ì „í™˜ì´ ì£¼ìš” íŠ¸ë Œë“œ",
                    'timestamp': datetime.now().isoformat(),
                    'note': 'API ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
                }
            
            result = response.json()
            
            return {
                'success': True,
                'trends': result['choices'][0]['message']['content'],
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Perplexity API ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
            return {
                'success': True,
                'trends': "ë””ì§€í„¸ ì „í™˜ ë° í†µí•© ê²°ì œ ì†”ë£¨ì…˜ ë„ì… ì¦ê°€",
                'timestamp': datetime.now().isoformat(),
                'note': f'API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ: {str(e)}'
            }



class EmailCopywriter:
    """Claude Opus 4.1ì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ë©”ì¼ ë¬¸ì•ˆ ìƒì„±"""
    
    def __init__(self):
        self.claude_client = ClaudeBedrockClient()
    
    def generate_email_variations(self, company_data, research_data, industry_trends=None):
        """Zendesk ëª¨ë²” ì‚¬ë¡€ë¥¼ ë°˜ì˜í•œ ê³ í’ˆì§ˆ ê°œì¸í™” ë©”ì¼ ë¬¸ì•ˆ ìƒì„± (ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ë³„ ë™ì  ìƒì„±)"""
        
        logger.info("=" * 60)
        logger.info("ğŸ“§ ì´ë©”ì¼ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        logger.info("=" * 60)
        
        # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data) or 'ê·€í•˜ì˜ íšŒì‚¬'
        ceo_name = get_contact_name(company_data) or 'ë‹´ë‹¹ìë‹˜'
        contact_position = get_contact_position(company_data)
        website = get_homepage(company_data)
        sales_point = get_sales_point(company_data).lower().strip()
        
        logger.info(f"ğŸ¢ íšŒì‚¬ ì •ë³´:")
        logger.info(f"   - íšŒì‚¬ëª…: {company_name}")
        logger.info(f"   - ëŒ€í‘œìëª…: {ceo_name}")
        logger.info(f"   - í™ˆí˜ì´ì§€: {website}")
        logger.info(f"   - ì„¸ì¼ì¦ˆí¬ì¸íŠ¸: {sales_point}")
        
        logger.debug(f"ğŸ“‹ ì „ì²´ company_data: {company_data}")
        logger.debug(f"ğŸ“‹ ì „ì²´ research_data: {research_data}")

        # ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ
        personalization_elements = self._extract_personalization_elements(company_data, research_data)
        
        # ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (RAG ë°©ì‹)
        from portone_blog_cache import get_relevant_blog_posts_by_industry, format_relevant_blog_for_email, load_blog_cache, get_best_blog_for_email_mention, format_blog_mention_for_email
        
        blog_content_opi = ""
        blog_content_recon = ""
        
        # ë¸”ë¡œê·¸ ìºì‹œ í™•ì¸ ë° í•„ìš” ì‹œ ìŠ¤í¬ë˜í•‘
        cached_posts = load_blog_cache()
        if not cached_posts:
            logger.info("ğŸ“° ë¸”ë¡œê·¸ ìºì‹œ ì—†ìŒ - ìë™ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
            try:
                blog_posts = scrape_portone_blog_initial()
                if blog_posts:
                    logger.info(f"âœ… ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(blog_posts)}ê°œ")
                    cached_posts = blog_posts
                else:
                    logger.warning("âš ï¸ ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì—†ìŒ")
            except Exception as blog_error:
                logger.error(f"âŒ ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(blog_error)}")
        
        # íšŒì‚¬ ì •ë³´ êµ¬ì¡°í™” (ì—…ì¢…ë³„ ë¸”ë¡œê·¸ í•„í„°ë§ìš©)
        company_info_for_blog = {
            'industry': research_data.get('industry', ''),
            'category': research_data.get('category', ''),
            'description': research_data.get('company_info', '')
        }
        
        # Pain Point í‚¤ì›Œë“œ ì¶”ì¶œ (Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ)
        pain_point_keywords = []
        company_info_text = research_data.get('company_info', '').lower()
        
        # Pain Point ê´€ë ¨ í‚¤ì›Œë“œ ë§¤ì¹­
        pain_point_mapping = {
            'êµ¬ë…': ['êµ¬ë…', 'subscription', 'ì •ê¸°ê²°ì œ', 'ë¹Œë§'],
            'PGê´€ë¦¬': ['pg', 'ì—¬ëŸ¬', 'ë³µìˆ˜', 'ë‹¤ìˆ˜', 'ê´€ë¦¬', 'ì—°ë™'],
            'ì •ì‚°': ['ì •ì‚°', 'ëŒ€ì‚¬', 'ë§ˆê°', 'íšŒê³„', 'ì¬ë¬´'],
            'í•´ì™¸': ['í•´ì™¸', 'ê¸€ë¡œë²Œ', 'global', 'ìˆ˜ì¶œ', 'ì§„ì¶œ'],
            'ì „í™˜ìœ¨': ['ì „í™˜ìœ¨', 'ì´íƒˆ', 'ì„±ê³µë¥ ', 'conversion'],
            'ìˆ˜ìˆ˜ë£Œ': ['ìˆ˜ìˆ˜ë£Œ', 'ë¹„ìš©', 'fee', 'ì ˆê°'],
            'í”Œë«í¼': ['í”Œë«í¼', 'ë§ˆì¼“í”Œë ˆì´ìŠ¤', 'ì¤‘ê°œ', 'íŒŒíŠ¸ë„ˆ'],
            'ì¸ì•±': ['ì¸ì•±', 'in-app', 'ì•±ìŠ¤í† ì–´', 'êµ¬ê¸€í”Œë ˆì´']
        }
        
        for pain_point, keywords in pain_point_mapping.items():
            if any(keyword in company_info_text for keyword in keywords):
                pain_point_keywords.append(pain_point)
        
        if pain_point_keywords:
            logger.info(f"ğŸ¯ {company_name} Pain Point ê°ì§€: {', '.join(pain_point_keywords)}")
        
        # OPI ê´€ë ¨ ë¸”ë¡œê·¸ (Pain Point + ì—…ì¢… í•„í„°ë§)
        if cached_posts and (sales_point in ['opi', ''] or 'opi' in sales_point):
            opi_blogs = get_relevant_blog_posts_by_industry(
                company_info_for_blog,
                max_posts=3,
                service_type='OPI',
                pain_points=pain_point_keywords if pain_point_keywords else None
            )
            if opi_blogs:
                blog_content_opi = format_relevant_blog_for_email(opi_blogs, company_name, 'OPI')
                logger.info(f"ğŸ“° [OPI] {company_name}: Pain Point ë§¤ì¹­ ë¸”ë¡œê·¸ {len(opi_blogs)}ê°œ ì¡°íšŒ")
        
        # Recon ê´€ë ¨ ë¸”ë¡œê·¸ (Pain Point + ì—…ì¢… í•„í„°ë§)
        if cached_posts and (sales_point in ['recon', ''] or 'recon' in sales_point):
            recon_blogs = get_relevant_blog_posts_by_industry(
                company_info_for_blog,
                max_posts=3,
                service_type='Recon',
                pain_points=pain_point_keywords if pain_point_keywords else None
            )
            if recon_blogs:
                blog_content_recon = format_relevant_blog_for_email(recon_blogs, company_name, 'Recon')
                logger.info(f"ğŸ“° [Recon] {company_name}: Pain Point ë§¤ì¹­ ë¸”ë¡œê·¸ {len(recon_blogs)}ê°œ ì¡°íšŒ")
        
        # ğŸ†• ì´ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰í•  ìµœì ì˜ ë¸”ë¡œê·¸ 1ê°œ ì„ íƒ
        blog_mention_info = None
        blog_mention_instruction = ""
        try:
            blog_mention_info = get_best_blog_for_email_mention(company_info_for_blog, research_data)
            if blog_mention_info:
                blog_title = blog_mention_info.get('title', '')
                blog_link = blog_mention_info.get('link', '')
                blog_reason = blog_mention_info.get('match_reason', '')
                industry_matched = blog_mention_info.get('industry_matched', False)
                
                # ì—…ì¢… ë§¤ì¹­ì´ ëœ ê²½ìš°ì—ë§Œ ë¸”ë¡œê·¸ ì–¸ê¸‰ (ë” ì—„ê²©í•œ ê¸°ì¤€)
                if industry_matched or blog_reason:
                    blog_mention_instruction = f"""
**ğŸ“Œ ê´€ë ¨ ë¸”ë¡œê·¸ ì–¸ê¸‰ ì§€ì¹¨ (í•„ìˆ˜!):**
íƒ€ê²Ÿ íšŒì‚¬ì™€ ê´€ë ¨ì„± ë†’ì€ ë¸”ë¡œê·¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë©”ì¼ ë³¸ë¬¸ì— ì•„ë˜ ë¸”ë¡œê·¸ë¥¼ **ë°˜ë“œì‹œ** ì–¸ê¸‰í•´ì£¼ì„¸ìš”.

ğŸ”— **ë¸”ë¡œê·¸ ì •ë³´:**
- ì œëª©: {blog_title}
- ë§í¬: {blog_link}
- ì—°ê´€ì„±: {blog_reason}

ğŸ“ **ì–¸ê¸‰ ë°©ì‹ (ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©):**
ë³¸ë¬¸ ì¤‘ê°„ ë˜ëŠ” ëë¶€ë¶„ì— ë‹¤ìŒê³¼ ê°™ì´ ì‚½ì…í•˜ì„¸ìš”:

"ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ í•˜ì…¨ë˜ ê³ ê°ì‚¬ì˜ ì‚¬ë¡€ê°€ ìˆëŠ”ë°ìš”, ì•„ë˜ ê¸€ì—ì„œ ìì„¸íˆ í™•ì¸í•´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ğŸ‘‰ {blog_title}
{blog_link}"

âš ï¸ **ì¤‘ìš”:**
- ë§í¬ URL({blog_link})ì„ ë°˜ë“œì‹œ ë³„ë„ ì¤„ì— ê·¸ëŒ€ë¡œ í¬í•¨í•˜ì„¸ìš”
- ë°›ëŠ” ì‚¬ëŒì´ ë§í¬ë¥¼ í´ë¦­í•´ì„œ ë¸”ë¡œê·¸ì— ì ‘ì†í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- "3,000ì—¬ê°œ ê³ ê°ì‚¬" ë¬¸êµ¬ ëŒ€ì‹  ì´ ë¸”ë¡œê·¸ ì–¸ê¸‰ì„ ì‚¬ìš©í•˜ì„¸ìš”
"""
                    logger.info(f"ğŸ“ {company_name}: ë¸”ë¡œê·¸ ì–¸ê¸‰ ì˜ˆì • - {blog_title[:30]}... (ì—…ì¢…ë§¤ì¹­: {industry_matched})")
        except Exception as blog_mention_error:
            logger.warning(f"ë¸”ë¡œê·¸ ì–¸ê¸‰ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(blog_mention_error)}")
        
        # ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ì— ë”°ë¼ ìƒì„±í•  ì´ë©”ì¼ ìœ í˜• ê²°ì •
        email_definitions = {
            "opi_professional": {
                "product": "One Payment Infra", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 8
            },
            "opi_curiosity": {
                "product": "One Payment Infra", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            },
            "finance_professional": {
                "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 8
            },
            "finance_curiosity": {
                "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            },
            "game_d2c_professional": {
                "product": "ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 9
            },
            "game_d2c_curiosity": {
                "product": "ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            }
        }
        
        requested_emails = {}
        if sales_point == 'opi':
            requested_emails = {k: v for k, v in email_definitions.items() if 'opi' in k}
        elif sales_point == 'recon':
            requested_emails = {k: v for k, v in email_definitions.items() if 'finance' in k}
        elif sales_point == 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°':
            requested_emails = {k: v for k, v in email_definitions.items() if 'game_d2c' in k}
        else: # 'opi + recon' ë˜ëŠ” ë¹ˆì¹¸ì¼ ê²½ìš°
            requested_emails = {k: v for k, v in email_definitions.items() if 'opi' in k or 'finance' in k}

        # ë™ì ìœ¼ë¡œ JSON ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±
        json_request_prompt = json.dumps(requested_emails, ensure_ascii=False, indent=2)
        
        # Geminiì—ê²Œ ì „ë‹¬í•  ìƒì„¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ë¡œ, ì‹¤ì œ ê²€ì¦ëœ í•œêµ­ì–´ ì˜ì—… ì´ë©”ì¼ íŒ¨í„´ì„ ì™„ë²½íˆ ìˆ™ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
- íšŒì‚¬ëª…: {company_name}
- ëŒ€í‘œì/ë‹´ë‹¹ì: {ceo_name}

**Perplexity ì¡°ì‚¬ ê²°ê³¼ (ìµœì‹  ê¸°ì‚¬/í™œë™/íŠ¸ë Œë“œ):**
{research_data.get('company_info', 'í•´ë‹¹ íšŒì‚¬ëŠ” ì„±ì¥í•˜ëŠ” ê¸°ì—…ìœ¼ë¡œ ë””ì§€í„¸ í˜ì‹ ê³¼ íš¨ìœ¨ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ì— ê´€ì‹¬ì´ ë†’ìŠµë‹ˆë‹¤.')}

**íšŒì‚¬ë³„ ë§ì¶¤ Pain Points:**
{research_data.get('pain_points', 'ì¼ë°˜ì ì¸ Pain Point')}

**ê°œì¸í™” ìš”ì†Œ:**
{personalization_elements}

{blog_content_opi}

{blog_content_recon}

{blog_mention_instruction}

**ê²€ì¦ëœ ì„±ê³¼ ì¢‹ì€ í•œêµ­ì–´ ì´ë©”ì¼ í…œí”Œë¦¿ ì°¸ê³ ìš© (ìŠ¤íƒ€ì¼ê³¼ í†¤ ì°¸ê³ ):**

**ì°¸ê³  í…œí”Œë¦¿ 1: ì§ì ‘ì  Pain Point ì ‘ê·¼**
"ì•ˆë…•í•˜ì„¸ìš”, íšŒì‚¬ëª… ë‹´ë‹¹ìë‹˜. ì½”ë¦¬ì•„í¬íŠ¸ì› ì˜¤ì¤€í˜¸ì…ë‹ˆë‹¤.
í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PGì‚¬ì˜ ë†’ì€ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´, ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìˆ˜ìˆ˜ë£Œ ì¸ìƒ,
ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ë³„ ìµœì  PG ì„ íƒì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?
ì €í¬ í¬íŠ¸ì›ì€ ë‹¨ í•˜ë‚˜ì˜ ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´ ë¹„êµ ë¶„ì„, ìµœì  PGì‚¬ ê²¬ì  ì œì•ˆ,
ê·¸ë¦¬ê³  ê¸€ë¡œë²Œ í™•ì¥ì„±ê¹Œì§€ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 2: ê¸°ìˆ  ë‹´ë‹¹ì ëŒ€ìƒ**
"í˜¹ì‹œ ì´ì‚¬ë‹˜ê»˜ì„œë„ ë‹¨ì¼ PGì‚¬ ì¢…ì†ìœ¼ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ê´€ë¦¬,
ì—¬ëŸ¬ PGì‚¬ ì—°ë™ ì‹œ ë°œìƒí•˜ëŠ” ê°œë°œ/ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ì— ëŒ€í•œ ê³ ë¯¼ì„ í•˜ê³ ê³„ì‹ ê°€ìš”?
í¬íŠ¸ì›ì€ ë‹¨ í•œ ë²ˆì˜ API ì—°ë™ìœ¼ë¡œ 50ê°œ ì´ìƒì˜ PGì‚¬ë¥¼ í†µí•©í•˜ê³ ,
ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 3: ì±„ìš© ì»¨í…ìŠ¤íŠ¸ í™œìš©**
"ìµœê·¼ 'ì¬ë¬´/íšŒê³„ ë‹´ë‹¹ì' ì±„ìš©ì„ ì§„í–‰í•˜ì‹œëŠ” ê²ƒì„ ë³´ê³  ì—°ë½ë“œë ¸ìŠµë‹ˆë‹¤.
ë§Œì•½ ìƒˆë¡œ í•©ë¥˜í•œ ìœ ëŠ¥í•œ ì¸ì¬ê°€, ê°€ì¥ ë¨¼ì € ë§ˆì£¼í•  ì—…ë¬´ê°€ ì—¬ëŸ¬ PGì‚¬ ì‚¬ì´íŠ¸ë¥¼ ì˜¤ê°€ë©°
ì—‘ì…€ë¡œ ì •ì‚° ë‚´ì—­ì„ ë§ì¶”ëŠ” ë‹¨ìˆœ ë°˜ë³µì ì¸ ìˆ˜ì‘ì—…ì´ë¼ë©´ ì–´ë–¨ê¹Œìš”?
ì €í¬ í¬íŠ¸ì›ì€ ì´ëŸ¬í•œ ë¶ˆí•„ìš”í•œ ìˆ˜ì‘ì—…ì„ ì•½ 90% ì´ìƒ ìë™í™”í•˜ì—¬,
ê·€í•œ ì¸ì¬ê°€ íšŒì‚¬ì˜ ì„±ì¥ì— ê¸°ì—¬í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ì¬ë¬´ ì „ëµ ì—…ë¬´ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë•ìŠµë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê·œëª¨ì˜ ê³ ê°ì‚¬ë“¤ì´ ê¸°ì¡´ ëŒ€ë¹„ í‰ê·  15-30% ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 4: ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ ì´ìŠˆ**
"ë§¤ì¶œì´ 10ì–µ, 30ì–µì„ ë„˜ì–´ì„œë©° ì„±ì¥í• ìˆ˜ë¡, PGì‚¬ì˜ 'ì˜ì¤‘ì†Œ êµ¬ê°„' ë³€ê²½ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ ë” ë‚´ê³  ê³„ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
í¬íŠ¸ì›ì€ êµ­ë‚´ 25ê°œ ì´ìƒ PGì‚¬ì™€ì˜ ì œíœ´ë¥¼ í†µí•´, íšŒì‚¬ëª…ì´ í˜„ì¬ë³´ë‹¤ ë” ë‚®ì€ ìˆ˜ìˆ˜ë£Œë¥¼ ì ìš©ë°›ì„ ìˆ˜ ìˆë„ë¡ ë¹ ë¥´ê²Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê·œëª¨ì˜ ê³ ê°ì‚¬ë“¤ì´ ê¸°ì¡´ ëŒ€ë¹„ í‰ê·  15-30% ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 5: ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™”**
"í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìš´ì˜í•˜ê³  ê³„ì‹œëŠ”ë°
ë„¤ì´ë²„í˜ì´, ì¿ íŒ¡ ë“± ì˜¤í”ˆë§ˆì¼“ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ë§¤ì¶œê³¼ ì‹¤ì œ ì…ê¸ˆì•¡ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ”
'ì •ì‚°' ì—…ë¬´ì— ìƒê°ë³´ë‹¤ ë§ì€ ì‹œê°„ì„ ìŸê³  ìˆì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”?
ì €í¬ PortOneì˜ ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì€ ì—¬ëŸ¬ ì±„ë„ì˜ ì •ì‚° ë‚´ì—­ì„ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ëŒ€ì‚¬í•˜ì—¬,
ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì‹¤ìˆ˜ë¥¼ ì›ì²œì ìœ¼ë¡œ ë§‰ê³  ìˆ¨ì–´ìˆë˜ ë¹„ìš©ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 6: ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™”**
"í˜¹ì‹œ ì• í”Œ ì•±ìŠ¤í† ì–´ì™€ êµ¬ê¸€ í”Œë ˆì´ìŠ¤í† ì–´ì˜ 30% ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì‹œì§€ ì•Šë‚˜ìš”?
ìµœê·¼ Com2uS, Neptune, Ntrance ë“± êµ­ë‚´ ì£¼ìš” ê²Œì„ì‚¬ë“¤ë„ D2C ì›¹ìƒì ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì„ ëŒ€í­ ì¤„ì´ê³  ê³„ì‹œëŠ”ë°,
ë§‰ìƒ ì§ì ‘ êµ¬ì¶•í•˜ë ¤ë‹¤ ë³´ë‹ˆ êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™, ì •ì‚° ê´€ë¦¬, ìˆ˜ìˆ˜ë£Œ ìµœì í™” ë“±ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
ì €í¬ PortOneì€ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ë¥¼ í†µí•©í•˜ì—¬, ìµœì ì˜ ë¹„ìš©ìœ¼ë¡œ ì›¹ìƒì  ê²°ì œë¥¼ ìš´ì˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ ê°€ì§„ ë‹¤ë¥¸ ê²Œì„ì‚¬ ê³ ê°ë‹˜ë“¤ë„ ê¸°ì¡´ ëŒ€ë¹„ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆì•½í•˜ë©°,
PGì‚¬ë³„ ì •ì‚° ê´€ë¦¬ ì—…ë¬´ë„ ì½˜ì†”ì—ì„œ í†µí•© ê´€ë¦¬í•˜ì—¬ ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ:**
1. YouTube ì˜ìƒ ë§í¬: "https://www.youtube.com/watch?v=2EjzX6uTlKc" (ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ)
2. "1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
3. êµ¬ì²´ì  CTA: "ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."

**One Payment Infraë¡œ í•´ê²° ê°€ëŠ¥í•œ Pain Points:**
- ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 6ê°œì›”+ ì†Œìš”ë˜ëŠ” ë¬¸ì œ â†’ 2ì£¼ ë‚´ êµ¬ì¶•
- ì—¬ëŸ¬ PGì‚¬ ê´€ë¦¬ì˜ ë³µì¡ì„± â†’ 50+ PGì‚¬ í†µí•© ê´€ë¦¬
- ê²°ì œ ì‹¤íŒ¨ë¡œ ì¸í•œ ë§¤ì¶œ ì†ì‹¤ â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ 15% ì„±ê³µë¥  í–¥ìƒ
- ë†’ì€ ê°œë°œ ë¹„ìš© ë¶€ë‹´ â†’ 85% ë¦¬ì†ŒìŠ¤ ì ˆê° + 100ë§Œì› ë¬´ë£Œ ì»¨ì„¤íŒ…
- ê²°ì œ ì¥ì•  ëŒ€ì‘ì˜ ì–´ë ¤ì›€ â†’ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° 24/7 ì§€ì›
- ì •ê¸°ê²°ì œ, ë³¸ì¸ì¸ì¦ ë“± ì¶”ê°€ ê°œë°œ â†’ ì›ìŠ¤í†± ì„œë¹„ìŠ¤ ì œê³µ

**ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•œ Pain Points:**
- ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ìˆ˜ì‘ì—… ì—‘ì…€ ì‘ì—… â†’ 90% ì´ìƒ ìë™í™”
- ë„¤ì´ë²„/ì¹´ì¹´ì˜¤/ì¹´í˜24 ë“± ì±„ë„ë³„ ë°ì´í„° ë¶ˆì¼ì¹˜ â†’ í†µí•© ê´€ë¦¬
- êµ¬ë§¤í™•ì •-ì •ì‚°ë‚´ì—­ ë§¤í•‘ ì˜¤ë¥˜ â†’ ë†’ì€ ì •í™•ë„ì˜ ìë™ ë§¤í•‘
- ë¶€ê°€ì„¸ ì‹ ê³  ìë£Œ ì¤€ë¹„ì˜ ë³µì¡ì„± â†’ ìë™í™”ëœ ì„¸ë¬´ ìë£Œ ìƒì„±
- ë°ì´í„° ëˆ„ë½ìœ¼ë¡œ ì¸í•œ ì†ì‹¤ â†’ ë†’ì€ ë°ì´í„° ì •í•©ì„± ë³´ì¥
- ë¶€ì •í™•í•œ ì†ìµ ë¶„ì„ â†’ ì‹¤ì‹œê°„ ì •í™•í•œ ì¬ë¬´ ë°ì´í„° ì œê³µ
- ì±„ê¶Œ/ë¯¸ìˆ˜ê¸ˆ ê´€ë¦¬ì˜ ì–´ë ¤ì›€ â†’ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ ì œê³µ

**ê²Œì„ì—…ê³„ íŠ¹í™” ì†”ë£¨ì…˜ (ëª¨ë°”ì¼ê²Œì„/ì•±ê²Œì„ ëŒ€ìƒ):**
- ì•±ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ â†’ D2C ì›¹ìƒì ìœ¼ë¡œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 90% ì ˆì•½
- êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™ ë³µì¡ì„± â†’ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ ëª¨ë“  PGì‚¬ í†µí•©
- PGì‚¬ë³„ ìˆ˜ìˆ˜ë£Œ ìµœì í™” ì–´ë ¤ì›€ â†’ ì½˜ì†”ì—ì„œ ì‹¤ì‹œê°„ PGì‚¬ ë³€ê²½ ë° ê²°ì œ ë¹„ìœ¨ ì„¤ì •
- ë³µì¡í•œ ì •ì‚° ê´€ë¦¬ ì—…ë¬´ â†’ ëª¨ë“  PGì‚¬ ì •ì‚°ë‚´ì—­ì„ í†µì¼ëœ í˜•íƒœë¡œ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
- ì›¹ìƒì  êµ¬ì¶•ì˜ ê¸°ìˆ ì  í—ˆë“¤ â†’ PortOne D2C ì›¹ìƒì  ê²°ì œ ì†”ë£¨ì…˜ìœ¼ë¡œ ê°„í¸ êµ¬ì¶•
- í•´ì™¸ ì§„ì¶œ ì‹œ ê¸€ë¡œë²Œ ê²°ì œ ëŒ€ì‘ â†’ ë©€í‹° MoR ì „ëµ ë° í¬ë¦½í†  ê²°ì œ(1.7% ìˆ˜ìˆ˜ë£Œ) ì§€ì›
- MoR ìš´ì˜ ë¹„ìš© ë¶€ë‹´ â†’ ë¹„ MoR ê²°ì œì‚¬ ìš´ì˜ìœ¼ë¡œ 50% ë¹„ìš© ì ˆê°
- ì°¨ì§€ë°± ë¦¬ìŠ¤í¬ â†’ í¬ë¦½í†  ê²°ì œë¡œ No Chargeback + D+1 ì •ì‚°

**CRITICAL: ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  íŒ¨í„´:**
- 'ê·€ì‚¬', 'ë‹¹ì‚¬' ê°™ì€ ëŒ€ëª…ì‚¬ ëŒ€ì‹  ë°˜ë“œì‹œ '{company_name}' íšŒì‚¬ëª…ì„ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
- ë¬¸ë‹¨ êµ¬ë¶„ì„ ìœ„í•´ ì ì ˆí•œ ì¤„ë°”ê¿ˆ ì‚¬ìš© - ë¬¸ë‹¨ë‹¹ 2-3ë¬¸ì¥ìœ¼ë¡œ ì œí•œí•˜ê³  ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ê¸ˆì§€
- ìƒí™©ë³„ ë§ì¶¤ ì ‘ê·¼ë²• ì‚¬ìš© (ìœ„ í…œí”Œë¦¿ë“¤ ì°¸ê³ )
- YouTube ì˜ìƒ ë§í¬ í•„ìˆ˜ í¬í•¨
- "ë‹¤ìŒ ì£¼ ì¤‘" ì¼ì • ìš”ì²­ìœ¼ë¡œ CTA ë§ˆë¬´ë¦¬
- êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í˜œíƒ ì–¸ê¸‰ (85% ì ˆê°, 90% ìë™í™” ë“±)
- **ì •ëŸ‰ì  ìˆ˜ì¹˜ì™€ í•µì‹¬ ê°€ì¹˜ ì œì•ˆì€ ë°˜ë“œì‹œ ë³¼ë“œ ì²˜ë¦¬í•˜ì„¸ìš” (ì˜ˆ: **85% ë¦¬ì†ŒìŠ¤ ì ˆê°**, **2ì£¼ ë‚´ êµ¬ì¶•**, **90% ìë™í™”**, **15% í–¥ìƒ** ë“±)**
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì²´ ìœ ì§€
- **âš ï¸ ì„œë¹„ìŠ¤ ì•½ì–´ ì‚¬ìš© ê¸ˆì§€**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'OPI', 'Recon', 'PS' ê°™ì€ ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'í†µí•© ê²°ì œ ì¸í”„ë¼', 'ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜', 'í”Œë«í¼ ì •ì‚° ìë™í™”' ë“± ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©. 'PortOne' ë¸Œëœë“œëª…ì€ ì‚¬ìš© ê°€ëŠ¥
- **âš ï¸ ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ ê·¹ë‹¨ì  í‘œí˜„ ê¸ˆì§€**: "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì™„ë²½", "ì ˆëŒ€", "ë¬´ì¡°ê±´", "ë°˜ë“œì‹œ", "í•„ìˆ˜" ë“± ê³¼ì¥ëœ í‘œí˜„ì€ í”¼í•˜ê³ , í˜„ì‹¤ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "90% ì´ìƒ", "ë¹ ë¥´ê²Œ", "ë†’ì€ ì •í™•ë„ë¡œ", "ëŒ€í­", "í¬ê²Œ", "íš¨ê³¼ì ìœ¼ë¡œ" ë“±)
- **âš ï¸ ì¤„ë°”ê¿ˆ ì œí•œ**: ê° ë¬¸ë‹¨ì€ ìµœëŒ€ 3-4ì¤„ì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ê³ , ì—°ì†ëœ ì¤„ë°”ê¿ˆì€ ìµœëŒ€ 1ê°œë§Œ ì‚¬ìš©


**ëª…í•¨ ì •ë³´: ë°˜ë“œì‹œ ë‹¤ìŒ ì„œëª…ìœ¼ë¡œ ëë‚´ê¸°:**
{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io

**ë°˜ë“œì‹œ JSON í˜•íƒœë¡œ ë‹¤ìŒ ì´ë©”ì¼ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”:**
{json_request_prompt}

ê° ì´ë©”ì¼ì€ ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
1. ê°œì¸í™”ëœ ì¸ì‚¬ ë° íšŒì‚¬ ê´€ë ¨ ì–¸ê¸‰ (ê²€ì¦ëœ í…œí”Œë¦¿ íŒ¨í„´ í™œìš©)
2. í•µì‹¬ ì§ˆë¬¸ ë˜ëŠ” ë¬¸ì œ ì œê¸° (íšŒì‚¬ë³„ Pain Points í™œìš©)
3. PortOneì˜ êµ¬ì²´ì  ê°€ì¹˜ ì œì•ˆ (ìˆ˜ì¹˜ í¬í•¨)
4. ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ CTA
5. ì „ë¬¸ì ì¸ ì„œëª… (ëª…í•¨ ì •ë³´)

**ì¤‘ìš”:** ê° ìŠ¤íƒ€ì¼ë³„ë¡œ ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ê³¼ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ëª¨ë“  ì´ë©”ì¼ì´ {company_name}ì— íŠ¹í™”ëœ ê°œì¸í™” ìš”ì†Œë¥¼ í¬í•¨í•˜ê³  ì œê³µëœ í…œí”Œë¦¿ íŒ¨í„´ì„ ì°¸ê³ í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        # ë™ì ìœ¼ë¡œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ìƒì„±
        email_schema_properties = {}
        for key in requested_emails.keys():
            email_schema_properties[key] = {
                "type": "object",
                "properties": {
                    "subject": {"type": "string"},
                    "body": {"type": "string"}
                },
                "required": ["subject", "body"]
            }

        payload = {
            "contents": [
                {
                    "parts": [
                        {
                            "text": context
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 4096,
                "responseMimeType": "application/json",
                "responseSchema": {
                    "type": "object",
                    "properties": email_schema_properties,
                    "required": list(requested_emails.keys())
                }
            }
        }
        
        try:
            logger.info("ğŸ¤– Claude API í˜¸ì¶œ ì¤€ë¹„")
            logger.info(f"   - íšŒì‚¬: {company_name}")
            logger.info(f"   - ì„¸ì¼ì¦ˆí¬ì¸íŠ¸: {sales_point}")
            logger.info(f"   - ìš”ì²­ ì´ë©”ì¼: {list(requested_emails.keys())}")
            
            # Claude í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
            if not self.claude_client.bedrock_runtime:
                logger.warning("âš ï¸  Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                raise Exception("Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            if not self.claude_client.model_id:
                logger.warning("âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ì´ ì—†ìŒ")
                raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"âœ… Claude ëª¨ë¸: {self.claude_client.model_id}")
            
            # Claudeë¡œ í”„ë¡¬í”„íŠ¸ ì „ì†¡
            prompt_text = context + '\n\n' + '\n\n'.join([f"# {key}\n{value}" for key, value in requested_emails.items()])
            logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt_text)} ë¬¸ì")
            
            logger.info("ğŸš€ Claude API í˜¸ì¶œ ì‹œì‘...")
            content = self.claude_client.generate_content(prompt_text)
            logger.info(f"âœ… Claude ì‘ë‹µ ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            
            logger.info("ğŸ” Claude ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
            email_variations = self._parse_claude_response(content, company_name)
            logger.info(f"âœ… ì´ë©”ì¼ íŒŒì‹± ì™„ë£Œ - ìƒì„±ëœ ì´ë©”ì¼: {len(email_variations)}ê°œ")
            
            return {
                'success': True,
                'variations': email_variations,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Claude API ì˜¤ë¥˜: {str(e)}")
            logger.info("ğŸ”„ í´ë°± ì´ë©”ì¼ ìƒì„± ì¤‘...")
            
            fallback_emails = self.generate_fallback_emails(company_name, sales_point, ceo_name, contact_position)
            logger.info(f"âœ… í´ë°± ì´ë©”ì¼ ìƒì„± ì™„ë£Œ - {len(fallback_emails)}ê°œ")
            
            return {
                'success': False,
                'error': f'Claude API ì˜¤ë¥˜: {str(e)}',
                'variations': fallback_emails
            }
    
    def _parse_claude_response(self, content, company_name):
        """Claude API ì‘ë‹µì„ ì•ˆì •ì ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” ë©”ì„œë“œ"""
        print(f"\n=== Claude ì‘ë‹µ íŒŒì‹± ì‹œì‘ ===\níšŒì‚¬: {company_name}")
        print(f"ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
        
        # JSON íŒŒì‹±ì„ ìœ„í•œ ê°•ë ¥í•œ ì „ì²˜ë¦¬
        import re
        
        # 1. ê¸°ë³¸ ì •ë¦¬
        cleaned_content = content.strip()
        
        # 2. JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ë˜ëŠ” { ... } íŒ¨í„´)
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', cleaned_content, re.DOTALL)
        if json_match:
            json_content = json_match.group(1)
            print("ğŸ“¦ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ì„±ê³µ")
        else:
            json_match = re.search(r'(\{[^{}]*\{[^{}]*\}[^{}]*\})', cleaned_content, re.DOTALL)
            if json_match:
                json_content = json_match.group(1)
                print("ğŸ“¦ ì¤‘ê´„í˜¸ íŒ¨í„´ì—ì„œ JSON ì¶”ì¶œ ì„±ê³µ")
            else:
                json_content = cleaned_content
                print("ğŸ“¦ ì „ì²´ ë‚´ìš©ì„ JSONìœ¼ë¡œ ì²˜ë¦¬")
        
        # 3. ê°•ë ¥í•œ JSON ì •ë¦¬
        # ë¬¸ìì—´ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ \\nìœ¼ë¡œ ë³€í™˜ ë° ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
        def clean_json_string(text):
            # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¬¸ìì—´ì„ ì°¾ì•„ì„œ ë‚´ë¶€ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            def replace_newlines_in_string(match):
                string_content = match.group(1)
                # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬ (3ê°œ ì´ìƒ -> 2ê°œë¡œ, 2ê°œ ì´ìƒ -> 1ê°œë¡œ)
                string_content = re.sub(r'\n{3,}', '\n\n', string_content)
                string_content = re.sub(r'\n{2,}', '\n', string_content)
                # ë¬¸ìì—´ ë‚´ë¶€ì˜ ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì´ìŠ¤ì¼€ì´í”„ëœ í˜•íƒœë¡œ ë³€í™˜
                string_content = string_content.replace('\n', '\\n')
                string_content = string_content.replace('\r', '\\r')
                string_content = string_content.replace('\t', '\\t')
                return f'"{string_content}"'
            
            # ë¬¸ìì—´ íŒ¨í„´ ë§¤ì¹­ ë° ë³€í™˜
            text = re.sub(r'"([^"]*)"', replace_newlines_in_string, text, flags=re.DOTALL)
            return text
        
        json_content = clean_json_string(json_content)
        
        # 4. ê¸°íƒ€ ì •ë¦¬
        json_content = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', json_content)  # ì œì–´ ë¬¸ì
        json_content = re.sub(r',\s*}', '}', json_content)  # í›„í–‰ ì‰¼í‘œ ì œê±°
        json_content = re.sub(r',\s*]', ']', json_content)  # í›„í–‰ ì‰¼í‘œ ì œê±°
        
        print(f"ì •ë¦¬ëœ JSON ê¸¸ì´: {len(json_content)} ë¬¸ì")
        print(f"ì •ë¦¬ëœ JSON ì‹œì‘: {json_content[:100]}...")
        
        try:
            # ì •ë¦¬ëœ JSON ë‚´ìš©ìœ¼ë¡œ íŒŒì‹± ì‹œë„
            print("ğŸ“ ì •ë¦¬ëœ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„...")
            parsed_result = json.loads(json_content)
            print("âœ… JSON íŒŒì‹± ì„±ê³µ!")
            return parsed_result
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            
            # ì˜¤ë¥˜ ìœ„ì¹˜ ë° ë¬¸ì œ ë¬¸ì ë¶„ì„
            error_msg = str(e)
            try:
                if 'char ' in error_msg:
                    char_pos = int(error_msg.split('char ')[-1].rstrip(')'))
                    if char_pos < len(json_content):
                        problem_area = json_content[max(0, char_pos-50):char_pos+50]
                        problem_char = repr(json_content[char_pos]) if char_pos < len(json_content) else "EOF"
                        print(f"ğŸ” ì˜¤ë¥˜ ìœ„ì¹˜ {char_pos}: {problem_char}")
                        print(f"ğŸ” ë¬¸ì œ ì˜ì—­: ...{problem_area}...")
            except:
                pass
            
            # ìµœí›„ ì‹œë„: ë” ê´€ëŒ€í•œ JSON íŒŒì‹±
            try:
                print("ğŸ“ ê´€ëŒ€í•œ JSON íŒŒì‹± ì‹œë„...")
                # ì˜ëª»ëœ ë”°ì˜´í‘œë‚˜ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ í•´ê²° ì‹œë„
                fixed_json = self._fix_malformed_json(json_content)
                if fixed_json:
                    parsed_result = json.loads(fixed_json)
                    print("âœ… ë³µêµ¬ëœ JSON íŒŒì‹± ì„±ê³µ!")
                    return parsed_result
            except Exception as fix_error:
                print(f"âŒ JSON ë³µêµ¬ë„ ì‹¤íŒ¨: {str(fix_error)}")
                
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°•ì œ JSON ì¬êµ¬ì„±
                try:
                    print("ğŸ“ ê°•ì œ JSON ì¬êµ¬ì„± ì‹œë„...")
                    reconstructed_json = self._reconstruct_json_from_fragments(json_content, company_name)
                    if reconstructed_json:
                        parsed_result = json.loads(reconstructed_json)
                        print("âœ… ì¬êµ¬ì„±ëœ JSON íŒŒì‹± ì„±ê³µ!")
                        return parsed_result
                except Exception as reconstruct_error:
                    print(f"âŒ JSON ì¬êµ¬ì„±ë„ ì‹¤íŒ¨: {str(reconstruct_error)}")
            
            # JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨ ì‹œ êµ¬ì¡°í™”ëœ ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜ (4ê°œ ì´ë©”ì¼)
            print("ğŸ”„ í´ë°± í…œí”Œë¦¿ ìƒì„± ì¤‘...")
            return {
                "opi_professional": {
                    "product": "One Payment Infra",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"ì•ˆë…•í•˜ì„¸ìš” {company_name} ë‹´ë‹¹ìë‹˜,\n\n{company_name}ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\n\nPortOneì˜ í†µí•© ê²°ì œ ì¸í”„ë¼ë¡œ 85% ë¦¬ì†ŒìŠ¤ ì ˆê°ê³¼ 2ì£¼ ë‚´ êµ¬ì¶•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 20ì—¬ ê°œ PGì‚¬ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ê´€ë¦¬ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ê³ , ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥ ì„ 15% í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n15ë¶„ í†µí™”ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "15ë¶„ í†µí™” ì¼ì • ì¡ê¸°",
                    "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤",
                    "personalization_score": 8
                },
                "opi_curiosity": {
                    "product": "One Payment Infra",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"í˜¹ì‹œ ê¶ê¸ˆí•œ ê²Œ ìˆì–´ ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\n{company_name}ì˜ ê²°ì œ ì‹œìŠ¤í…œì´ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ì†ë„ë¥¼ ë”°ë¼ê°€ê³  ìˆë‚˜ìš”? PGì‚¬ ê´€ë¦¬ì— ë‚­ë¹„ë˜ëŠ” ì‹œê°„ì€ ì–¼ë§ˆë‚˜ ë ê¹Œìš”?\n\nPortOneìœ¼ë¡œ ì´ ëª¨ë“  ê±±ì •ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 85% ë¦¬ì†ŒìŠ¤ ì ˆê°, 15% ì„±ê³µë¥  í–¥ìƒ, 2ì£¼ ë‚´ êµ¬ì¶•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n10ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "ë¯¸íŒ… ìš”ì²­í•˜ê¸°",
                    "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤",
                    "personalization_score": 9
                },
                "finance_professional": {
                    "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"ì•ˆë…•í•˜ì„¸ìš” {company_name} ë‹´ë‹¹ìë‹˜,\n\n{company_name}ì˜ ë‹¤ì±„ë„ ì»¤ë¨¸ìŠ¤ ìš´ì˜ì— ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\n\ní˜„ì¬ ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´, ì¹´ì¹´ì˜¤ìŠ¤íƒ€ì¼, ì¹´í˜24 ë“± ì±„ë„ë³„ ì¬ë¬´ë§ˆê°ì— ì›” ìˆ˜ì‹­ ì‹œê°„ì„ ì†Œë¹„í•˜ê³  ê³„ì‹ ê°€ìš”? PortOneì˜ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ 90% ì´ìƒ ë‹¨ì¶•í•˜ê³  100% ë°ì´í„° ì •í•©ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¸Œëœë“œë³„/ì±„ë„ë³„ ë§¤ì¶œë³´ê³ ì„œì™€ ë¶€ê°€ì„¸ì‹ ê³ ìë£Œê¹Œì§€ ìë™í™”ë¡œ ì œê³µí•´ë“œë¦½ë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "ë¯¸íŒ… ìš”ì²­í•˜ê¸°",
                    "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤",
                    "personalization_score": 8
                },
                "finance_curiosity": {
                    "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"í˜¹ì‹œ ê¶ê¸ˆí•œ ê²Œ ìˆì–´ ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\n{company_name}ì˜ ì¬ë¬´íŒ€ì´ ë„¤ì´ë²„, ì¹´ì¹´ì˜¤, ì¹´í˜24 ë“± ì±„ë„ë³„ ë°ì´í„°ë¥¼ ì—‘ì…€ë¡œ ë§¤ë²ˆ ë§¤í•‘í•˜ëŠ” ë° ì–¼ë§ˆë‚˜ ë§ì€ ì‹œê°„ì„ ì“°ê³  ìˆë‚˜ìš”? êµ¬ë§¤í™•ì •ë‚´ì—­ê³¼ ì •ì‚°ë‚´ì—­ì´ ë§¤ì¹­ì´ ì•ˆ ë˜ì–´ ê³ ìƒí•˜ì‹œì§€ ì•Šë‚˜ìš”?\n\nPortOneì˜ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ ì´ ëª¨ë“  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 90% ì´ìƒ ì‹œê°„ ë‹¨ì¶•ê³¼ 100% ë°ì´í„° ì •í•©ì„± ë³´ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "15ë¶„ ìƒë‹´ ì¼ì • ì¡ê¸°",
                    "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤",
                    "personalization_score": 9
                },
                "_fallback_used": True,
                "_original_content": content
            }
    
    def _extract_personalization_elements(self, company_data, research_data):
        """íšŒì‚¬ ë°ì´í„°ì—ì„œ ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ (í•œêµ­ì–´ í…œí”Œë¦¿ íŒ¨í„´ ê¸°ë°˜)"""
        elements = []
        
        # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data)
        ceo_name = get_contact_name(company_data) or 'ë‹´ë‹¹ìë‹˜'
        website = get_homepage(company_data)
        
        # ì§ê¸‰ë³„ ë§ì¶¤ ì¸ì‚¬ë§ ê²°ì •
        position_title = 'ë‹´ë‹¹ìë‹˜'
        if 'ëŒ€í‘œ' in ceo_name or 'CEO' in ceo_name:
            position_title = 'ëŒ€í‘œë‹˜'
        elif 'ì´ì‚¬' in ceo_name or 'ì„ì›' in ceo_name:
            position_title = 'ì´ì‚¬ë‹˜'
        elif 'ì „ë¬´' in ceo_name or 'ìƒë¬´' in ceo_name:
            position_title = 'ì „ë¬´ë‹˜'
        
        if company_name:
            elements.append(f"- {company_name}ì˜ ìµœê·¼ ì„±ì¥ê³¼ ë°œì „ì— ì£¼ëª©í•˜ê³  ìˆìŠµë‹ˆë‹¤")
            elements.append(f"- ì¸ì‚¬ë§ì— '{position_title}' í˜¸ì¹­ ì‚¬ìš© ('{ceo_name}' ê¸°ë°˜)")
        
        if website:
            elements.append(f"- ì›¹ì‚¬ì´íŠ¸({website})ë¥¼ í†µí•´ {company_name}ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë°©í–¥ì„±ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤")
            elements.append(f"- 'ìš°ì—°íˆ {company_name}ì˜ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ë¥¼ ë°©ë¬¸í–ˆë‹¤ê°€, ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤' ì ‘ê·¼ ê°€ëŠ¥")
        
        # ì¡°ì‚¬ ë°ì´í„°ì—ì„œ ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ
        company_info = research_data.get('company_info', '')
        pain_points = research_data.get('pain_points', '')
        
        if 'ì„±ì¥' in company_info or 'í™•ì¥' in company_info:
            elements.append("- ë¹ ë¥¸ ì„±ì¥ì„¸ì™€ ì‹œì¥ í™•ì¥ ê³„íšì„ ì–¸ê¸‰ ê°€ëŠ¥")
            elements.append("- 'ë§¤ì¶œì´ 10ì–µ, 30ì–µì„ ë„˜ì–´ì„œë©° ì„±ì¥í• ìˆ˜ë¡' ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ ì´ìŠˆ ì ‘ê·¼ ê°€ëŠ¥")
        
        if 'ë””ì§€í„¸' in company_info or 'ê¸°ìˆ ' in company_info:
            elements.append("- ë””ì§€í„¸ í˜ì‹ ê³¼ ê¸°ìˆ  ë„ì… ê´€ì‹¬ë„ë¥¼ ê°•ì¡° ê°€ëŠ¥")
            elements.append("- ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¬¸ì œ ì ‘ê·¼ ì¶”ì²œ")
        
        if 'ì»¤ë¨¸ìŠ¤' in company_info or 'ì˜¨ë¼ì¸' in company_info or 'ì‡¼í•‘' in company_info:
            elements.append("- ì»¤ë¨¸ìŠ¤/ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì ‘ê·¼ ê°€ëŠ¥")
            elements.append("- ë„¤ì´ë²„í˜ì´, ì¹´ì¹´ì˜¤, ì¹´í˜24 ë“± ì±„ë„ë³„ ì •ì‚° ì´ìŠˆ ì–¸ê¸‰ ê°€ëŠ¥")
            elements.append("- 'í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ...' íŒ¨í„´ ì‚¬ìš© ì¶”ì²œ")
        
        if 'ì±„ìš©' in company_info or 'ì¸ì¬' in company_info:
            elements.append("- ì±„ìš© ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ í™œìš© ê°€ëŠ¥")
            elements.append("- 'ìµœê·¼ ì¬ë¬´/íšŒê³„ ë‹´ë‹¹ì ì±„ìš©ì„ ì§„í–‰í•˜ì‹œëŠ” ê²ƒì„ ë³´ê³ ...' íŒ¨í„´ ì‚¬ìš© ì¶”ì²œ")
        
        # Pain Points ê¸°ë°˜ ê°œì¸í™”
        if 'ë°ì´í„°' in pain_points or 'ì •ì‚°' in pain_points:
            elements.append("- ì •ì‚°/ë°ì´í„° ë§¤í•‘ ë¬¸ì œ ì¤‘ì‹¬ ì ‘ê·¼ ì¶”ì²œ")
        
        if 'ê°œë°œ' in pain_points or 'ë¦¬ì†ŒìŠ¤' in pain_points:
            elements.append("- ê°œë°œ ë¦¬ì†ŒìŠ¤ ì ˆì•½ ì¤‘ì‹¬ ì ‘ê·¼ ì¶”ì²œ")
        
        if not elements:
            elements.append(f"- {company_name}ì˜ ì§€ì†ì ì¸ ë°œì „ê³¼ í˜ì‹  ë…¸ë ¥ì— ê´€ì‹¬")
            elements.append(f"- ê¸°ë³¸ '{position_title}' í˜¸ì¹­ ì‚¬ìš©")
        
        return '\n'.join(elements)
    
    def refine_email_copy(self, original_copy, feedback):
        """ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë©”ì¼ ë¬¸ì•ˆ ê°œì„ """
        
        refinement_prompt = f"""
        ë‹¤ìŒ ë©”ì¼ ë¬¸ì•ˆì„ ì‚¬ìš©ì í”¼ë“œë°±ì— ë”°ë¼ ê°œì„ í•´ì£¼ì„¸ìš”:

        **ì›ë³¸ ë©”ì¼ ë¬¸ì•ˆ:**
        {original_copy}

        **ì‚¬ìš©ì í”¼ë“œë°±:**
        {feedback}

        **ê°œì„  ìš”ì²­ì‚¬í•­:**
        - Zendesk ëª¨ë²” ì‚¬ë¡€ ì¤€ìˆ˜ (ê°„ê²°ì„±, ê°œì¸í™”, ëª…í™•í•œ CTA)
        - PortOne ì œí’ˆ ê°€ì¹˜ ê°•ì¡°
        - ë” ìì—°ìŠ¤ëŸ½ê³  ì„¤ë“ë ¥ ìˆëŠ” ë¬¸ì²´

        ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        payload = {
            "model": "gemini-3-pro-preview",
            "max_tokens": 1000,
            "temperature": 0.5,
            "messages": [
                {
                    "role": "user",
                    "content": refinement_prompt
                }
            ]
        }
        
        try:
            # Gemini API í˜¸ì¶œë¡œ ë³€ê²½ (ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì„ ì˜ˆì •)
            logger.warning("ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Gemini APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            response = requests.post(self.gemini_url, json=payload, headers=self.headers)
            response.raise_for_status()
            
            result = response.json()
            refined_copy = result['content'][0]['text']
            
            return {
                'success': True,
                'refined_copy': refined_copy,
                'timestamp': datetime.now().isoformat()
            }
            
        except requests.exceptions.RequestException as e:
            return {
                'success': False,
                'error': f'ë©”ì¼ ë¬¸ì•ˆ ê°œì„  ì˜¤ë¥˜: {str(e)}',
                'refined_copy': None
            }
    
    def generate_fallback_emails(self, company_name, sales_point='', contact_name='', contact_position=''):
        """ì‹¤ì œ API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  í•œêµ­ì–´ í…œí”Œë¦¿ ê¸°ë°˜ í´ë°± ì´ë©”ì¼ ìƒì„± (ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ë³„ ë™ì  ìƒì„±)"""
        
        # ê°œì¸í™”ëœ ì¸ì‚¬ë§ ìƒì„±
        researcher = CompanyResearcher()
        personalized_greeting = researcher.generate_personalized_greeting(contact_name, contact_position, company_name)
        
        all_fallbacks = {
            'opi_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} ì½”ë¦¬ì•„í¬íŠ¸ì› ì˜¤ì¤€í˜¸ì…ë‹ˆë‹¤.

í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PGì‚¬ì˜ ë†’ì€ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´, ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìˆ˜ìˆ˜ë£Œ ì¸ìƒ,
ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ë³„ ìµœì  PG ì„ íƒì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?

ì €í¬ í¬íŠ¸ì›ì€ ë‹¨ í•˜ë‚˜ì˜ ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´ ë¹„êµ ë¶„ì„, ìµœì  PGì‚¬ ê²¬ì  ì œì•ˆ,
ê·¸ë¦¬ê³  ê¸€ë¡œë²Œ í™•ì¥ì„±ê¹Œì§€ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë§Œì•½ ì´ëŸ¬í•œ ê³ ë¯¼ì„ í•´ê²°í•˜ê³  ëŒ€í‘œë‹˜ì˜ ì‚¬ì—… ì„±ì¥ì—ë§Œ ì§‘ì¤‘í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´,
ë¯¸íŒ…ì„ í†µí•´ ì €í¬ê°€ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'opi_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ ë‹¨ì¼ PGì‚¬ ì¢…ì†ìœ¼ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ê´€ë¦¬,
ì—¬ëŸ¬ PGì‚¬ ì—°ë™ ì‹œ ë°œìƒí•˜ëŠ” ê°œë°œ/ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ì— ëŒ€í•œ ê³ ë¯¼ì„ í•˜ê³ ê³„ì‹ ê°€ìš”?

í¬íŠ¸ì›ì€ ë‹¨ í•œ ë²ˆì˜ API ì—°ë™ìœ¼ë¡œ 50ê°œ ì´ìƒì˜ PGì‚¬ë¥¼ í†µí•©í•˜ê³ ,
ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë§Œì•½ ì´ëŸ¬í•œ ê¸°ìˆ ì  ê³ ë¯¼ì„ í•´ê²°í•˜ê³  ëŒ€í‘œë‹˜ íŒ€ì˜ ê·€í•œ ë¦¬ì†ŒìŠ¤ê°€
ë³¸ì§ˆì ì¸ ì„œë¹„ìŠ¤ ê°œë°œì—ë§Œ ì§‘ì¤‘ë˜ê¸°ë¥¼ ë°”ë¼ì‹ ë‹¤ë©´,
ë¯¸íŒ…ì„ í†µí•´ ì €í¬ê°€ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'finance_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìš´ì˜í•˜ê³  ê³„ì‹œëŠ”ë°
ë„¤ì´ë²„í˜ì´, ì¿ íŒ¡ ë“± ì˜¤í”ˆë§ˆì¼“ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ë§¤ì¶œê³¼ ì‹¤ì œ ì…ê¸ˆì•¡ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ”
'ì •ì‚°' ì—…ë¬´ì— ìƒê°ë³´ë‹¤ ë§ì€ ì‹œê°„ì„ ìŸê³  ìˆì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”?

ë§ì€ ëŒ€í‘œë‹˜ë“¤ì´ ì´ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ëˆ„ë½ëœ ë§¤ì¶œê³¼ ìˆ¨ê²¨ì§„ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³¨ë¨¸ë¦¬ë¥¼ ì•“ê³  ê³„ì‹­ë‹ˆë‹¤.

ì €í¬ PortOneì˜ ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì€ ì—¬ëŸ¬ ì±„ë„ì˜ ì •ì‚° ë‚´ì—­ì„ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ëŒ€ì‚¬í•˜ì—¬,
ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì‹¤ìˆ˜ë¥¼ ì›ì²œì ìœ¼ë¡œ ë§‰ê³  ìˆ¨ì–´ìˆë˜ ë¹„ìš©ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¨ 15ë¶„ë§Œ íˆ¬ìí•´ì£¼ì‹ ë‹¤ë©´, ë¯¸íŒ…ì„ í†µí•´ {company_name}ì˜ ì¬ë¬´ í˜„í™©ì—ì„œ
ì§€ê¸ˆ ë‹¹ì¥ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ë°ì´í„°ë¡œ ëª…í™•íˆ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ íšŒì‹ ë¶€íƒë“œë¦½ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{user_name} ë“œë¦¼

{user_name}
Sales team
Sales Manager
M {user_phone}
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'finance_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

ìš°ì—°íˆ {company_name}ì˜ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ë¥¼ ë°©ë¬¸í–ˆë‹¤ê°€, ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
ì´ë ‡ê²Œ í›Œë¥­í•œ ì œí’ˆì„ ë§Œë“œì‹œëŠ” ë§Œí¼, ì‚¬ì—…ë„ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆìœ¼ë¦¬ë¼ ìƒê°í•©ë‹ˆë‹¤.

í˜¹ì‹œ ì‚¬ì—… ê·œëª¨ê°€ ì»¤ì§€ë©´ì„œ, ì˜ˆì „ì—ëŠ” ê°„ë‹¨í–ˆë˜ ë§¤ì¶œ ì •ì‚° ì—…ë¬´ê°€ ì ì  ë” ë³µì¡í•˜ê³  ë¶€ë‹´ìŠ¤ëŸ¬ì›Œì§€ëŠ” ë‹¨ê³„ì— ì ‘ì–´ë“¤ì§€ëŠ” ì•Šìœ¼ì…¨ë‚˜ìš”?
ë§ì€ ê¸°ì—…ë“¤ì´ ì €í¬ í¬íŠ¸ì› ì†”ë£¨ì…˜ì„ í†µí•´ ë§¤ì¼ ëª‡ ì‹œê°„ì”© ê±¸ë¦¬ë˜ ì •ì‚° ì—…ë¬´ë¥¼ ë‹¨ 5ë¶„ ë§Œì— ëë‚´ê³ , ì•„ë‚€ ì‹œê°„ì„ ë‹¤ì‹œ ì œí’ˆ ê°œë°œê³¼ ë§ˆì¼€íŒ…ì— íˆ¬ìí•˜ê³  ìˆìŠµë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¤ìŒ ì£¼ ì¤‘ ë¯¸íŒ…ê°€ëŠ¥í•œ ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹ ë‹¤ë©´
{company_name}ì˜ ì„±ê³µ ìŠ¤í† ë¦¬ì— PortOneì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€, ì ì‹œ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.

ê¸ì •ì ì¼ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{user_name} ë“œë¦¼

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'game_d2c_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

í˜¹ì‹œ ì• í”Œ ì•±ìŠ¤í† ì–´ì™€ êµ¬ê¸€ í”Œë ˆì´ìŠ¤í† ì–´ì˜ 30% ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì‹œì§€ ì•Šë‚˜ìš”?
ìµœê·¼ Com2uS, Neptune ë“± êµ­ë‚´ ì£¼ìš” ê²Œì„ì‚¬ë“¤ë„ D2C ì›¹ìƒì ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì„ ëŒ€í­ ì¤„ì´ê³  ìˆìŠµë‹ˆë‹¤.

ì €í¬ PortOneì€ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ë¥¼ í†µí•©í•˜ì—¬, ìµœì ì˜ ë¹„ìš©ìœ¼ë¡œ ì›¹ìƒì  ê²°ì œë¥¼ ìš´ì˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.
ì‹¤ì œë¡œ ê³ ê°ì‚¬ë“¤ì€ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆì•½í•˜ê³ , ì •ì‚° ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  ê³„ì‹­ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´, {company_name}ì— ìµœì í™”ëœ ë°©ì•ˆì„ ì œì•ˆë“œë¦¬ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'game_d2c_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

ìµœê·¼ ë§ì€ ê²Œì„ì‚¬ë“¤ì´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ì ˆê°ì„ ìœ„í•´ D2C ì›¹ìƒì ì„ êµ¬ì¶•í•˜ì§€ë§Œ,
ë§‰ìƒ ì§ì ‘ êµ¬ì¶•í•˜ë ¤ë‹¤ ë³´ë‹ˆ êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™, ì •ì‚° ê´€ë¦¬, ìˆ˜ìˆ˜ë£Œ ìµœì í™” ë“±ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

PortOneì„ ì‚¬ìš©í•˜ì‹œë©´ ì´ ëª¨ë“  ê³¼ì •ì„ í•œ ë²ˆì— í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì–´ë–»ê²Œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆê°í•˜ê³  ìš´ì˜ ì—…ë¬´ë¥¼ ìë™í™”í•  ìˆ˜ ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ì§€ ì•Šìœ¼ì‹ ê°€ìš”?

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

15ë¶„ë§Œ ì‹œê°„ì„ ë‚´ì–´ì£¼ì‹œë©´, ì–´ë–»ê²Œ ê°€ëŠ¥í•œì§€ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            }
        }

        if sales_point == 'opi':
            return {k: v for k, v in all_fallbacks.items() if 'opi' in k}
        elif sales_point == 'recon':
            return {k: v for k, v in all_fallbacks.items() if 'finance' in k}
        elif sales_point == 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°':
            return {k: v for k, v in all_fallbacks.items() if 'game_d2c' in k}
        else: # 'opi + recon' ë˜ëŠ” ë¹ˆì¹¸ì¼ ê²½ìš°
            return {k: v for k, v in all_fallbacks.items() if 'opi' in k or 'finance' in k}
    
    def _fix_malformed_json(self, json_content):
        """ì†ìƒëœ JSON ë³µêµ¬ ì‹œë„"""
        try:
            import re
            
            # 1. ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œ ìˆ˜ì •
            fixed_content = json_content
            
            # 2. ë¶ˆì™„ì „í•œ ë¬¸ìì—´ ìˆ˜ì • (ëë‚˜ì§€ ì•Šì€ ë¬¸ìì—´)
            # ë§ˆì§€ë§‰ ë”°ì˜´í‘œê°€ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš° ìˆ˜ì •
            lines = fixed_content.split('\n')
            for i, line in enumerate(lines):
                # í‚¤: "ê°’" íŒ¨í„´ì—ì„œ ê°’ ë¶€ë¶„ì´ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš°
                if line.strip().endswith('"') == False and '"' in line and ':' in line:
                    # ë¬¸ìì—´ì´ ë‹«íˆì§€ ì•Šì•˜ë‹¤ë©´ ë‹«ì•„ì£¼ê¸°
                    quote_count = line.count('"')
                    if quote_count % 2 == 1:  # í™€ìˆ˜ ê°œì˜ ë”°ì˜´í‘œ = ë‹«íˆì§€ ì•ŠìŒ
                        lines[i] = line + '"'
            
            fixed_content = '\n'.join(lines)
            
            # 3. í›„í–‰ ì‰¼í‘œ ì œê±°
            fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)
            
            # 4. ì¤‘ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
            open_braces = fixed_content.count('{')
            close_braces = fixed_content.count('}')
            if open_braces > close_braces:
                fixed_content += '}' * (open_braces - close_braces)
            
            return fixed_content
            
        except Exception as e:
            logger.debug(f"JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _reconstruct_json_from_fragments(self, broken_json, company_name):
        """ì™„ì „íˆ ê¹¨ì§„ JSONì„ ì¡°ê°ì—ì„œ ì¬êµ¬ì„±"""
        try:
            import re
            
            print("ğŸ”§ JSON ì¡°ê°ì—ì„œ í‚¤-ê°’ ìŒ ì¶”ì¶œ ì¤‘...")
            
            # 4ê°œ ì´ë©”ì¼ í…œí”Œë¦¿ í‚¤
            email_keys = ["opi_professional", "opi_curiosity", "finance_professional", "finance_curiosity"]
            reconstructed = {}
            
            # ê° ì´ë©”ì¼ ìœ í˜•ë³„ë¡œ subjectì™€ body ì¶”ì¶œ ì‹œë„
            for key in email_keys:
                reconstructed[key] = {"subject": "", "body": ""}
                
                # subject ì°¾ê¸°
                subject_match = re.search(rf'"{key}"[^{{]*"subject"\s*:\s*"([^"]*)"', broken_json, re.DOTALL)
                if subject_match:
                    reconstructed[key]["subject"] = subject_match.group(1)
                else:
                    reconstructed[key]["subject"] = f"{company_name} ê²°ì œ ì†”ë£¨ì…˜ ì œì•ˆ"
                
                # body ì°¾ê¸° (ë” ë³µì¡í•¨ - ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆì„ ìˆ˜ ìˆìŒ)
                body_pattern = rf'"{key}"[^{{]*"body"\s*:\s*"([^"]*(?:\\"[^"]*)*)'
                body_match = re.search(body_pattern, broken_json, re.DOTALL)
                if body_match:
                    body_content = body_match.group(1)
                    # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ë³µì›
                    body_content = body_content.replace('\\"', '"').replace('\\n', '\n')
                    reconstructed[key]["body"] = body_content[:500] + "..." if len(body_content) > 500 else body_content
                else:
                    # ê¸°ë³¸ í…œí”Œë¦¿
                    reconstructed[key]["body"] = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜.\n\nPortOneì˜ ê²°ì œ ì†”ë£¨ì…˜ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ íš¨ìœ¨ì„±ì„ ë†’ì—¬ë³´ì„¸ìš”.\n\nê°ì‚¬í•©ë‹ˆë‹¤."
            
            # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            import json
            reconstructed_json = json.dumps(reconstructed, ensure_ascii=False, indent=2)
            
            print(f"ğŸ”§ ì¬êµ¬ì„± ì™„ë£Œ: {len(reconstructed)} ê°œ ì´ë©”ì¼ í…œí”Œë¦¿")
            return reconstructed_json
            
        except Exception as e:
            print(f"ğŸ”§ JSON ì¬êµ¬ì„± ì‹¤íŒ¨: {e}")
            return None


def generate_email_with_gemini(company_data, research_data, user_info=None):
    """Gemini 2.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œì¸í™”ëœ ì´ë©”ì¼ ìƒì„±"""
    try:
        # ì‚¬ìš©ì ì •ë³´ (ì„œëª…ìš©) - user_info íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ current_user ì²´í¬
        if user_info:
            user_name = user_info.get('name', 'ì˜¤ì¤€í˜¸')
            user_company_nickname = user_info.get('company_nickname', f'PortOne {user_name} ë§¤ë‹ˆì €')
            user_phone = user_info.get('phone', '010-2580-2580')
            logger.info(f"ğŸ‘¤ ì´ë©”ì¼ ìƒì„±ì: {user_name} ({user_company_nickname})")
            logger.info(f"âœ… ì „ë‹¬ë°›ì€ ì‚¬ìš©ì ì •ë³´ ì‚¬ìš©: {user_info.get('email', 'N/A')}")
        else:
            user_name = current_user.name if (current_user and current_user.is_authenticated) else "ì˜¤ì¤€í˜¸"
            user_company_nickname = current_user.company_nickname if (current_user and current_user.is_authenticated) else f"PortOne {user_name} ë§¤ë‹ˆì €"
            user_phone = current_user.phone if (current_user and current_user.is_authenticated) else "010-2580-2580"
            
            # ë””ë²„ê¹…: ì‚¬ìš©ì ì •ë³´ ë¡œê·¸
            logger.info(f"ğŸ‘¤ ì´ë©”ì¼ ìƒì„±ì: {user_name} (PortOne {user_name} ë§¤ë‹ˆì €)")
            if current_user and current_user.is_authenticated:
                logger.info(f"âœ… ë¡œê·¸ì¸ ì‚¬ìš©ì ì¸ì¦ë¨: {current_user.email}")
            else:
                logger.warning(f"âš ï¸  current_user ì¸ì¦ ì•ˆ ë¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        # íšŒì‚¬ ì •ë³´ ìš”ì•½ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data) or 'Unknown'
        
        # sales_item ì—´ í™•ì¸ (ì„œë¹„ìŠ¤ë³„ ë¬¸ì•ˆ ìƒì„± ê²°ì •)
        sales_item = get_sales_item(company_data).lower().strip()
        logger.info(f"Sales item í™•ì¸: '{sales_item}' for {company_name}")
        
        # ë‹´ë‹¹ì ì •ë³´ ì¶”ì¶œ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        # ì´ë©”ì¼ í˜¸ì¹­ ì—´ì„ ìš°ì„  ì°¸ì¡° (ì´ë¯¸ ì™„ì„±ëœ í˜¸ì¹­)
        email_name = get_email_salutation(company_data)
        
        # ì´ë©”ì¼ í˜¸ì¹­ì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        if not email_name:
            contact_name = get_contact_name(company_data)
            contact_position = get_contact_position(company_data)
            
            # ë‹´ë‹¹ìëª…ê³¼ ì§ì±… ì²˜ë¦¬ (ê¸°ë³¸ê°’ ì„¤ì •)
            if not contact_name or contact_name == 'ë‹´ë‹¹ì':
                email_name = 'ë‹´ë‹¹ìë‹˜'
            else:
                # ì§ì±… ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                if contact_position:
                    # ì§ì±…ì— ë”°ë¥¸ ì ì ˆí•œ í˜¸ì¹­ ì²˜ë¦¬
                    if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €', 'ì‹¤ì¥', 'ê³¼ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì£¼ì„', 'ëŒ€ë¦¬', 'ì„ ì„', 'ì±…ì„']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    else:
                        # ê¸°íƒ€ ì§ì±…
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                else:
                    # ì§ì±… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì´ë¦„ë§Œìœ¼ë¡œ ì²˜ë¦¬
                    if any(title in contact_name for title in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name}ë‹˜'
                    else:
                        email_name = f'{contact_name} ë‹´ë‹¹ìë‹˜'
        
        # ê²½ìŸì‚¬ ì •ë³´ ì¶”ì¶œ (PortOne ì´ìš© ê¸°ì—…) - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        competitor_name = get_competitor(company_data)
        
        company_info = f"íšŒì‚¬ëª…: {company_name}\në‹´ë‹¹ì: {email_name}"
        if competitor_name:
            company_info += f"\nPortOne ì´ìš© ê²½ìŸì‚¬: {competitor_name}"
        
        # ğŸ†• í˜¸ìŠ¤íŒ… ì •ë³´ ëª…ì‹œì  ì¶”ê°€ (PGì™€ í˜¼ë™ ë°©ì§€)
        hosting_info = get_hosting(company_data)
        if hosting_info:
            company_info += f"\nğŸ  í˜¸ìŠ¤íŒ…ì‚¬ (ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…, ê²°ì œì™€ ë¬´ê´€): {hosting_info}"
        
        # ì‚¬ìš©PG ì •ë³´ ì¶”ê°€ (ìš°ì„  í‘œì‹œ) - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        pg_info = get_pg_provider(company_data)
        if pg_info:
            company_info += f"\nğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG (ê²°ì œ ì„œë¹„ìŠ¤): {pg_info}"
        else:
            company_info += f"\nğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG: ì •ë³´ ì—†ìŒ (PG ê´€ë ¨ ë‚´ìš© ì–¸ê¸‰ ê¸ˆì§€)"
        
        # ì¶”ê°€ íšŒì‚¬ ì •ë³´ê°€ ìˆë‹¤ë©´ í¬í•¨
        # ğŸ†• ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì œì™¸ í‚¤ ëª©ë¡ í™•ì¥
        excluded_keys = [
            'íšŒì‚¬ëª…', 'ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìëª…', 'ì´ë¦„', 'ì§ì±…', 'ì§ê¸‰', 'ê²½ìŸì‚¬ëª…', 'ê²½ìŸì‚¬', 
            'ì‚¬ìš©PG', 'PG', 'ì´ë©”ì¼ í˜¸ì¹­', 'ì´ë©”ì¼í˜¸ì¹­', 'ëŒ€í‘œì´ë©”ì¼', 'ì´ë©”ì¼', 'sales_item',
            'í™ˆí˜ì´ì§€', 'í™ˆí˜ì´ì§€ë§í¬', 'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸', 'ì‚¬ì—…ìë²ˆí˜¸',
            'í˜¸ìŠ¤íŒ…ì‚¬', 'í˜¸ìŠ¤íŒ…', 'hosting'  # ğŸ†• í˜¸ìŠ¤íŒ… ì •ë³´ëŠ” ë³„ë„ë¡œ OPI íŒë‹¨ì—ë§Œ ì‚¬ìš©
        ]
        for key, value in company_data.items():
            if key not in excluded_keys and value and not key.startswith('_'):
                company_info += f"\n{key}: {value}"
        
        # ì¡°ì‚¬ ì •ë³´ ë° Pain Point ìš”ì•½
        research_summary = research_data.get('company_info', 'ì¡°ì‚¬ ì •ë³´ ì—†ìŒ')
        pain_points = research_data.get('pain_points', 'ì¼ë°˜ì ì¸ Pain Point')
        industry_trends = research_data.get('industry_trends', '')
        
        # ğŸ†• BM ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if 'business_model' in research_data:
            bm_info = research_data['business_model']
            
            # ë¶€ê°€ BM í•œê¸€ ë²ˆì—­
            secondary_models_kr = []
            if bm_info.get('secondary_models'):
                bm_translator = BusinessModelAnalyzer()
                secondary_models_kr = [bm_translator._translate_bm(bm) for bm in bm_info['secondary_models']]
            
            bm_summary = f"""
## ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ ê²°ê³¼ (ì‹ ë¢°ë„: {bm_info['confidence']}%)
**ì£¼ìš” BM**: {bm_info['primary_model_kr']}
**ë¶€ê°€ BM**: {', '.join(secondary_models_kr) if secondary_models_kr else 'ì—†ìŒ'}

**ì¶”ì²œ ì†”ë£¨ì…˜**:
"""
            for idx, solution in enumerate(bm_info.get('recommended_solutions', [])[:2], 1):
                bm_summary += f"{idx}. **{solution['primary']}**: {solution['description']}\n"
                bm_summary += f"   - Pain Point: {solution['pain_points'][0] if solution['pain_points'] else 'N/A'}\n"
                bm_summary += f"   - í•µì‹¬ í˜œíƒ: {solution['benefits'][0] if solution['benefits'] else 'N/A'}\n\n"
            
            research_summary += "\n\n" + bm_summary
            logger.info(f"âœ… BM ì •ë³´ë¥¼ research_summaryì— ì¶”ê°€: {bm_info['primary_model_kr']}")
        
        # ğŸ†• ë§ì¶¤í˜• ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ì¶”ê°€
        if 'customized_pitch' in research_data and research_data['customized_pitch']:
            research_summary += f"\n\n## ğŸ’¡ ë§ì¶¤í˜• ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸\n{research_data['customized_pitch']}"
        
        # í˜¸ìŠ¤íŒ…ì‚¬ ì •ë³´ í™•ì¸ (OPI ì œê³µ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨) - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        hosting = get_hosting(company_data).lower().strip()
        
        if hosting:
            logger.info(f"{company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ë°œê²¬: '{hosting}'")
        else:
            logger.warning(f"{company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ - CSVì— í˜¸ìŠ¤íŒ…ì‚¬ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        
        # AWS, Cloudflareë„ ìì²´êµ¬ì¶•ìœ¼ë¡œ ê°„ì£¼
        is_self_hosted = ('ìì²´' in hosting or 'self' in hosting or 'ì§ì ‘' in hosting or 
                         'aws' in hosting.lower() or 'cloudflare' in hosting.lower())
        
        # ğŸ†• sales_itemì—ì„œ ë³µìˆ˜ ì„œë¹„ìŠ¤ ê°ì§€ (ì½¤ë§ˆ, +, & ë“±ìœ¼ë¡œ ë¶„ë¦¬)
        def parse_sales_items(sales_item_str):
            """sales_item ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ì¶”ì¶œ"""
            if not sales_item_str:
                return []
            
            # ì½¤ë§ˆ, +, &, ê³µë°± ë“±ìœ¼ë¡œ ë¶„ë¦¬
            import re
            items = re.split(r'[,+&\s]+', sales_item_str.lower().strip())
            # ë¹ˆ ë¬¸ìì—´ ì œê±°
            items = [item.strip() for item in items if item.strip()]
            return items
        
        # sales_item íŒŒì‹±
        sales_items = parse_sales_items(sales_item)
        logger.info(f"ğŸ“‹ Sales items íŒŒì‹± ê²°ê³¼: {sales_items} for {company_name}")
        
        # ê°ì§€ëœ ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)
        detected_services = set()
        for item in sales_items:
            if 'opi' in item:
                detected_services.add('opi')
            if 'recon' in item or 'ì¬ë¬´' in item:
                detected_services.add('recon')
            if 'prism' in item or 'í”„ë¦¬ì¦˜' in item:
                detected_services.add('prism')
            if 'ps' in item or 'í”Œë«í¼ì •ì‚°' in item or 'íŒŒíŠ¸ë„ˆì •ì‚°' in item:
                detected_services.add('ps')
            if 'ì„¸ê¸ˆê³„ì‚°ì„œ' in item or 'ì—­ë°œí–‰' in item or 'tax' in item or 'invoice' in item:
                detected_services.add('tax_invoice')
        
        detected_services = list(detected_services)
        logger.info(f"ğŸ¯ ê°ì§€ëœ ì„œë¹„ìŠ¤: {detected_services} for {company_name}")
        
        # sales_itemì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ê²°ì •
        services_to_generate = []
        is_multi_service = len(detected_services) > 1
        
        if sales_item:
            if is_multi_service:
                # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ ê°ì§€: í†µí•© ë¬¸ì•ˆ ìƒì„±
                # OPIëŠ” ìì²´êµ¬ì¶•ì¼ ë•Œë§Œ í¬í•¨
                if 'opi' in detected_services and not is_self_hosted:
                    logger.warning(f"âš ï¸ OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ ì œì™¸: {company_name}")
                    detected_services.remove('opi')
                
                services_to_generate = ['multi_service_professional', 'multi_service_curiosity']
                service_names = []
                if 'opi' in detected_services:
                    service_names.append('OPI')
                if 'recon' in detected_services:
                    service_names.append('Recon')
                if 'prism' in detected_services:
                    service_names.append('Prism')
                if 'ps' in detected_services:
                    service_names.append('PS')
                if 'tax_invoice' in detected_services:
                    service_names.append('ì„¸ê¸ˆê³„ì‚°ì„œ')
                
                logger.info(f"ğŸ¯ ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ ìƒì„±: {' + '.join(service_names)} for {company_name}")
            
            elif 'opi' in detected_services:
                # ë‹¨ì¼ OPI ì„œë¹„ìŠ¤
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity']
                    logger.info(f"âœ… OPI ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
                else:
                    # ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconìœ¼ë¡œ ëŒ€ì²´
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    detected_services = ['recon']
                    logger.warning(f"âš ï¸ OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ Recon(ì¬ë¬´ìë™í™”)ìœ¼ë¡œ ì „í™˜: {company_name}")
            
            elif 'recon' in detected_services:
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"Recon(ì¬ë¬´ìë™í™”) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            elif 'prism' in detected_services:
                services_to_generate = ['prism_professional', 'prism_curiosity']
                logger.info(f"Prism(ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            elif 'ps' in detected_services:
                services_to_generate = ['ps_professional', 'ps_curiosity']
                logger.info(f"í”Œë«í¼ ì •ì‚°(íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            elif 'tax_invoice' in detected_services:
                services_to_generate = ['tax_invoice_professional', 'tax_invoice_curiosity']
                logger.info(f"ì„¸ê¸ˆê³„ì‚°ì„œ ìë™í™”(ì—­ë°œí–‰) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” sales_itemì¸ ê²½ìš°
                if is_self_hosted:
                    # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                    services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                    logger.info(f"ì•Œ ìˆ˜ ì—†ëŠ” sales_item '{sales_item}', ìì²´êµ¬ì¶•ì´ë¯€ë¡œ 4ê°œ ë¬¸ì•ˆ ìƒì„±: {company_name}")
                else:
                    # ìì²´êµ¬ì¶• ì•„ë‹ˆë©´ Reconë§Œ
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.info(f"ì•Œ ìˆ˜ ì—†ëŠ” sales_item '{sales_item}', ìì²´êµ¬ì¶• ì•„ë‹ˆë¯€ë¡œ Reconë§Œ ìƒì„±: {company_name}")
        else:
            # sales_itemì´ ì—†ìœ¼ë©´ í˜¸ìŠ¤íŒ…ì‚¬ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            if not hosting:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ì—†ìœ¼ë©´ 4ê°œ ëª¨ë‘ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ â†’ 4ê°œ ëª¨ë‘ ìƒì„±: {company_name}")
            elif is_self_hosted:
                # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + ìì²´êµ¬ì¶• â†’ 4ê°œ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
            else:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ìˆê³  ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconë§Œ
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ…='{hosting}' (ìì²´êµ¬ì¶• ì•„ë‹˜) â†’ Reconë§Œ ìƒì„±: {company_name}")
        
        # ë¸”ë¡œê·¸ ìºì‹œ í™•ì¸ ë° í•„ìš” ì‹œ ìŠ¤í¬ë˜í•‘ (ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ ì „ì— ì‹¤í–‰)
        from portone_blog_cache import load_blog_cache
        cached_posts = load_blog_cache()
        if not cached_posts:
            logger.info("ğŸ“° ë¸”ë¡œê·¸ ìºì‹œ ì—†ìŒ - ìë™ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (generate_email_with_gemini)")
            try:
                blog_posts = scrape_portone_blog_initial()
                if blog_posts:
                    logger.info(f"âœ… ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(blog_posts)}ê°œ")
                else:
                    logger.warning("âš ï¸ ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì—†ìŒ")
            except Exception as blog_error:
                logger.error(f"âŒ ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(blog_error)}")
        else:
            logger.info(f"âœ… ë¸”ë¡œê·¸ ìºì‹œ ì‚¬ìš©: {len(cached_posts)}ê°œ")
        
        # ì„œë¹„ìŠ¤ë³„ í†µí•© ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ (ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´)
        from portone_blog_cache import get_service_knowledge
        
        # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ì¼ ê²½ìš° detected_services ê¸°ë°˜ìœ¼ë¡œ ëª¨ë‘ ë¡œë“œ
        if is_multi_service:
            logger.info(f"ğŸ“š ë³µìˆ˜ ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ ì‹œì‘: {detected_services}")
        
        # OPIìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        opi_blog_content = ""
        if any('opi' in s for s in services_to_generate) or (is_multi_service and 'opi' in detected_services):
            opi_blog_content = get_service_knowledge(service_type='OPI')
            logger.info(f"ğŸ“š [OPI] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # Reconìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        recon_blog_content = ""
        if any('finance' in s for s in services_to_generate) or (is_multi_service and 'recon' in detected_services):
            recon_blog_content = get_service_knowledge(service_type='Recon')
            logger.info(f"ğŸ“š [Recon] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # Prismìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        prism_blog_content = ""
        if any('prism' in s for s in services_to_generate) or (is_multi_service and 'prism' in detected_services):
            prism_blog_content = get_service_knowledge(service_type='Prism')
            logger.info(f"ğŸ“š [Prism] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # í”Œë«í¼ ì •ì‚°(PS)ìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        ps_blog_content = ""
        if any('ps' in s for s in services_to_generate) or (is_multi_service and 'ps' in detected_services):
            ps_blog_content = get_service_knowledge(service_type='PS')
            logger.info(f"ğŸ“š [í”Œë«í¼ ì •ì‚°] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # ğŸ†• ì´ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰í•  ìµœì ì˜ ë¸”ë¡œê·¸ 1ê°œ ì„ íƒ (ë¸”ë¡œê·¸ ì–¸ê¸‰ ê°•í™”)
        from portone_blog_cache import get_best_blog_for_email_mention
        blog_mention_instruction = ""
        try:
            company_info_for_blog = {
                'industry': research_data.get('industry', ''),
                'category': research_data.get('category', ''),
                'description': research_data.get('company_info', '')
            }
            blog_mention_info = get_best_blog_for_email_mention(company_info_for_blog, research_data)
            if blog_mention_info:
                blog_title = blog_mention_info.get('title', '')
                blog_link = blog_mention_info.get('link', '')
                blog_reason = blog_mention_info.get('match_reason', '')
                industry_matched = blog_mention_info.get('industry_matched', False)
                
                # ì—…ì¢… ë§¤ì¹­ì´ ëœ ê²½ìš°ì—ë§Œ ë¸”ë¡œê·¸ ì–¸ê¸‰
                if industry_matched or blog_reason:
                    blog_summary = blog_mention_info.get('summary', '')
                    blog_case_company = blog_mention_info.get('case_company', '')
                    
                    # ğŸ†• ì˜ì‚¬ê²°ì •ì ê´€ì ì˜ êµ¬ì²´ì  ì •ë³´ í¬í•¨
                    blog_mention_instruction = f"""
**ğŸ“Œ ê´€ë ¨ ë¸”ë¡œê·¸ - ì˜ì‚¬ê²°ì •ì— ë„ì›€ë˜ëŠ” ì‚¬ë¡€ (í•„ìˆ˜ í™œìš©!):**

ğŸ”— **ë¸”ë¡œê·¸ ì •ë³´:**
- ì œëª©: {blog_title}
- ë§í¬: {blog_link}
- ì—°ê´€ì„±: {blog_reason}
{f'- ì‚¬ë¡€ ê³ ê°ì‚¬: {blog_case_company}' if blog_case_company else ''}
{f'- í•µì‹¬ ë‚´ìš©: {blog_summary[:150]}...' if blog_summary else ''}

ğŸ’¡ **ì˜ì‚¬ê²°ì •ìê°€ ê´€ì‹¬ ê°€ì§ˆ ì •ë³´ í™œìš©ë²•:**
ì´ë©”ì¼ì—ì„œ ì•„ë˜ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì‚¬ìš©í•˜ì„¸ìš”:
1. **êµ¬ì²´ì  ìˆ˜ì¹˜**: ë¸”ë¡œê·¸ì— ì–¸ê¸‰ëœ "X% ì ˆê°", "Xì–µì› ì ˆê°", "Xì£¼ ë‚´ êµ¬ì¶•" ë“± ì •ëŸ‰ì  íš¨ê³¼
2. **ë¹„ìŠ·í•œ ì‚¬ë¡€**: "{blog_case_company if blog_case_company else 'ìœ ì‚¬ ì—…ì¢…ì˜ ê³ ê°ì‚¬'}ë„ ê°™ì€ ê³ ë¯¼ì„ í•˜ì…¨ëŠ”ë°..."
3. **ë¦¬ìŠ¤í¬ ê°ì†Œ**: "ë‹¨ì¼ PG ì˜ì¡´ ë¦¬ìŠ¤í¬", "ì •ì‚° ì˜¤ë¥˜ ë¦¬ìŠ¤í¬" ë“± í•´ê²° ì‚¬ë¡€

ğŸ“ **ê¶Œì¥ ì–¸ê¸‰ ë°©ì‹:**
ë³¸ë¬¸ì—ì„œ ì‚¬ë¡€ë¥¼ ì–¸ê¸‰í•œ í›„, ëë¶€ë¶„ì—:
"ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ í•˜ì…¨ë˜ ê³ ê°ì‚¬ ì‚¬ë¡€ê°€ ìˆëŠ”ë°ìš”:
ğŸ‘‰ {blog_title}
{blog_link}"

âš ï¸ **ì¤‘ìš”:**
- ë¸”ë¡œê·¸ ë§í¬ë¥¼ ë°˜ë“œì‹œ ë³„ë„ ì¤„ì— ê·¸ëŒ€ë¡œ í¬í•¨
- ë¸”ë¡œê·¸ì˜ êµ¬ì²´ì  ìˆ˜ì¹˜/íš¨ê³¼ë¥¼ ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ ë¨¼ì € ì–¸ê¸‰í•˜ë©´ ë” ì„¤ë“ë ¥ ìˆìŒ
"""
                    logger.info(f"ğŸ“ {company_name}: ë¸”ë¡œê·¸ ì–¸ê¸‰ ì˜ˆì • - {blog_title[:30]}... (ì—…ì¢…ë§¤ì¹­: {industry_matched})")
        except Exception as blog_mention_error:
            logger.warning(f"ë¸”ë¡œê·¸ ì–¸ê¸‰ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(blog_mention_error)}")
        
        # CSV ë‰´ìŠ¤ ì œê³µ ì—¬ë¶€ í™•ì¸
        has_csv_news = "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)" in research_summary
        
        # ğŸ†• Perplexity ì¡°ì‚¬ ê²°ê³¼ì— 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_recent_news_in_research = research_data.get('has_recent_news', True)
        
        # í•´ì™¸ ì§„ì¶œ ì—¬ë¶€ í™•ì¸ (ë‰´ìŠ¤/ì¡°ì‚¬ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ)
        global_keywords = ['í•´ì™¸', 'ê¸€ë¡œë²Œ', 'global', 'ìˆ˜ì¶œ', 'export', 'í•´ì™¸ì§„ì¶œ', 'êµ­ì œ', 'ì•„ì‹œì•„', 'ìœ ëŸ½', 'ë¯¸êµ­', 'ì¼ë³¸', 'ì¤‘êµ­', 'ë™ë‚¨ì•„']
        is_global = any(keyword in research_summary.lower() for keyword in global_keywords)
        
        # PGì‚¬ ê°œìˆ˜ ë™ì  í‘œí˜„
        if is_global:
            pg_count = "êµ­ë‚´ì™¸ 50ì—¬ê°œ"
            logger.info(f"ğŸŒ {company_name}: í•´ì™¸ íƒ€ê²Ÿ ê°ì§€ â†’ {pg_count} PGì‚¬ ì–¸ê¸‰")
        else:
            pg_count = "êµ­ë‚´ 20ì—¬ê°œ"
            logger.info(f"ğŸ‡°ğŸ‡· {company_name}: êµ­ë‚´ íƒ€ê²Ÿ â†’ {pg_count} PGì‚¬ ì–¸ê¸‰")
        
        # ê¸°ë³¸ context ì •ì˜ - ë‰´ìŠ¤ í›„í‚¹ ìš°ì„ ìˆœìœ„: CSV ë‰´ìŠ¤ > Perplexity ìµœê·¼ ë‰´ìŠ¤ > ì‚°ì—… ë™í–¥
        if has_csv_news:
            news_instruction = """**ğŸ¯ ìµœìš°ì„  ì§€ì‹œ: CSVì—ì„œ ì œê³µëœ 'ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬' ì„¹ì…˜ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì´ë©”ì¼ ë„ì…ë¶€ì— í™œìš©í•˜ì„¸ìš”!**

ì´ ë‰´ìŠ¤ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ ì •í•œ ì¤‘ìš”í•œ ê¸°ì‚¬ì´ë¯€ë¡œ, ë‹¤ë¥¸ ì–´ë–¤ ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.

**í•„ìˆ˜ í™œìš© ë°©ì‹:**
- "ìµœê·¼ '{news_title}' ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤..." í˜•íƒœë¡œ ì§ì ‘ ì¸ìš©
- CSV ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ Perplexity ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ 
- ë‰´ìŠ¤ ë‚´ìš©ê³¼ íšŒì‚¬ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì—°ê²°

ì˜ˆì‹œ:
- "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ëŠ” ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
- "'{company_name}ì˜ ë§¤ì¶œ 200% ì¦ê°€' ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
        elif has_recent_news_in_research:
            # ğŸ†• Perplexity ì¡°ì‚¬ ê²°ê³¼ì— 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ê°€ ìˆëŠ” ê²½ìš°
            news_instruction = """**ì¤‘ìš”**: ìœ„ì˜ Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ êµ¬ì²´ì ì¸ ìµœê·¼ ë‰´ìŠ¤ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©í•˜ì—¬ ì´ë©”ì¼ ë„ì…ë¶€ì— í™œìš©í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ 100ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ê³  ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ì— ë”°ë¥¸ ê²°ì œ ì¸í”„ë¼ í™•ì¥ ê³„íšë„ ìˆìœ¼ì‹¤ í…ë°..."
- "'{company_name}ì˜ 3ë¶„ê¸° ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 150% ì¦ê°€í–ˆë‹¤'ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ ì§„í–‰í•˜ê³  ê³„ì‹ ê°€ìš”?" """
            logger.info(f"ğŸ“° {company_name}: ìµœê·¼ ë‰´ìŠ¤ ì‚¬ìš© (Perplexity ì¡°ì‚¬ ê²°ê³¼)")
        else:
            # ğŸ†• 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° â†’ ì‚°ì—… ë™í–¥ ì‚¬ìš©
            logger.info(f"ğŸ­ {company_name}: ìµœê·¼ ë‰´ìŠ¤ ì—†ìŒ â†’ ì‚°ì—… ë™í–¥ ê¸°ë°˜ ì„œë¡  ì‚¬ìš©")
            news_instruction = """**ğŸ¯ ì¤‘ìš”**: 3ê°œì›” ì´ë‚´ ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë¯€ë¡œ, ê´€ë ¨ ì‚°ì—…ì˜ ë™í–¥ì„ ì„œë¡ ì— ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.

**í•„ìˆ˜**: ìœ„ ì¡°ì‚¬ ê²°ê³¼ì˜ "ì—…ê³„ë³„ ê¸°ìˆ  íŠ¸ë Œë“œ" ì„¹ì…˜ ë˜ëŠ” ì—…ì¢… ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì‚°ì—… ë™í–¥ ê¸°ë°˜ ë„ì…ë¶€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**ì˜µì…˜ 1 - ì—…ê³„ íŠ¸ë Œë“œ ê¸°ë°˜ (ê¶Œì¥):**
- "{company_name}ë‹˜ì´ ì†í•œ {ì—…ì¢…} ì—…ê³„ì—ì„œëŠ” ìš”ì¦˜ {íŠ¸ë Œë“œ}ê°€ í™”ë‘ì¸ë°, í˜¹ì‹œ {ê´€ë ¨ Pain Point} ê³ ë¯¼ ì¤‘ì´ì‹ ê°€ìš”?"
- ì˜ˆ: "ê²Œì„ ì—…ê³„ì—ì„œ ì¸ì•± ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì´ ì»¤ì§€ê³  ìˆëŠ”ë°, {company_name}ë‹˜ë„ ì´ ë¶€ë¶„ ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?"
- ì˜ˆ: "ì»¤ë¨¸ìŠ¤ ì—…ê³„ì—ì„œ ë©€í‹° ì±„ë„ í™•ì¥ì´ í™œë°œí•œë°, {company_name}ë‹˜ë„ ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?"

**ì˜µì…˜ 2 - íšŒì‚¬ ê·œëª¨/ì„±ì¥ ë‹¨ê³„ ì–¸ê¸‰:**
- "{company_name}ë‹˜ ê·œëª¨ì˜ íšŒì‚¬ë¼ë©´ {ì˜ˆìƒ Pain Point}ë¥¼ ê²ªê³  ê³„ì‹¤ ê²ƒ ê°™ì€ë°, ë§ë‚˜ìš”?"
- ì˜ˆ: "ì—°ë§¤ì¶œ 100ì–µ ê·œëª¨ì˜ ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì´ë¼ë©´ PGì‚¬ ê´€ë¦¬ì— ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ ë“¤ì–´ê°€ì‹¤ í…ë°..."

**ì˜µì…˜ 3 - ì§ì ‘ì  ê³µê° (ê°€ì¥ ìì—°ìŠ¤ëŸ¬ì›€):**
- "{ì—…ì¢…} ê¸°ì—…ë“¤ì´ ê³µí†µì ìœ¼ë¡œ {Pain Point}ë¥¼ ê²ªê³  ê³„ì‹œëŠ”ë°, {company_name}ë‹˜ë„ ë¹„ìŠ·í•œ ìƒí™©ì´ì‹ ê°€ìš”?"
- ì˜ˆ: "ì»¤ë¨¸ìŠ¤ ê¸°ì—…ë“¤ì´ ì—¬ëŸ¬ PGì‚¬ë¥¼ ê´€ë¦¬í•˜ëŠë¼ ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹œëŠ”ë°, {company_name}ë‹˜ë„ ê°™ì€ ê³ ë¯¼ì´ì‹ ê°€ìš”?"

âš ï¸ **ì ˆëŒ€ ê¸ˆì§€**: "ìµœê·¼ ë‰´ìŠ¤ë¥¼ í™•ì¸í–ˆëŠ”ë°..." ê°™ì€ ê±°ì§“ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
âœ… **ê¶Œì¥**: ìœ„ ì¡°ì‚¬ ê²°ê³¼ì˜ ì—…ì¢…, ê·œëª¨, Pain Point ì •ë³´ë¥¼ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ê³µê° """ 
        
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ë¡œ, ì‹¤ì œ ê²€ì¦ëœ í•œêµ­ì–´ ì˜ì—… ì´ë©”ì¼ íŒ¨í„´ì„ ì™„ë²½íˆ ìˆ™ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ğŸš¨ ì¤‘ìš”: ì„œë¹„ìŠ¤ ì†Œê°œì„œì™€ ë¸”ë¡œê·¸ ê¸°ë°˜ ì œì•½ ì‚¬í•­ ğŸš¨**
- ì•„ë˜ ì œê³µëœ OPI/Recon ì°¸ê³  ì •ë³´(ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸)ì— ëª…ì‹œëœ ê¸°ëŠ¥ê³¼ ìˆ˜ì¹˜ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ì„œë¹„ìŠ¤ ì†Œê°œì„œ/ë¸”ë¡œê·¸ì— ì—†ëŠ” ê¸°ëŠ¥ì´ë‚˜ ì±„ë„ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì œê³µí•  ìˆ˜ ì—†ëŠ” ì˜ì—­ì„ ì œê³µí•œë‹¤ê³  ë§í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤
- í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¼ë°˜ì ì¸ Pain Point ì¤‘ì‹¬ìœ¼ë¡œë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- **í¬íŠ¸ì› ë¸”ë¡œê·¸(https://blog.portone.io/)ì˜ ë‚´ìš©ì€ ê³µì‹ ì¶œì²˜ì´ë¯€ë¡œ ììœ ë¡­ê²Œ ì¸ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤**
- **ë¸”ë¡œê·¸ ë‚´ìš©ì„ ì¸ìš©í•˜ê±°ë‚˜ ì°¸ê³ í–ˆì„ ê²½ìš°, ë°˜ë“œì‹œ ì´ë©”ì¼ ì œì¼ ë§ˆì§€ë§‰(ì„œëª… ì´í›„)ì— `[ì°¸ê³ ] <ë¸”ë¡œê·¸ ì œëª©>: <ë§í¬>` í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ ë‚¨ê¸°ì„¸ìš”**
- **ğŸš¨ ë¸”ë¡œê·¸ ë§í¬ ì‚¬ìš© ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**
  1. **ì ˆëŒ€ ë§í¬ë¥¼ ì„ì˜ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”** (UUIDë‚˜ ë‹¤ë¥¸ í˜•ì‹ ê¸ˆì§€!)
  2. **ì•„ë˜ OPI/Recon ì°¸ê³  ì •ë³´ì— ì œê³µëœ "ë§í¬:" ë¶€ë¶„ì˜ URLì„ ì •í™•íˆ ë³µì‚¬**í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
  3. **ì˜ˆì‹œ**: ì°¸ê³ ìë£Œì— "ë§í¬: https://blog.portone.io/opi_case_game/" ì´ ìˆë‹¤ë©´, ì •í™•íˆ ì´ URLì„ ì‚¬ìš©
  4. **ì˜ëª»ëœ ì˜ˆ**: https://blog.portone.io/84f99450-... (UUID í˜•ì‹ ì ˆëŒ€ ê¸ˆì§€!)
- **ğŸš¨ ë¸”ë¡œê·¸ ì¶œì²˜ í‘œê¸° ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**
  1. **ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰í•˜ê±°ë‚˜ ì¸ìš©í•œ ë¸”ë¡œê·¸ë§Œ ì¶œì²˜ë¡œ í‘œê¸°**í•˜ì„¸ìš”
  2. **ì–¸ê¸‰í•˜ì§€ ì•Šì€ ë¸”ë¡œê·¸ë¥¼ ì¶œì²˜ë¡œ ë„£ì§€ ë§ˆì„¸ìš”** (ì°¸ê³ ë§Œ í•˜ê³  ë³¸ë¬¸ì— ì•ˆ ì“´ ê²½ìš° ì¶œì²˜ ë¶ˆí•„ìš”)
  3. **í•´ë‹¹ íšŒì‚¬ ì—…ì¢…ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ë¸”ë¡œê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”** (ì˜ˆ: ê²Œì„ì—…ì²´ì— ì—¬í–‰ì—…ê³„ ë¸”ë¡œê·¸ âŒ)
  4. **ì•„ë˜ ì°¸ê³  ì •ë³´ì˜ ë¸”ë¡œê·¸ëŠ” ì´ë¯¸ {company_name}ì˜ ì—…ì¢…ì— ë§ì¶° í•„í„°ë§ëœ ê²ƒ**ì´ë¯€ë¡œ ì•ˆì‹¬í•˜ê³  í™œìš©í•˜ì„¸ìš”
- **Perplexity ì¡°ì‚¬ ê²°ê³¼ì™€ PortOne ê³µì‹ ë¸”ë¡œê·¸ëŠ” ëª¨ë‘ ê²€ì¦ëœ ì¶œì²˜ì´ë¯€ë¡œ í™˜ê°ì´ ì•„ë‹™ë‹ˆë‹¤**

**âœ… OPIì—ì„œ ì–¸ê¸‰ ê°€ëŠ¥í•œ ê²°ì œ ìˆ˜ë‹¨ (ì†Œê°œì„œ ê¸°ë°˜):**
- ì‹ ìš©ì¹´ë“œ, ê°„í¸ê²°ì œ (êµ­ë‚´ 0.5% ìˆ˜ìˆ˜ë£Œ)
- í•´ì™¸: ê°êµ­ì˜ ê°„í¸ê²°ì œ ìˆ˜ë‹¨ (100+ ê²°ì œ ìˆ˜ë‹¨)
- í¬ë¦½í†  ê²°ì œ ë“±
- âŒ **ê³„ì¢Œì´ì²´ëŠ” ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì ˆëŒ€ ì–¸ê¸‰ ê¸ˆì§€**

**í¬íŠ¸ì› í•µì‹¬ ìˆ˜ì¹˜:**
- êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ í¬íŠ¸ì› ì‚¬ìš© ì¤‘
- ì—°í™˜ì‚° ê±°ë˜ì•¡ 12ì¡°ì› (2024ë…„ 12ì›” ê¸°ì¤€)
- {pg_count} PGì‚¬ ì—°ë™ ê°€ëŠ¥

**ğŸ”¥ CTA ì§ì „ ì‹ ë¢°ë„ ë¬¸êµ¬ - ë¸”ë¡œê·¸ ì‚¬ë¡€ ìš°ì„ ! ğŸ”¥**
ì•„ë˜ì— "ğŸ“Œ ê´€ë ¨ ë¸”ë¡œê·¸" ì •ë³´ê°€ ì œê³µëœ ê²½ìš°:
â†’ **ë°˜ë“œì‹œ** ë¸”ë¡œê·¸ ì‚¬ë¡€ë¥¼ CTA ì§ì „ì— ì–¸ê¸‰ (3,000ì—¬ê°œ ë¬¸êµ¬ ëŒ€ì‹ )
â†’ **ğŸš¨ ì‚¬ë¡€ ì–¸ê¸‰ ì‹œ ë¸”ë¡œê·¸ ë§í¬ ì¶œì²˜ í•„ìˆ˜! ğŸš¨**
â†’ í˜•ì‹: "ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ í•˜ì…¨ë˜ [ì‚¬ë¡€ ê³ ê°ì‚¬]ë„ í¬íŠ¸ì› ë„ì… í›„ [êµ¬ì²´ì  ì„±ê³¼]ë¥¼ ë‹¬ì„±í–ˆëŠ”ë°ìš”, ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê¸€ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ğŸ‘‰ [ë¸”ë¡œê·¸ ì œëª©](ë¸”ë¡œê·¸ ë§í¬)"
â†’ **ì ˆëŒ€ ê¸ˆì§€**: ì‚¬ë¡€ë§Œ ì–¸ê¸‰í•˜ê³  ë§í¬ ì—†ì´ ëë‚´ê¸° âŒ
â†’ **í•„ìˆ˜**: ì‚¬ë¡€ ì–¸ê¸‰ â†’ ë¸”ë¡œê·¸ ë§í¬ê¹Œì§€ ì„¸íŠ¸ë¡œ í¬í•¨ âœ…

ë¸”ë¡œê·¸ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ:
â†’ "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..." ë˜ëŠ” "ì—° 12ì¡°ì› ê·œëª¨ì˜ ê±°ë˜ë¥¼..." ì‚¬ìš©

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
{company_info}

**ğŸ’³ ì‚¬ìš©PG ì •ë³´ í™œìš© ê°€ì´ë“œ (ì¤‘ìš”!):**

**ğŸš¨ğŸš¨ğŸš¨ í˜¸ìŠ¤íŒ…ì‚¬ vs PG êµ¬ë¶„ - ìµœìš°ì„  ê·œì¹™ (ìœ„ë°˜ ì‹œ ì´ë©”ì¼ ë¬´íš¨!) ğŸš¨ğŸš¨ğŸš¨**

ìœ„ íšŒì‚¬ ì •ë³´ì—ì„œ ë‘ ê°€ì§€ ì •ë³´ë¥¼ ë°˜ë“œì‹œ êµ¬ë¶„í•˜ì„¸ìš”:
- **ğŸ  í˜¸ìŠ¤íŒ…ì‚¬**: "ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…, ê²°ì œì™€ ë¬´ê´€"ì´ë¼ê³  ëª…ì‹œë¨ â†’ ì´ê²ƒì€ **ì ˆëŒ€ë¡œ PGê°€ ì•„ë‹˜!**
  - ì˜ˆ: Web Hosting, Vercel, AWS, Cloudflare, Cafe24, ìì²´êµ¬ì¶• ë“±
  - âŒ ì ˆëŒ€ ê¸ˆì§€: "í˜„ì¬ Web Hostingì„ ì‚¬ìš©í•˜ê³  ê³„ì‹ ë°, ë‹¨ì¼ PG ì˜ì¡´ìœ¼ë¡œ..." (ì´ê±´ ì™„ì „íˆ í‹€ë¦° ë¬¸ì¥!)
  - âŒ ì ˆëŒ€ ê¸ˆì§€: "í˜„ì¬ Vercelì„ ì‚¬ìš©í•˜ê³  ê³„ì‹ ë°..." (í˜¸ìŠ¤íŒ…ì„ PGì²˜ëŸ¼ ì–¸ê¸‰)
  
- **ğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG**: "ê²°ì œ ì„œë¹„ìŠ¤"ë¼ê³  ëª…ì‹œë¨ â†’ ì´ê²ƒë§Œ PG ê´€ë ¨ ì–¸ê¸‰ì— ì‚¬ìš©
  - ì˜ˆ: ë„¤ì´ë²„í˜ì´, í† ìŠ¤í˜ì´ë¨¼ì¸ , KGì´ë‹ˆì‹œìŠ¤, ë‚˜ì´ìŠ¤í˜ì´, ì¹´ì¹´ì˜¤í˜ì´ ë“±
  - âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: "í˜„ì¬ ë„¤ì´ë²„í˜ì´ë¥¼ ì‚¬ìš©í•˜ê³  ê³„ì‹ ë°, ë‹¨ì¼ PG ì˜ì¡´ìœ¼ë¡œ..."

**PG ì •ë³´ í™œìš© ê·œì¹™:**
- **ğŸ’³ PG ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ** (ì˜ˆ: "ğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG (ê²°ì œ ì„œë¹„ìŠ¤): ë„¤ì´ë²„í˜ì´"):
  - ë‹¨ì¼ PG: "í˜„ì¬ [PGëª…]ì„ ì‚¬ìš©í•˜ê³  ê³„ì‹ ë°, ë‹¨ì¼ PG ì˜ì¡´ ë¦¬ìŠ¤í¬ë¥¼ OPIë¡œ í•´ê²°..."
  - ì—¬ëŸ¬ PG: "ì—¬ëŸ¬ PGì‚¬ë¥¼ ê°œë³„ ê´€ë¦¬í•˜ì‹œëŠ” ê²ƒë³´ë‹¤ PortOne ì½˜ì†” í•˜ë‚˜ë¡œ..."
- **ğŸ’³ PG ì •ë³´ê°€ "ì •ë³´ ì—†ìŒ"ì¸ ê²½ìš°**: PG ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ì¼ë°˜ì ì¸ ê²°ì œ ìµœì í™”ë§Œ ì–¸ê¸‰

**ğŸ”¥ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ (ì´ë©”ì¼ì— ë°˜ë“œì‹œ í™œìš©í•´ì•¼ í•¨):**
{research_summary}

**ì—…ê³„ íŠ¸ë Œë“œ:**
{industry_trends}

{news_instruction}
- "'{company_name}ì˜ 3ë¶„ê¸° ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 150% ì¦ê°€í–ˆë‹¤'ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì†í•œ ì„±ì¥ì— ë”°ë¥¸ ì¬ë¬´ ê´€ë¦¬ ë¶€ë‹´ì´ ëŠ˜ì–´ë‚˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?"
- "'{company_name}ê°€ ì¼ë³¸ ì‹œì¥ì— ì§„ì¶œí•œë‹¤'ëŠ” ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í•´ì™¸ ì§„ì¶œ ì‹œ í˜„ì§€ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™ì´ ë³µì¡í•˜ì‹¤ í…ë°..."

{blog_mention_instruction}

"""

        # ìƒì„±í•  ì„œë¹„ìŠ¤ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if is_multi_service:
            # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ
            service_names_kr = []
            if 'opi' in detected_services:
                service_names_kr.append('í†µí•© ê²°ì œ ì¸í”„ë¼')
            if 'recon' in detected_services:
                service_names_kr.append('ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜')
            if 'prism' in detected_services:
                service_names_kr.append('ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©')
            if 'ps' in detected_services:
                service_names_kr.append('í”Œë«í¼ ì •ì‚° ìë™í™”')

            service_focus = f"{' + '.join(service_names_kr)} í†µí•© ì†”ë£¨ì…˜ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ ì œì•ˆí•˜ëŠ” 2ê°œì˜"
            logger.info(f"ğŸ“§ ë³µìˆ˜ ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ì´ˆì : {service_focus}")
        elif len(services_to_generate) == 2:
            if 'opi' in services_to_generate[0]:
                service_focus = "í†µí•© ê²°ì œ ì¸í”„ë¼ ì„œë¹„ìŠ¤ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            elif 'prism' in services_to_generate[0]:
                service_focus = "ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            elif 'ps' in services_to_generate[0]:
                service_focus = "í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            else:
                service_focus = "ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ì— ì§‘ì¤‘í•œ 2ê°œì˜"
        else:
            service_focus = "4ê°œì˜ ì„¤ë“ë ¥ ìˆê³  ì°¨ë³„í™”ëœ"
        
        prompt = f"""
{context}

**íšŒì‚¬ë³„ ë§ì¶¤ Pain Points (ì¡°ì‚¬ ê²°ê³¼ ê¸°ë°˜):**
{pain_points}

ë‹¤ìŒ ê³ ì •ëœ í˜•ì‹ì— ë”°ë¼ {service_focus} ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

**ğŸ¯ ìµœìš°ì„  ëª©í‘œ: B2B ì˜ì‚¬ê²°ì •ìê°€ "ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ë‹¤"ê³  ëŠë¼ëŠ” ë©”ì¼ ì‘ì„±**

ë‹¹ì‹ ì´ ì‘ì„±í•˜ëŠ” ë©”ì¼ì€ AI í‰ê°€ ì‹œìŠ¤í…œìœ¼ë¡œ íš¨ê³¼ì„±ì„ ì¸¡ì •í•˜ë©°, ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ 5ì  ë§Œì  í‰ê°€ë©ë‹ˆë‹¤:

**5ì  (ëª©í‘œ)**: "ì •í™•íˆ ìš°ë¦¬ê°€ ì°¾ë˜ ì†”ë£¨ì…˜ì´ë©° ì¦‰ì‹œ ë‹µì¥í•˜ê² ìŠµë‹ˆë‹¤", "ë§¤ìš° ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ", "ìš°ë¦¬ íšŒì‚¬ì˜ í˜„ì¬ ë¬¸ì œë¥¼ ì •í™•íˆ ì´í•´í•˜ê³  ìˆì–´ ë§¤ìš° ì¸ìƒì "
**4ì  (í•©ê²©)**: "ë§¤ìš° ê´€ì‹¬ì´ ê°€ë©° ê³§ ë‹µì¥í•  ê°€ëŠ¥ì„± ë†’ìŒ", "ìš°ë¦¬ íšŒì‚¬ì˜ pain pointë¥¼ ì˜ íŒŒì•…", "êµ¬ì²´ì ì´ê³  ê´€ë ¨ì„±ì´ ë†’ì•„ ë¯¸íŒ…ì„ ì¡ê³  ì‹¶ë‹¤"
**3ì  ì´í•˜ (ì‹¤íŒ¨)**: "ì–´ëŠ ì •ë„ ê´€ì‹¬", "ì œì•ˆì´ ê´œì°®ì•„ ë³´ì´ì§€ë§Œ í™•ì‹  ì—†ìŒ", "ë³„ë¡œ ê´€ì‹¬ ì—†ìŒ", "ìŠ¤íŒ¸ì²˜ëŸ¼ ëŠê»´ì§"

**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ (4-5ì ì„ ë°›ê¸° ìœ„í•œ ì¡°ê±´):**
1. **ê°€ì¥ ì¤‘ìš”**: í¼í”Œë ‰ì‹œí‹°ê°€ ì¡°ì‚¬í•œ {company_name}ì˜ ìµœì‹  ë‰´ìŠ¤/í™œë™ì„ ë°˜ë“œì‹œ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì—¬ ê°œì¸í™”
   â†’ "ì´ íšŒì‚¬ì˜ í˜„ì¬ ìƒí™©ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìˆë‹¤" ì¸ìƒ í•„ìˆ˜
2. ìœ„ì— ì œì‹œëœ íšŒì‚¬ë³„ ë§ì¶¤ Pain Pointë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì—¬ ì°¨ë³„í™”
   â†’ "ìš°ë¦¬ íšŒì‚¬ì˜ pain pointë¥¼ ì˜ íŒŒì•…í–ˆë‹¤" ë°˜ì‘ ìœ ë„  
3. ê³ ì •ëœ ì„œë¡ /ê²°ë¡  í˜•ì‹ ì‚¬ìš© (ë‹´ë‹¹ìì˜ ì´ë¦„ê³¼ ì§ì±…ì´ ì •í™•íˆ ë°˜ì˜ë˜ë„ë¡)
4. ë‹´ë‹¹ìì˜ ì§ì±…ì— ë§ëŠ” ê´€ì ìœ¼ë¡œ Pain Pointì™€ í•´ê²°ì±… ì œì‹œ
5. ì‹¤ì œ ìˆ˜ì¹˜ì™€ êµ¬ì²´ì  í˜œíƒ ì œì‹œ (85% ì ˆê°, 90% ë‹¨ì¶•, 15% í–¥ìƒ ë“±)
   â†’ "êµ¬ì²´ì ì´ê³  ê´€ë ¨ì„±ì´ ë†’ë‹¤" í‰ê°€ í™•ë³´
6. PortOne ì´ìš© ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í•´ë‹¹ ê¸°ì—… ì‚¬ë¡€ë¥¼ ì–¸ê¸‰
   â†’ "ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ" ì¸ì‹ ê°•í™”
7. **ğŸ†• ë¸”ë¡œê·¸ ì‚¬ë¡€ í™œìš© (ì˜ì‚¬ê²°ì •ì ì„¤ë“ì— í•µì‹¬!):**
   - ìœ„ì— ì œê³µëœ ë¸”ë¡œê·¸ ì •ë³´ê°€ ìˆë‹¤ë©´, ë¸”ë¡œê·¸ì˜ **êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ì‚¬ë¡€**ë¥¼ ë³¸ë¬¸ì— ë…¹ì—¬ì„œ ì–¸ê¸‰
   - ì˜ˆ: "ìœ ì‚¬ ì—…ì¢…ì˜ ê³ ê°ì‚¬ëŠ” í¬íŠ¸ì› ë„ì… í›„ ìˆ˜ìˆ˜ë£Œ 15% ì ˆê°, ì •ì‚° ì—…ë¬´ 90% ìë™í™”ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤"
   - ì˜ˆ: "ë¹„ìŠ·í•œ ê³ ë¯¼ì„ í•˜ì…¨ë˜ [ë¸”ë¡œê·¸ ì‚¬ë¡€ ê³ ê°ì‚¬]ë„ ì´ ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ë°ìš”..."
   - **ë‹¨ìˆœíˆ ë§í¬ë§Œ ë˜ì§€ì§€ ë§ê³ , í•µì‹¬ ìˆ˜ì¹˜/íš¨ê³¼ë¥¼ ë¨¼ì € ì–¸ê¸‰ í›„ "ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê¸€ì—ì„œ"**
8. **ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ìš”ì†Œ í¬í•¨**:
   - ì‹œê¸‰ì„±: "ì§€ê¸ˆ ê²ªê³  ê³„ì‹¤" ë¬¸ì œ ì–¸ê¸‰
   - ê´€ë ¨ì„±: "{company_name}ë§Œì˜ êµ¬ì²´ì  ìƒí™©" ì •í™•íˆ ì§€ì 
   - ì‹¤í˜„ ê°€ëŠ¥ì„±: "2ì£¼ ë‚´ êµ¬ì¶•" ë“± êµ¬ì²´ì  íƒ€ì„ë¼ì¸
   - **ì£¼ì˜**: ì‹¤ì œ ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œëŠ” "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì ˆëŒ€" ë“± ê·¹ë‹¨ì  í‘œí˜„ì€ í”¼í•˜ê³  í˜„ì‹¤ì  í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "ë¹ ë¥´ê²Œ", "90% ì´ìƒ", "ë†’ì€ ì •í™•ë„ë¡œ")

**ğŸ”¥ ëª…ë£Œí•œ ì œì•ˆ ì‘ì„± ê°€ì´ë“œ (ë§¤ìš° ì¤‘ìš”!):**

**í•µì‹¬ ì›ì¹™: "íšŒì‚¬ ìƒí™© â†’ Pain Point â†’ í¬íŠ¸ì› ê¸°ëŠ¥ â†’ êµ¬ì²´ì  ê°€ì¹˜" ìˆœì„œë¡œ ëª…í™•í•˜ê²Œ ì—°ê²°**

**ë‹¨ê³„ë³„ ì‘ì„± ë°©ë²•:**

**1ë‹¨ê³„: íšŒì‚¬ì˜ ì„œë¹„ìŠ¤/ìƒí™© íŒŒì•… (ë‰´ìŠ¤ ê¸°ë°˜)**
   - "{company_name}ê°€ XX ì‹œì¥ ì§„ì¶œ" / "ë§¤ì¶œ 200% ì¦ê°€" ë“± êµ¬ì²´ì  ìƒí™© ì–¸ê¸‰
   
**2ë‹¨ê³„: ì´ë¡œ ì¸í•œ êµ¬ì²´ì  Pain Point ì œì‹œ**
   - "ì´ë¡œ ì¸í•´ [êµ¬ì²´ì ì¸ ì–´ë ¤ì›€]ì´ ë°œìƒí•˜ì‹¤ í…ë°..."
   - ì˜ˆ: "í•´ì™¸ ì§„ì¶œë¡œ ì¸í•´ ê°êµ­ì˜ ì„œë¡œ ë‹¤ë¥¸ ê²°ì œ ìˆ˜ë‹¨ ì—°ë™ì´ ë³µì¡í•˜ì‹¤ í…ë°..."
   - ì˜ˆ: "ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ê²°ì œ ì‹œìŠ¤í…œ ë¶€í•˜ì™€ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì´ ì»¤ì§€ì‹¤ í…ë°..."
   
**3ë‹¨ê³„: í¬íŠ¸ì›ì˜ êµ¬ì²´ì  ê¸°ëŠ¥ ì„¤ëª…**
   - **ë‹¨ìˆœíˆ "OPIë¡œ í•´ê²°" ì‹ì˜ ì¶”ìƒì  í‘œí˜„ ê¸ˆì§€**
   - **ë°˜ë“œì‹œ "ì–´ë–¤ ê¸°ëŠ¥ì„ í†µí•´" í•´ê²°í•˜ëŠ”ì§€ ëª…ì‹œ**
   - ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:
     * âŒ "í¬íŠ¸ì›ìœ¼ë¡œ ê²°ì œ ì‹œìŠ¤í…œì„ íš¨ìœ¨í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
     * âœ… "í¬íŠ¸ì›ì€ **ë‹¨ í•˜ë‚˜ì˜ APIë¡œ {pg_count} PGì‚¬ë¥¼ í†µí•© ì—°ë™**í•˜ì—¬, **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•˜ëŠ” PGì‚¬ë¥¼ ì œì•ˆ**í•¨ìœ¼ë¡œì¨ ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•©ë‹ˆë‹¤"
     * âŒ "ì¬ë¬´ ì—…ë¬´ë¥¼ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
     * âœ… "í¬íŠ¸ì›ì€ **ê° PGì‚¬ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í†µí•©**í•˜ê³ , **ERPì™€ ì—°ë™**í•˜ì—¬ ìˆ˜ì‘ì—…ì„ ì—†ì•±ë‹ˆë‹¤"

**4ë‹¨ê³„: ê·¸ ê¸°ëŠ¥ì´ ì œê³µí•˜ëŠ” êµ¬ì²´ì  ê°€ì¹˜**
   - **"í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¡œ ëë‚´ì§€ ë§ê³ , ì •ëŸ‰ì  ê²°ê³¼ê¹Œì§€ ëª…ì‹œ**
   - ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:
     * "ë‹¨ í•˜ë‚˜ì˜ APIë¡œ {pg_count} PGì‚¬ë¥¼ í†µí•© ì—°ë™í•˜ì—¬, **ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ 85% ì ˆê°**í•˜ê³  **2ì£¼ ë‚´ êµ¬ì¶•**ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"
     * "ìë™ ë°ì´í„° í†µí•©ê³¼ ERP ì—°ë™ìœ¼ë¡œ **ì¬ë¬´ ë§ˆê° ì‹œê°„ì„ 90% ë‹¨ì¶•**í•˜ê³ , **íœ´ë¨¼ì—ëŸ¬ë¥¼ ì œê±°**í•˜ì—¬ í™•ë³´ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì„±ì¥ ì „ëµì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
     * "ë©€í‹° PG ì „ëµìœ¼ë¡œ **ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ í‰ê·  15-30% ì ˆê°**í•˜ê³ , **ê²°ì œ ì„±ê³µë¥ ì„ 15% í–¥ìƒ**ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

**ëª…ë£Œí•œ ë¬¸ì¥ êµ¬ì¡° í…œí”Œë¦¿:**
"[í¬íŠ¸ì› ê¸°ëŠ¥]ì„ í†µí•´ [êµ¬ì²´ì  ì‘ë™ ë°©ì‹], ì´ë¡œì¨ [ì •ëŸ‰ì  ê²°ê³¼ 1]í•˜ê³  [ì •ëŸ‰ì  ê²°ê³¼ 2]í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"

**ë‚˜ìœ ì˜ˆì‹œ (ì¶”ìƒì , ë¶ˆëª…í™•):**
"í¬íŠ¸ì›ì€ ê²°ì œ ì‹œìŠ¤í…œì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ ë„ì™€ë“œë¦½ë‹ˆë‹¤. ê°œë°œ ì‹œê°„ë„ ì¤„ê³  ë¹„ìš©ë„ ì ˆê°ë©ë‹ˆë‹¤."

**ì¢‹ì€ ì˜ˆì‹œ (ëª…ë£Œí•˜ê³  êµ¬ì²´ì  - í•µì‹¬ ê°€ì¹˜ ìš°ì„ ):**
"í¬íŠ¸ì›ì€ **ë©€í‹° PG ë¼ìš°íŒ…**ìœ¼ë¡œ ê±°ë˜ë§ˆë‹¤ ìµœì € ìˆ˜ìˆ˜ë£Œ PGë¥¼ ìë™ ì„ íƒí•˜ì—¬ **PG ìˆ˜ìˆ˜ë£Œë¥¼ 15-30% ì ˆê°**í•©ë‹ˆë‹¤. ë˜í•œ **ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…**ì„ í†µí•´ PGì‚¬ ì¥ì•  ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ PGë¡œ ì „í™˜ë˜ì–´ **ê²°ì œ ì„±ê³µë¥ ì„ 15% í–¥ìƒ**ì‹œí‚¤ê³  ë§¤ì¶œ ì†ì‹¤ì„ ë°©ì§€í•©ë‹ˆë‹¤. ì•„ìš¸ëŸ¬ **ë‹¨ í•˜ë‚˜ì˜ APIë¡œ {pg_count} PGì‚¬ë¥¼ í†µí•© ì—°ë™**í•˜ì—¬ ê° PGì‚¬ë³„ ê°œë³„ ê°œë°œì´ í•„ìš” ì—†ì–´, **ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ 85% ì ˆê°**í•˜ê³  **6ê°œì›” ê±¸ë¦¬ë˜ êµ¬ì¶•ì„ 2ì£¼ë¡œ ë‹¨ì¶•**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

**ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ë³„ ë§ì¶¤ ê¸°ëŠ¥ ì œì•ˆ (ì¤‘ìš”!):**

Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ íšŒì‚¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ íŒŒì•…í•˜ê³ , ê·¸ì— ë§ëŠ” PortOne ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ì„¸ìš”:

**ì£¼ìš” ë§¤í•‘:**

**1. êµ¬ë…/ì •ê¸°ê²°ì œ ì„œë¹„ìŠ¤ (SaaS, ë©¤ë²„ì‹­, OTT, êµ¬ë…ë°•ìŠ¤, ì •ê¸°ë°°ì†¡ ë“±):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: PGì‚¬ì— ì¢…ì†ë˜ì§€ ì•ŠëŠ” ë…ë¦½ì ì¸ ë¹Œë§í‚¤ë¡œ ì–¸ì œë“  PGì‚¬ ì´ê´€ ê°€ëŠ¥
   â€¢ **ì œê³µ ê°€ì¹˜**: PGì‚¬ ê°„ ê²½ìŸì„ í†µí•´ í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œ ìœ ì§€, ë²¤ë” ë½ì¸ ë°©ì§€
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: ì¥ê¸°ì ìœ¼ë¡œ ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ ì§€ì†ì ìœ¼ë¡œ ì ˆê°í•˜ê³ , PGì‚¬ í˜‘ìƒë ¥ í™•ë³´
   â€¢ **ì–¸ê¸‰ ë°©ì‹**: "êµ¬ë… ì„œë¹„ìŠ¤ë¥¼ ìš´ì˜í•˜ì‹œëŠ” {company_name}ë‹˜ì€..."ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ë¹Œë§í‚¤ì˜ í•„ìš”ì„± ê°•ì¡°
   
**2. í•´ì™¸ ì§„ì¶œ ê¸°ì—… (ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤, ìˆ˜ì¶œ, ë‹¤êµ­ê°€ ì „ê°œ):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: ê°êµ­ ê°„í¸ê²°ì œ 100+ ìˆ˜ë‹¨ ì—°ë™
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: ì¼ë³¸(PayPay), ë™ë‚¨ì•„(GrabPay, GCash), ì¤‘êµ­(Alipay) ë“± í˜„ì§€ ê²°ì œ ìˆ˜ë‹¨ ë¹ ë¥¸ ì—°ë™
   â€¢ **ì œê³µ ê°€ì¹˜**: í˜„ì§€ ì„ í˜¸ ê²°ì œ ìˆ˜ë‹¨ ì œê³µìœ¼ë¡œ êµ¬ë§¤ ì „í™˜ìœ¨ ê·¹ëŒ€í™”, ê¸€ë¡œë²Œ ìˆ˜ìˆ˜ë£Œ ì ˆê°
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: í•´ì™¸ ì‹œì¥ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ, ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°
   â€¢ **ì‘ì„± ë°©ë²•**: Perplexity ì¡°ì‚¬ì—ì„œ íŒŒì•…í•œ ì§„ì¶œ êµ­ê°€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ. ì˜ˆ: "ì¼ë³¸ì— ì§„ì¶œí•˜ì‹  ABCë‹˜ì€ PayPay ê°™ì€ í˜„ì§€ ê²°ì œ ìˆ˜ë‹¨ì´..."
   â€¢ **ê²°ê³¼**: êµ­ê°€ë³„ ê²°ì œ ì„±ê³µë¥  15-30% í–¥ìƒ, í•´ì™¸ ë§¤ì¶œ ì¦ëŒ€
   
**3. ê±°ë˜ëŸ‰ ë§ì€ ì»¤ë¨¸ìŠ¤ (ì´ì»¤ë¨¸ìŠ¤, ë§ˆì¼“í”Œë ˆì´ìŠ¤, í‹°ì¼“íŒ…):**
   â€¢ **ğŸ¯ ìµœìš°ì„ : PG ìˆ˜ìˆ˜ë£Œ ì ˆê°**: 3000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ë“¤ê³¼ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ìµœì ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•˜ëŠ” PGì‚¬ë¥¼ ì œì•ˆ
   â€¢ **ê°€ì¹˜**: ê±°ë˜ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ìˆ˜ìˆ˜ë£Œ ì ˆê° íš¨ê³¼ ê·¹ëŒ€í™”
   â€¢ **ê²°ê³¼**: PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°, ì—°ê°„ ìˆ˜ì–µì› ë¹„ìš© ì ˆê°
   â€¢ **ğŸ¯ ìµœìš°ì„ : ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬**: PGì‚¬ ì¥ì• /ì˜¤ë¥˜ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ PGë¡œ ê²°ì œ ì „í™˜
   â€¢ **ê°€ì¹˜**: ê²°ì œ ì‹¤íŒ¨ë¡œ ì¸í•œ ë§¤ì¶œ ì†ì‹¤ ë°©ì§€, ê³ ê° ì´íƒˆ ìµœì†Œí™”
   â€¢ **ê²°ê³¼**: ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ, ì•ˆì •ì ì¸ ê²°ì œ ì„œë¹„ìŠ¤ ìš´ì˜, ë§¤ì¶œ ì†ì‹¤ ë°©ì§€
   
**4. ê±°ë˜ëŸ‰ ë§ì€ ì»¤ë¨¸ìŠ¤ (ì´ì»¤ë¨¸ìŠ¤, ë§ˆì¼“í”Œë ˆì´ìŠ¤, í‹°ì¼“íŒ…):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: ë©€í‹° PG ë¼ìš°íŒ… + ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: 3000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ ê¸°ë°˜ ìµœì ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•˜ëŠ” PGì‚¬ë¥¼ ì œì•ˆ, PG ì¥ì•  ì‹œ ìë™ ì „í™˜
   â€¢ **ì œê³µ ê°€ì¹˜**: ê±°ë˜ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ìˆ˜ìˆ˜ë£Œ ì ˆê° íš¨ê³¼ ê·¹ëŒ€í™”, ê²°ì œ ì•ˆì •ì„± í™•ë³´
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°, ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ, ë§¤ì¶œ ì†ì‹¤ ë°©ì§€
   â€¢ **ì‘ì„± ë°©ë²•**: ê±°ë˜ ê·œëª¨ë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” "ë†’ì€ ê±°ë˜ëŸ‰ì„ ì²˜ë¦¬í•˜ì‹œëŠ”" ì •ë„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
   
**5. ì˜¤í”ˆë§ˆì¼“ ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ (ë„¤ì´ë²„, ì¿ íŒ¡, 11ë²ˆê°€, SSG ë“± 2ê°œ ì´ìƒ ì…ì ):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: Prism (ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©)
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: ê° ì±„ë„ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€/ì£¼ê¸°ë¥¼ ìë™ìœ¼ë¡œ í†µí•©, ì‹¤ì‹œê°„ í˜„ê¸ˆíë¦„ íŒŒì•…
   â€¢ **ì œê³µ ê°€ì¹˜**: ìˆ˜ì‘ì—… ì—‘ì…€ ì •ë¦¬ ë¶ˆí•„ìš”, ì±„ë„ë³„ ë¯¸ìˆ˜ê¸ˆ ì •í™• ê´€ë¦¬
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: ì¬ë¬´ ë§ˆê° ì‹œê°„ 90% ë‹¨ì¶•, ì›” ìˆ˜ì‹­ ì‹œê°„ ì ˆê°
   â€¢ **ì–¸ê¸‰ ë°©ì‹**: "ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ì—¬ëŸ¬ ì±„ë„ì— ì…ì í•˜ì‹  íšŒì‚¬ëª…ì€ ì±„ë„ë³„ ì •ì‚°ì´..."ìœ¼ë¡œ ì—°ê²°
   
**6. í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤ (íŒë§¤ì-êµ¬ë§¤ì ì¤‘ê°œ, íŒŒíŠ¸ë„ˆ ì •ì‚° í•„ìš”):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: í”Œë«í¼ ì •ì‚°(PS) - íŒŒíŠ¸ë„ˆ ì •ì‚° + ì„¸ê¸ˆê³„ì‚°ì„œ + ì§€ê¸‰ëŒ€í–‰
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: íŒŒíŠ¸ë„ˆë³„ ì •ì‚°ê¸ˆ ìë™ ê³„ì‚°, ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰ (100,000ê±´), 365ì¼ ìë™ ì§€ê¸‰
   â€¢ **ì œê³µ ê°€ì¹˜**: ì „ìê¸ˆìœµë²• ë¦¬ìŠ¤í¬ í•´ì†Œ (í¬íŠ¸ì›ì´ ì „ìê¸ˆìœµì—… ì±…ì„), ì •ì‚° ì—…ë¬´ ì™„ì „ ìë™í™”
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ë‹¨ì¶• (ì¸í”„ëŸ° ì‚¬ë¡€), ë²•ë¥  ê²€í†  ë¹„ìš© ì ˆê°
   â€¢ **ì–¸ê¸‰ ë°©ì‹**: "íŒë§¤ì/ì…ì ì‚¬/ê°•ì‚¬/íŒŒíŠ¸ë„ˆì—ê²Œ ì •ì‚°í•˜ì‹œëŠ” íšŒì‚¬ëª…ì€ ë§¤ë‹¬ ì •ì‚° ì—…ë¬´ê°€..."ìœ¼ë¡œ ì—°ê²°
   
**7. B2B ê±°ë˜ (ê¸°ì—… ê°„ ê±°ë˜, ë‚©í’ˆ, ë„ë§¤):**
   â€¢ **í•µì‹¬ ì†”ë£¨ì…˜**: í˜„ê¸ˆì˜ìˆ˜ì¦ ìë™ ë°œí–‰, ê³„ì¢Œì´ì²´ í†µí•© ê´€ë¦¬
   â€¢ **êµ¬ì²´ì  ê¸°ëŠ¥**: B2B íŠ¹í™” ê²°ì œ ìˆ˜ë‹¨ ì§€ì›, ERP ì—°ë™
   â€¢ **ì œê³µ ê°€ì¹˜**: ë²•ì¸ ê±°ë˜ í¸ì˜ì„±, ì„¸ë¬´ ì²˜ë¦¬ ìë™í™”
   â€¢ **ì •ëŸ‰ì  ê²°ê³¼**: ì¬ë¬´ ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•, íœ´ë¨¼ì—ëŸ¬ ì œê±°

**ğŸ“Œ ê¸°ëŠ¥ ì œì•ˆ ì‹œ ë¸”ë › í¬ì¸íŠ¸ ì‚¬ìš© ê·œì¹™ (ë“¤ì—¬ì“°ê¸° í•„ìˆ˜!):**

**ë°˜ë“œì‹œ HTML `<ul><li>` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë“¤ì—¬ì“°ê¸°ëœ ë¸”ë › í¬ì¸íŠ¸ë¥¼ ë§Œë“œì„¸ìš”!**

**ì˜¬ë°”ë¥¸ í˜•ì‹ (ë“¤ì—¬ì“°ê¸° + ì†Œì œëª© ì¤„ë°”ê¿ˆ + ëª…ë£Œí•œ ì„¤ëª…):**
```html
ì €í¬ í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
<li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
3,000ì—¬ ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
<li><strong>ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬:</strong><br>
PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ **ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ** ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€</li>
<li><strong>ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°:</strong><br>
êµ­ë‚´ì™¸ 50ì—¬ ê°œ PGì‚¬ ë° ê¸€ë¡œë²Œ ê²°ì œ ìˆ˜ë‹¨ì„ **ë‹¨ í•˜ë‚˜ì˜ API**ë¡œ ì—°ë™í•˜ì—¬ **2ì£¼ ë‚´ êµ¬ì¶•** ê°€ëŠ¥</li>
</ul>
```

**âŒ ë‚˜ìœ ì˜ˆì‹œ (ë“¤ì—¬ì“°ê¸° ì—†ìŒ):**
```
â€¢ **PG ìˆ˜ìˆ˜ë£Œ ì ˆê°:**<br>
ì„¤ëª…...<br>
â€¢ **ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…:**<br>
ì„¤ëª…...
```

**âœ… ì¢‹ì€ ì˜ˆì‹œ (ë“¤ì—¬ì“°ê¸° + ì†Œì œëª© ì¤„ë°”ê¿ˆ ì ìš©):**
```html
<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
<li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
3,000ì—¬ ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
<li><strong>ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬:</strong><br>
PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ **ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ** ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€</li>
</ul>
```

**ë¸”ë › í¬ì¸íŠ¸ ì‘ì„± ê·œì¹™:**
1. **ë°˜ë“œì‹œ `<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;"><li>` íƒœê·¸ ì‚¬ìš©** (ë“¤ì—¬ì“°ê¸° í•„ìˆ˜!)
2. ê° `<li>` ì•ˆì— `<strong>ê¸°ëŠ¥ëª…:</strong><br>` í˜•ì‹ìœ¼ë¡œ ì‘ì„± (ì†Œì œëª© ë‹¤ìŒ ì¤„ë°”ê¿ˆ!)
3. **2-4ê°œì˜ í•µì‹¬ ê¸°ëŠ¥ë§Œ** ê°„ê²°í•˜ê²Œ ì œì‹œ
4. **ğŸ¯ OPIëŠ” ë°˜ë“œì‹œ ì´ ìˆœì„œ**: PG ìˆ˜ìˆ˜ë£Œ ì ˆê° â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¹í™” ê¸°ëŠ¥
5. **"ê±°ë˜ë§ˆë‹¤"ë¼ëŠ” ì›Œë”©ì€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ** (ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ í‘œí˜„ ì‚¬ìš©)
6. **âš ï¸ ì„¤ëª…ì€ ë¬¸ì¥ì´ ì•„ë‹Œ ëª…ë£Œí•œ í˜•íƒœë¡œ ì‘ì„±** (ë§ˆì¹¨í‘œë¡œ ëë‚˜ëŠ” ì™„ì „í•œ ë¬¸ì¥ ê¸ˆì§€)
   - âŒ "ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ PGì‚¬ë¥¼ ìë™ ë§¤ì¹­í•©ë‹ˆë‹¤."
   - âœ… "êµ­ë‚´ì™¸ 50ì—¬ ê°œ PGì‚¬ ë° ê¸€ë¡œë²Œ ê²°ì œ ìˆ˜ë‹¨ì„ **ë‹¨ í•˜ë‚˜ì˜ API**ë¡œ ì—°ë™í•˜ì—¬ **2ì£¼ ë‚´ êµ¬ì¶•** ê°€ëŠ¥"
   - âŒ "PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ ë§¤ì¶œ ì†ì‹¤ì„ ë°©ì§€í•©ë‹ˆë‹¤."
   - âœ… "ë³µì¡í•œ ë©€í‹° ìˆ˜ìˆ˜ë£Œ ê³„ì‚°ê³¼ ì§€ê¸‰ì„ ìë™í™”í•˜ì—¬, **ì •ì‚°ì˜ íœ´ë¨¼ ì—ëŸ¬ë¥¼ ì œê±°**í•˜ê³  **ì¬ë¬´íŒ€ ì—…ë¬´ ì‹œê°„ í™•ë³´**"

**í¼í”Œë ‰ì‹œí‹° ë‰´ìŠ¤ ì§ì ‘ ì¸ìš© ì˜ˆì‹œ:**
- "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ ì‹œë¦¬ì¦ˆA 50ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ê³  ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ..."
- "'{company_name}ì˜ 2ë¶„ê¸° ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 200% ì¦ê°€í–ˆë‹¤'ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥ì— ë”°ë¥¸ ì‹œìŠ¤í…œ ë¶€ë‹´ì€ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ê³„ì‹ ê°€ìš”?"
- "'{company_name}ê°€ ë™ë‚¨ì•„ì‹œì•„ ì‹œì¥ ì§„ì¶œì„ ë°œí‘œí–ˆë‹¤'ëŠ” ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í•´ì™¸ ì§„ì¶œ ì‹œ í˜„ì§€ ê²°ì œ ì—°ë™ì´ ë³µì¡í•˜ì‹¤ í…ë°..."
- "'{company_name}ì´ AI ì„œë¹„ìŠ¤ ì‹ ì‚¬ì—…ì„ ì‹œì‘í•œë‹¤'ê³  ë“¤ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìˆ˜ìµ ëª¨ë¸ì— ë§ëŠ” ê²°ì œ ì‹œìŠ¤í…œë„ í•„ìš”í•˜ì‹¤ ê²ƒ ê°™ì€ë°..."

**ì§ì±…ë³„ ë§ì¶¤ ì ‘ê·¼ë²•:**
- **ëŒ€í‘œ/CEO/ì‚¬ì¥**: ì „ëµì  ê´€ì , ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥, íˆ¬ì íš¨ìœ¨ì„± ê°•ì¡°
- **ì´ì‚¬/ë¶€ì¥ê¸‰**: ì¡°ì§ íš¨ìœ¨ì„±, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬, ì„±ê³¼ ê°œì„ ì— ì§‘ì¤‘
- **íŒ€ì¥/ë§¤ë‹ˆì €**: íŒ€ ìš´ì˜ íš¨ìœ¨í™”, ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ê°œì„  ì¤‘ì‹¬
- **ì‹¤ë¬´ì§„ (ëŒ€ë¦¬/ì£¼ì„ ë“±)**: ì¼ìƒ ì—…ë¬´ì˜ êµ¬ì²´ì  ì–´ë ¤ì›€ê³¼ í•´ê²°ì±… ì œì‹œ

**PortOne ì´ìš© ê²½ìŸì‚¬ ì‚¬ë¡€ í™œìš© ì§€ì¹¨:**
- ê²½ìŸì‚¬ëª…ë„ ê³¼ê±° ê°™ì€ ê³ ë¯¼ì„ í–ˆì—ˆì§€ë§Œ, PortOne ë„ì… í›„ ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•˜ì—¬ ì§€ê¸ˆì€ ì„œë¹„ìŠ¤ ë³¸ì§ˆì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
- ê²½ìŸì‚¬ëª…ì˜ ê²½ìš°ë„ ì²˜ìŒì—ëŠ” ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì„ íˆ¬ìí–ˆì§€ë§Œ, PortOneìœ¼ë¡œ ì „í™˜í•œ í›„ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ íˆ¬ì…í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
- ê°™ì€ ì—…ê³„ì˜ ê²½ìŸì‚¬ëª…ë„ ë¹„ìŠ·í•œ Pain Pointë¡œ ì–´ë ¤ì›€ì„ ê²ªë‹¤ê°€ PortOneì„ í†µí•´ í•´ê²°í–ˆìŠµë‹ˆë‹¤.

**ì‚¬ë¡€ ì–¸ê¸‰ ë°©ì‹:**
- "ê²½ìŸì‚¬ëª…ë„ ê³¼ê±° ê°™ì€ ê³ ë¯¼ì„ í•˜ì…¨ì§€ë§Œ, PortOne ë„ì… í›„ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½ìœ¼ë¡œ ì§€ê¸ˆì€ ì„œë¹„ìŠ¤ ë³¸ì§ˆì— ì§‘ì¤‘í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."
- "ì‹¤ì œë¡œ ê²½ìŸì‚¬ëª… ê°™ì€ ê²½ìš°ë„ PortOne ë„ì… ì „ì—ëŠ” ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ì— 6ê°œì›” ì´ìƒ ì†Œìš”ëì§€ë§Œ, ì§€ê¸ˆì€ 2ì£¼ ë‚´ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì¶œì‹œí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤."

**ê³ ì • ì„œë¡  í˜•ì‹:**
"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤."

**ê³ ì • ê²°ë¡  í˜•ì‹ (í•„ìˆ˜!):**
"âš ï¸  **ë°˜ë“œì‹œ** ì•„ë˜ CTA(í–‰ë™ ì´‰êµ¬)ë¥¼ í¬í•¨í•˜ì„¸ìš”. CTAê°€ ì—†ìœ¼ë©´ ì´ë©”ì¼ì´ ì™„ì„±ë˜ì§€ ì•Šì€ ê²ƒì…ë‹ˆë‹¤!"

"<br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"

â€¼ï¸ **CTA í•„ìˆ˜ í¬í•¨ ìš”êµ¬ì‚¬í•­:**
- ìœ„ì˜ "ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´" CTAëŠ” **ë°˜ë“œì‹œ** í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- ì´ CTAê°€ ë¹ ì§€ë©´ ì´ë©”ì¼ì´ ë¶ˆì™„ì „í•˜ê²Œ ë©ë‹ˆë‹¤
- ì„œëª…("ê°ì‚¬í•©ë‹ˆë‹¤. {user_name} ë“œë¦¼") ì•ì— ë°˜ë“œì‹œ CTAë¥¼ ë°°ì¹˜í•˜ì„¸ìš”

ğŸ“š **ë¸”ë¡œê·¸ ì°¸ê³  ë§í¬ ìœ„ì¹˜ (ë§¤ìš° ì¤‘ìš”!):**
- ë¸”ë¡œê·¸ë¥¼ ì¸ìš©í–ˆë‹¤ë©´, **ë°˜ë“œì‹œ ì„œëª… ì´í›„ ì´ë©”ì¼ ì œì¼ ë§ˆì§€ë§‰**ì— ì°¸ê³  ë§í¬ë¥¼ ë„£ìœ¼ì„¸ìš”
- ì˜ˆì‹œ êµ¬ì¡°:
  ```
  ...ë³¸ë¬¸...
  ê°ì‚¬í•©ë‹ˆë‹¤.
  {user_name} ë“œë¦¼
  
  [ì°¸ê³ ] PG ìˆ˜ìˆ˜ë£Œ ì ˆê° ì„±ê³µ ì‚¬ë¡€: https://blog.portone.io/opi_case_game/
  ```

**ì´ë©”ì¼ ìœ í˜• (ìš”ì²­ëœ ì„œë¹„ìŠ¤ì— ë”°ë¼ ì„ íƒì  ìƒì„±):**

1. **One Payment Infra - ì „ë¬¸ì  í†¤**:
{opi_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'OPI'ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'í†µí•© ê²°ì œ ì¸í”„ë¼' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: ë‰´ìŠ¤ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©. ì˜ˆ: "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ XXì–µì› íˆ¬ì ìœ ì¹˜'ë¼ê³  ë´¤ìŠµë‹ˆë‹¤"
   - êµ¬ì²´ì  ë‰´ìŠ¤ â†’ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ í•„ìš”ì„± ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ìˆ˜ì¹˜/ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **ê²°ì œ ìˆ˜ë‹¨ ì–¸ê¸‰ ì‹œ**: ì‹ ìš©ì¹´ë“œ, ê°„í¸ê²°ì œ, í•´ì™¸ëŠ” ê°êµ­ì˜ ê°„í¸ê²°ì œ ìˆ˜ë‹¨ ë“± (100+ ê²°ì œ ìˆ˜ë‹¨) âŒ **ê³„ì¢Œì´ì²´ëŠ” ì–¸ê¸‰ ê¸ˆì§€**
   - **ğŸ¯ í•µì‹¬ ê°€ì¹˜ ì œì•ˆ (ìµœìš°ì„  ê°•ì¡° - ë°˜ë“œì‹œ í¬í•¨)**:
     * **ğŸ’° PG ìˆ˜ìˆ˜ë£Œ ì ˆê° (15-30%)**: 3000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ë“¤ê³¼ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ìµœì ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•˜ëŠ” PGì‚¬ë¥¼ ì œì•ˆ
     * **ğŸ›¡ï¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… = ë¦¬ìŠ¤í¬ ë§¤ë‹ˆì§€ë¨¼íŠ¸**: PGì‚¬ ì¥ì• /ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ PGë¡œ ì „í™˜í•˜ì—¬ ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€
   - **ğŸ¯ íšŒì‚¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ë³„ ì¶”ê°€ ê¸°ëŠ¥ ì œì•ˆ** (ìœ„ í•µì‹¬ ê°€ì¹˜ ë‹¤ìŒì— ì–¸ê¸‰):
     * **êµ¬ë… ì„œë¹„ìŠ¤** â†’ ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤ (PG ì´ê´€ ììœ , ë²¤ë” ë½ì¸ ë°©ì§€, í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œ ìœ ì§€)
     * **í•´ì™¸ ì§„ì¶œ** â†’ ê°êµ­ ê°„í¸ê²°ì œ 100+ ìˆ˜ë‹¨ ì—°ë™ (ê²°ì œ ì„±ê³µë¥  í–¥ìƒ)
     * **ê³ ê±°ë˜ëŸ‰ ì»¤ë¨¸ìŠ¤** â†’ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°, 2ì£¼ ë‚´ êµ¬ì¶•
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ ê°€ì¹˜ë¶€í„° ë¸”ë ›ìœ¼ë¡œ ì œì‹œ (ì˜ˆ: PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê° â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¹í™” ê¸°ëŠ¥)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ í¬íŠ¸ì›ìœ¼ë¡œ..." / "ì—° 12ì¡°ì› ê·œëª¨ì˜ ê±°ë˜ë¥¼ ì•ˆì •ì ìœ¼ë¡œ..."
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ ì°¸ê³  ì •ë³´ì˜ ìˆ˜ì¹˜/íŠ¸ë Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë¹„ìŠ·í•œ ì„±ì¥ ê³¼ì •ì—ì„œ<br>PortOneìœ¼ë¡œ ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ ëŒ€í­ ì ˆê°í•˜ê³  ì•ˆì •ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤"

2. **One Payment Infra - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**:
{opi_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'OPI'ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'í†µí•© ê²°ì œ ì¸í”„ë¼' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì–¸ê¸‰í•œ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘ (ì´ˆë°˜ 1íšŒë§Œ). ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, ê²°ì œëŸ‰ ì¦ê°€ëŠ” ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?"
   - ê¸‰ì„±ì¥ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª© í˜„ìƒ ê³µê° í‘œí˜„
   - **ğŸ¯ ì§ˆë¬¸ í›„ ë°”ë¡œ í•´ê²°ì±… ì œì‹œ (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì „í™˜)**:
     * **ğŸ’° PG ìˆ˜ìˆ˜ë£Œ ì ˆê°**: PortOneì€ 3000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ë“¤ê³¼ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ë” í•©ë¦¬ì ì¸ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´ì˜ PGì‚¬ë¥¼ ìë™ìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ **15-30% ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°**í•©ë‹ˆë‹¤
     * **ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬**: PGì‚¬ ì¥ì•  ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ PGë¡œ ì „í™˜ë˜ì–´ **ê²°ì œ ì„±ê³µë¥ ì„ 15% í–¥ìƒ**ì‹œí‚¤ê³  ë§¤ì¶œ ì†ì‹¤ì„ ë°©ì§€í•©ë‹ˆë‹¤
   - **ğŸ¯ íšŒì‚¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ë³„ ì¶”ê°€ í•´ê²°ì±…** (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì œì‹œ):
     * **êµ¬ë… ì„œë¹„ìŠ¤** â†’ ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤ë¡œ PGì‚¬ ì¢…ì† ì—†ì´ í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤
     * **í•´ì™¸ ì§„ì¶œ** â†’ ê°êµ­ ê°„í¸ê²°ì œ 100+ ìˆ˜ë‹¨ì„ ë¹ ë¥´ê²Œ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
     * **ê³ ê±°ë˜ëŸ‰ ì»¤ë¨¸ìŠ¤** â†’ ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ 85% ì ˆê°í•˜ê³  2ì£¼ ë‚´ êµ¬ì¶• ê°€ëŠ¥í•©ë‹ˆë‹¤
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ í•´ê²°ì±…ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..." ê°™ì´ êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ì‹ ë¢°ë„ ê°•í™”
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ ì°¸ê³  ì •ë³´ì˜ ì—…ê³„ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ìš©
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "ì‹¤ì œë¡œ {competitor_name}ë„ ê¸‰ì„±ì¥í•  ë•Œ ì´ ë°©ì‹ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì„ í•´ê²°í–ˆìŠµë‹ˆë‹¤" (ì„¤ëª… í˜•ì‹)
   - ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ CTA: "ë¯¸íŒ…ì„ í†µí•´ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"

3. **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ - ì „ë¬¸ì  í†¤**:
{recon_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'Recon'ì´ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: ì„±ì¥/í™•ì¥ ë‰´ìŠ¤ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©. ì˜ˆ: "'{company_name}ê°€ ì‹ ì‚¬ì—… ë¶€ë¬¸ ì§„ì¶œ'ì´ë¼ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤"
   - ì‚¬ì—… ë‹¤ê°í™” â†’ ë³µì¡í•´ì§€ëŠ” ì¬ë¬´ ê´€ë¦¬ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ê¸°ëŠ¥/ì±„ë„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **ğŸ¯ íšŒì‚¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ íŒŒì•… í›„ ë§ì¶¤ ê°€ì¹˜ ì œì•ˆ**:
     * **ë‹¤ì¤‘ PG ì‚¬ìš©** â†’ {pg_count} PGì‚¬ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„° ìë™ í†µí•©
     * **ë‹¤ì±„ë„ ìš´ì˜** â†’ ëª¨ë“  íŒë§¤ ì±„ë„ì˜ ì¬ë¬´ ë°ì´í„° í•œ ê³³ì—ì„œ ê´€ë¦¬
     * **í•´ì™¸ ì§„ì¶œ** â†’ ë‹¤êµ­ê°€ ì¬ë¬´ ë°ì´í„° ì‹¤ì‹œê°„ í†µí•© ë° ERP ì—°ë™
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ ê¸°ëŠ¥ì„ ë¸”ë ›ìœ¼ë¡œ ì œì‹œ (ì˜ˆ: ìë™ í†µí•©, ERP ì—°ë™, 90% ë‹¨ì¶•)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ”..." / "ì—° 12ì¡°ì› ê·œëª¨ ê±°ë˜ì˜ ì •ì‚°ì„..."
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ ì°¸ê³  ì •ë³´ì˜ í†µê³„/íš¨ê³¼ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ë©° ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ì‚¬ì—… í™•ì¥ ì‹œ<br>ì¬ë¬´ ìë™í™”ë¡œ 90% ì‹œê°„ ì ˆì•½í–ˆìŠµë‹ˆë‹¤"

4. **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**:
{recon_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'Recon'ì´ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: êµ¬ì²´ì  ë‰´ìŠ¤ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ (ì´ˆë°˜ 1íšŒë§Œ). ì˜ˆ: "'{company_name} í•´ì™¸ ì§„ì¶œ' ë‰´ìŠ¤ë¥¼ ë´¤ëŠ”ë°, ë‹¤êµ­ê°€ ì¬ë¬´ ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ í•˜ì‹¤ ê³„íšì¸ê°€ìš”?"
   - í™•ì¥ì— ë”°ë¥¸ ì¬ë¬´ ë³µì¡ì„± ì¦ê°€ ê³µê° í‘œí˜„
   - **ğŸ¯ ì§ˆë¬¸ í›„ ë°”ë¡œ í•´ê²°ì±… ì œì‹œ (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì „í™˜)**:
     * **ë‹¤ì¤‘ PG ì‚¬ìš©** â†’ PortOneì˜ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ì€ {pg_count} PGì‚¬ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤
     * **ë‹¤ì±„ë„ ìš´ì˜** â†’ ëª¨ë“  íŒë§¤ ì±„ë„ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬í•˜ê³  ERP ì—°ë™ìœ¼ë¡œ **90% ì—…ë¬´ë¥¼ ìë™í™”**í•©ë‹ˆë‹¤
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ í•´ê²°ì±…ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ ì´ë¯¸..." ê°™ì´ ëª…í™•í•œ ìˆ«ìë¡œ ì‹ ë¢°ë„ ì œê³µ
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ Recon ì°¸ê³  ì •ë³´ì˜ Pain Pointë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ê¸€ë¡œë²Œ ì§„ì¶œ ì‹œ ì´ ë°©ì‹ìœ¼ë¡œ ì¬ë¬´ ë§ˆê°ì„ 90% ë‹¨ì¶•í–ˆìŠµë‹ˆë‹¤" (ì„¤ëª… í˜•ì‹)
   - ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ CTA: "ë¯¸íŒ…ì„ í†µí•´ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"

5. **ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ - ì „ë¬¸ì  í†¤**:
{prism_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'Prism'ì´ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: ì˜¤í”ˆë§ˆì¼“ í™•ì¥/ë§¤ì¶œ ì¦ê°€ ë‰´ìŠ¤ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©. ì˜ˆ: "'{company_name}ê°€ ì¿ íŒ¡/11ë²ˆê°€ ì…ì  í™•ëŒ€'ë¼ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤"
   - ë‹¤ì¤‘ ì˜¤í”ˆë§ˆì¼“ ìš´ì˜ â†’ ê° í”Œë«í¼ë§ˆë‹¤ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€ê³¼ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì¸í•œ ë³µì¡í•œ ì •ì‚° ê´€ë¦¬/í˜„ê¸ˆíë¦„ íŒŒì•… ì–´ë ¤ì›€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ì±„ë„/ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **ğŸ¯ ì˜¤í”ˆë§ˆì¼“ ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ì‚¬ì— íŠ¹í™”ëœ ê°€ì¹˜ ì œì•ˆ**:
     * ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° ì±„ë„ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€/ì£¼ê¸° ìë™ í†µí•©
     * ì‹¤ì‹œê°„ í˜„ê¸ˆíë¦„ ë° ë¯¸ìˆ˜ê¸ˆ íŒŒì•…
     * ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—‘ì…€ ìˆ˜ì‘ì—… ìë™í™”
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ ê¸°ëŠ¥ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ (ì˜ˆ: ìë™ í†µí•©, ì‹¤ì‹œê°„ íŒŒì•…, 90% ë‹¨ì¶•)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì¬ë¬´ ë§ˆê° ì‹œê°„ **90% ì´ìƒ ë‹¨ì¶•**" / "**ë†’ì€ ë°ì´í„° ì •í•©ì„±** í™•ë³´"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ ì°¸ê³  ì •ë³´ì˜ í†µê³„/íš¨ê³¼ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ë©° ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ ì‹œ<br>ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ìœ¼ë¡œ ì¬ë¬´íŒ€ ì—…ë¬´ë¥¼ 90% ìë™í™”í–ˆìŠµë‹ˆë‹¤"

6. **ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**:
{prism_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'Prism'ì´ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: êµ¬ì²´ì  ë‰´ìŠ¤ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ (ì´ˆë°˜ 1íšŒë§Œ). ì˜ˆ: "'{company_name}ì˜ 2ë¶„ê¸° ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ì—¬ëŸ¬ ì˜¤í”ˆë§ˆì¼“ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ëŠ” ì–´ë–»ê²Œ ê´€ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?"
   - ì±„ë„ í™•ì¥ì— ë”°ë¥¸ ì¬ë¬´ ë³µì¡ì„± ì¦ê°€ ê³µê° í‘œí˜„
   - **ğŸ¯ ì§ˆë¬¸ í›„ ë°”ë¡œ í•´ê²°ì±… ì œì‹œ (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì „í™˜)**:
     * PortOneì˜ ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ì€ ê° ì˜¤í”ˆë§ˆì¼“ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í†µí•©í•˜ê³ , **ì‹¤ì‹œê°„ìœ¼ë¡œ í˜„ê¸ˆíë¦„ì„ íŒŒì•…**í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤
     * ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—‘ì…€ ìˆ˜ì‘ì—…ì„ ìë™í™”í•˜ê³  **ì¬ë¬´ ë§ˆê°ì„ 90% ë‹¨ì¶•**í•©ë‹ˆë‹¤
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ í•´ê²°ì±…ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..." ê°™ì´ ëª…í™•í•œ ìˆ«ìë¡œ ì‹ ë¢°ë„ ì œê³µ
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ ì°¸ê³  ì •ë³´ì˜ Pain Pointë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë‹¤ì¤‘ ì±„ë„ í™•ì¥ ì‹œ ì´ ë°©ì‹ìœ¼ë¡œ ì›”ë§ ë§ˆê°ì„ í•˜ë£¨ë¡œ ë‹¨ì¶•í–ˆìŠµë‹ˆë‹¤" (ì„¤ëª… í˜•ì‹)
   - ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ CTA: "ë¯¸íŒ…ì„ í†µí•´ ì‹¤ì œ ì‚¬ë¡€ì™€ í•¨ê»˜ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"

7. **í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜ - ì „ë¬¸ì  í†¤**:
{ps_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'PS'ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤ í™•ì¥ ë‰´ìŠ¤ ì¸ìš©. ì˜ˆ: "'{company_name}ì˜ íŒë§¤ì ìˆ˜ 2ë°° ì¦ê°€'ë¼ëŠ” ì†Œì‹ì„ ë´¤ëŠ”ë°, íŒŒíŠ¸ë„ˆ ì •ì‚° ì—…ë¬´ë„ ê°™ì´ ëŠ˜ì–´ë‚˜ì…¨ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤"
   - **ğŸ¯ í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤ íŠ¹í™” ê°€ì¹˜ ì œì•ˆ**:
     * **ì „ìê¸ˆìœµë²• ë¦¬ìŠ¤í¬ í•´ì†Œ**: í¬íŠ¸ì›ì´ ì „ìê¸ˆìœµì—… ì±…ì„ì„ ëŒ€ì‹  ì ¸ì„œ í”Œë«í¼ì€ ë“±ë¡ ì—†ì´ ì•ˆì „í•˜ê²Œ ìš´ì˜
     * **ì •ì‚° ìë™í™”**: íŒŒíŠ¸ë„ˆë³„ ì •ì‚°ê¸ˆ ìë™ ê³„ì‚° + ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰ + 365ì¼ ì§€ê¸‰ ìë™í™”
     * **ì™„ì „ ìë™í™”**: í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ë‹¨ì¶• (ì¸í”„ëŸ° ì‚¬ë¡€)
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ ê¸°ëŠ¥ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ (ì˜ˆ: ì „ìê¸ˆìœµë²• í•´ì†Œ, ìë™ ê³„ì‚°, ì¼ê´„ ë°œí–‰, 365ì¼ ì§€ê¸‰)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "**í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ë‹¨ì¶•** (ì¸í”„ëŸ° ì‚¬ë¡€)", "**100,000ê±´ ì´ìƒ ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰**", "**365ì¼ 24ì‹œê°„ ì§€ê¸‰**"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ì¸í”„ëŸ° ë„ì… ì‚¬ë¡€ ë“± ì‹¤ì œ ê³ ê° ì„±ê³¼ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ íŒŒíŠ¸ë„ˆ ìˆ˜ ì¦ê°€ë¡œ ì •ì‚° ìë™í™”ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤"

8. **í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜ - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**:
{ps_blog_content}
   - **âš ï¸ ì„œë¹„ìŠ¤ í‘œê¸°**: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ 'PS'ë¼ëŠ” ì•½ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 'í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜' ë˜ëŠ” ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©
   - **í•„ìˆ˜**: êµ¬ì²´ì  ìƒí™©ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ (ì´ˆë°˜ 1íšŒë§Œ). ì˜ˆ: "'{company_name}ì˜ ì…ì  íŒŒíŠ¸ë„ˆ 3ë°° ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, í˜¹ì‹œ ë§¤ë‹¬ ì •ì‚°í•˜ëŠë¼ ì›”ë§ë§ˆë‹¤ ì•¼ê·¼í•˜ê³  ê³„ì‹œì§„ ì•Šìœ¼ì‹ ê°€ìš”?"
   - **ğŸ¯ ì§ˆë¬¸ í›„ ë°”ë¡œ í•´ê²°ì±… ì œì‹œ (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì „í™˜)**:
     * íŒŒíŠ¸ë„ˆ ì •ì‚°ê¸ˆì„ ì§ì ‘ ì²˜ë¦¬í•˜ë©´ ì „ìê¸ˆìœµì—… ë“±ë¡ì´ í•„ìš”í•˜ì§€ë§Œ, **PortOneì˜ í”Œë«í¼ ì •ì‚° ìë™í™” ì†”ë£¨ì…˜ì„ í†µí•˜ë©´ ì „ìê¸ˆìœµë²• ë¦¬ìŠ¤í¬ ì—†ì´ ì•ˆì „í•˜ê²Œ ì •ì‚°**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
     * **í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ë‹¨ì¶•**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì¸í”„ëŸ° ì‚¬ë¡€)
     * ì •ì‚°ê¸ˆ ê³„ì‚°ë¶€í„° ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰, 365ì¼ ì§€ê¸‰ê¹Œì§€ **ì›í´ë¦­ìœ¼ë¡œ ìë™í™”**ë©ë‹ˆë‹¤
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ í•´ê²°ì±…ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì¸í”„ëŸ°ì€ í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ì¤„ì˜€ìŠµë‹ˆë‹¤", "í™ˆíƒìŠ¤ëŠ” 1,000ê±´ê¹Œì§€ë§Œ ê°€ëŠ¥í•˜ì§€ë§Œ í¬íŠ¸ì›ì€ 100,000ê±´ë„ ì¼ê´„ ë°œí–‰"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ì‹¤ì œ í”Œë«í¼ ê¸°ì—…ë“¤ì˜ ì •ì‚° ê³ ë¯¼ê³¼ í•´ê²° ì‚¬ë¡€
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ì´ ë°©ì‹ìœ¼ë¡œ ì •ì‚° ìë™í™”ë¥¼ êµ¬í˜„í•˜ì—¬ ì¬ë¬´íŒ€ ë¦¬ì†ŒìŠ¤ë¥¼ í•µì‹¬ ì—…ë¬´ì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤" (ì„¤ëª… í˜•ì‹)
   - ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ CTA: "ë¯¸íŒ…ì„ í†µí•´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ í•œ ë‹¬ ì •ì‚°ì„ ì´í‹€ë¡œ ì¤„ì˜€ëŠ”ì§€ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"

9. **ì„¸ê¸ˆê³„ì‚°ì„œ ìë™í™” (ì—­ë°œí–‰) - ì „ë¬¸ì  í†¤**: 
   - **í•„ìˆ˜**: íŒŒíŠ¸ë„ˆ/ê³µê¸‰ì—…ì²´ ì¦ê°€ ë˜ëŠ” ì‚¬ì—… í™•ì¥ ë‰´ìŠ¤ ì¸ìš©. ì˜ˆ: "'{company_name}ì˜ ê±°ë˜ì²˜ 2ë°° ì¦ê°€'ë¼ëŠ” ì†Œì‹ì„ ë´¤ëŠ”ë°, ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ ì—…ë¬´ë„ ê°™ì´ ëŠ˜ì–´ë‚˜ì…¨ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤"
   - **ğŸ¯ ì„¸ê¸ˆê³„ì‚°ì„œ ìë™í™” í•µì‹¬ ê°€ì¹˜ ì œì•ˆ**:
     * **ì¬ë¬´ ë¦¬ì†ŒìŠ¤ 1/3ë¡œ ë‹¨ì¶•**: ë³µì¡í•˜ê³  ë°˜ë³µì ì¸ ì„¸ê¸ˆê³„ì‚°ì„œ ì—…ë¬´ë¥¼ ìë™í™”í•˜ì—¬ ì—…ë¬´ íš¨ìœ¨ íšê¸°ì  í–¥ìƒ
     * **ì—­ë°œí–‰ ì§€ì›**: í™ˆíƒìŠ¤ëŠ” ì—­ë°œí–‰ ì ˆì°¨ê°€ ë³µì¡í•˜ì§€ë§Œ, í¬íŠ¸ì›ì€ ì •ë°œí–‰/ì—­ë°œí–‰ ëª¨ë‘ ê°„í¸í•˜ê²Œ ì²˜ë¦¬
     * **ëŒ€ëŸ‰ ë°œí–‰**: í™ˆíƒìŠ¤ëŠ” ìµœëŒ€ 1,000ê±´ê¹Œì§€ë§Œ ê°€ëŠ¥í•˜ì§€ë§Œ, **í¬íŠ¸ì›ì€ 100,000ê±´ ì´ìƒ ì¼ê´„ ë°œí–‰** ê°€ëŠ¥
     * **íœ´ë¨¼ ì—ëŸ¬ ì œë¡œ**: ì‚¬ì—…ì ì •ë³´ ì¡°íšŒ APIë¡œ ìˆ˜ê¸° ì…ë ¥ ì˜¤ë¥˜ ë°©ì§€ + íœ´íì—… ìë™ í™•ì¸
     * **íŒŒíŠ¸ë„ˆ ê´€ë¦¬**: ë°œí–‰ ëŒ€ìƒ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ê°€ëŠ¥, ëª¨ë“  íˆìŠ¤í† ë¦¬ ê´€ë¦¬
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ ê¸°ëŠ¥ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ (ì˜ˆ: ì—­ë°œí–‰ ì§€ì›, ëŒ€ëŸ‰ ë°œí–‰, íœ´ë¨¼ ì—ëŸ¬ ì œê±°)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "**ì¬ë¬´ ë¦¬ì†ŒìŠ¤ 3ë¶„ì˜ 1ë¡œ ë‹¨ì¶•**", "**100,000ê±´ ì´ìƒ ì¼ê´„ ë°œí–‰**", "**íŒŒíŠ¸ë„ˆ ì •ì‚°ê³¼ ì—°ë™ ì‹œ ì •ì‚°â†’ì„¸ê¸ˆê³„ì‚°ì„œâ†’ì§€ê¸‰ í•œë²ˆì—**"
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ê±°ë˜ì²˜ ì¦ê°€ë¡œ ì„¸ê¸ˆê³„ì‚°ì„œ ìë™í™”ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤"

10. **ì„¸ê¸ˆê³„ì‚°ì„œ ìë™í™” (ì—­ë°œí–‰) - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**: 
   - **í•„ìˆ˜**: êµ¬ì²´ì  ìƒí™©ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ (ì´ˆë°˜ 1íšŒë§Œ). ì˜ˆ: "'{company_name}ì˜ íŒŒíŠ¸ë„ˆì‚¬ í™•ëŒ€' ì†Œì‹ì„ ë´¤ëŠ”ë°, í˜¹ì‹œ ë§¤ë‹¬ ìˆ˜ë°± ê±´ì˜ ì„¸ê¸ˆê³„ì‚°ì„œ ë•Œë¬¸ì— ì›”ë§ë§ˆë‹¤ ì•¼ê·¼í•˜ê³  ê³„ì‹œì§„ ì•Šìœ¼ì‹ ê°€ìš”?"
   - **ğŸ¯ ì§ˆë¬¸ í›„ ë°”ë¡œ í•´ê²°ì±… ì œì‹œ (ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì „í™˜)**:
     * í™ˆíƒìŠ¤ë¡œëŠ” ì—­ë°œí–‰ì´ ë³µì¡í•˜ê³  1,000ê±´ê¹Œì§€ë§Œ ë°œí–‰ ê°€ëŠ¥í•˜ì§€ë§Œ, **í¬íŠ¸ì› ì„¸ê¸ˆê³„ì‚°ì„œëŠ” ì—­ë°œí–‰ë„ ê°„í¸í•˜ê²Œ, 100,000ê±´ ì´ìƒë„ ì¼ê´„ ë°œí–‰** ê°€ëŠ¥í•©ë‹ˆë‹¤
     * **ì‚¬ì—…ì ì •ë³´ ì¡°íšŒ API**ë¡œ ìˆ˜ê¸° ì…ë ¥ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê³  íœ´íì—…ë„ ìë™ í™•ì¸í•©ë‹ˆë‹¤
     * **íŒŒíŠ¸ë„ˆ ì •ì‚°ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ë©´** ì •ì‚°ê¸ˆ ê³„ì‚°â†’ì§€ê¸‰â†’ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ê¹Œì§€ ì˜¤ë¥˜ ì—†ì´ í•œë²ˆì— ì™„ë£Œë©ë‹ˆë‹¤
   - **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©**: í•µì‹¬ í•´ê²°ì±…ì„ ë¸”ë ›ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì œì‹œ
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì¬ë¬´ ë¦¬ì†ŒìŠ¤ë¥¼ 3ë¶„ì˜ 1ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤", "í™ˆíƒìŠ¤ 1,000ê±´ vs í¬íŠ¸ì› 100,000ê±´ ì´ìƒ"
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ì´ ë°©ì‹ìœ¼ë¡œ ì„¸ê¸ˆê³„ì‚°ì„œ ì—…ë¬´ë¥¼ ìë™í™”í•˜ì—¬ ì¬ë¬´íŒ€ ë¦¬ì†ŒìŠ¤ë¥¼ í•µì‹¬ ì—…ë¬´ì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤" (ì„¤ëª… í˜•ì‹)
   - ë§ˆì§€ë§‰ì— ê°„ë‹¨í•œ CTA: "ë¯¸íŒ…ì„ í†µí•´ ì–´ë–»ê²Œ ì„¸ê¸ˆê³„ì‚°ì„œ ì—…ë¬´ë¥¼ ìë™í™”í•  ìˆ˜ ìˆëŠ”ì§€ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"

ğŸ†• **11. ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ (multi_service_professional / multi_service_curiosity):**

Detected Services: {', '.join(detected_services) if is_multi_service else 'N/A'}

**ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ì „ëµ:**
- **í•µì‹¬ ì›ì¹™**: í•˜ë‚˜ì˜ íìŠ¤í† ë¨¸ Pain Pointì—ì„œ ì‹œì‘í•˜ì—¬ ë³µìˆ˜ ì„œë¹„ìŠ¤ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- **ì–´ìƒ‰í•˜ê²Œ ë¶€ê°ëœ ì œì•ˆì„ í•˜ì§€ ë§ ê²ƒ**: "ì´ê²ƒë„ í•´ë“œë¦½ë‹ˆë‹¤, ì €ê²ƒë„ í•´ë“œë¦½ë‹ˆë‹¤" ë°©ì‹ ê¸ˆì§€
- **ìŠ¤í† ë¦¬ ê¸°ë°˜ í†µí•©**: ê³ ê°ì˜ ì„±ì¥ ìŠ¤í† ë¦¬ ì•ˆì—ì„œ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•œ ì´ìœ ë¥¼ ì„¤ëª…

**í†µí•© ë°©ì‹ ì˜ˆì‹œ (âš ï¸ ì£¼ì˜: ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œëŠ” ì•½ì–´ ëŒ€ì‹  ì™„ì „í•œ ì„œë¹„ìŠ¤ëª… ì‚¬ìš©):**

**í†µí•© ê²°ì œ ì¸í”„ë¼ + í”Œë«í¼ ì •ì‚° ìë™í™” ì¡°í•© (í•´ì™¸ ì§„ì¶œ + í”Œë«í¼)**:
- ì‹œì‘: "í•´ì™¸ ì§„ì¶œ ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í˜„ì§€ ê²°ì œ ì—°ë™ê³¼ íŒŒíŠ¸ë„ˆ ì •ì‚°, ë‘˜ ë‹¤ ë¶€ë‹´ë˜ì‹¤ í…ë°..."
- ì—°ê²°: "**í†µí•© ê²°ì œ ì¸í”„ë¼ë¡œ í˜„ì§€ ê²°ì œ** ì—°ë™í•˜ë©´ì„œ, ë™ì‹œì— **í”Œë«í¼ ì •ì‚° ìë™í™”ë¡œ í˜„ì§€ íŒŒíŠ¸ë„ˆ ì •ì‚°ê¹Œì§€** ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- ê°€ì¹˜: "ê¸€ë¡œë²Œ í™•ì¥ì— í•„ìš”í•œ ëª¨ë“  ì¬ë¬´ ì¸í”„ë¼ë¥¼ í•œ ë²ˆì— í•´ê²°"

**ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© + í”Œë«í¼ ì •ì‚° ìë™í™” ì¡°í•© (ì»¤ë¨¸ìŠ¤ + í”Œë«í¼ ì •ì‚°)**:
- ì‹œì‘: "ë‹¤ì¤‘ ì˜¤í”ˆë§ˆì¼“ í™•ì¥ ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ê° ì±„ë„ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€ê³¼ íŒŒíŠ¸ë„ˆì‚¬ ì •ì‚°ê¹Œì§€, ì¬ë¬´íŒ€ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ì€ë°..."
- ì—°ê²°: "**ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©ìœ¼ë¡œ ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©** + **í”Œë«í¼ ì •ì‚° ìë™í™”ë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”**ë¡œ ëª¨ë‘ í•´ê²°ë©ë‹ˆë‹¤"
- ê°€ì¹˜: "ì›”ë§ ì¬ë¬´ ë§ˆê°ì„ **90% ì´ìƒ ë‹¨ì¶•**í•˜ê³  ì •í™•ì„±ë„ í™•ë³´"

**í†µí•© ê²°ì œ ì¸í”„ë¼ + ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ ì¡°í•© (í•´ì™¸ + ì¬ë¬´ìë™í™”)**:
- ì‹œì‘: "ê¸€ë¡œë²Œ í™•ì¥ê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ PGì‚¬ ë°ì´í„° í†µí•©ì´ ë³µì¡í•´ì§€ì‹¤ í…ë°..."
- ì—°ê²°: "**í†µí•© ê²°ì œ ì¸í”„ë¼ë¡œ {pg_count} PGì‚¬ í†µí•©** + **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ ë‹¤êµ­ê°€ ì¬ë¬´ ìë™í™”**"
- ê°€ì¹˜: "êµ­ë‚´ì™¸ ëª¨ë“  ì¬ë¬´ ë°ì´í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬"

**í”Œë«í¼ ì •ì‚° ìë™í™” + ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ ì¡°í•© (í”Œë«í¼ + ì¬ë¬´)**:
- ì‹œì‘: "í”Œë«í¼ í™•ì¥ìœ¼ë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚°ê³¼ ì „ì²´ ì¬ë¬´ ê´€ë¦¬ê°€ ë³µì¡í•´ì§€ì…¨ì„ í…ë°..."
- ì—°ê²°: "**í”Œë«í¼ ì •ì‚° ìë™í™”ë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”** + **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ ì „ì²´ ì¬ë¬´ í†µí•©**"
- ê°€ì¹˜: "íŒŒíŠ¸ë„ˆ ì •ì‚°ë¶€í„° ERP ì—°ë™ê¹Œì§€ ì™„ì „ ìë™í™”"

**í†µí•© ë¬¸ì•ˆ ì‘ì„± ì£¼ì˜ì‚¬í•­:**
- ê° ì„œë¹„ìŠ¤ì˜ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ëª¨ë‘ í™œìš©í•˜ë˜, **í•˜ë‚˜ì˜ ìŠ¤í† ë¦¬ë¡œ ì—°ê²°**
- ì„œë¹„ìŠ¤ë³„ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ì€ ë³¸ë¬¸ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì–¸ê¸‰ (ëª©ë¡í˜• ë‚˜ì—´ ê¸ˆì§€)
- Pain Point ê³µê° â†’ í†µí•© ì†”ë£¨ì…˜ ì œì•ˆ â†’ ê²°í•© íš¨ê³¼ ê°•ì¡° ìˆœì„œë¡œ ì „ê°œ
- **ë¶„ëŸ‰ ì£¼ì˜**: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ì–¸ê¸‰í•˜ë”ë¼ë„ ì „ì²´ ë³¸ë¬¸ì€ 130-200ë‹¨ì–´ ìœ ì§€

**êµ¬ì¡° ë° í˜•ì‹:**
- ì œëª©: ê³ ì • í˜•ì‹ ì‚¬ìš© ("[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤") - ë³¸ë¬¸ì— ì œëª© í¬í•¨í•˜ì§€ ë§ê²ƒ
- ë³¸ë¬¸: ê³ ì • ì„œë¡  â†’ Pain Point ì œê¸°(30-40ë‹¨ì–´) â†’ í•´ê²°ì±… ì œì‹œ(ë¸”ë › í¬ì¸íŠ¸, 40-60ë‹¨ì–´) â†’ ê³ ì • ê²°ë¡ 
- **ì „ì²´ ë³¸ë¬¸: 100-130ë‹¨ì–´ë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ì„± (í˜„ì¬ ë„ˆë¬´ ê¸¸ë‹¤ëŠ” í”¼ë“œë°± ë°˜ì˜)**
- **ğŸ‘Š ì •ëŸ‰ì  ìˆ˜ì¹˜ì™€ í•µì‹¬ ê°€ì¹˜ ì œì•ˆì€ ë°˜ë“œì‹œ ë³¼ë“œ ì²˜ë¦¬í•˜ì„¸ìš”**:
  * ì˜ˆ: **85% ë¦¬ì†ŒìŠ¤ ì ˆê°**, **2ì£¼ ë‚´ êµ¬ì¶•**, **90% ìë™í™”**, **15% í–¥ìƒ**, **0.5% ìˆ˜ìˆ˜ë£Œ** ë“±
  * ê°€ì¹˜ ì œì•ˆ: **ë¬´ë£Œ ì»¨ì„¤íŒ…**, **ì‹ ìš©ì¹´ë“œ/ê°„í¸ê²°ì œ**, **100+ ê²°ì œ ìˆ˜ë‹¨** ë“±
  * Pain Point í•´ê²°ì±…ì˜ í•µì‹¬ ê¸°ëŠ¥ë„ ë³¼ë“œ ì²˜ë¦¬
- **í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¾¸ê¸° ê·œì¹™ (ê°€ë…ì„± ì¤‘ì‹¬!)**:
  * **ê¸°ë³¸ ê·œì¹™: ë¬¸ì¥ì´ ëë‚˜ëŠ” `.` ë˜ëŠ” ì‰¼í‘œ(`,`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆ (`<br>`)**
  * **ì˜¨ì „í•œ ì§§ì€ ì ˆ ì•ˆì—ì„œëŠ” ì¤„ë°”ê¿ˆí•˜ì§€ ì•ŠìŒ** (ì˜ë¯¸ ë‹¨ìœ„ë¡œ ëŠê¸°)
  * **ë¬¸ë‹¨ ê°„ êµ¬ë¶„: `</p><p>` íƒœê·¸ë¡œ ë‹¨ë½ êµ¬ë¶„ (ë¹ˆ ì¤„ íš¨ê³¼)**
  * **ë¸”ë › í¬ì¸íŠ¸ ê·œì¹™: ë³¼ë“œ ì†Œì œëª©(`:`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆí•˜ì—¬ ì„¤ëª…ì€ ì•„ë˜ ì¤„ì—**
  * **âœ… ì¢‹ì€ ì˜ˆì‹œ (`.` ë˜ëŠ” `,` ë‹¤ìŒ ì¤„ë°”ê¿ˆ + ë¸”ë › ì†Œì œëª© ì¤„ë°”ê¿ˆ):**
    ```html
    <p>'ë“€ì–¼ì†Œë‹‰ ì˜µí‹°ë©ˆ ì‚¬ì „ì˜ˆì•½ 1ì°¨ ì™„íŒ' ì†Œì‹ì„ ì ‘í–ˆìŠµë‹ˆë‹¤.<br>
    ë„¤ì´ë²„ ìŠ¤í† ì–´ì™€ í™ˆì‡¼í•‘ ë“± ëŠ˜ì–´ë‚˜ëŠ” ì±„ë„ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ëŠ” ì–´ë–»ê²Œ ê´€ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?<br>
    ë§¤ì¶œì´ ê¸‰ì¦í• ìˆ˜ë¡ ì •ì‚° ë°ì´í„°ê°€ í©ì–´ì ¸ ìˆìœ¼ë©´,<br>
    ì •í™•í•œ ì†ìµ íŒŒì•…ì´ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.</p>
    
    <p>í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì´ ë³µì¡í•œ ì •ì‚° ì—…ë¬´ë¥¼ ìë™í™”í•´ ë“œë¦½ë‹ˆë‹¤:</p>
    
    <ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
    <li><strong>ì‹¤ì‹œê°„ í˜„ê¸ˆíë¦„ íŒŒì•…:</strong><br>
    ê° ì˜¤í”ˆë§ˆì¼“ì˜ ìƒì´í•œ ì •ì‚° ê¸°ì¤€ì„ ìë™ìœ¼ë¡œ í†µí•©í•˜ì—¬ **ë¯¸ìˆ˜ê¸ˆê³¼ ìê¸ˆ íë¦„ì„ í•œëˆˆì— í™•ì¸** ê°€ëŠ¥</li>
    <li><strong>ì •ì‚° ì—…ë¬´ 90% ìë™í™”:</strong><br>
    ë³µì¡í•œ ë©€í‹° ìˆ˜ìˆ˜ë£Œ ê³„ì‚°ê³¼ ì§€ê¸‰ì„ ìë™í™”í•˜ì—¬, **ì •ì‚°ì˜ íœ´ë¨¼ ì—ëŸ¬ë¥¼ ì œê±°**í•˜ê³  **ì¬ë¬´íŒ€ ì—…ë¬´ ì‹œê°„ í™•ë³´**</li>
    </ul>
    ```
  * **í•µì‹¬: ë¬¸ì¥ ë(`.`)ì—ì„œ ì¤„ë°”ê¿ˆ, ë¸”ë › ì†Œì œëª©(`:`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆ**
- í†¤: ì „ë¬¸ì ì´ë©´ì„œë„ ê³µê°í•˜ê³  ë„ì›€ì„ ì£¼ëŠ” ê´€ì , ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„

**ì¤‘ìš”**: ì–´ë–¤ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

**ìƒì„±í•  ì„œë¹„ìŠ¤**: {', '.join(services_to_generate)}

{{
  "opi_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "opi_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "ps_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "ps_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "tax_invoice_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "tax_invoice_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "multi_service_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "multi_service_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }}
}}
"""
        
        # Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í´ë°± ì‘ë‹µ ìƒì„±
        if not GEMINI_API_KEY:
            return {
                'success': True,
                'variations': {
                    'professional': {
                        'subject': company_name + ' ë§ì¶¤í˜• ê²°ì œ ì¸í”„ë¼ ì œì•ˆ',
                        'body': 'ì•ˆë…•í•˜ì„¸ìš”, ' + company_name + ' ë‹´ë‹¹ìë‹˜!\n\n' + company_name + 'ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” PortOneì˜ One Payment Infraë¥¼ ì†Œê°œë“œë¦¬ê³ ì ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ê³¼ ë””ì§€í„¸ ì „í™˜ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. PortOneì˜ ì†”ë£¨ì…˜ì€:\n\nâ€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ ì ˆì•½ (80% ë‹¨ì¶•)\nâ€¢ ë¹ ë¥¸ ë„ì… (ìµœì†Œ 2ì£¼)\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ\n\në¯¸íŒ…ì„ í†µí•´ ' + company_name + 'ì— ì–´ë–¤ í˜œíƒì´ ìˆëŠ”ì§€ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                    },
                    'friendly': {
                        'subject': company_name + 'ë‹˜, ê²°ì œ ì‹œìŠ¤í…œ ê³ ë¯¼ ìˆìœ¼ì‹ ê°€ìš”?',
                        'body': 'ì•ˆë…•í•˜ì„¸ìš”! ' + company_name + ' ë‹´ë‹¹ìë‹˜ :)\n\ní˜¹ì‹œ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ì´ë‚˜ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¬¸ì œë¡œ ê³ ë¯¼ì´ ìˆìœ¼ì‹ ê°€ìš”?\n\nì €í¬ PortOneì€ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ One Payment Infraë¥¼ ë§Œë“¤ì—ˆì–´ìš”!\n\níŠ¹íˆ ì´ëŸ° ì ë“¤ì´ ë„ì›€ì´ ë  ê±°ì˜ˆìš”:\nğŸš€ ê°œë°œ ì‹œê°„ 80% ë‹¨ì¶•\nğŸ’° ë¹„ìš© ì ˆì•½\nğŸ”§ ë¬´ë£Œ ì»¨ì„¤íŒ…\nğŸ“ˆ ê²°ì œ ì„±ê³µë¥  UP\n\nì ê¹ ë¯¸íŒ…ì„ í†µí•´ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”? ì–´ë–¤ ë‚ ì´ í¸í•˜ì‹ ì§€ ì•Œë ¤ì£¼ì„¸ìš”!\n\nê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š\nPortOne ì˜ì—…íŒ€'
                    }
                },
                'timestamp': datetime.now().isoformat(),
                'note': 'AWS Bedrock ëª¨ë¸ ì ‘ê·¼ ë¶ˆê°€ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
            }
        
        # Gemini API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ 180ì´ˆ + ì¬ì‹œë„ ë¡œì§)
        try:
            import requests
            import time
            
            # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
            max_retries = 3
            retry_count = 0
            # Gemini API í˜¸ì¶œ (ìë™ fallback ì ìš©)
            response_text = call_gemini_with_fallback(prompt, timeout=180, max_retries=max_retries)
            
            # response_textë¥¼ response.textë¡œ ë³€í™˜ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
            class ResponseWrapper:
                def __init__(self, text):
                    self.text = text
            
            response = ResponseWrapper(response_text)
            
            if response.text:
                # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
                try:
                    # ì „ì²´ ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ
                    clean_response = response.text.strip()
                    
                    # JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
                    if '```json' in clean_response:
                        json_start = clean_response.find('```json') + 7
                        json_end = clean_response.find('```', json_start)
                        if json_end != -1:
                            clean_response = clean_response[json_start:json_end]
                        else:
                            clean_response = clean_response[json_start:]
                    elif '{' in clean_response and '}' in clean_response:
                        # JSON ê°ì²´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        json_start = clean_response.find('{')
                        json_end = clean_response.rfind('}') + 1
                        clean_response = clean_response[json_start:json_end]
                    
                    clean_response = clean_response.strip()
                    
                    # JSON íŒŒì‹±
                    email_variations = json.loads(clean_response)
                    
                    # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
                    def convert_markdown_to_html(text):
                        """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ HTMLë¡œ ë³€í™˜ (**ë³¼ë“œ**, *ì´íƒ¤ë¦­* ë“±)"""
                        import re
                        # **í…ìŠ¤íŠ¸** â†’ <strong>í…ìŠ¤íŠ¸</strong>
                        text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
                        # *í…ìŠ¤íŠ¸* â†’ <em>í…ìŠ¤íŠ¸</em> (ë³¼ë“œ ì²˜ë¦¬ í›„ ë‚¨ì€ ë‹¨ì¼ *)
                        text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
                        return text
                    
                    # í”Œë ˆì´ìŠ¤í™€ë” êµì²´ í•¨ìˆ˜
                    def replace_placeholders(text, company_name, email_name, competitor_name=''):
                        result = text.replace('{company_name}', company_name).replace('{email_name}', email_name)
                        if competitor_name:
                            result = result.replace('{competitor_name}', competitor_name)
                        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
                        result = result.replace('ì˜¤ì¤€í˜¸', user_name)
                        result = result.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
                        # ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì ìš©
                        result = convert_markdown_to_html(result)
                        return result
                    
                    # ì‘ë‹µ í˜•ì‹ ë³€í™˜ ë° í”Œë ˆì´ìŠ¤í™€ë” êµì²´ (ìš”ì²­ëœ ì„œë¹„ìŠ¤ë§Œ)
                    formatted_variations = {}
                    
                    for service in services_to_generate:
                        if service in email_variations:
                            # ê³ ì • ì œëª© ì‚¬ìš©
                            subject = f'[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤'
                            
                            # bodyë§Œ í”Œë ˆì´ìŠ¤í™€ë” êµì²´
                            body = replace_placeholders(email_variations[service]['body'], company_name, email_name, competitor_name)
                            
                            formatted_variations[service] = {
                                'subject': subject,
                                'body': body,
                                'type': service  # type í•„ë“œ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œ ë Œë”ë§ìš©)
                            }
                            logger.info(f"ì„œë¹„ìŠ¤ '{service}' ë¬¸ì•ˆ ìƒì„± ì™„ë£Œ: {company_name}")
                    
                    # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
                    logger.info(f"{company_name}: CTA ê²€ì¦ ì‹œì‘...")
                    for service_key, email_content in formatted_variations.items():
                        if 'body' in email_content:
                            email_content['body'] = validate_and_fix_cta(
                                email_content['body'],
                                company_name
                            )
                    
                    # ğŸ†• Upstage Groundedness Check: ìƒì„±ëœ ì´ë©”ì¼ ê²€ì¦ (ì„ íƒì )
                    ENABLE_HALLUCINATION_CHECK = True  # í™˜ê° ê²€ì¦ í™œì„±í™” (ê¸°ì¤€ ì™„í™”ë¨)
                    
                    if not ENABLE_HALLUCINATION_CHECK:
                        # í™˜ê° ê²€ì¦ ë¹„í™œì„±í™” - ëª¨ë“  ì´ë©”ì¼ ë°”ë¡œ ë°˜í™˜
                        logger.info(f"{company_name}: â„¹ï¸ í™˜ê° ê²€ì¦ ë¹„í™œì„±í™” - ëª¨ë“  ì´ë©”ì¼ ì‚¬ìš©")
                        return {
                            'success': True,
                            'variations': formatted_variations,
                            'services_generated': services_to_generate,
                            'sales_item': sales_item if sales_item else 'all',
                            'timestamp': datetime.now().isoformat(),
                            'model': 'gemini-3-pro-preview',
                            'groundedness_check': {
                                'enabled': False,
                                'note': 'í™˜ê° ê²€ì¦ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.'
                            }
                        }
                    
                    # ğŸ” í™˜ê° ê²€ì¦ í™œì„±í™”ëœ ê²½ìš°
                    logger.info(f"{company_name}: ğŸ” Upstage Groundedness Check ì‹œì‘...")
                    
                    try:
                        checker = get_groundedness_checker()
                        
                        # Perplexity ì¡°ì‚¬ ê²°ê³¼ + CSV ë°ì´í„°ë¥¼ ì°¸ì¡° ë¬¸ì„œë¡œ ì‚¬ìš©
                        # CSVì— ìˆëŠ” ì •ë³´(ëŒ€í‘œìëª…, ë‹´ë‹¹ìëª… ë“±)ëŠ” í™˜ê°ì´ ì•„ë‹ˆë¯€ë¡œ contextì— í¬í•¨
                        csv_data_context = f"""
**CSVì—ì„œ í™•ì¸ëœ íšŒì‚¬ ì •ë³´ (ê²€ì¦ëœ ë°ì´í„°):**
- íšŒì‚¬ëª…: {company_name}
- ë‹´ë‹¹ì/ëŒ€í‘œì: {email_name}
"""
                        if competitor_name:
                            csv_data_context += f"- ê²½ìŸì‚¬: {competitor_name}\n"
                        
                        # ì‚¬ìš©PG ì •ë³´ ì¶”ê°€
                        pg_info = get_pg_provider(company_data)
                        if pg_info:
                            csv_data_context += f"- ì‚¬ìš© ì¤‘ì¸ PG: {pg_info}\n"
                        
                        # ê¸°íƒ€ CSV ë°ì´í„° ì¶”ê°€
                        for key, value in company_data.items():
                            if key not in ['íšŒì‚¬ëª…', 'ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìëª…', 'ì´ë¦„', 'ì§ì±…', 'ì§ê¸‰', 'ê²½ìŸì‚¬ëª…', 'ê²½ìŸì‚¬', 'ì‚¬ìš©PG', 'PG'] and value and str(value).strip():
                                csv_data_context += f"- {key}: {value}\n"
                        
                        context_for_verification = csv_data_context + "\n\n" + research_summary
                        
                        # ë°°ì¹˜ ê²€ì¦: ëª¨ë“  ì´ë©”ì¼ ë™ì‹œ ê²€ì¦
                        emails_to_verify = {}
                        for service_key, email_content in formatted_variations.items():
                            subject = email_content.get('subject', '')
                            body = email_content.get('body', '')
                            full_email = f"ì œëª©: {subject}\n\në³¸ë¬¸:\n{body}"
                            emails_to_verify[service_key] = full_email
                        
                        verification_results = checker.batch_check(
                            context_for_verification,
                            emails_to_verify
                        )
                        
                        # í™˜ê° ê°ì§€ëœ ì´ë©”ì¼ í•„í„°ë§ + ì¬ìƒì„±
                        verified_variations = {}
                        hallucinated_count = 0
                        hallucinated_services = []  # í™˜ê° ê°ì§€ëœ ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸
                        
                        for service_key, result in verification_results.items():
                            if result['groundedness'] == 'grounded' or result['groundedness'] == 'notSure':
                                # ê²€ì¦ í†µê³¼ or ë¶ˆí™•ì‹¤ (ë³´ìˆ˜ì ìœ¼ë¡œ í†µê³¼ ì²˜ë¦¬)
                                verified_variations[service_key] = formatted_variations[service_key]
                                logger.info(f"âœ… {service_key}: ê²€ì¦ í†µê³¼ ({result['groundedness']}, ì‹ ë¢°ë„: {result['confidence_score']:.2f})")
                            else:
                                # í™˜ê° ê°ì§€ - ë¬¸ì œë¶€ë¶„ê³¼ ìˆ˜ì •ì œì•ˆ í‘œì‹œ
                                hallucinated_count += 1
                                hallucinated_services.append(service_key)
                                
                                logger.warning(f"âš ï¸ {service_key}: í™˜ê° ê°ì§€ (ì‹ ë¢°ë„: {result['confidence_score']:.2f})")
                                if result.get('reason'):
                                    logger.warning(f"  â”” ì´ìœ : {result['reason']}")
                                if result.get('problem_part'):
                                    logger.warning(f"  â”” ë¬¸ì œë¶€ë¶„: {result['problem_part']}")
                                if result.get('fix_suggestion'):
                                    logger.info(f"  â”” ìˆ˜ì •ì œì•ˆ: {result['fix_suggestion']}")
                                
                                # ì›ë³¸ì— ìƒì„¸í•œ í”¼ë“œë°± ì¶”ê°€
                                hallucination_email = formatted_variations[service_key].copy()
                                hallucination_email['type'] = service_key
                                hallucination_email['hallucination_warning'] = True
                                
                                # ì‚¬ìš©ìë¥¼ ìœ„í•œ ìˆ˜ì • ê°€ì´ë“œ ìƒì„±
                                feedback_message = f"âš ï¸ í™˜ê° ê°€ëŠ¥ì„± ê°ì§€ë¨"
                                if result.get('reason'):
                                    feedback_message += f"\nğŸ“Œ ì´ìœ : {result['reason']}"
                                if result.get('problem_part'):
                                    feedback_message += f"\nğŸ” ë¬¸ì œë¶€ë¶„: {result['problem_part']}"
                                if result.get('fix_suggestion'):
                                    feedback_message += f"\nğŸ’¡ ìˆ˜ì •ì œì•ˆ: {result['fix_suggestion']}"
                                
                                hallucination_email['feedback_message'] = feedback_message
                                hallucination_email['hallucination_details'] = {
                                    'reason': result.get('reason'),
                                    'problem_part': result.get('problem_part'),
                                    'fix_suggestion': result.get('fix_suggestion')
                                }
                                verified_variations[service_key] = hallucination_email
                        
                        # ğŸ”„ í™˜ê° ê°ì§€ëœ ì´ë©”ì¼ ì¬ìƒì„± ì‹œë„ (ë¹„í™œì„±í™” - ì‚¬ìš©ìê°€ ì§ì ‘ í™•ì¸)
                        # ì‚¬ìš©ìê°€ ì›ë³¸ì„ ë³´ê³  ì§ì ‘ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ì¬ìƒì„± ë¡œì§ ë¹„í™œì„±í™”
                        MAX_RETRY = 0  # ì¬ìƒì„± ë¹„í™œì„±í™”
                        regeneration_log = []
                        
                        if False and hallucinated_services and len(hallucinated_services) <= 4:  # ì¬ìƒì„± ë¹„í™œì„±í™”
                            logger.info(f"ğŸ”„ í™˜ê° ê°ì§€ëœ {len(hallucinated_services)}ê°œ ì´ë©”ì¼ ì¬ìƒì„± ì‹œì‘...")
                            
                            for retry_attempt in range(MAX_RETRY):
                                logger.info(f"  ì¬ì‹œë„ {retry_attempt + 1}/{MAX_RETRY}...")
                                
                                # ì¬ìƒì„±í•  ì„œë¹„ìŠ¤ë§Œ ì„ íƒ
                                retry_services = hallucinated_services.copy()
                                
                                # ë” ì—„ê²©í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ìƒì„±
                                strict_prompt_addition = f"""
                                
**âš ï¸ í™˜ê° ë°©ì§€ ìµœìš°ì„  ì§€ì¹¨ (ì¬ìƒì„±) âš ï¸**
ì´ì „ ìƒì„±ì—ì„œ ì°¸ì¡° ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê°ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.
ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:

1. **ì°¸ì¡° ë¬¸ì„œ(Perplexity ì¡°ì‚¬ ê²°ê³¼)ì— ëª…ì‹œëœ ì •ë³´ë§Œ ì‚¬ìš©**
2. **ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì •ë³´ë¡œ ì±„ìš°ì§€ ë§ˆì„¸ìš”**
3. **êµ¬ì²´ì  ìˆ˜ì¹˜ë‚˜ ì‚¬ì‹¤ì€ ì°¸ì¡° ë¬¸ì„œì— ìˆì„ ë•Œë§Œ ì–¸ê¸‰**
4. **í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ì ì¸ Pain Point ì¤‘ì‹¬ìœ¼ë¡œë§Œ ì‘ì„±**

ì¬ìƒì„± ëŒ€ìƒ: {', '.join(retry_services)}
"""
                                
                                # ì¬ìƒì„± ìš”ì²­ (ìë™ fallback ì ìš©)
                                retry_prompt = context + strict_prompt_addition
                                
                                try:
                                    retry_response_text = call_gemini_with_fallback(
                                        retry_prompt,
                                        timeout=180,
                                        max_retries=3,
                                        generation_config={
                                            "temperature": 0.3,
                                            "topP": 0.85,
                                            "topK": 30,
                                            "maxOutputTokens": 8000
                                        }
                                    )
                                    
                                    # ResponseWrapperë¡œ ë³€í™˜
                                    class RetryResponseWrapper:
                                        def __init__(self, text):
                                            self.text = text
                                    
                                    retry_response = RetryResponseWrapper(retry_response_text)
                                    
                                    retry_variations_raw = json.loads(retry_response.text)
                                    
                                    # ì¬ìƒì„±ëœ ì´ë©”ì¼ í¬ë§·íŒ…
                                    retry_formatted = {}
                                    for service_key in retry_services:
                                        if service_key in retry_variations_raw.get('variations', {}):
                                            retry_formatted[service_key] = retry_variations_raw['variations'][service_key]
                                    
                                    # ì¬ìƒì„±ëœ ì´ë©”ì¼ ê²€ì¦
                                    retry_emails_to_verify = {}
                                    for service_key, email_content in retry_formatted.items():
                                        subject = email_content.get('subject', '')
                                        body = email_content.get('body', '')
                                        full_email = f"ì œëª©: {subject}\n\në³¸ë¬¸:\n{body}"
                                        retry_emails_to_verify[service_key] = full_email
                                    
                                    retry_verification = checker.batch_check(
                                        context_for_verification,
                                        retry_emails_to_verify
                                    )
                                    
                                    # ì¬ìƒì„± ê²°ê³¼ í™•ì¸
                                    newly_verified = 0
                                    for service_key, result in retry_verification.items():
                                        if result['groundedness'] == 'grounded' or result['groundedness'] == 'notSure':
                                            verified_variations[service_key] = retry_formatted[service_key]
                                            hallucinated_services.remove(service_key)
                                            newly_verified += 1
                                            logger.info(f"âœ… {service_key}: ì¬ìƒì„± ì„±ê³µ! ê²€ì¦ í†µê³¼")
                                            regeneration_log.append(f"{service_key}: ì¬ìƒì„± ì„±ê³µ (ì‹œë„ {retry_attempt + 1})")
                                        else:
                                            logger.warning(f"âŒ {service_key}: ì¬ìƒì„±í–ˆì§€ë§Œ ì—¬ì „íˆ í™˜ê° ê°ì§€")
                                            regeneration_log.append(f"{service_key}: ì¬ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {retry_attempt + 1})")
                                    
                                    if newly_verified > 0:
                                        logger.info(f"ğŸ‰ ì¬ì‹œë„ {retry_attempt + 1}ì—ì„œ {newly_verified}ê°œ ë³µêµ¬ ì„±ê³µ!")
                                    
                                    # ëª¨ë“  í™˜ê°ì´ í•´ê²°ë˜ì—ˆìœ¼ë©´ ì¤‘ë‹¨
                                    if not hallucinated_services:
                                        logger.info(f"âœ… ëª¨ë“  í™˜ê° ë¬¸ì œ í•´ê²°! ì¬ì‹œë„ ì¤‘ë‹¨")
                                        break
                                        
                                except Exception as retry_error:
                                    logger.error(f"ì¬ìƒì„± ì˜¤ë¥˜ (ì‹œë„ {retry_attempt + 1}): {str(retry_error)}")
                                    regeneration_log.append(f"ì¬ìƒì„± ì˜¤ë¥˜ (ì‹œë„ {retry_attempt + 1}): {str(retry_error)}")
                            
                            # ğŸ†• ì¬ì‹œë„ í›„ì—ë„ ì—¬ì „íˆ í™˜ê°ì´ ìˆë‹¤ë©´, ë§¤ìš° ë³´ìˆ˜ì ì¸ ì¼ë°˜ ë²„ì „ìœ¼ë¡œ ì¬ìƒì„±
                            if hallucinated_services:
                                logger.warning(f"âš ï¸ {len(hallucinated_services)}ê°œ ì´ë©”ì¼ì´ {MAX_RETRY}íšŒ ì¬ì‹œë„ í›„ì—ë„ í™˜ê° ê°ì§€ë¨")
                                logger.info(f"ğŸ”„ ë§¤ìš° ë³´ìˆ˜ì ì¸ ì¼ë°˜ ë²„ì „ìœ¼ë¡œ ìµœì¢… ì¬ìƒì„± ì‹œë„...")
                                
                                try:
                                    # ë§¤ìš° ë³´ìˆ˜ì ì¸ í”„ë¡¬í”„íŠ¸ (íšŒì‚¬ë³„ êµ¬ì²´ì  ì •ë³´ ìµœì†Œí™”)
                                    conservative_prompt = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì´ë©”ì¼ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**âš ï¸ ë§¤ìš° ë³´ìˆ˜ì ì¸ ì ‘ê·¼ - ì¼ë°˜ì ì¸ ë‚´ìš©ë§Œ ì‚¬ìš© âš ï¸**

ë‹¤ìŒ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì´ë©”ì¼ì„ ì‘ì„±í•˜ë˜, **ì¶”ì¸¡í•˜ì§€ ë§ê³  ì¼ë°˜ì ì¸ Pain Pointì™€ í•´ê²°ì±…ë§Œ ì œì‹œ**í•˜ì„¸ìš”:
{', '.join(hallucinated_services)}

**ê·œì¹™:**
1. íšŒì‚¬ëª…: {company_name}
2. ë‹´ë‹¹ì ì •ë³´: {email_name}
3. **êµ¬ì²´ì ì¸ íšŒì‚¬ ì •ë³´ëŠ” ìµœì†Œí™”** (ì¼ë°˜ì ì¸ ì—…ê³„ Pain Point ì¤‘ì‹¬)
4. **PortOne ê²€ì¦ëœ ê¸°ëŠ¥ê³¼ ìˆ˜ì¹˜ë§Œ ì‚¬ìš©** (ì˜ˆ: 85% ì ˆê°, 90% ë‹¨ì¶•, 15% í–¥ìƒ)
5. **ë¸”ë › í¬ì¸íŠ¸ í•„ìˆ˜ ì‚¬ìš©** (ê°€ë…ì„± í–¥ìƒ)
6. **ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ë§ëŠ” ê¸°ëŠ¥ ì œì•ˆ** (êµ¬ë…â†’ë¹Œë§í‚¤, í•´ì™¸â†’ê°„í¸ê²°ì œ, ê±°ë˜ëŸ‰â†’ë¼ìš°íŒ…)

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""
                                    
                                    # ìë™ fallback ì ìš©
                                    conservative_response_text = call_gemini_with_fallback(
                                        conservative_prompt,
                                        timeout=180,
                                        max_retries=3,
                                        generation_config={
                                            "temperature": 0.2,
                                            "topP": 0.7,
                                            "topK": 20,
                                            "maxOutputTokens": 8000
                                        }
                                    )
                                    
                                    conservative_variations = json.loads(conservative_response_text)
                                    
                                    # ë³´ìˆ˜ì  ë²„ì „ì„ ê²€ì¦ ì—†ì´ ì¶”ê°€ (ì´ë¯¸ ì¶©ë¶„íˆ ë³´ìˆ˜ì ìœ¼ë¡œ ìƒì„±ë¨)
                                    for service_key in hallucinated_services.copy():
                                        if service_key in conservative_variations.get('variations', {}):
                                            verified_variations[service_key] = conservative_variations['variations'][service_key]
                                            hallucinated_services.remove(service_key)
                                            logger.info(f"âœ… {service_key}: ë³´ìˆ˜ì  ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ ì„±ê³µ")
                                            regeneration_log.append(f"{service_key}: ë³´ìˆ˜ì  ë²„ì „ ìƒì„± ì„±ê³µ (í™˜ê° ë°©ì§€)")
                                
                                except Exception as conservative_error:
                                    logger.error(f"ë³´ìˆ˜ì  ë²„ì „ ìƒì„± ì‹¤íŒ¨: {str(conservative_error)}")
                                    regeneration_log.append(f"ë³´ìˆ˜ì  ë²„ì „ ìƒì„± ì‹¤íŒ¨: {str(conservative_error)}")
                        
                        # ìµœì¢… í™˜ê° ê°œìˆ˜ ì—…ë°ì´íŠ¸
                        final_hallucinated_count = len(hallucinated_services)
                        
                        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì´ë©”ì¼ì´ ê²€ì¦ í†µê³¼í•´ì•¼ í•¨
                        if verified_variations:
                            logger.info(f"ğŸ“Š Groundedness Check ì™„ë£Œ: {len(verified_variations)}/{len(formatted_variations)} ê²€ì¦ í†µê³¼")
                            if regeneration_log:
                                logger.info(f"ğŸ”„ ì¬ìƒì„± ë¡œê·¸: {', '.join(regeneration_log)}")
                            
                            # ê²€ì¦ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                            return {
                                'success': True,
                                'variations': verified_variations,
                                'services_generated': services_to_generate,
                                'sales_item': sales_item if sales_item else 'all',
                                'timestamp': datetime.now().isoformat(),
                                'model': 'gemini-3-pro-preview',
                                'groundedness_check': {
                                    'enabled': True,
                                    'verified_count': len(verified_variations),
                                    'hallucinated_count': final_hallucinated_count,
                                    'total_count': len(formatted_variations),
                                    'regeneration_attempted': len(regeneration_log) > 0,
                                    'regeneration_log': regeneration_log
                                }
                            }
                        else:
                            # ëª¨ë“  ì´ë©”ì¼ì´ í™˜ê°ìœ¼ë¡œ íŒì •ë¨ - í´ë°± ì²˜ë¦¬
                            logger.error(f"âš ï¸ ëª¨ë“  ì´ë©”ì¼ì´ í™˜ê°ìœ¼ë¡œ ê°ì§€ë¨! ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
                            return {
                                'success': True,
                                'variations': formatted_variations,  # ê·¸ë˜ë„ ì¼ë‹¨ ë°˜í™˜ (ì‚¬ìš©ì íŒë‹¨)
                                'services_generated': services_to_generate,
                                'sales_item': sales_item if sales_item else 'all',
                                'timestamp': datetime.now().isoformat(),
                                'model': 'gemini-3-pro-preview',
                                'groundedness_check': {
                                    'enabled': True,
                                    'verified_count': 0,
                                    'hallucinated_count': hallucinated_count,
                                    'total_count': len(formatted_variations),
                                    'warning': 'ëª¨ë“  ì´ë©”ì¼ì´ í™˜ê°ìœ¼ë¡œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì— ì£¼ì˜í•˜ì„¸ìš”.'
                                }
                            }
                    
                    except Exception as groundedness_error:
                        # Groundedness Check ì‹¤íŒ¨ ì‹œ ê²½ê³ ë§Œ í‘œì‹œí•˜ê³  ê³„ì† ì§„í–‰
                        logger.warning(f"âš ï¸ Groundedness Check ì‹¤íŒ¨: {groundedness_error}")
                        logger.warning(f"ê¸°ë³¸ ê²€ì¦ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
                        
                        return {
                            'success': True,
                            'variations': formatted_variations,
                            'services_generated': services_to_generate,
                            'sales_item': sales_item if sales_item else 'all',
                            'timestamp': datetime.now().isoformat(),
                            'model': 'gemini-3-pro-preview',
                            'groundedness_check': {
                                'enabled': False,
                                'error': str(groundedness_error)
                            }
                        }
                    
                except json.JSONDecodeError as json_error:
                    logger.error(f"Gemini JSON íŒŒì‹± ì˜¤ë¥˜: {json_error}")
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
                    return {
                        'success': True,
                        'variations': {
                            'professional': {
                                'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                                'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\n{pain_points}\n\nPortOneì˜ One Payment Infraë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½\nâ€¢ 2ì£¼ ë‚´ êµ¬ì¶• ì™„ë£Œ\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\n\nê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                            }
                        },
                        'timestamp': datetime.now().isoformat(),
                        'note': 'JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
                    }
            
            else:
                logger.error("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                # ë¹ˆ ì‘ë‹µ ì‹œ í´ë°±
                return {
                    'success': True,
                    'variations': {
                        'professional': {
                            'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                            'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ê³¼ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.\n\nPortOneì˜ ì†”ë£¨ì…˜ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ì‹œê°„ 85% ë‹¨ì¶•\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ì•ˆì •ì ì¸ ê²°ì œ ì¸í”„ë¼\n\n15ë¶„ ê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                        }
                    },
                    'timestamp': datetime.now().isoformat(),
                    'note': 'Gemini ë¹ˆ ì‘ë‹µìœ¼ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
                }
                
        except Exception as gemini_error:
            logger.error(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {str(gemini_error)}")
            # Gemini API ì˜¤ë¥˜ ì‹œ í´ë°±
            return {
                'success': True,
                'variations': {
                    'professional': {
                        'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                        'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œê³¼ í†µí•©ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.\n\nPortOneì˜ One Payment Infraë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ì‹œê°„ 85% ë‹¨ì¶•\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ì•ˆì •ì ì¸ ê²°ì œ ì‹œìŠ¤í…œ\n\nê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                    }
                },
                'timestamp': datetime.now().isoformat(),
                'note': f'Gemini API ì˜¤ë¥˜ë¡œ ì¸í•œ í´ë°± ë°ì´í„°: {str(gemini_error)}'
            }
            
    except Exception as e:
        logger.error(f"Gemini ì´ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def generate_email_with_user_template(company_data, research_data, user_template, case_examples="", news_content=None, user_info=None):
    """
    ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ ê¸°ë°˜ ì´ë©”ì¼ ìƒì„± (ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  + ì‚¬ìš©ì ë³¸ë¬¸ 90%)
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    try:
        # ì‚¬ìš©ì ì •ë³´ (ì„œëª…ìš©) - user_info íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ current_user ì²´í¬
        if user_info:
            user_name = user_info.get('name', 'ì˜¤ì¤€í˜¸')
            user_company_nickname = user_info.get('company_nickname', f'PortOne {user_name} ë§¤ë‹ˆì €')
            user_phone = user_info.get('phone', '010-2580-2580')
            logger.info(f"ğŸ‘¤ [ì‚¬ìš©ìë¬¸ì•ˆ] ì´ë©”ì¼ ìƒì„±ì: {user_name} ({user_company_nickname})")
            logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] ì „ë‹¬ë°›ì€ ì‚¬ìš©ì ì •ë³´ ì‚¬ìš©: {user_info.get('email', 'N/A')}")
        else:
            user_name = current_user.name if (current_user and current_user.is_authenticated) else "ì˜¤ì¤€í˜¸"
            user_company_nickname = current_user.company_nickname if (current_user and current_user.is_authenticated) else f"PortOne {user_name} ë§¤ë‹ˆì €"
            user_phone = current_user.phone if (current_user and current_user.is_authenticated) else "010-2580-2580"
            
            # ë””ë²„ê¹…: ì‚¬ìš©ì ì •ë³´ ë¡œê·¸
            logger.info(f"ğŸ‘¤ [ì‚¬ìš©ìë¬¸ì•ˆ] ì´ë©”ì¼ ìƒì„±ì: {user_name} (PortOne {user_name} ë§¤ë‹ˆì €)")
            if current_user and current_user.is_authenticated:
                logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] ë¡œê·¸ì¸ ì‚¬ìš©ì ì¸ì¦ë¨: {current_user.email}")
            else:
                logger.warning(f"âš ï¸  [ì‚¬ìš©ìë¬¸ì•ˆ] current_user ì¸ì¦ ì•ˆ ë¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data) or 'Unknown'
        
        # ë‹´ë‹¹ì ì •ë³´ ì¶”ì¶œ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        email_name = get_email_salutation(company_data)
        
        if not email_name:
            contact_name = get_contact_name(company_data)
            contact_position = get_contact_position(company_data)
            if not contact_name or contact_name == 'ë‹´ë‹¹ì':
                email_name = 'ë‹´ë‹¹ìë‹˜'
            else:
                if contact_position:
                    if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €', 'ì‹¤ì¥', 'ê³¼ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì£¼ì„', 'ëŒ€ë¦¬', 'ì„ ì„', 'ì±…ì„']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    else:
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                else:
                    if any(title in contact_name for title in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name}ë‹˜'
                    else:
                        email_name = f'{contact_name} ë‹´ë‹¹ìë‹˜'
        
        # ê²½ìŸì‚¬ ì •ë³´ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        competitor_name = get_competitor(company_data)
        
        company_info = f"íšŒì‚¬ëª…: {company_name}\në‹´ë‹¹ì: {email_name}"
        if competitor_name:
            company_info += f"\nPortOne ì´ìš© ê²½ìŸì‚¬: {competitor_name}"
        
        # ğŸ†• í˜¸ìŠ¤íŒ… ì •ë³´ ëª…ì‹œì  ì¶”ê°€ (PGì™€ í˜¼ë™ ë°©ì§€)
        hosting_info = get_hosting(company_data)
        if hosting_info:
            company_info += f"\nğŸ  í˜¸ìŠ¤íŒ…ì‚¬ (ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…, ê²°ì œì™€ ë¬´ê´€): {hosting_info}"
        
        # ğŸ†• ì‚¬ìš©PG ì •ë³´ ì¶”ê°€ (ê²°ì œ ì„œë¹„ìŠ¤ ëª…ì‹œ)
        pg_info = get_pg_provider(company_data)
        if pg_info:
            company_info += f"\nğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG (ê²°ì œ ì„œë¹„ìŠ¤): {pg_info}"
        else:
            company_info += f"\nğŸ’³ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PG: ì •ë³´ ì—†ìŒ (PG ê´€ë ¨ ë‚´ìš© ì–¸ê¸‰ ê¸ˆì§€)"
        
        # ì¡°ì‚¬ ì •ë³´
        research_summary = research_data.get('company_info', 'ì¡°ì‚¬ ì •ë³´ ì—†ìŒ')
        
        # í˜¸ìŠ¤íŒ…ì‚¬ ì •ë³´ í™•ì¸ (OPI ì œê³µ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨) - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        hosting = get_hosting(company_data).lower().strip()
        
        if hosting:
            logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] {company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ë°œê²¬: '{hosting}'")
        else:
            logger.warning(f"[ì‚¬ìš©ìë¬¸ì•ˆ] {company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ")
        
        # AWS, Cloudflareë„ ìì²´êµ¬ì¶•ìœ¼ë¡œ ê°„ì£¼
        is_self_hosted = ('ìì²´' in hosting or 'self' in hosting or 'ì§ì ‘' in hosting or 
                         'aws' in hosting.lower() or 'cloudflare' in hosting.lower())
        
        # sales_itemì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ê²°ì • - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        sales_item = get_sales_item(company_data).lower().strip()
        services_to_generate = []
        if sales_item:
            if 'opi' in sales_item:
                # OPIëŠ” ìì²´êµ¬ì¶•ì¸ ê²½ìš°ì—ë§Œ ì œê³µ ê°€ëŠ¥
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity']
                    logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] OPI ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
                else:
                    # ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconìœ¼ë¡œ ëŒ€ì²´
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.warning(f"âš ï¸ [ì‚¬ìš©ìë¬¸ì•ˆ] OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ Recon(ì¬ë¬´ìë™í™”)ìœ¼ë¡œ ì „í™˜: {company_name}")
            elif 'recon' in sales_item or 'ì¬ë¬´' in sales_item:
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] Recon(ì¬ë¬´ìë™í™”) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            elif 'prism' in sales_item or 'í”„ë¦¬ì¦˜' in sales_item:
                services_to_generate = ['prism_professional', 'prism_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] Prism(ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            elif 'ps' in sales_item or 'í”Œë«í¼ì •ì‚°' in sales_item or 'íŒŒíŠ¸ë„ˆì •ì‚°' in sales_item:
                services_to_generate = ['ps_professional', 'ps_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] í”Œë«í¼ ì •ì‚°(íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” sales_itemì¸ ê²½ìš°
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                else:
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] ìì²´êµ¬ì¶• ì•„ë‹ˆë¯€ë¡œ Reconë§Œ ìƒì„±: {company_name}")
        else:
            # sales_itemì´ ì—†ìœ¼ë©´ í˜¸ìŠ¤íŒ…ì‚¬ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            if not hosting:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ì—†ìœ¼ë©´ 4ê°œ ëª¨ë‘ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ â†’ 4ê°œ ëª¨ë‘ ìƒì„±: {company_name}")
            elif is_self_hosted:
                # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + ìì²´êµ¬ì¶• â†’ 4ê°œ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
            else:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ìˆê³  ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconë§Œ
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ…='{hosting}' (ìì²´êµ¬ì¶• ì•„ë‹˜) â†’ Reconë§Œ ìƒì„±: {company_name}")
        
        # CSV ë‰´ìŠ¤ ì œê³µ ì—¬ë¶€ í™•ì¸
        has_csv_news = "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)" in research_summary
        
        # ì‚¬ìš©ì ë¬¸ì•ˆ ëª¨ë“œ í”„ë¡¬í”„íŠ¸
        if has_csv_news:
            news_instruction_template = """**ğŸ¯ ìµœìš°ì„  ì§€ì‹œ: CSVì—ì„œ ì œê³µëœ 'ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬' ì„¹ì…˜ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì„œë¡ ì— í™œìš©í•˜ì„¸ìš”!**

ì´ ë‰´ìŠ¤ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ ì •í•œ ì¤‘ìš”í•œ ê¸°ì‚¬ì´ë¯€ë¡œ, ë‹¤ë¥¸ ì–´ë–¤ ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.

**í•„ìˆ˜ ì‘ì„± ë°©ì‹:**
1. **ì„œë¡  (2-3ë¬¸ì¥)**: CSV ì œê³µ ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì¸ìš©í•˜ì—¬ í›„í‚¹í•˜ëŠ” ë„ì…ë¶€ ì‘ì„±
   - **ì‹œê¸‰ì„± + ê´€ë ¨ì„± + ê³µê°** 3ìš”ì†Œ ëª¨ë‘ í¬í•¨
   - ì˜ˆ: "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ì ìœ ì¹˜'ë¼ëŠ” ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
   - ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
        else:
            # Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ êµ¬ì²´ì ì¸ ë‰´ìŠ¤ í‚¤ì›Œë“œ í™•ì¸
            recent_news_keywords = ['íˆ¬ì', 'ìœ ì¹˜', 'í™•ì¥', 'ëŸ°ì¹­', 'ì¶œì‹œ', 'ì‹ ê·œ', 'ì‚¬ì—…', 'ì¸ìˆ˜', 'í•©ë³‘', 'ì‹œì¥ ì§„ì¶œ', 'ë§¤ì¶œ', 'ì„±ì¥']
            has_specific_news_template = any(keyword in research_summary for keyword in recent_news_keywords)
            
            if has_specific_news_template:
                news_instruction_template = """**í•„ìˆ˜ ì‘ì„± ë°©ì‹:**
1. **ì„œë¡  (2-3ë¬¸ì¥)**: ìœ„ì˜ ì¡°ì‚¬ ê²°ê³¼ì—ì„œ êµ¬ì²´ì ì¸ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì¸ìš©í•˜ì—¬ í›„í‚¹í•˜ëŠ” ë„ì…ë¶€ ì‘ì„±
   - **ì‹œê¸‰ì„± + ê´€ë ¨ì„± + ê³µê°** 3ìš”ì†Œ ëª¨ë‘ í¬í•¨
   - ì˜ˆ: "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ì ìœ ì¹˜' ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
   - ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ê¸°ì‚¬ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
            else:
                news_instruction_template = """**í•„ìˆ˜ ì‘ì„± ë°©ì‹:**
1. **ì„œë¡  (2-3ë¬¸ì¥)**: ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ìì—°ìŠ¤ëŸ¬ìš´ ë„ì…ë¶€ ì‘ì„±
   
   **ì˜µì…˜ 1 - ì—…ê³„ íŠ¸ë Œë“œ ê¸°ë°˜ (ê¶Œì¥):**
   - "{company_name}ë‹˜ì´ ì†í•œ {ì—…ì¢…} ì—…ê³„ì—ì„œëŠ” ìš”ì¦˜ {íŠ¸ë Œë“œ}ê°€ í™”ë‘ì¸ë°, í˜¹ì‹œ {ê´€ë ¨ Pain Point} ê³ ë¯¼ ì¤‘ì´ì‹ ê°€ìš”?"
   - ì˜ˆ: "ê²Œì„ ì—…ê³„ì—ì„œ ì¸ì•± ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì´ ì»¤ì§€ê³  ìˆëŠ”ë°, {company_name}ë‹˜ë„ ì´ ë¶€ë¶„ ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?"
   
   **ì˜µì…˜ 2 - íšŒì‚¬ ê·œëª¨/ì„±ì¥ ë‹¨ê³„ ì–¸ê¸‰:**
   - "{company_name}ë‹˜ ê·œëª¨ì˜ íšŒì‚¬ë¼ë©´ {ì˜ˆìƒ Pain Point}ë¥¼ ê²ªê³  ê³„ì‹¤ ê²ƒ ê°™ì€ë°, ë§ë‚˜ìš”?"
   - ì˜ˆ: "ì—°ë§¤ì¶œ 100ì–µ ê·œëª¨ì˜ ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì´ë¼ë©´ PGì‚¬ ê´€ë¦¬ì— ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ ë“¤ì–´ê°€ì‹¤ í…ë°..."
   
   **ì˜µì…˜ 3 - ì§ì ‘ì  ê³µê° (ê°€ì¥ ìì—°ìŠ¤ëŸ¬ì›€):**
   - "{ì—…ì¢…} ê¸°ì—…ë“¤ì´ ê³µí†µì ìœ¼ë¡œ {Pain Point}ë¥¼ ê²ªê³  ê³„ì‹œëŠ”ë°, {company_name}ë‹˜ë„ ë¹„ìŠ·í•œ ìƒí™©ì´ì‹ ê°€ìš”?"
   - ì˜ˆ: "ì»¤ë¨¸ìŠ¤ ê¸°ì—…ë“¤ì´ ì—¬ëŸ¬ PGì‚¬ë¥¼ ê´€ë¦¬í•˜ëŠë¼ ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹œëŠ”ë°, {company_name}ë‹˜ë„ ê°™ì€ ê³ ë¯¼ì´ì‹ ê°€ìš”?"
   
   âš ï¸ **ì ˆëŒ€ ê¸ˆì§€**: "ìµœê·¼ ë‰´ìŠ¤ë¥¼ í™•ì¸í–ˆëŠ”ë°..." ê°™ì€ ê±°ì§“ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
   âœ… **ê¶Œì¥**: ìœ„ ì¡°ì‚¬ ê²°ê³¼ì˜ ì—…ì¢…, ê·œëª¨, Pain Point ì •ë³´ë¥¼ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ê³µê° """
        
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
{company_info}

**ğŸ”¥ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ (ì´ë©”ì¼ ì„œë¡ ì— ë°˜ë“œì‹œ í™œìš©):**
{research_summary}

**ğŸ¯ íŠ¹ë³„ ìš”ì²­ì‚¬í•­: ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ í™œìš©**

ì‚¬ìš©ìê°€ ì œê³µí•œ ë³¸ë¬¸ ë¬¸ì•ˆ:
---
{user_template}
---

**ğŸ¯ ìµœìš°ì„  ëª©í‘œ: B2B ì˜ì‚¬ê²°ì •ìê°€ "ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ë‹¤"ê³  ëŠë¼ëŠ” ë©”ì¼ ì‘ì„±**

ë‰´ìŠ¤ í›„í‚¹ ì„œë¡ ì´ ë‹¤ìŒ ë°˜ì‘ì„ ì´ëŒì–´ë‚´ì•¼ í•©ë‹ˆë‹¤:
- "ìš°ë¦¬ íšŒì‚¬ì˜ í˜„ì¬ ìƒí™©ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìˆë‹¤"
- "ë§¤ìš° ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ"
- "ì¦‰ì‹œ ë‹µì¥í•  ê°€ì¹˜ê°€ ìˆë‹¤"

**âš ï¸ ì¤‘ìš”**: ì´ë©”ì¼ ë³¸ë¬¸ ì‘ì„± ì‹œ "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì ˆëŒ€", "ë¬´ì¡°ê±´" ë“±ì˜ ê·¹ë‹¨ì  í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , í˜„ì‹¤ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "ë¹ ë¥´ê²Œ", "90% ì´ìƒ", "ë†’ì€ ì •í™•ë„ë¡œ", "ëŒ€í­")

{news_instruction_template}

2. **ë³¸ë¬¸ (90%)**: ìœ„ì— ì œê³µëœ ì‚¬ìš©ì ë¬¸ì•ˆì„ **ê±°ì˜ ê·¸ëŒ€ë¡œ** ì‚¬ìš©í•˜ë˜, ë‹¤ìŒë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì¸í™”:
   - {{company_name}} íšŒì‚¬ëª…ì„ ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…
   - {{email_name}} ë‹´ë‹¹ìëª…ì„ ë§¥ë½ì— ë§ê²Œ ì¶”ê°€ ê°€ëŠ¥
   - ë¬¸ì¥ ìˆœì„œë‚˜ í•µì‹¬ ë‚´ìš©ì€ **ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ê²ƒ**
   - ë‹¨ì–´ ì„ íƒì´ë‚˜ ë¬¸ì²´ë„ **ìµœëŒ€í•œ ì›ë³¸ ìœ ì§€**

3. **ê³ ì • ê²°ë¡  (âš ï¸ í•„ìˆ˜!)**: 
   "<br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"
   
   â€¼ï¸ **CTAëŠ” ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤!** "ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´..."ì´ ë¹ ì§€ë©´ ì•ˆ ë©ë‹ˆë‹¤.

**ê³ ì • ì„œë¡  í˜•ì‹ (ì„œë¡  ì‹œì‘ ì „):**
"ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>"

**êµ¬ì¡°:**
- ì œëª©: "[PortOne] {{company_name}} {{email_name}}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤"
- ë³¸ë¬¸: ê³ ì • ì„œë¡  â†’ ë‰´ìŠ¤ í›„í‚¹ ì„œë¡ (2-3ë¬¸ì¥) â†’ ì‚¬ìš©ì ë¬¸ì•ˆ(90% ìœ ì§€) â†’ ê³ ì • ê²°ë¡ 

**ì¤‘ìš”**: ì–´ë–¤ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

**ìƒì„±í•  ì„œë¹„ìŠ¤**: {', '.join(services_to_generate)}

{{
  "opi_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "opi_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }}
}}
"""
        
        # Gemini API í˜¸ì¶œ
        if not GEMINI_API_KEY:
            return {
                'success': False,
                'error': 'Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'timestamp': datetime.now().isoformat()
            }
        
        try:
            # ìœ ë£Œ API í‚¤ ì‚¬ìš© - Gemini 3 Pro ì‚¬ìš©
            model = genai.GenerativeModel('gemini-3-pro-preview')
            
            # 503 ì—ëŸ¬ ì¬ì‹œë„ ë¡œì§
            max_retries = 3
            retry_delay = 3
            response = None
            
            for attempt in range(max_retries):
                try:
                    response = model.generate_content(context)
                    break  # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
                except Exception as api_error:
                    error_msg = str(api_error)
                    if '503' in error_msg or 'overloaded' in error_msg.lower() or 'unavailable' in error_msg.lower():
                        logger.warning(f"Gemini API ê³¼ë¶€í•˜ (ì‹œë„ {attempt+1}/{max_retries}): {company_name}")
                        if attempt < max_retries - 1:
                            logger.info(f"{retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                            import time
                            time.sleep(retry_delay)
                            continue
                        else:
                            logger.error(f"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ - Gemini ì„œë²„ ê³¼ë¶€í•˜: {company_name}")
                            raise Exception("Gemini API ì„œë²„ ê³¼ë¶€í•˜ (ì¬ì‹œë„ ì‹¤íŒ¨)")
                    else:
                        # 503ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¦‰ì‹œ ì¬ë°œìƒ
                        raise
            
            if response and response.text:
                # JSON íŒŒì‹±
                clean_response = response.text.strip()
                if '```json' in clean_response:
                    json_start = clean_response.find('```json') + 7
                    json_end = clean_response.find('```', json_start)
                    if json_end != -1:
                        clean_response = clean_response[json_start:json_end]
                    else:
                        clean_response = clean_response[json_start:]
                elif '{' in clean_response and '}' in clean_response:
                    json_start = clean_response.find('{')
                    json_end = clean_response.rfind('}') + 1
                    clean_response = clean_response[json_start:json_end]
                
                clean_response = clean_response.strip()
                email_variations = json.loads(clean_response)
                
                # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
                def convert_markdown_to_html(text):
                    """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ HTMLë¡œ ë³€í™˜ (**ë³¼ë“œ**, *ì´íƒ¤ë¦­* ë“±)"""
                    import re
                    # **í…ìŠ¤íŠ¸** â†’ <strong>í…ìŠ¤íŠ¸</strong>
                    text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
                    # *í…ìŠ¤íŠ¸* â†’ <em>í…ìŠ¤íŠ¸</em> (ë³¼ë“œ ì²˜ë¦¬ í›„ ë‚¨ì€ ë‹¨ì¼ *)
                    text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
                    return text
                
                # í”Œë ˆì´ìŠ¤í™€ë” êµì²´
                def replace_placeholders(text, company_name, email_name, competitor_name=''):
                    result = text.replace('{company_name}', company_name).replace('{email_name}', email_name)
                    result = result.replace('{{company_name}}', company_name).replace('{{email_name}}', email_name)
                    if competitor_name:
                        result = result.replace('{competitor_name}', competitor_name).replace('{{competitor_name}}', competitor_name)
                    # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
                    result = result.replace('ì˜¤ì¤€í˜¸', user_name)
                    result = result.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
                    # ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì ìš©
                    result = convert_markdown_to_html(result)
                    return result
                
                formatted_variations = {}
                for service in services_to_generate:
                    if service in email_variations:
                        subject = f'[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤'
                        body = replace_placeholders(email_variations[service]['body'], company_name, email_name, competitor_name)
                        
                        formatted_variations[service] = {
                            'subject': subject,
                            'body': body
                        }
                
                # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
                logger.info(f"{company_name}: [ì‚¬ìš©ìë¬¸ì•ˆ] CTA ê²€ì¦ ì‹œì‘...")
                for service_key, email_content in formatted_variations.items():
                    if 'body' in email_content:
                        email_content['body'] = validate_and_fix_cta(
                            email_content['body'],
                            company_name
                        )
                
                return {
                    'success': True,
                    'variations': formatted_variations,
                    'services_generated': services_to_generate,
                    'sales_item': sales_item if sales_item else 'all',
                    'timestamp': datetime.now().isoformat(),
                    'model': 'gemini-3-pro-preview',
                    'mode': 'user_template'
                }
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ë¬¸ì•ˆ ì´ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì ë¬¸ì•ˆ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def generate_persuasive_reply(context, company_name, email_name, case_examples=""):
    """
    ê³ ê° ë°˜ë°•/ë¶€ì •ì  ë‹µë³€ì— ëŒ€í•œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
    
    Args:
        context: ê³ ê°ì˜ ë‹µë³€ ë˜ëŠ” ìƒí™© ì„¤ëª…
        company_name: íšŒì‚¬ëª…
        email_name: ë‹´ë‹¹ì í˜¸ì¹­
        case_examples: ê´€ë ¨ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
    
    Returns:
        dict: ìƒì„±ëœ ì¬ì„¤ë“ ë©”ì¼
    """
    try:
        logger.info(f"{company_name}: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹œì‘")
        
        # Gemini í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ìµœê³  ì˜ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ë¶€ì •ì  ë°˜ì‘ì´ë‚˜ ë°˜ë°•ì— ëŒ€ì‘í•˜ì—¬ ì¬ì„¤ë“í•˜ëŠ” ë©”ì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤.

**ê³ ê° ìƒí™©/ë‹µë³€:**
{context}

**íšŒì‚¬ ì •ë³´:**
- íšŒì‚¬ëª…: {company_name}
- ë‹´ë‹¹ì: {email_name}

**í¬íŠ¸ì› ì„œë¹„ìŠ¤ ì†Œê°œ, ì‹¤ì œ ì‚¬ë¡€ ë° ìµœì‹  ë¸”ë¡œê·¸ ì½˜í…ì¸ :**
{case_examples}

ğŸ’¡ **ìœ„ ì •ë³´ í™œìš© ë°©ë²•:**
- ì‹¤ì œ ê³ ê°ì‚¬ ì‚¬ë¡€ë¥¼ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ë„ ë†’ì´ê¸°
- ìµœì‹  ë¸”ë¡œê·¸ ì½˜í…ì¸ ì—ì„œ ê´€ë ¨ íŠ¸ë Œë“œë‚˜ ê¸°ìˆ  ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
- "ìµœê·¼ í¬íŠ¸ì› ë¸”ë¡œê·¸ì—ì„œë„..." ê°™ì€ ë°©ì‹ìœ¼ë¡œ í™œìš© ê°€ëŠ¥
- **í¬íŠ¸ì› ê³µì‹ ë¸”ë¡œê·¸(https://blog.portone.io/)ì˜ ë‚´ìš©ì€ ê²€ì¦ëœ ì¶œì²˜ì´ë¯€ë¡œ ììœ ë¡­ê²Œ ì¸ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤**
- **ë¸”ë¡œê·¸ ë‚´ìš©ì„ ì¸ìš©í•˜ê±°ë‚˜ ì°¸ê³ í–ˆì„ ê²½ìš°, ë°˜ë“œì‹œ ì´ë©”ì¼ ì œì¼ ë§ˆì§€ë§‰(ì„œëª… ì´í›„)ì— `[ì°¸ê³ ] <ë¸”ë¡œê·¸ ì œëª©>: <ë§í¬>` í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ ë‚¨ê¸°ì„¸ìš”**
- **ğŸš¨ ë¸”ë¡œê·¸ ë§í¬ ì‚¬ìš© ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**
  1. **ì ˆëŒ€ ë§í¬ë¥¼ ì„ì˜ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”** (UUIDë‚˜ ë‹¤ë¥¸ í˜•ì‹ ê¸ˆì§€!)
  2. **ì•„ë˜ ì°¸ê³  ì •ë³´ì— ì œê³µëœ "ë§í¬:" ë¶€ë¶„ì˜ URLì„ ì •í™•íˆ ë³µì‚¬**í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
  3. **ì˜ˆì‹œ**: ì°¸ê³ ìë£Œì— "ë§í¬: https://blog.portone.io/opi_case_game/" ì´ ìˆë‹¤ë©´, ì •í™•íˆ ì´ URLì„ ì‚¬ìš©
  4. **ì˜ëª»ëœ ì˜ˆ**: https://blog.portone.io/84f99450-... (UUID í˜•ì‹ ì ˆëŒ€ ê¸ˆì§€!)
- **ğŸš¨ ë¸”ë¡œê·¸ ì¶œì²˜ í‘œê¸° ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!):**
  1. **ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰í•˜ê±°ë‚˜ ì¸ìš©í•œ ë¸”ë¡œê·¸ë§Œ ì¶œì²˜ë¡œ í‘œê¸°**í•˜ì„¸ìš”
  2. **ì–¸ê¸‰í•˜ì§€ ì•Šì€ ë¸”ë¡œê·¸ë¥¼ ì¶œì²˜ë¡œ ë„£ì§€ ë§ˆì„¸ìš”** (ì°¸ê³ ë§Œ í•˜ê³  ë³¸ë¬¸ì— ì•ˆ ì“´ ê²½ìš° ì¶œì²˜ ë¶ˆí•„ìš”)
  3. **í•´ë‹¹ íšŒì‚¬ ì—…ì¢…ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ë¸”ë¡œê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”** (ì˜ˆ: ê²Œì„ì—…ì²´ì— ì—¬í–‰ì—…ê³„ ë¸”ë¡œê·¸ âŒ)
  4. **ì•„ë˜ ì°¸ê³  ì •ë³´ì˜ ë¸”ë¡œê·¸ëŠ” ì´ë¯¸ {company_name}ì˜ ì—…ì¢…ì— ë§ì¶° í•„í„°ë§ëœ ê²ƒ**ì´ë¯€ë¡œ ì•ˆì‹¬í•˜ê³  í™œìš©í•˜ì„¸ìš”
- **Perplexity ì¡°ì‚¬ ê²°ê³¼ì™€ PortOne ê³µì‹ ë¸”ë¡œê·¸ëŠ” ëª¨ë‘ ê²€ì¦ëœ ì¶œì²˜ì´ë¯€ë¡œ í™˜ê°ì´ ì•„ë‹™ë‹ˆë‹¤**

**ğŸ¯ ëª©í‘œ: ê³ ê°ì˜ ìš°ë ¤ë¥¼ í•´ì†Œí•˜ê³  ì¬ë¯¸íŒ… ê¸°íšŒë¥¼ ë§Œë“œëŠ” ì„¤ë“ë ¥ ìˆëŠ” ë©”ì¼ ì‘ì„±**

**ë©”ì¼ ì‘ì„± ì „ëµ:**

1. **ê³µê° ë¨¼ì €**: ê³ ê°ì˜ ìš°ë ¤ë‚˜ ì˜ê²¬ì„ ë¨¼ì € ì¸ì •í•˜ê³  ê³µê°
   - "ë§ì”€í•˜ì‹  ìš°ë ¤ ì¶©ë¶„íˆ ì´í•´í•©ë‹ˆë‹¤"
   - "ì¢‹ì€ ì§€ì ì´ì‹­ë‹ˆë‹¤"
   
2. **ì˜¤í•´ í•´ì†Œ**: ê³ ê°ì´ ì˜ëª» ì´í•´í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë¶€ë“œëŸ½ê²Œ ì„¤ëª…
   - ê°•ì••ì ì´ì§€ ì•Šê²Œ
   - ë°ì´í„°ì™€ ì‚¬ë¡€ë¡œ ë’·ë°›ì¹¨

3. **êµ¬ì²´ì  ì‚¬ë¡€ + ìµœì‹  ì •ë³´ ì œì‹œ**: 
   - ìœ„ì˜ ì‹¤ì œ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ í™œìš©
   - ë¹„ìŠ·í•œ ìš°ë ¤ë¥¼ ê°€ì¡Œë˜ ë‹¤ë¥¸ ê³ ê°ì‚¬ ì‚¬ë¡€
   - ë„ì… í›„ ê²°ê³¼ ìˆ˜ì¹˜ ì œì‹œ
   - **í¬íŠ¸ì› ë¸”ë¡œê·¸ì˜ ìµœì‹  ì½˜í…ì¸ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰**í•˜ì—¬ ì „ë¬¸ì„±ê³¼ ìµœì‹ ì„± ê°•ì¡°
   - "{company_name}ë‹˜ê³¼ ë¹„ìŠ·í•œ ìƒí™©ì´ì—ˆë˜ [ê³ ê°ì‚¬ëª…]ë„..."

4. **ìƒˆë¡œìš´ ê°€ì¹˜ ì œì•ˆ**: ê³ ê°ì´ ë†“ì¹œ ë¶€ë¶„ ê°•ì¡°
   - ROI, ì‹œê°„ ì ˆì•½, ë¦¬ìŠ¤í¬ ê°ì†Œ ë“±
   - êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ì„¤ë“
   - ìµœì‹  íŠ¸ë Œë“œë‚˜ ì—…ê³„ ë™í–¥ ì–¸ê¸‰

5. **ë¶€ë‹´ ì—†ëŠ” ì¬ì œì•ˆ**: 
   - "ë‹¨ 15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹œë©´..."
   - "ë¯¸íŒ…ì„ í†µí•´ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ë©´..."
   - "ë¬´ë£Œ ì»¨ì„¤íŒ…ìœ¼ë¡œ ê°€ëŠ¥ì„±ë§Œ í™•ì¸í•´ë³´ì‹œê² ìŠµë‹ˆê¹Œ?"

**ë°˜ë°• ìœ í˜•ë³„ ëŒ€ì‘ ì „ëµ:**

A. **"ë¹„ìš©ì´ ë¶€ë‹´ë©ë‹ˆë‹¤"**
   â†’ ROI ê³„ì‚°, ì¥ê¸°ì  ì ˆê° íš¨ê³¼, ë¬´ë£Œ ì²´í—˜ ì œì•ˆ

B. **"ì§€ê¸ˆì€ ë°”ë¹ ì„œ ì–´ë µìŠµë‹ˆë‹¤"**
   â†’ ê°„ë‹¨í•œ ë„ì… í”„ë¡œì„¸ìŠ¤ ê°•ì¡°, 2ì£¼ ë‚´ êµ¬ì¶• ê°€ëŠ¥, ìµœì†Œ ë¦¬ì†ŒìŠ¤

C. **"í˜„ì¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤"**
   â†’ ìˆ¨ê²¨ì§„ ë¹„íš¨ìœ¨ ì§€ì , í™•ì¥ì„± ë¬¸ì œ, ë¯¸ë˜ ì„±ì¥ ëŒ€ë¹„

D. **"ë‹¤ë¥¸ ì†”ë£¨ì…˜ê³¼ ë¹„êµ ì¤‘ì…ë‹ˆë‹¤"**
   â†’ ì°¨ë³„ì  ê°•ì¡°, ê³ ê°ì‚¬ ë§Œì¡±ë„, PGì‚¬ ë¹„êµ ê²¬ì  ì œê³µ

E. **"ë‚´ë¶€ ê²€í† ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤"**
   â†’ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ìë£Œ ì œê³µ, ë ˆí¼ëŸ°ìŠ¤ ì—°ê²°, CTO ë¯¸íŒ… ì œì•ˆ

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ:**

1. **ì„œë¡ **: ì´ì „ ë©”ì¼ ê°ì‚¬ + ê³µê°
   "ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name}ì…ë‹ˆë‹¤.<br><br>
   ë°”ì˜ì‹  ì™€ì¤‘ì—ë„ ë‹µë³€ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."

2. **ë³¸ë¬¸**: 
   - ìš°ë ¤ì‚¬í•­ ê³µê° ë° í•´ì†Œ
   - ì‹¤ì œ ì‚¬ë¡€ 2-3ê°œ êµ¬ì²´ì  ì œì‹œ
   - ìˆ˜ì¹˜ ê¸°ë°˜ ì„¤ë“ (85% ì ˆê°, 2ì£¼ ë‚´ êµ¬ì¶• ë“±)
   - ìƒˆë¡œìš´ ê´€ì  ì œì‹œ

3. **CTA (í•„ìˆ˜!)**: 
   "<br>ê·¸ë˜ë„ í•œ ë²ˆë§Œ ê¸°íšŒë¥¼ ì£¼ì‹œë©´ {company_name}ì˜ ìƒí™©ì— ë§ëŠ”<br>
   êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ë³´ì—¬ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>
   ë‹¤ìŒ ì£¼ ì¤‘ 15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?<br>
   ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>
   ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"

**í†¤ì•¤ë§¤ë„ˆ:**
- ì ˆëŒ€ ê°•ì••ì ì´ê±°ë‚˜ ê³µê²©ì ì´ì§€ ì•Šê²Œ
- ì§„ì •ì„± ìˆê²Œ, ê³ ê°ì˜ ì„±ê³µì„ ì§„ì‹¬ìœ¼ë¡œ ì›í•˜ëŠ” íŒŒíŠ¸ë„ˆë¡œ
- ì „ë¬¸ì ì´ì§€ë§Œ ì¹œê·¼í•˜ê²Œ
- ë°ì´í„°ì™€ ì‚¬ì‹¤ ê¸°ë°˜

**êµ¬ì¡°:**
ì œëª©: [PortOne] {company_name} {email_name} - ì¶”ê°€ ë§ì”€ ë“œë¦½ë‹ˆë‹¤

ë³¸ë¬¸: HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±
<p>ì„œë¡ </p>
<p>ë³¸ë¬¸ - ê³µê° + í•´ì†Œ</p>
<p>ë³¸ë¬¸ - ì‚¬ë¡€ ì œì‹œ</p>
<p>ë³¸ë¬¸ - ìƒˆë¡œìš´ ê°€ì¹˜</p>
<p>CTA</p>

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:**
{{
  "subject": "ì œëª©",
  "body": "HTML ë³¸ë¬¸",
  "strategy_used": "ì‚¬ìš©í•œ ì „ëµ ê°„ë‹¨ ì„¤ëª…",
  "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"]
}}
"""

        # Gemini API í˜¸ì¶œ
        model = genai.GenerativeModel('gemini-3-pro-preview')
        response = model.generate_content(prompt)
        
        if not response or not response.text:
            raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # JSON íŒŒì‹±
        import re
        response_text = response.text.strip()
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        elif '{' in response_text and '}' in response_text:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text
        
        email_data = json.loads(json_str)
        
        # CTA ê²€ì¦
        if 'body' in email_data:
            email_data['body'] = validate_and_fix_cta(email_data['body'], company_name)
        
        logger.info(f"{company_name}: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì™„ë£Œ")
        
        return {
            'success': True,
            'email': email_data,
            'timestamp': datetime.now().isoformat(),
            'model': 'gemini-3-pro-preview'
        }
        
    except Exception as e:
        logger.error(f"{company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def validate_and_fix_cta(email_body, company_name):
    """
    ì´ë©”ì¼ ë³¸ë¬¸ì— CTA(Call-to-Action)ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
    
    Args:
        email_body: ì´ë©”ì¼ ë³¸ë¬¸ (HTML)
        company_name: íšŒì‚¬ëª…
    
    Returns:
        str: CTAê°€ í¬í•¨ëœ ì´ë©”ì¼ ë³¸ë¬¸
    """
    # CTA í‚¤ì›Œë“œ ì²´í¬
    cta_keywords = [
        'ë‹¤ìŒì£¼ ì¤‘', 'ë‹¤ìŒ ì£¼ ì¤‘', 'í¸í•˜ì‹  ì¼ì •', 'í¸í•˜ì‹  ì‹œê°„',
        'ê¸ì •ì ì¸ íšŒì‹ ', 'íšŒì‹  ë¶€íƒ', 'ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´',
        'ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´', 'ë¯¸íŒ… ê°€ëŠ¥í•œ ì‹œê°„'
    ]
    
    # ë³¸ë¬¸ì— CTA í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
    has_cta = any(keyword in email_body for keyword in cta_keywords)
    
    if has_cta:
        logger.info(f"{company_name}: CTA ê²€ì¦ í†µê³¼ âœ“")
        return email_body
    
    # CTAê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
    logger.warning(f"{company_name}: âš ï¸  CTA ëˆ„ë½ ê°ì§€ - ìë™ ì¶”ê°€")
    
    # í‘œì¤€ CTA í…œí”Œë¦¿
    standard_cta = f"""<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"""
    
    # ì„œëª… íŒ¨í„´ ì°¾ê¸°
    import re
    signature_patterns = [
        r'<p>\s*ê°ì‚¬í•©ë‹ˆë‹¤\.?<br>\s*ì˜¤ì¤€í˜¸\s*ë“œë¦¼\s*</p>',
        r'<p>\s*ì˜¤ì¤€í˜¸\s*Junho\s*Oh<br>\s*Sales\s*team.*?</p>',
        r'<p>\s*ì˜¤ì¤€í˜¸\s*ë“œë¦¼\s*</p>',
        r'ê°ì‚¬í•©ë‹ˆë‹¤[.\s]*$'
    ]
    
    # ì„œëª…ì´ ìˆìœ¼ë©´ ê·¸ ì•ì— CTA ì‚½ì…
    for pattern in signature_patterns:
        if re.search(pattern, email_body, re.DOTALL | re.IGNORECASE):
            email_body = re.sub(
                pattern,
                standard_cta,
                email_body,
                flags=re.DOTALL | re.IGNORECASE
            )
            logger.info(f"{company_name}: CTA ì¶”ê°€ ì™„ë£Œ (ì„œëª… ì•ì— ì‚½ì…)")
            return email_body
    
    # ì„œëª…ì´ ì—†ìœ¼ë©´ ë³¸ë¬¸ ëì— CTA ì¶”ê°€
    email_body = email_body.rstrip() + "\n\n" + standard_cta
    logger.info(f"{company_name}: CTA ì¶”ê°€ ì™„ë£Œ (ë³¸ë¬¸ ëì— ì¶”ê°€)")
    
    return email_body

def generate_email_with_gemini_and_cases(company_data, research_data, case_examples="", user_template=None, news_content=None, user_input_mode='template', user_info=None):
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ê°œì¸í™”ëœ ì´ë©”ì¼ ìƒì„± (ì‹¤ì œ ì‚¬ë¡€ í¬í•¨ ë²„ì „)
    
    Args:
        company_data: íšŒì‚¬ ì •ë³´ dict
        research_data: Perplexity ì¡°ì‚¬ ê²°ê³¼
        case_examples: ì„ íƒëœ ì‹¤ì œ ì‚¬ë¡€ í…ìŠ¤íŠ¸ (formatted)
        user_template: ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ ë˜ëŠ” ìš”ì²­ì‚¬í•­ (ì˜µì…˜)
        news_content: ìŠ¤í¬ë˜í•‘ëœ ë‰´ìŠ¤ ë‚´ìš© (ì˜µì…˜)
        user_input_mode: 'request' (ìš”ì²­ì‚¬í•­ ëª¨ë“œ) ë˜ëŠ” 'template' (ë¬¸ì•ˆ ëª¨ë“œ)
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    
    Returns:
        dict: ìƒì„±ëœ ì´ë©”ì¼ variations
    """
    # ì‚¬ìš©ì ì…ë ¥ì´ ìˆìœ¼ë©´ ëª¨ë“œì— ë”°ë¼ ì²˜ë¦¬ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
    company_name_for_log = get_company_name(company_data) or 'Unknown'
    if user_template:
        if user_input_mode == 'request':
            logger.info(f"{company_name_for_log}: ìš”ì²­ì‚¬í•­ ëª¨ë“œ - ê¸°ë³¸ ìƒì„± + ìš”ì²­ì‚¬í•­ ë°˜ì˜")
            return generate_email_with_user_request(company_data, research_data, user_template, case_examples, news_content, user_info)
        else:
            logger.info(f"{company_name_for_log}: ë¬¸ì•ˆ ëª¨ë“œ - ë‰´ìŠ¤ í›„í‚¹ + ì‚¬ìš©ì ë³¸ë¬¸")
            return generate_email_with_user_template(company_data, research_data, user_template, case_examples, news_content, user_info)
    
    # ì‚¬ìš©ì ì…ë ¥ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ SSR ë°©ì‹ (4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨)
    logger.info(f"{company_name_for_log}: SSR ëª¨ë“œ - 4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨")
    return generate_email_with_gemini(company_data, research_data, user_info)

def generate_email_with_user_request(company_data, research_data, user_request, case_examples="", news_content=None, user_info=None):
    """
    ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ê¸°ë°˜ ì´ë©”ì¼ ìƒì„± (2ë‹¨ê³„)
    
    1ë‹¨ê³„: ê¸°ë³¸ SSR ë°©ì‹ìœ¼ë¡œ 4ê°œ ë¬¸ì•ˆ ìƒì„± (Pain Point + í¬íŠ¸ì› í•´ê²°ì±… í¬í•¨)
    2ë‹¨ê³„: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜í•´ì„œ ê° ë¬¸ì•ˆ ê°œì„ 
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    try:
        # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data) or 'Unknown'
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ 1ë‹¨ê³„ - ê¸°ë³¸ ë¬¸ì•ˆ ìƒì„± ì‹œì‘")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ SSR ëª¨ë“œë¡œ ë¬¸ì•ˆ ìƒì„±
        base_result = generate_email_with_gemini(company_data, research_data, user_info)
        
        if not base_result.get('success'):
            logger.error(f"{company_name}: ê¸°ë³¸ ë¬¸ì•ˆ ìƒì„± ì‹¤íŒ¨")
            return base_result
        
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ 2ë‹¨ê³„ - ìš”ì²­ì‚¬í•­ ë°˜ì˜ ê°œì„  ì‹œì‘")
        
        # 2ë‹¨ê³„: ê° ë¬¸ì•ˆì„ ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì— ë§ì¶° ê°œì„ 
        base_variations = base_result.get('variations', {})
        refined_variations = {}
        
        for service_key, email_content in base_variations.items():
            try:
                # ì›ë³¸ ì´ë©”ì¼
                original_subject = email_content.get('subject', '')
                original_body = email_content.get('body', '')
                
                # ìš”ì²­ì‚¬í•­ ë°˜ì˜í•´ì„œ ê°œì„ 
                refined_email = refine_email_with_user_request(
                    original_subject=original_subject,
                    original_body=original_body,
                    user_request=user_request,
                    company_data=company_data,
                    user_info=user_info
                )
                
                if refined_email:
                    refined_variations[service_key] = refined_email
                else:
                    # ê°œì„  ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    refined_variations[service_key] = email_content
                    
            except Exception as e:
                logger.error(f"{company_name} {service_key} ê°œì„  ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ì‚¬ìš©
                refined_variations[service_key] = email_content
        
        # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
        for service_key, email_content in refined_variations.items():
            if 'body' in email_content:
                email_content['body'] = validate_and_fix_cta(
                    email_content['body'],
                    company_name
                )
        
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ ì™„ë£Œ - {len(refined_variations)}ê°œ ë¬¸ì•ˆ ìƒì„±")
        
        return {
            'success': True,
            'variations': refined_variations,
            'services_generated': base_result.get('services_generated', []),
            'sales_item': base_result.get('sales_item', 'all'),
            'timestamp': datetime.now().isoformat(),
            'model': 'gemini-3-pro-preview',
            'mode': 'user_request'
        }
        
    except Exception as e:
        logger.error(f"ìš”ì²­ëª¨ë“œ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def refine_email_with_user_request(original_subject, original_body, user_request, company_data, user_info=None):
    """
    ìƒì„±ëœ ì´ë©”ì¼ì„ ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì— ë§ì¶° ê°œì„ 
    
    âš ï¸ í•µì‹¬: ì›ë³¸ ì´ë©”ì¼ì˜ Pain Point + í¬íŠ¸ì› í•´ê²°ì±…ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ë©´ì„œ
             ì‚¬ìš©ì ìš”ì²­ì‚¬í•­(í†¤, ê°•ì¡°ì , ì œëª© ìŠ¤íƒ€ì¼ ë“±)ë§Œ ë°˜ì˜
    """
    try:
        # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
        company_name = get_company_name(company_data) or 'Unknown'
        
        # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
        if user_info:
            user_name = user_info.get('name', 'ì˜¤ì¤€í˜¸')
        else:
            user_name = 'ì˜¤ì¤€í˜¸'
        
        # ìš”ì²­ì‚¬í•­ ê°œì„  í”„ë¡¬í”„íŠ¸
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì´ë©”ì¼ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ğŸ¯ ìµœìš°ì„  ì„ë¬´: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì„ ë°˜ë“œì‹œ ëª¨ë‘ ë°˜ì˜í•˜ì„¸ìš”!**

**ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ (MUST FOLLOW - ì´ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤):**
{user_request}

**ğŸ‘† ìœ„ ìš”ì²­ì‚¬í•­ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³ , ëª¨ë“  ë””í…Œì¼ì„ ì™„ë²½íˆ ë°˜ì˜í•˜ì„¸ìš”:**

**ğŸ” STEP 1: ìš”ì²­ì‚¬í•­ ë””í…Œì¼ ë¶„ì„ (ì„¸ë°€í•˜ê²Œ íŒŒì•…)**
1. **ëª…ì‹œì  ìš”ì²­ íŒŒì•…**
   - í†¤ ë³€ê²½: "ì¹œê·¼í•˜ê²Œ", "ê²©ì‹ìˆê²Œ", "ì „ë¬¸ì ìœ¼ë¡œ" ë“±
   - ê¸¸ì´: "ì§§ê²Œ", "3ë¬¸ë‹¨ìœ¼ë¡œ", "ê°„ê²°í•˜ê²Œ", "ë” ìì„¸í•˜ê²Œ" ë“±
   - ê°•ì¡°: "OPI ê¸°ëŠ¥ ê°•ì¡°", "ìˆ˜ìˆ˜ë£Œ ì ˆê° ê°•ì¡°", "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•ì¡°" ë“±
   - ì œëª©: "ì œëª© ë³€ê²½", "ì œëª©ì— XXX í¬í•¨" ë“±
   - êµ¬ì¡°: "bullet pointë¡œ", "ë‹¨ë½ë³„ë¡œ", "Q&A í˜•ì‹" ë“±

2. **ì•”ë¬µì  ì˜ë„ íŒŒì•…**
   - "ë” ì„¤ë“ë ¥ìˆê²Œ" â†’ êµ¬ì²´ì  ìˆ˜ì¹˜, ì‚¬ë¡€ ì¶”ê°€
   - "ì„íŒ©íŠ¸ìˆê²Œ" â†’ ê°•ì¡° í¬ì¸íŠ¸ ëª…í™•íˆ, ë³¼ë“œ ì²˜ë¦¬
   - "ì½ê¸° ì‰½ê²Œ" â†’ ì§§ì€ ë¬¸ì¥, ë¸”ë › í¬ì¸íŠ¸, ì ì ˆí•œ ì¤„ë°”ê¿ˆ
   - "ê³ ê° ì…ì¥ì—ì„œ" â†’ Pain Point ê°•í™”, ê³µê° í‘œí˜„ ì¦ê°€
   - "êµ¬ì²´ì ìœ¼ë¡œ" â†’ ì¶”ìƒì  í‘œí˜„ â†’ êµ¬ì²´ì  ìˆ˜ì¹˜/ê¸°ëŠ¥ ë³€ê²½

3. **ë³µí•© ìš”ì²­ ë¶„í•´**
   - "ë” ì§§ê³  ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì„± ìˆê²Œ" â†’ 
     * ê¸¸ì´: 30% ì¶•ì†Œ
     * í†¤: ì¹œê·¼ í‘œí˜„ + ì „ë¬¸ ìš©ì–´ ê· í˜•
     * êµ¬ì¡°: í•µì‹¬ë§Œ ë‚¨ê¸°ê¸°
   - "OPIì˜ ìˆ˜ìˆ˜ë£Œ ì ˆê°ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê°•ì¡°í•˜ë˜ 3ë¬¸ë‹¨ìœ¼ë¡œ" â†’
     * ê°•ì¡°: ìˆ˜ìˆ˜ë£Œ ì ˆê°, ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë³¼ë“œ ì²˜ë¦¬
     * êµ¬ì¡°: 3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ì¬êµ¬ì„±
     * ë‚´ìš©: í•µì‹¬ ê°€ì¹˜ ìš°ì„  ë°°ì¹˜

4. **ì˜ˆì‹œ ê¸°ë°˜ ì´í•´**
   - "ì´ëŸ° ëŠë‚Œìœ¼ë¡œ: ì•ˆë…•í•˜ì„¸ìš”~ ìµœê·¼..." â†’ ì˜ˆì‹œ í†¤ ë¶„ì„ ë° ì ìš©
   - "ì œëª©ì„ 'ê²°ì œ ì‹œìŠ¤í…œ ê³ ë¯¼ í•´ê²°í•´ë“œë¦½ë‹ˆë‹¤' ê°™ì€ ëŠë‚Œìœ¼ë¡œ" â†’ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ì œëª© ìƒì„±

5. **ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤**
   - íšŒì‚¬ ê·œëª¨/ë‹¨ê³„ ê³ ë ¤: ìŠ¤íƒ€íŠ¸ì—… vs ëŒ€ê¸°ì—…
   - ì‚°ì—… íŠ¹ì„±: ì»¤ë¨¸ìŠ¤, í”Œë«í¼, êµ¬ë… ì„œë¹„ìŠ¤ ë“±
   - ìˆ˜ì‹ ì ì§ê¸‰: ëŒ€í‘œ, ì‹¤ë¬´ì, ê°œë°œíŒ€ì¥ ë“±

**ğŸ¯ STEP 2: ë°˜ì˜ ê³„íš ìˆ˜ë¦½**
- ê° ìš”ì²­ì‚¬í•­ì„ ì–´ë–¤ ìˆœì„œë¡œ ë°˜ì˜í• ì§€ ê³„íš
- ì¶©ëŒí•˜ëŠ” ìš”ì²­ì´ ìˆë‹¤ë©´ ìš°ì„ ìˆœìœ„ íŒë‹¨
- Pain Point + í•´ê²°ì±… ìœ ì§€ í™•ì¸

**âœ… STEP 3: ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ëª¨ë“  ìš”ì²­ì‚¬í•­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] í†¤ ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ê°•ì¡° ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ì œëª© ìˆ˜ì • ìš”ì²­ì´ ìˆë‹¤ë©´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] êµ¬ì¡°/ê¸¸ì´ ì¡°ì • ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] Pain Pointê°€ ìœ ì§€ë˜ì—ˆëŠ”ê°€?
- [ ] PortOne í•´ê²°ì±…ì´ ìœ ì§€ë˜ì—ˆëŠ”ê°€?
- [ ] êµ¬ì²´ì  ìˆ˜ì¹˜ê°€ ìœ ì§€ë˜ì—ˆëŠ”ê°€?
- [ ] ê¸°íƒ€ ëª¨ë“  ì„¸ë¶€ ìš”ì²­ì‚¬í•­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?

---

**ì›ë³¸ ì´ë©”ì¼:**
ì œëª©: {original_subject}

ë³¸ë¬¸:
{original_body}

---

**ğŸš¨ ì ˆëŒ€ ê·œì¹™ - MUST KEEP (ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•˜ëŠ” ë‚´ìš©):**

1. **Pain Point (ê³ ê° ê³¼ì œ) ë‚´ìš© 100% ìœ ì§€**
   - ì›ë³¸ì—ì„œ ì–¸ê¸‰í•œ íšŒì‚¬ì˜ ì–´ë ¤ì›€/ê³¼ì œëŠ” ì ˆëŒ€ ì‚­ì œ ë¶ˆê°€
   - ì˜ˆ: "ê±°ë˜ëŸ‰ ê¸‰ì¦", "ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ ë¶€ë‹´", "ì •ì‚° ì—…ë¬´ ë³µì¡ë„ ì¦ê°€" ë“±
   - í‘œí˜„ë§Œ ë‹¤ë“¬ì„ ìˆ˜ ìˆì§€ë§Œ, í•µì‹¬ ë©”ì‹œì§€ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€

2. **PortOne í•´ê²°ì±… 100% ìœ ì§€**
   - OPI/ì¬ë¬´ìë™í™” ë“± í¬íŠ¸ì› ì†”ë£¨ì…˜ ì„¤ëª…ì€ ì ˆëŒ€ ì‚­ì œ ë¶ˆê°€
   - êµ¬ì²´ì  ìˆ˜ì¹˜(85% ì ˆê°, 90% ë‹¨ì¶• ë“±)ëŠ” ë°˜ë“œì‹œ í¬í•¨
   - ì˜ˆ: "ë‹¨ í•˜ë‚˜ì˜ APIë¡œ êµ­ë‚´ì™¸ ì£¼ìš” PGì‚¬ ì—°ë™", "ì •ì‚° ì—…ë¬´ 90% ë‹¨ì¶•" ë“±

3. **ë‰´ìŠ¤ í›„í‚¹ ë‚´ìš© ìœ ì§€**
   - ì›ë³¸ì—ì„œ ì–¸ê¸‰í•œ íšŒì‚¬ ë‰´ìŠ¤/ì„±ì¥ ì´ì•¼ê¸°ëŠ” ìœ ì§€
   - íˆ¬ì ìœ ì¹˜, ì‚¬ì—… í™•ì¥ ë“± êµ¬ì²´ì  ë‚´ìš© ë³´ì¡´

**âœ… ë³€ê²½ ê°€ëŠ¥í•œ ë¶€ë¶„ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜):**

1. **í†¤&ë§¤ë„ˆ ì¡°ì •**
   - ì¹œê·¼í•œ/ì „ë¬¸ì /ê²©ì‹ìˆëŠ” ë“± ìš”ì²­ëœ í†¤ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥
   - ì˜ˆ: "í˜¹ì‹œ ì´ëŸ° ê³ ë¯¼ ìˆìœ¼ì‹ ê°€ìš”?" â†” "ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì œë¥¼ ê²€í† í•˜ê³  ê³„ì‹¤ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤"

2. **ê°•ì¡°ì  ë³€ê²½**
   - ì‚¬ìš©ìê°€ ê°•ì¡° ìš”ì²­í•œ ë¶€ë¶„ì„ `<strong>` íƒœê·¸ë¡œ ê°•ì¡°
   - ë³¼ë“œ ì²˜ë¦¬ ìœ„ì¹˜ ì¡°ì • ê°€ëŠ¥

3. **ì œëª© ìˆ˜ì • (ì¡°ê±´ë¶€)**
   - âš ï¸ **ì‚¬ìš©ìê°€ ì œëª© ìˆ˜ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ** ì œëª© ë³€ê²½ ê°€ëŠ¥
   - ì˜ˆ: "ì œëª©ì„ ë” ì„íŒ©íŠ¸ìˆê²Œ", "ì œëª©ì— ROI ìˆ˜ì¹˜ í¬í•¨" ë“±ì˜ ëª…í™•í•œ ìš”ì²­ì´ ìˆì„ ë•Œë§Œ
   - **ì œëª© ê´€ë ¨ ìš”ì²­ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì œëª©({original_subject})ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©**

4. **ğŸ¯ OPI/ê²°ì œ ê´€ë ¨ ì´ë©”ì¼ì˜ í•µì‹¬ ê°€ì¹˜ ì œì•ˆ (ìµœìš°ì„  ê°•ì¡° - ë°˜ë“œì‹œ í¬í•¨)**
   - **ğŸ’° PG ìˆ˜ìˆ˜ë£Œ ì ˆê° (15-30%)**: ë©€í‹° PG ë¼ìš°íŒ…ìœ¼ë¡œ ìµœì ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•˜ëŠ” PGì‚¬ë¥¼ ì œì•ˆ
   - **ğŸ›¡ï¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… = ë¦¬ìŠ¤í¬ ë§¤ë‹ˆì§€ë¨¼íŠ¸**: PGì‚¬ ì¥ì• /ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ PGë¡œ ì „í™˜í•˜ì—¬ ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€

5. **ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ë§ëŠ” ì¶”ê°€ ê¸°ëŠ¥ ì œì•ˆ** (ìœ„ í•µì‹¬ ê°€ì¹˜ ë‹¤ìŒì— ì–¸ê¸‰)
   - **êµ¬ë… ì„œë¹„ìŠ¤** â†’ ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤ (PG ì´ê´€ ììœ , ë²¤ë” ë½ì¸ ë°©ì§€, í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œ ìœ ì§€)
   - **í•´ì™¸ ì§„ì¶œ** â†’ ê°êµ­ ê°„í¸ê²°ì œ 100+ ìˆ˜ë‹¨ ì—°ë™ (ê²°ì œ ì„±ê³µë¥  í–¥ìƒ)
   - **ê³ ê±°ë˜ëŸ‰ ì»¤ë¨¸ìŠ¤** â†’ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°, 2ì£¼ ë‚´ êµ¬ì¶•
   - **í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤** â†’ íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”, ì „ìê¸ˆìœµë²• ë¦¬ìŠ¤í¬ í•´ì†Œ
   - **ì˜¤í”ˆë§ˆì¼“ ë‹¤ì¤‘ ì±„ë„** â†’ Prism (ê° ì±„ë„ ì •ì‚° ìë™ í†µí•©, 90% ë‹¨ì¶•)

6. **ğŸ“Œ ë¸”ë › í¬ì¸íŠ¸ ì‚¬ìš© (ë“¤ì—¬ì“°ê¸° í•„ìˆ˜!)**
   - **ë°˜ë“œì‹œ HTML `<ul><li>` íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë“¤ì—¬ì“°ê¸°ëœ ë¸”ë › í¬ì¸íŠ¸ë¥¼ ë§Œë“œì„¸ìš”!**
   - **OPI ì´ë©”ì¼ ì˜ˆì‹œ** (ë“¤ì—¬ì“°ê¸° + ì†Œì œëª© ì¤„ë°”ê¿ˆ + ëª…ë£Œí•œ ì„¤ëª…):
   ```html
   í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
   <ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
   <li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
   3,000ì—¬ ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
   <li><strong>ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬:</strong><br>
   PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ **ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ** ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€</li>
   <li><strong>ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°:</strong><br>
   êµ­ë‚´ì™¸ 50ì—¬ ê°œ PGì‚¬ë¥¼ **ë‹¨ í•˜ë‚˜ì˜ API**ë¡œ ì—°ë™í•˜ì—¬ **2ì£¼ ë‚´ êµ¬ì¶•** ê°€ëŠ¥</li>
   </ul>
   ```
   - ë¸”ë › í¬ì¸íŠ¸ ê·œì¹™:
     * **ë°˜ë“œì‹œ `<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;"><li>` íƒœê·¸ ì‚¬ìš©** (ë“¤ì—¬ì“°ê¸° í•„ìˆ˜!)
     * ê° `<li>` ì•ˆì— `<strong>ê¸°ëŠ¥ëª…:</strong><br>` í˜•ì‹ìœ¼ë¡œ ì‘ì„± (ì†Œì œëª© ë‹¤ìŒ ì¤„ë°”ê¿ˆ!)
     * **2-4ê°œì˜ í•µì‹¬ ê¸°ëŠ¥ë§Œ** ê°„ê²°í•˜ê²Œ ì œì‹œ
     * **âš ï¸ ì„¤ëª…ì€ ë¬¸ì¥ì´ ì•„ë‹Œ ëª…ë£Œí•œ í˜•íƒœë¡œ** (ë§ˆì¹¨í‘œë¡œ ëë‚˜ëŠ” ì™„ì „í•œ ë¬¸ì¥ ê¸ˆì§€)
     * **"ê±°ë˜ë§ˆë‹¤"ë¼ëŠ” ì›Œë”©ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ** (ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ í‘œí˜„ ì‚¬ìš©)

7. **êµ¬ì¡° ê°œì„  ë° í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆ (ê°€ë…ì„± ì¤‘ì‹¬!)**
   - **ê¸°ë³¸ ê·œì¹™: ë¬¸ì¥ì´ ëë‚˜ëŠ” `.` ë˜ëŠ” ì‰¼í‘œ(`,`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆ (`<br>`)**
   - **ì˜¨ì „í•œ ì§§ì€ ì ˆ ì•ˆì—ì„œëŠ” ì¤„ë°”ê¿ˆí•˜ì§€ ì•ŠìŒ** (ì˜ë¯¸ ë‹¨ìœ„ë¡œ ëŠê¸°)
   - **ë¬¸ë‹¨ ê°„ êµ¬ë¶„: `</p><p>` íƒœê·¸ë¡œ ë‹¨ë½ êµ¬ë¶„ (ë¹ˆ ì¤„ íš¨ê³¼)**
   - **ë¸”ë › í¬ì¸íŠ¸: ë³¼ë“œ ì†Œì œëª©(`:`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆ**
   - ì˜ˆì‹œ:
     ```html
     âœ… ì¢‹ì€ ì¤„ë°”ê¿ˆ (ë¬¸ì¥ ë + ì†Œì œëª© ì¤„ë°”ê¿ˆ):
     <p>ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤.<br>
     ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>
     <p>ì €í¬ í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
     <ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
     <li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
     3,000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
     </ul>
     ```
   - **í•µì‹¬: ë¬¸ì¥ ë(`.`)ì—ì„œ ì¤„ë°”ê¿ˆ, ë¸”ë › ì†Œì œëª©(`:`) ë‹¤ìŒì— ì¤„ë°”ê¿ˆ**

8. **ê¸¸ì´ ì¡°ì • (ê°„ê²°í•¨ ìš°ì„ !)**
   - **ì „ì²´ ë³¸ë¬¸: 100-130ë‹¨ì–´ë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ì„±**
   - Pain Point + í•´ê²°ì±…ì€ ìœ ì§€í•˜ë˜, ì¤‘ë³µ/ì¥í™©í•œ ì„¤ëª… ì œê±°

**âŒ ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- Pain Point ë‚´ìš©ì„ ì‚­ì œí•˜ê±°ë‚˜ ì¶•ì†Œ
- PortOne í•´ê²°ì±… ì„¤ëª…ì„ ì‚­ì œí•˜ê±°ë‚˜ ì¶”ìƒí™” ("ë„ì›€ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¡œë§Œ ëë‚´ê¸° ê¸ˆì§€)
- êµ¬ì²´ì  ìˆ˜ì¹˜ ì‚­ì œ
- ë‰´ìŠ¤ í›„í‚¹ ë‚´ìš© ì‚­ì œ

**ğŸ’¡ ë³µì¡í•œ ìš”ì²­ì‚¬í•­ ì²˜ë¦¬ ì˜ˆì‹œ:**

**ì˜ˆì‹œ 1: ë³µí•© ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "ë” ì§§ê³  ì¹œê·¼í•˜ê²Œ ì‘ì„±í•˜ë˜, ìˆ˜ìˆ˜ë£Œ ì ˆê° íš¨ê³¼ë¥¼ ê°•ì¡°í•˜ê³  ì œëª©ë„ ì„íŒ©íŠ¸ìˆê²Œ ë°”ê¿”ì¤˜"

ë¶„ì„:
- ê¸¸ì´: 30% ì¶•ì†Œ
- í†¤: ì¹œê·¼í•œ í‘œí˜„ ("~í•˜ì‹¤ ê²ƒ ê°™ì•„ìš”", "~í•˜ì§€ ì•Šìœ¼ì‹ ê°€ìš”?")
- ê°•ì¡°: "ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°" ë³¼ë“œ ì²˜ë¦¬
- ì œëª©: ìˆ˜ìˆ˜ë£Œ í‚¤ì›Œë“œ í¬í•¨í•œ ì„íŒ©íŠ¸ ì œëª© ìƒì„±

**ì˜ˆì‹œ 2: êµ¬ì¡° ë³€ê²½ ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "bullet point í˜•ì‹ìœ¼ë¡œ ë°”ê¾¸ê³ , ê° í¬ì¸íŠ¸ë§ˆë‹¤ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë„£ì–´ì¤˜"

ë¶„ì„:
- êµ¬ì¡°: ë¸”ë › í¬ì¸íŠ¸(â€¢) í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
- ë‚´ìš©: ê° ë¸”ë ›ì— "85% ì ˆê°", "15% í–¥ìƒ", "2ì£¼ êµ¬ì¶•" ë“± ìˆ˜ì¹˜ ëª…ì‹œ
- ê°€ë…ì„±: ë¸”ë › ì‚¬ì´ ì¤„ë°”ê¿ˆ, ì„¹ì…˜ ì „í›„ ë¹ˆ ì¤„

**ì˜ˆì‹œ 3: í†¤ ë””í…Œì¼ ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "ì²« ì¸ì‚¬ëŠ” ì¹œê·¼í•˜ê²Œ í•˜ê³ , ì œí’ˆ ì„¤ëª…ì€ ì „ë¬¸ì ìœ¼ë¡œ, ë§ˆë¬´ë¦¬ëŠ” ë¶€ë“œëŸ½ê²Œ"

ë¶„ì„:
- ì¸ì‚¬: "ì•ˆë…•í•˜ì„¸ìš”~ ìµœê·¼ ì†Œì‹ ë´¤ìŠµë‹ˆë‹¤!" (ì¹œê·¼)
- ì œí’ˆ: "í¬íŠ¸ì›ì€ ë©€í‹° PG ë¼ìš°íŒ… ê¸°ìˆ ì„ í†µí•´..." (ì „ë¬¸)
- ë§ˆë¬´ë¦¬: "í•œë²ˆ í¸í•˜ê²Œ ì´ì•¼ê¸° ë‚˜ëˆ ë³´ì‹¤ë˜ìš”?" (ë¶€ë“œëŸ¬ì›€)

**ì˜ˆì‹œ 4: ì˜ˆì‹œ ê¸°ë°˜ ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "ì´ëŸ° ëŠë‚Œìœ¼ë¡œ ì‘ì„±í•´ì¤˜: 'ê²°ì œ ì‹œìŠ¤í…œ ë•Œë¬¸ì— ë°¤ìƒ˜ ê°œë°œí•˜ê³  ê³„ì‹œì§„ ì•Šë‚˜ìš”?'"

ë¶„ì„:
- í†¤: ê³µê°í˜• ì§ˆë¬¸ + ìœ ë¨¸ëŸ¬ìŠ¤í•œ í‘œí˜„
- ë„ì…: Pain Pointë¥¼ ì§ˆë¬¸ í˜•íƒœë¡œ ì œì‹œ
- ìŠ¤íƒ€ì¼: ì§ì ‘ì ì´ê³  ì†”ì§í•œ ì–´ì¡°

**ì˜ˆì‹œ 5: ì‚°ì—… íŠ¹í™” ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "êµ¬ë… ì„œë¹„ìŠ¤ íšŒì‚¬ì¸ë°, ë¹Œë§í‚¤ ê´€ë ¨ ë‚´ìš©ì„ ë” ê°•ì¡°í•˜ê³  êµ¬ë… ê²°ì œ ì‹¤íŒ¨ ë¬¸ì œë¥¼ Pain Pointë¡œ ë„£ì–´ì¤˜"

ë¶„ì„:
- ì»¨í…ìŠ¤íŠ¸: êµ¬ë… ì„œë¹„ìŠ¤ â†’ ë¹Œë§í‚¤ ê¸°ëŠ¥ ê°•ì¡°
- Pain Point: "êµ¬ë… ê²°ì œ ì‹¤íŒ¨ë¡œ ì¸í•œ ì´íƒˆë¥  ì¦ê°€" ì¶”ê°€
- í•´ê²°ì±…: "ìŠ¤ë§ˆíŠ¸ ë¹Œë§í‚¤ë¡œ PG ì´ê´€ ììœ , í•­ìƒ ë‚®ì€ ìˆ˜ìˆ˜ë£Œ" ê°•ì¡°

**ì˜ˆì‹œ 6: ë‹¤ì¸µì  ìš”ì²­**
ì‚¬ìš©ì ìš”ì²­: "ì œëª©ì— ìˆ«ì ë„£ê³ , ë³¸ë¬¸ì€ 3ê°œ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ë˜ (1)ë‰´ìŠ¤ í›„í‚¹ (2)Pain Point + ê³µê° (3)í•´ê²°ì±… ìˆœìœ¼ë¡œ, ê° ì„¹ì…˜ë§ˆë‹¤ ê°•ì¡° í¬ì¸íŠ¸ í•˜ë‚˜ì”© ë³¼ë“œ ì²˜ë¦¬í•´ì¤˜"

ë¶„ì„:
- ì œëª©: "PG ìˆ˜ìˆ˜ë£Œ 30% ì ˆê° ë°©ë²•" (ìˆ«ì í¬í•¨)
- êµ¬ì¡°: 3ê°œ ì„¹ì…˜ ëª…í™•íˆ ë¶„ë¦¬ (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)
- ê°•ì¡°: ì„¹ì…˜ë³„ í•µì‹¬ ë¬¸êµ¬ 1ê°œì”© `<strong>` íƒœê·¸

---

**ê°œì„  ì˜ˆì‹œ:**

ì›ë³¸:
"ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 
ì €í¬ OPIëŠ” ë‹¨ í•˜ë‚˜ì˜ APIë¡œ ì£¼ìš” PGì‚¬ë¥¼ ì—°ë™í•˜ê³  ê°œë°œ ê¸°ê°„ì„ 85% ë‹¨ì¶•í•©ë‹ˆë‹¤."

ìš”ì²­ì‚¬í•­: "ë” ì¹œê·¼í•œ í†¤ìœ¼ë¡œ, ROI ìˆ˜ì¹˜ ê°•ì¡°"

ê°œì„ :
```html
<p>'{company_name} íˆ¬ì ìœ ì¹˜' ì†Œì‹ ì •ë§ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤!<br>
ì´ë ‡ê²Œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì‹œë‹¤ ë³´ë©´, ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ê°œë°œíŒ€ì— í° ë¶€ë‹´ ë˜ì§€ ì•Šìœ¼ì‹¤ê¹Œìš”?</p>
<p>í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
<li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
3,000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
<li><strong>ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬:</strong><br>
PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ **ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ** ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€</li>
<li><strong>ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°:</strong><br>
êµ­ë‚´ì™¸ 50ì—¬ ê°œ PGì‚¬ë¥¼ **ë‹¨ í•˜ë‚˜ì˜ API**ë¡œ ì—°ë™í•˜ì—¬ **2ì£¼ ë‚´ êµ¬ì¶•** ê°€ëŠ¥</li>
</ul>
```

â†’ Pain Point + í•µì‹¬ ê°€ì¹˜ + í•´ê²°ì±… ëª¨ë‘ ìœ ì§€í•˜ë©´ì„œ, í†¤ì„ ì¹œê·¼í•˜ê²Œ ë³€ê²½í•˜ê³  **ë“¤ì—¬ì“°ê¸°ëœ** ë¸”ë › í¬ì¸íŠ¸ ì ìš©

---

**âœ… ìµœì¢… í™•ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ (JSON ì¶œë ¥ ì „ì— ë°˜ë“œì‹œ í™•ì¸):**

ì‚¬ìš©ì ìš”ì²­ì‚¬í•­: "{user_request}"

ìœ„ ìš”ì²­ì‚¬í•­ì˜ ê° í•­ëª©ì´ ì´ë©”ì¼ì— ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸:
- [ ] í†¤&ë§¤ë„ˆ ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ê°•ì¡° ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ì œëª© ìˆ˜ì • ìš”ì²­ì´ ìˆë‹¤ë©´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] êµ¬ì¡°/ê¸¸ì´ ì¡°ì • ìš”ì²­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ê¸°íƒ€ ëª¨ë“  ì„¸ë¶€ ìš”ì²­ì‚¬í•­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?

**ëª¨ë“  í•­ëª©ì´ ì²´í¬ë˜ì—ˆë‹¤ë©´ JSONì„ ì¶œë ¥í•˜ì„¸ìš”.**

---

**ğŸ“¤ JSON ì¶œë ¥ í˜•ì‹ (ì¤‘ìš” - ì •í™•íˆ ì¤€ìˆ˜):**

{{
  "subject": "ì‚¬ìš©ìê°€ ì œëª© ìˆ˜ì •ì„ ìš”ì²­í–ˆë‹¤ë©´ ê°œì„ ëœ ì œëª©, ì•„ë‹ˆë©´ ì›ë³¸ ì œëª© ê·¸ëŒ€ë¡œ",
  "body": "ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì´ ëª¨ë‘ ë°˜ì˜ëœ ê°œì„ ëœ ë³¸ë¬¸ (HTML í˜•ì‹, <p>, <br>, <strong> íƒœê·¸ ì‚¬ìš©, í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆ)"
}}

**âš ï¸ JSON ì‘ì„± ì£¼ì˜ì‚¬í•­:**
- subjectì™€ body ê°’ì— í°ë”°ì˜´í‘œ(")ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ (\")
- ì¤„ë°”ê¿ˆì€ HTML íƒœê·¸(<br>)ë¡œë§Œ í‘œí˜„ (\n ì‚¬ìš© ê¸ˆì§€)
- ì˜ëª»ëœ JSONì€ íŒŒì‹± ì‹¤íŒ¨ë¡œ ì´ì–´ì§€ë¯€ë¡œ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ ì¤€ìˆ˜

**ì¤„ë°”ê¿ˆ ì˜ˆì‹œ (ë¬¸ì¥ ë ì¤„ë°”ê¿ˆ + ì†Œì œëª© ì¤„ë°”ê¿ˆ):**
```html
<p>ì•ˆë…•í•˜ì„¸ìš”, ABCíšŒì‚¬ ê¹€ì² ìˆ˜ ëŒ€í‘œë‹˜.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ìµœê·¼ 'ABCíšŒì‚¬ ì‹œë¦¬ì¦ˆ A íˆ¬ì ìœ ì¹˜' ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤.<br>
ì´ë ‡ê²Œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì‹œë‹¤ ë³´ë©´ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<p>ì €í¬ í¬íŠ¸ì›ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<ul style="padding-left: 20px; margin: 10px 0; font-size: inherit;">
<li><strong>PG ìˆ˜ìˆ˜ë£Œ 15-30% ì ˆê°:</strong><br>
3,000ê°œ ê³ ê°ì‚¬ ê·œëª¨ì™€ PGì‚¬ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ **ìµœì ì˜ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´** ì œì•ˆ</li>
<li><strong>ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ë¦¬ìŠ¤í¬ ê´€ë¦¬:</strong><br>
PG ì¥ì•  ì‹œ ìë™ ì „í™˜ìœ¼ë¡œ **ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ** ë° ë§¤ì¶œ ì†ì‹¤ ë°©ì§€</li>
<li><strong>ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°:</strong><br>
êµ­ë‚´ì™¸ 50ì—¬ ê°œ PGì‚¬ë¥¼ **ë‹¨ í•˜ë‚˜ì˜ API**ë¡œ ì—°ë™í•˜ì—¬ **2ì£¼ ë‚´ êµ¬ì¶•** ê°€ëŠ¥</li>
</ul>
```
"""
        
        payload = {
            "contents": [{"parts": [{"text": context}]}],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 2048,
                "responseMimeType": "application/json"
            }
        }
        
        # ìë™ fallback ì ìš©
        try:
            response_text = call_gemini_with_fallback(
                context,
                timeout=60,
                max_retries=2,
                generation_config={
                    "temperature": 0.7,
                    "maxOutputTokens": 2048,
                    "responseMimeType": "application/json"
                }
            )
            
            # JSON íŒŒì‹±
            result = {"candidates": [{"content": {"parts": [{"text": response_text}]}}]}
            
        except Exception as e:
            logger.error(f"{company_name} API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None
        
        # ì „ì²´ ì‘ë‹µ êµ¬ì¡° ë¡œê¹… (ë””ë²„ê¹…ìš©)
        logger.debug(f"{company_name} Gemini ì‘ë‹µ êµ¬ì¡°: {json.dumps(result, ensure_ascii=False, indent=2)[:500]}")
        
        # ì•ˆì „í•œ ì‘ë‹µ ì²˜ë¦¬
        if 'candidates' not in result or not result['candidates']:
            logger.error(f"{company_name} ê°œì„  ì‹¤íŒ¨: Gemini ì‘ë‹µì— candidatesê°€ ì—†ìŒ")
            logger.error(f"ì „ì²´ ì‘ë‹µ: {result}")
            return None
        
        candidate = result['candidates'][0]
        
        # finish_reason í™•ì¸ (ì•ˆì „ í•„í„°ë§ ì²´í¬)
        finish_reason = candidate.get('finishReason', candidate.get('finish_reason'))
        if finish_reason in ['SAFETY', 2]:  # 2 = SAFETY enum value
            logger.warning(f"{company_name} ê°œì„  ì‹¤íŒ¨: ì•ˆì „ í•„í„°ë¡œ ì¸í•œ ì‘ë‹µ ì°¨ë‹¨ (finishReason: {finish_reason})")
            return None
        
        # contentì™€ parts ì•ˆì „í•˜ê²Œ ì ‘ê·¼
        if 'content' not in candidate:
            logger.error(f"{company_name} ê°œì„  ì‹¤íŒ¨: ì‘ë‹µì— contentê°€ ì—†ìŒ")
            logger.error(f"Candidate ì „ì²´: {json.dumps(candidate, ensure_ascii=False, indent=2)}")
            return None
        
        if 'parts' not in candidate['content']:
            logger.error(f"{company_name} ê°œì„  ì‹¤íŒ¨: contentì— partsê°€ ì—†ìŒ")
            logger.error(f"Content ì „ì²´: {json.dumps(candidate['content'], ensure_ascii=False, indent=2)}")
            
            # text í•„ë“œê°€ ì§ì ‘ ìˆëŠ”ì§€ í™•ì¸ (ì¼ë¶€ ì‘ë‹µ í˜•ì‹)
            if 'text' in candidate['content']:
                logger.info(f"{company_name} content.text í•„ë“œ ë°œê²¬ - ëŒ€ì²´ ê²½ë¡œ ì‚¬ìš©")
                generated_text = candidate['content']['text'].strip()
            else:
                return None
        else:
            parts = candidate['content']['parts']
            if not parts:
                logger.error(f"{company_name} ê°œì„  ì‹¤íŒ¨: parts ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
                return None
            
            if not parts[0].get('text'):
                logger.error(f"{company_name} ê°œì„  ì‹¤íŒ¨: parts[0]ì— textê°€ ì—†ìŒ")
                logger.error(f"parts[0] ì „ì²´: {json.dumps(parts[0], ensure_ascii=False, indent=2)}")
                return None
            
            generated_text = parts[0]['text'].strip()
        
        # JSON íŒŒì‹± ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            # JSON ì •ì œ (ì½”ë“œ ë¸”ë¡ ì œê±°)
            if generated_text.startswith('```json'):
                generated_text = generated_text[7:]
            if generated_text.startswith('```'):
                generated_text = generated_text[3:]
            if generated_text.endswith('```'):
                generated_text = generated_text[:-3]
            generated_text = generated_text.strip()
            
            refined_email = json.loads(generated_text)
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if 'subject' not in refined_email or 'body' not in refined_email:
                logger.error(f"{company_name} JSONì— í•„ìˆ˜ í•„ë“œ(subject/body)ê°€ ì—†ìŒ")
                logger.debug(f"JSON í‚¤ë“¤: {list(refined_email.keys())}")
                return None
            
        except json.JSONDecodeError as je:
            logger.error(f"{company_name} JSON íŒŒì‹± ì‹¤íŒ¨: {str(je)}")
            logger.error(f"íŒŒì‹± ì‹¤íŒ¨ ìœ„ì¹˜: line {je.lineno}, column {je.colno}")
            logger.debug(f"íŒŒì‹± ì‹¤íŒ¨í•œ í…ìŠ¤íŠ¸ (ì²˜ìŒ 300ì): {generated_text[:300]}")
            logger.debug(f"íŒŒì‹± ì‹¤íŒ¨í•œ í…ìŠ¤íŠ¸ (ë§ˆì§€ë§‰ 100ì): {generated_text[-100:]}")
            return None
        
        return {
            'subject': refined_email.get('subject', original_subject),
            'body': refined_email.get('body', original_body)
        }
        
    except Exception as e:
        logger.error(f"{company_name} ì´ë©”ì¼ ê°œì„  ì˜¤ë¥˜: {str(e)}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
        return None

def refine_email_with_gemini(current_email, refinement_request):
    """Gemini 2.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë©”ì¼ ê°œì„ """
    try:
        # Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í´ë°± ì‘ë‹µ ìƒì„±
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            logger.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return f"""ì œëª©: ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆ - {refinement_request} ë°˜ì˜

ì•ˆë…•í•˜ì„¸ìš”!

ìš”ì²­í•´ì£¼ì‹  "{refinement_request}" ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

PortOneì˜ One Payment InfraëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤:

â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 80% ì ˆì•½
â€¢ 2ì£¼ ë‚´ ë¹ ë¥¸ ë„ì…
â€¢ ë¬´ë£Œ ì „ë¬¸ ì»¨ì„¤íŒ…
â€¢ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ

ë¯¸íŒ…ì„ í†µí•´ êµ¬ì²´ì ì¸ í˜œíƒì„ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.

ì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?

ê°ì‚¬í•©ë‹ˆë‹¤.
PortOne ì˜ì—…íŒ€

(ì£¼ì˜: Gemini API í‚¤ ë¯¸ì„¤ì •ìœ¼ë¡œ ì¸í•œ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ)"""
        
        # URLì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ìŠ¤í¬ë˜í•‘
        article_context = ""
        import re
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, refinement_request)
        
        if urls:
            logger.info(f"ê°œì„  ìš”ì²­ì—ì„œ URL ë°œê²¬: {len(urls)}ê°œ")
            for url in urls[:3]:  # ìµœëŒ€ 3ê°œ URLê¹Œì§€ ì²˜ë¦¬
                try:
                    logger.info(f"URL ë‚´ìš© ìŠ¤í¬ë˜í•‘ ì‹œë„: {url}")
                    article_data = scrape_news_article(url)
                    
                    if article_data:
                        article_context += f"\n\n### ğŸ“° ì°¸ê³  ê¸°ì‚¬ ì •ë³´ (ì¶œì²˜: {url})\n"
                        article_context += f"**ì œëª©**: {article_data.get('title', 'ì œëª© ì—†ìŒ')}\n"
                        article_context += f"**ë³¸ë¬¸**: {article_data.get('content', '')[:1500]}\n"
                        logger.info(f"URL ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {article_data.get('title', '')[:50]}")
                    else:
                        logger.warning(f"URL ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {url}")
                        article_context += f"\n\n### âš ï¸ ê¸°ì‚¬ URL ì œê³µë¨: {url}\n(ìë™ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ - ìˆ˜ë™ìœ¼ë¡œ ë‚´ìš© í™•ì¸ í•„ìš”)\n"
                except Exception as e:
                    logger.error(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    article_context += f"\n\n### âš ï¸ ê¸°ì‚¬ URL: {url}\n(ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)})\n"
        
        prompt = f"""
ë‹¹ì‹ ì€ B2B SaaS ì„¸ì¼ì¦ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í•˜ëŠ” ì„ë¬´ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.

**í˜„ì¬ ì´ë©”ì¼:**
{current_email}

**ì‚¬ìš©ìì˜ ê°œì„  ìš”ì²­:**
{refinement_request}
{article_context}

---

## ğŸš¨ ì œí’ˆ ì„ íƒ ê·œì¹™

**ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”:**

### 1ï¸âƒ£ ë³µìˆ˜ ì œí’ˆ ìš”ì²­ ê°ì§€ (ìµœìš°ì„  í™•ì¸)
ì‚¬ìš©ìê°€ **ì—¬ëŸ¬ ì œí’ˆì„ í•¨ê»˜ ì–¸ê¸‰**í•˜ê±°ë‚˜ **ì¢…í•© ì†”ë£¨ì…˜ì„ ìš”ì²­**í–ˆëŠ”ì§€ í™•ì¸:

**ë³µìˆ˜ ì œí’ˆ í‚¤ì›Œë“œ:**
- "OPIì™€ Recon", "OPI, Recon", "OPI ê·¸ë¦¬ê³  Recon"
- "Prismê³¼ ì¬ë¬´ìë™í™”", "ì—¬ëŸ¬ ì œí’ˆ", "ë³µìˆ˜ ì†”ë£¨ì…˜"
- "ì¢…í•©ì ìœ¼ë¡œ", "í†µí•© ì†”ë£¨ì…˜", "ì „ì²´ì ìœ¼ë¡œ ì–´í•„"
- "ë‘˜ ë‹¤", "ëª¨ë‘", "í•¨ê»˜"

**ë³µìˆ˜ ì œí’ˆ ìš”ì²­ ì˜ˆì‹œ:**
- "OPI ê°œì„  ìš”ì²­ì— Reconë„ ê°™ì´ ì–´í•„í•˜ëŠ” ë©”ì¼ ë§Œë“¤ì–´ì¤˜"
- "Prismê³¼ ì¬ë¬´ìë™í™” ë‘˜ ë‹¤ ì–¸ê¸‰í•´ì¤˜"
- "ì¢…í•© ì†”ë£¨ì…˜ìœ¼ë¡œ ì‘ì„±í•´ì¤˜"

â†’ **ë³µìˆ˜ ì œí’ˆ ê°ì§€ ì‹œ**: ì–¸ê¸‰ëœ ì œí’ˆë“¤ì„ Pain Pointì— ë§ì¶° ì¡°í•©í•˜ì—¬ ì œì•ˆ
   ì˜ˆ: Pain Point 1 â†’ OPI, Pain Point 2 â†’ Recon

### 2ï¸âƒ£ ë‹¨ì¼ ì œí’ˆ ìš”ì²­ (ë³µìˆ˜ ì œí’ˆ í‚¤ì›Œë“œ ì—†ì„ ë•Œ)
- "prism", "Prism" â†’ **Prismë§Œ ì‚¬ìš©**
- "recon", "Recon" â†’ **Reconë§Œ ì‚¬ìš©**  
- "ì¬ë¬´ìë™í™”", "ì •ì‚°ìë™í™”" â†’ **ì¬ë¬´ìë™í™”ë§Œ ì‚¬ìš©**
- "OPI", "One Payment Infra" â†’ **OPIë§Œ ì‚¬ìš©**
- ì œí’ˆëª… ì–¸ê¸‰ ì—†ìŒ â†’ **ê¸°ë³¸ ì œí’ˆ (OPI ë˜ëŠ” Pain Pointì— ê°€ì¥ ì í•©í•œ ì œí’ˆ)**

**ì œí’ˆë³„ ì •ë³´:**
- **OPI (One Payment Infra)**: í†µí•© ê²°ì œ ì‹œìŠ¤í…œ, 2ì£¼ ë‚´ êµ¬ì¶•, ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°, ì—¬ëŸ¬ PGì‚¬ í†µí•© ê´€ë¦¬
- **Prism**: ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ê´€ë¦¬, ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° í”Œë«í¼ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ì™€ ê¸°ì¤€ì„ í•œ ëˆˆì— í†µí•©, ì¬ë¬´ ë§ˆê° ì‹œê°„ 90% ë‹¨ì¶•, ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—‘ì…€ ì‘ì—… ìë™í™”
- **ì¬ë¬´ìë™í™”**: ì •ì‚° ë°ì´í„° ìë™í™”, ì •ì‚° í”„ë¡œì„¸ìŠ¤ 90% ì‹œê°„ ë‹¨ì¶•, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ, íšŒê³„ ì‹œìŠ¤í…œ ì—°ë™
- **Recon**: ê±°ë˜ ë‚´ì—­ ìë™ ëŒ€ì‚¬, ì •ì‚° ì˜¤ë¥˜ ìë™ ê°ì§€ ë° ë°©ì§€, ìˆ˜ì‘ì—… ëŒ€ì‚¬ ì‹œê°„ 95% ì ˆê°

**ì¤‘ìš”: ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ í•´ë‹¹ ì œí’ˆë§Œ ì‚¬ìš©. ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ ê° Pain Pointì— ë§ëŠ” ì œí’ˆ ì¡°í•©.**

### ğŸ¯ ë‰´ìŠ¤ ê¸°ì‚¬ ê¸°ë°˜ ì„œë¡  ì‘ì„± ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ê°€ì´ë“œ

**âŒ í”¼í•´ì•¼ í•  ì–´ìƒ‰í•œ í‘œí˜„:**
- "ìµœê·¼ ì†Œì‹ì„ ì ‘í–ˆìŠµë‹ˆë‹¤. ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤." â†’ ë„ˆë¬´ ë»”í•¨
- "ì´ëŸ° ë¬¸ì œë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?" â†’ ì¶”ì¸¡ì„± ì§ˆë¬¸ì€ ì–´ìƒ‰
- "í° ê³¼ì œê°€ ì•„ë‹ê¹Œ ìƒê°ë©ë‹ˆë‹¤" â†’ ì¼ë°˜ì ì´ê³  ë»”í•¨
- "PortOneì´ í•´ê²°í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤" â†’ ì˜ì—… í”¼ì¹­ì²˜ëŸ¼ ë“¤ë¦¼

**âœ… ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ëŒ€ì²´:**
- ê¸°ì‚¬ ì–¸ê¸‰: "[ê¸°ì‚¬ ë‚´ìš©]ì„ ë³´ë‹¤ê°€ ì—°ë½ë“œë¦¬ê²Œ ëìŠµë‹ˆë‹¤"
- Pain Point ì—°ê²°: "ì´ëŸ° ìƒí™©ì—ì„œ ë³´í†µ [X]ê°€ ì¤‘ìš”í•´ì§€ë”ë¼ê³ ìš”"
- Pain Point ì—°ê²°: "[ê¸°ì‚¬ ë‚´ìš©]ì„ ì¤€ë¹„í•˜ì‹œë ¤ë©´ [X]ë„ ê°™ì´ ì›€ì§ì—¬ì•¼ í•  ê²ƒ ê°™ì€ë°"
- Pain Point ì—°ê²°: "ì´ ì •ë„ ê·œëª¨ê°€ ë˜ë©´ [X] ìª½ì´ ê½¤ ë³µì¡í•´ì§€ê±°ë“ ìš”"
- ì†”ë£¨ì…˜ ì œì•ˆ: "í˜¹ì‹œ ë„ì›€ì´ ë ê¹Œ í•´ì„œ ê°„ë‹¨íˆ ê³µìœ ë“œë¦¬ë©´"
- ì†”ë£¨ì…˜ ì œì•ˆ: "ì°¸ê³ ê°€ ë˜ì‹¤ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ìˆì–´ì„œìš”"

**í•µì‹¬ ì›ì¹™:**
- ê¸°ì‚¬ ë‚´ìš© â†’ Pain Point â†’ ì†”ë£¨ì…˜ íë¦„ì€ ìœ ì§€í•˜ë˜
- ê° ì „í™˜ì´ **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´**ë¡œ ì—°ê²°ë˜ë„ë¡
- ì§ˆë¬¸í˜•ì´ë‚˜ ì¶”ì¸¡í˜• ëŒ€ì‹  **ê²½í—˜/ê´€ì°° ê¸°ë°˜ í‘œí˜„** ì‚¬ìš©

### ğŸ“ ì¼ë°˜ ê°œì„  ìš”ì²­ ì²˜ë¦¬ ê·œì¹™

**ğŸ¯ ìµœìš°ì„  ì›ì¹™: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì´ ëª¨ë“  ê²ƒë³´ë‹¤ ìš°ì„ í•©ë‹ˆë‹¤!**

**ì‚¬ìš©ì ê°œì„  ìš”ì²­ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ (ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰):**

**1ë‹¨ê³„: ìš”ì²­ì‚¬í•­ ë¶„ì„**
   - ì‚¬ìš©ì ìš”ì²­ì„ ë¬¸ì¥ë³„, í•­ëª©ë³„ë¡œ ì„¸ë¶„í™”
   - ê° ìš”ì²­ì´ êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ëª…í™•íˆ íŒŒì•…
   - ì—¬ëŸ¬ ìš”ì²­ì´ ì„ì—¬ìˆë‹¤ë©´ ìš°ì„ ìˆœìœ„ ì—†ì´ ëª¨ë‘ ë™ë“±í•˜ê²Œ ì²˜ë¦¬

**2ë‹¨ê³„: ìš”ì²­ì‚¬í•­ ì ìš© ê³„íš**
   - ê° ìš”ì²­ì‚¬í•­ì´ ì´ë©”ì¼ì˜ ì–´ëŠ ë¶€ë¶„ì— ì–´ë–»ê²Œ ë°˜ì˜ë ì§€ ê³„íš
   - í†¤&ë§¤ë„ˆ / ì œëª© / ë³¸ë¬¸ êµ¬ì¡° / ê°•ì¡°ì  / ê¸¸ì´ ë“±ì„ êµ¬ë¶„
   - ì¥ë¬¸ì˜ ìš”ì²­ì´ë¼ë„ ê° í¬ì¸íŠ¸ë¥¼ ë†“ì¹˜ì§€ ì•Šê³  ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬

**3ë‹¨ê³„: ì´ë©”ì¼ ìƒì„±**
   - ìœ„ì—ì„œ ê³„íší•œ ëª¨ë“  ìš”ì²­ì‚¬í•­ì„ ë¹ ì§ì—†ì´ ë°˜ì˜í•˜ì—¬ ì´ë©”ì¼ ì‘ì„±
   - ìš”ì²­ì—ì„œ ì–¸ê¸‰ëœ í†¤ì•¤ë§¤ë„ˆ, ìŠ¤íƒ€ì¼, ë‚´ìš© ë³€ê²½ì‚¬í•­ì„ ìš°ì„ ì ìœ¼ë¡œ ì ìš©
   - ìš”ì²­ëœ ë¬¸ì²´ë‚˜ ì ‘ê·¼ ë°©ì‹ì— ë§ì¶° ì „ë¬¸ì  ë˜ëŠ” ì¹œê·¼í•œ í†¤ ì¡°ì ˆ
   - ì‚¬ìš©ìê°€ ìš”ì²­í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì •ë³´ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨
   - ìš”ì²­ëœ ê¸¸ì´ë‚˜ êµ¬ì¡° ë³€ê²½ì‚¬í•­ ì ê·¹ ë°˜ì˜
   - ì‚¬ìš©ìê°€ íŠ¹ì • í‘œí˜„ì´ë‚˜ ë¬¸êµ¬ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ì ìš©

**4ë‹¨ê³„: ìµœì¢… ê²€ì¦**
   - ìƒì„±ëœ ì´ë©”ì¼ì— ëª¨ë“  ìš”ì²­ì‚¬í•­ì´ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¡œ í™•ì¸
   - ëˆ„ë½ëœ ìš”ì²­ì´ ìˆë‹¤ë©´ ë‹¤ì‹œ ìˆ˜ì •
   - **ì‚¬ìš©ì ìš”ì²­ì´ ê¸°ë³¸ í˜•ì‹ê³¼ ì¶©ëŒí•˜ëŠ” ê²½ìš°, í•­ìƒ ì‚¬ìš©ì ìš”ì²­ì„ ìš°ì„ ì‹œ**

---

**ì œí’ˆ ì„ íƒ ì ìš©:**
1. âœ… ìœ„ì—ì„œ í™•ì¸í•œ ì œí’ˆì„ ì´ë©”ì¼ ì „ì²´ì— ì¼ê´€ë˜ê²Œ ì‚¬ìš©
2. âœ… ì„ íƒëœ ì œí’ˆì´ ì•„ë‹Œ ë‹¤ë¥¸ ì œí’ˆì€ ì ˆëŒ€ ì–¸ê¸‰ ê¸ˆì§€
3. âœ… ì œí’ˆì˜ íŠ¹ì§•ê³¼ ê°€ì¹˜ë¥¼ Pain Point í•´ê²°ì±…ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°

**ì™¸ì  í˜•ì‹ ë° ë””ìì¸ ìš”ì²­ ì²˜ë¦¬:**
11. HTML íƒœê·¸ ìˆ˜ì • ìš”ì²­: ì‚¬ìš©ìê°€ íŠ¹ì • HTML íƒœê·¸ë‚˜ ìŠ¤íƒ€ì¼ ë³€ê²½ì„ ìš”ì²­í•˜ë©´ ì •í™•íˆ ì ìš©
12. ë ˆì´ì•„ì›ƒ ë³€ê²½: ë¬¸ë‹¨ êµ¬ì„±, ì¤„ë°”ê¿ˆ, ë“¤ì—¬ì“°ê¸° ë“±ì˜ ë ˆì´ì•„ì›ƒ ìš”ì²­ ë°˜ì˜
13. ì‹œê°ì  ê°•ì¡°: ë³¼ë“œì²´(**í…ìŠ¤íŠ¸**), ì´íƒ¤ë¦­ì²´(*í…ìŠ¤íŠ¸*), ë°‘ì¤„ ë“±ì˜ ê°•ì¡° ìš”ì²­ ì ìš©
14. ëª©ë¡ í˜•ì‹: ë²ˆí˜¸ ëª©ë¡, ë¶ˆë¦¿ í¬ì¸íŠ¸, ì²´í¬ë¦¬ìŠ¤íŠ¸ ë“±ì˜ í˜•ì‹ ë³€ê²½ ìš”ì²­ ì²˜ë¦¬
15. ìƒ‰ìƒ/ìŠ¤íƒ€ì¼ íŒíŠ¸: HTMLì—ì„œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒì´ë‚˜ ìŠ¤íƒ€ì¼ í´ë˜ìŠ¤ ì ìš©
16. í…Œì´ë¸” í˜•ì‹: ì •ë³´ë¥¼ í‘œ í˜•íƒœë¡œ ì •ë¦¬ ìš”ì²­ ì‹œ HTML í…Œì´ë¸”ë¡œ êµ¬ì„±
17. ì´ë¯¸ì§€/ì•„ì´ì½˜ íŒíŠ¸: í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ë‚˜ ì•„ì´ì½˜ ìœ„ì¹˜ í‘œì‹œ (ì˜ˆ: [ì´ë¯¸ì§€ ìœ„ì¹˜], ğŸ“§ ë“±)
18. ë²„íŠ¼/ë§í¬ ìŠ¤íƒ€ì¼: CTA ë²„íŠ¼ì´ë‚˜ ë§í¬ì˜ HTML ìŠ¤íƒ€ì¼ ë³€ê²½ ìš”ì²­ ì²˜ë¦¬

**ê¸°ë³¸ ì„œë¡  í˜•ì‹ (ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ìš”ì²­ì„ í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ):**
"<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…].<br>PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>"

**ê¸°ë³¸ ê²°ë¡  í˜•ì‹ (ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ìš”ì²­ì„ í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ):**
"<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ [íšŒì‚¬ëª…]ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{{user_name}} ë“œë¦¼</p>"

**ì¤‘ìš” ì£¼ì˜ì‚¬í•­:**
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ "ì œëª©ì„ ì´ë ‡ê²Œ ë°”ê¿”ì¤˜", "ì¸ì‚¬ë§ì„ ì´ë ‡ê²Œ í•´ì¤˜", "ë§ˆë¬´ë¦¬ë¥¼ ì´ë ‡ê²Œ í•´ì¤˜" ë“±ì˜ ìš”ì²­ì„ í–ˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ì ìš©
- ì‚¬ìš©ìê°€ "ë” ì§§ê²Œ", "ë” ê¸¸ê²Œ", "ì¹œê·¼í•˜ê²Œ", "ê²©ì‹ìˆê²Œ" ë“±ì˜ í†¤ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ì „ì²´ì ìœ¼ë¡œ ì ìš©
- ì‚¬ìš©ìê°€ íŠ¹ì • ë‚´ìš© ì¶”ê°€/ì‚­ì œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ë°˜ì˜
- ì‚¬ìš©ì ìš”ì²­ì´ ì• ë§¤í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•œ ê²½ìš°ì—ë§Œ ê¸°ë³¸ í˜•ì‹ ìœ ì§€

**ì™¸ì  í˜•ì‹ ìš”ì²­ ì˜ˆì‹œ:**
- "ë³¼ë“œì²´ë¡œ ê°•ì¡°í•´ì¤˜" â†’ <strong> ë˜ëŠ” <b> íƒœê·¸ ì‚¬ìš©
- "ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜" â†’ <ul><li> í˜•ì‹ìœ¼ë¡œ ë³€ê²½
- "ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œ í•´ì¤˜" â†’ <ol><li> í˜•ì‹ìœ¼ë¡œ ë³€ê²½
- "í‘œë¡œ ì •ë¦¬í•´ì¤˜" â†’ <table> í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
- "ë²„íŠ¼ ìŠ¤íƒ€ì¼ë¡œ í•´ì¤˜" â†’ <button> ë˜ëŠ” ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ <a> íƒœê·¸ ì‚¬ìš©
- "ìƒ‰ê¹”ì„ ë„£ì–´ì¤˜" â†’ style="color:" ì†ì„± ì¶”ê°€
- "ì¤‘ì•™ ì •ë ¬í•´ì¤˜" â†’ style="text-align:center" ì ìš©
- "í° ê¸€ì”¨ë¡œ í•´ì¤˜" â†’ <h1>, <h2> íƒœê·¸ë‚˜ style="font-size:" ì‚¬ìš©

---

### ğŸ¬ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ (URL/ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ìˆëŠ” ê²½ìš°)

**ë‹¨ê³„ 1: ê¸°ì‚¬ ë¶„ì„**
ìœ„ì— ì œê³µëœ "ì°¸ê³  ê¸°ì‚¬ ì •ë³´"ë¥¼ ë©´ë°€íˆ ë¶„ì„í•˜ì„¸ìš”.
- íšŒì‚¬ëª…, ì œí’ˆ/ì„œë¹„ìŠ¤ëª…, ì‚¬ì—… ë‚´ìš©
- íˆ¬ì ê¸ˆì•¡, ë§¤ì¶œ ëª©í‘œ, ë§¤ì¥ ìˆ˜, í™•ì¥ ê³„íš ë“± êµ¬ì²´ì  ìˆ˜ì¹˜
- ì¶œì‹œ ì‹œê¸°, ëª©í‘œ ì‹œì¥, ê²½ìŸ ì „ëµ

**ë‹¨ê³„ 2: Pain Point ì¶”ë¡ **
ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ íšŒì‚¬ê°€ í˜„ì¬ ì§ë©´í–ˆê±°ë‚˜ ê³§ ì§ë©´í•  ê²°ì œ/ì •ì‚° ê´€ë ¨ ê³¼ì œë¥¼ **3ê°€ì§€ ì´ìƒ** ë„ì¶œí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- ìì²´ë¸Œëœë“œ ì¶œì‹œ â†’ ì‹ ê·œ SKU ëŒ€ëŸ‰ ì¶”ê°€ë¡œ ì¸í•œ ì •ì‚° ë³µì¡ë„ ì¦ê°€
- ì „êµ­ ë§¤ì¥ í™•ëŒ€ â†’ ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ ì±„ë„ í†µí•© ê²°ì œ í•„ìš”
- ë¹ ë¥¸ ì¶œì‹œ ì¼ì • â†’ IT ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±, ì™¸ë¶€ ì†”ë£¨ì…˜ í•„ìš”

**ë‹¨ê³„ 3: PortOne ì†”ë£¨ì…˜ ë§¤í•‘**
ê° Pain Pointì— ëŒ€í•´ PortOneì´ ì œê³µí•  ìˆ˜ ìˆëŠ” **êµ¬ì²´ì  í•´ê²°ì±…**ì„ ì—°ê²°í•˜ì„¸ìš”.
- OPI (One Payment Infra): í†µí•© ê²°ì œ ì‹œìŠ¤í…œ, 2ì£¼ ë‚´ êµ¬ì¶•, ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°
- ì¬ë¬´ìë™í™”: ì •ì‚° ë°ì´í„° ìë™í™”, 90% ì‹œê°„ ë‹¨ì¶•, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
- ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…: ì—¬ëŸ¬ PGì‚¬ ìë™ ì„ íƒ, ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ

**ë‹¨ê³„ 4: ì´ë©”ì¼ ì‘ì„±**
ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ **HTML í˜•ì‹**ì˜ ì´ë©”ì¼ ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.

âš ï¸ **ì¤‘ìš”**: 
- ì œëª©ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš” (ë³¸ë¬¸ë§Œ ì‘ì„±)
- HTML íƒœê·¸ ì‚¬ìš©: <p>, <br>, <strong>, <ul>, <li> ë“±
- ê¸°ì‚¬ ë‚´ìš©ì„ ë‹¨ìˆœ ì–¸ê¸‰ì´ ì•„ë‹Œ Pain Point ê·¼ê±°ë¡œ í™œìš©
- êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ì‚¬ì‹¤ ê¸°ë°˜ ì„¤ë“

**ì¶œë ¥ í˜•ì‹:**
```html
<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…]ë‹˜.<br>
PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ìµœê·¼ [ê¸°ì‚¬ì—ì„œ ë°œê²¬í•œ êµ¬ì²´ì  ì‚¬ì‹¤]ì— ëŒ€í•œ ì†Œì‹ì„ ì ‘í–ˆìŠµë‹ˆë‹¤.<br>
[êµ¬ì²´ì  ìˆ˜ì¹˜/ëª©í‘œ]ëŠ” ì •ë§ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤.</p>

<p>ì´ëŸ° ë¹ ë¥¸ ì„±ì¥ê³¼ [êµ¬ì²´ì  ì‚¬ì—… í™•ì¥] ê³¼ì •ì—ì„œ<br>
[Pain Point 1]ê³¼ [Pain Point 2]ê°€<br>
ì¤‘ìš”í•œ ê³¼ì œê°€ ë  ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤.</p>

<p>PortOneì˜ [ì œí’ˆëª…]ì€ ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>

<ul>
<li><strong>[Pain Point 1 í•´ê²°]</strong>: [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ìˆ˜ì¹˜ ê²°ê³¼]</li>
<li><strong>[Pain Point 2 í•´ê²°]</strong>: [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ìˆ˜ì¹˜ ê²°ê³¼]</li>
<li><strong>[ì¶”ê°€ í˜œíƒ]</strong>: [ì°¨ë³„í™” í¬ì¸íŠ¸]</li>
</ul>

<p>[íšŒì‚¬ëª…]ì˜ [ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ ëª©í‘œ]ë¥¼ ë” ë¹ ë¥´ê²Œ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆë„ë¡<br>
ë¯¸íŒ…ì„ í†µí•´ êµ¬ì²´ì ì¸ ë„ì›€ì„ ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.</p>

<p>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´<br>
[íšŒì‚¬ëª…]ì˜ ì„±ì¥ì— í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€<br>
ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>
{{user_name}} ë“œë¦¼</p>
```

---

### âš ï¸ ìµœì¢… ê²€ì¦ (ì¶œë ¥ ì „ ë°˜ë“œì‹œ í™•ì¸)

**ğŸš¨ ì œí’ˆ ì„ íƒ ê²€ì¦ (ìµœìš°ì„ )**

**ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ:**
- [ ] ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì œí’ˆëª…ì„ ì •í™•íˆ íŒŒì•…í–ˆëŠ”ê°€?
- [ ] ì„ íƒëœ ì œí’ˆë§Œ ì´ë©”ì¼ ì „ì²´ì— ì‚¬ìš©í–ˆëŠ”ê°€?
- [ ] ë‹¤ë¥¸ ì œí’ˆ(OPI, Prism, ì¬ë¬´ìë™í™”, Recon ì¤‘ ì„ íƒ ì•ˆ ëœ ì œí’ˆ)ì„ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì œí’ˆì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ íŠ¹ì§•ì„ ì •í™•íˆ ì‚¬ìš©í–ˆëŠ”ê°€?

**ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ:**
- [ ] ì‚¬ìš©ìê°€ ë³µìˆ˜ ì œí’ˆì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸í–ˆëŠ”ê°€? ("OPIì™€ Recon", "ë‘˜ ë‹¤", "ì¢…í•©ì ìœ¼ë¡œ" ë“±)
- [ ] ìš”ì²­ëœ ì œí’ˆë“¤ë§Œ ì‚¬ìš©í•˜ê³  ë‹¤ë¥¸ ì œí’ˆì€ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ê° ì œí’ˆì´ ì ì ˆí•œ Pain Point í•´ê²°ì— ë§¤í•‘ë˜ì—ˆëŠ”ê°€?
- [ ] ì œí’ˆ ê°„ ì‹œë„ˆì§€ë‚˜ ì¢…í•© ê°€ì¹˜ë¥¼ ì–¸ê¸‰í–ˆëŠ”ê°€?
- [ ] ê° ì œí’ˆì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ ì •í™•íˆ ì‚¬ìš©í–ˆëŠ”ê°€?

**ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜ ê²€ì¦**
- [ ] ì‚¬ìš©ìê°€ í†¤/ê¸¸ì´/ìŠ¤íƒ€ì¼ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ëª¨ë‘ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ì‚¬ìš©ìê°€ íŠ¹ì • ë‚´ìš© ì¶”ê°€/ì‚­ì œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ì ìš©ë˜ì—ˆëŠ”ê°€?

**ê¸°ì‚¬ ë¶„ì„ ê²€ì¦ (ê¸°ì‚¬ê°€ ì œê³µëœ ê²½ìš°ë§Œ)**
- [ ] ê¸°ì‚¬ì—ì„œ ë°œê²¬í•œ **êµ¬ì²´ì  ì‚¬ì‹¤** (íšŒì‚¬ëª…, ì‚¬ì—…, ìˆ˜ì¹˜ ë“±) ëª…ì‹œ
- [ ] **ìµœì†Œ 2ê°œ**ì˜ êµ¬ì²´ì  Pain Point ì œê¸°
- [ ] ê° Pain Pointì— ëŒ€í•´ **ì„ íƒëœ ì œí’ˆ(ë“¤)**ìœ¼ë¡œ ì†”ë£¨ì…˜ ì œì‹œ
- [ ] ì†”ë£¨ì…˜ì— í•´ë‹¹ ì œí’ˆì˜ **êµ¬ì²´ì  ìˆ˜ì¹˜** í¬í•¨
- [ ] <ul><li> íƒœê·¸ë¡œ ì†”ë£¨ì…˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‘ì„±

---

### ğŸš¨ ì¶œë ¥ í˜•ì‹ (ë§¤ìš° ì¤‘ìš” - ë°˜ë“œì‹œ ì¤€ìˆ˜)

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- âŒ "í•µì‹¬ ê°œì„  í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤" ê°™ì€ ì„¤ëª… í…ìŠ¤íŠ¸
- âŒ "ê°œì„ ëœ ì´ë©”ì¼ ë¬¸ì•ˆ:" ê°™ì€ ì œëª©ì´ë‚˜ í—¤ë”
- âŒ "ì œëª©: ~" í˜•ì‹ì˜ ì œëª© ìƒì„±
- âŒ ê°œì„  ì´ìœ ë‚˜ ë³€ê²½ ì‚¬í•­ ì„¤ëª…
- âŒ ì½”ë“œ ë¸”ë¡(```) ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹
- âŒ ê·¸ ì™¸ ì–´ë– í•œ ë¶€ê°€ ì„¤ëª…ì´ë‚˜ ì£¼ì„

**ë°˜ë“œì‹œ ì¶œë ¥:**
- âœ… HTML í˜•ì‹ì˜ ì´ë©”ì¼ **ë³¸ë¬¸ë§Œ** ì¶œë ¥
- âœ… <p>, <br>, <strong>, <ul>, <li> ë“± HTML íƒœê·¸ ì‚¬ìš©
- âœ… ì²« ì¤„ë¶€í„° ë°”ë¡œ "<p>ì•ˆë…•í•˜ì„¸ìš”..." ë¡œ ì‹œì‘

**ì¶œë ¥ ì˜ˆì‹œ:**
<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…].<br>PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>
<p>ìµœê·¼ [ë‚´ìš©]...</p>
...

ì´ì œ ê°œì„ ëœ ì´ë©”ì¼ ë³¸ë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
"""
        
        # Gemini API í˜¸ì¶œ (ìë™ fallback ì ìš©)
        logger.info("ì´ë©”ì¼ ê°œì„  ì‹œì‘ - call_gemini_with_fallback ì‚¬ìš©")
        
        try:
            refined_content = call_gemini_with_fallback(
                prompt=prompt,
                timeout=60,
                max_retries=3,
                generation_config={
                    'temperature': 0.5,
                    'maxOutputTokens': 4096,
                    'topP': 0.9,
                    'topK': 40
                }
            )
            
            logger.info(f"Gemini ì´ë©”ì¼ ê°œì„  ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(refined_content)} ë¬¸ì")
            return refined_content
            
        except Exception as fallback_error:
            logger.error(f"Gemini fallback í¬í•¨ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {str(fallback_error)}")
            raise
        
    except Exception as e:
        logger.error(f"Gemini ì´ë©”ì¼ ê°œì„  ì˜¤ë¥˜: {str(e)}")
        return f"""ì œëª©: ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆ - {refinement_request} ë°˜ì˜

ì•ˆë…•í•˜ì„¸ìš”!

ìš”ì²­í•´ì£¼ì‹  "{refinement_request}" ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

PortOneì˜ One Payment InfraëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤:

â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½
â€¢ 2ì£¼ ë‚´ ë¹ ë¥¸ ë„ì…
â€¢ ë¬´ë£Œ ì „ë¬¸ ì»¨ì„¤íŒ…
â€¢ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ

ë¯¸íŒ…ì„ í†µí•´ êµ¬ì²´ì ì¸ í˜œíƒì„ ìƒì„¸íˆ ì•ˆë‚´ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.

ì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?

ê°ì‚¬í•©ë‹ˆë‹¤.
PortOne ì˜ì—…íŒ€

(ì£¼ì˜: Gemini API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ - {str(e)})"""

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
researcher = CompanyResearcher()
copywriter = EmailCopywriter()

@app.route('/api/research-company', methods=['POST'])
def research_company():
    """íšŒì‚¬ ì •ë³´ ì¡°ì‚¬ API"""
    try:
        data = request.json
        company_name = data.get('company_name')
        website = data.get('website')
        
        if not company_name:
            return jsonify({'error': 'íšŒì‚¬ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # Perplexityë¡œ íšŒì‚¬ ì •ë³´ ì¡°ì‚¬
        research_result = researcher.research_company(company_name, website)
        
        # íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥ (ë‰´ìŠ¤ ë¶„ì„ì—ì„œ ì¬ì‚¬ìš©)
        if research_result and research_result.get('success'):
            company_info = {
                'company_name': company_name,
                'industry': research_result.get('industry', ''),
                'business_description': research_result.get('business_description', ''),
                'company_size': research_result.get('company_size', ''),
                'special_notes': research_result.get('pain_points', ''),
                'website': website,
                'research_timestamp': datetime.now().isoformat()
            }
            save_company_info_cache(company_name, company_info)
        
        return jsonify(research_result)
        
    except Exception as e:
        return jsonify({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/api/generate-emails', methods=['POST'])
@login_required
def generate_emails():
    """ë©”ì¼ ë¬¸ì•ˆ ìƒì„± API (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        company_data = data.get('company_data', {})
        research_data = data.get('research_data', {})
        industry = data.get('industry')
        
        # ì—…ê³„ íŠ¸ë Œë“œ ì¡°ì‚¬ (ì„ íƒì‚¬í•­)
        industry_trends = None
        if industry:
            industry_trends = researcher.get_industry_trends(industry)
        
        # Geminië¡œ ë©”ì¼ ë¬¸ì•ˆ ìƒì„±
        if research_data:
            research_data['industry_trends'] = industry_trends
        else:
            research_data = {'industry_trends': industry_trends}
            
        email_result = generate_email_with_gemini(company_data, research_data)
        
        return jsonify({
            'email_result': email_result,
            'industry_trends': industry_trends,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': f'ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}'}), 500

def process_single_company(company, index, user_template=None, user_input_mode='template', user_info=None):
    """
    ë‹¨ì¼ íšŒì‚¬ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ ì‹¤í–‰ìš©) - SSR ìµœì í™” ë²„ì „
    
    ë‰´ìŠ¤ í›„í‚¹ + SSR ì ìš© (4ê°œ ìƒì„± â†’ ìµœì  1ê°œ ì¶”ì²œ) ë˜ëŠ” ì‚¬ìš©ì ë¬¸ì•ˆ/ìš”ì²­ì‚¬í•­ í™œìš©
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    # ThreadPoolExecutorì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ app context í•„ìš”!
    with app.app_context():
        try:
            # ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš© - ì—´ ì´ë¦„ì´ ë³€ê²½ë˜ì–´ë„ ì˜¬ë°”ë¥´ê²Œ ì‘ë™
            company_name = get_company_name(company)
            
            # CSVì—ì„œ "ê´€ë ¨ë‰´ìŠ¤" ì—´ í™•ì¸ (ë™ì  ë§¤í•‘)
            news_url = get_news_url(company)
            news_content = None
            
            # ë‰´ìŠ¤ URLì´ ìˆìœ¼ë©´ ìŠ¤í¬ë˜í•‘
            if news_url and news_url.strip():
                logger.info(f"{company_name}: ê´€ë ¨ë‰´ìŠ¤ ë°œê²¬ - {news_url}")
                news_content = scrape_news_article(news_url.strip())
                if news_content:
                    logger.info(f"{company_name}: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ - {news_content.get('title', '')}")
                else:
                    logger.warning(f"{company_name}: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")
            
            # 1. íšŒì‚¬ ì •ë³´ ì¡°ì‚¬ (CSV ì¶”ê°€ ì •ë³´ í™œìš©) - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
            additional_info = get_additional_info(company)
            
            # í™ˆí˜ì´ì§€ URL ì¶”ì¶œ (ë™ì  ë§¤í•‘)
            homepage_url = get_homepage(company)
            
            research_result = researcher.research_company(
                company_name, 
                homepage_url,
                additional_info
            )
            
            # 2. ë©”ì¼ ë¬¸ì•ˆ ìƒì„± (Gemini ì‚¬ìš©)
            if research_result['success']:
                # ë‰´ìŠ¤ ë‚´ìš©ì„ research_resultì— ì¶”ê°€
                if news_content:
                    news_title = news_content.get('title', '')
                    news_text = news_content.get('content', '')
                    logger.info(f"{company_name}: ê´€ë ¨ë‰´ìŠ¤ ë‚´ìš©ì„ researchì— ì¶”ê°€")
                    research_result['company_info'] += f"\n\n## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)\n**ì œëª©:** {news_title}\n**ë‚´ìš©:** {news_text[:1000]}"
                
                # 2-1. ê´€ë ¨ ì‚¬ë¡€ ì„ íƒ (ì œì•ˆì„œ ê¸°ë°˜ ì‹¤ì œ ì‚¬ë¡€)
                relevant_case_keys = select_relevant_cases(
                    company, 
                    research_result.get('company_info', ''),
                    max_cases=2
                )
                
                logger.info(f"{company_name} - ì„ íƒëœ ì‚¬ë¡€: {relevant_case_keys}")
                
                # ì‚¬ë¡€ ì •ë³´ í¬ë§·íŒ…
                case_examples = ""
                for case_key in relevant_case_keys:
                    case_examples += format_case_for_email(case_key)
                
                # 2-2. Gemini APIë¥¼ ì‚¬ìš©í•œ ë©”ì¼ ìƒì„± (ë‰´ìŠ¤ ë‚´ìš©, ì‚¬ë¡€ ì •ë³´, ì‚¬ìš©ì ë¬¸ì•ˆ/ìš”ì²­ì‚¬í•­ í¬í•¨)
                email_result = generate_email_with_gemini_and_cases(
                    company, research_result, case_examples, user_template=user_template, news_content=news_content, user_input_mode=user_input_mode, user_info=user_info
                )
                
                # 2-3. SSRë¡œ 4ê°œ ì´ë©”ì¼ í‰ê°€ ë° ìˆœìœ„ ë§¤ê¸°ê¸°
                if email_result.get('success') and email_result.get('variations'):
                    try:
                        # 4ê°œ ì´ë©”ì¼ì„ SSRë¡œ í‰ê°€
                        all_emails = []
                        for key, variation in email_result['variations'].items():
                            all_emails.append({
                                'type': key,
                                'product': variation.get('product', 'PortOne'),
                                'subject': variation.get('subject', ''),
                                'body': variation.get('body', ''),
                                'cta': variation.get('cta', ''),
                                'tone': variation.get('tone', '')
                            })
                        
                        # SSR ìˆœìœ„ ë§¤ê¸°ê¸°
                        ranked_emails = rank_emails(all_emails, company)
                        
                        logger.info(f"{company.get('íšŒì‚¬ëª…')} SSR ì ìˆ˜: " + 
                                  ", ".join([f"{e['type']}: {e.get('ssr_score', 0):.2f}" 
                                           for e in ranked_emails]))
                        
                        # ìµœê³  ì ìˆ˜ ì´ë©”ì¼
                        top_email = ranked_emails[0]
                        
                        # ê²°ê³¼ì— SSR ì •ë³´ ì¶”ê°€
                        email_result['recommended_email'] = top_email
                        email_result['all_ranked_emails'] = ranked_emails
                        email_result['ssr_enabled'] = True
                        
                    except Exception as ssr_error:
                        logger.warning(f"SSR í‰ê°€ ì‹¤íŒ¨: {ssr_error}, ê¸°ë³¸ ìˆœì„œ ì‚¬ìš©")
                        email_result['ssr_enabled'] = False
                
                return {
                    'company': company,
                    'research': research_result,
                    'emails': email_result,
                    'selected_cases': relevant_case_keys,
                    'index': index
                }
            else:
                return {
                    'company': company,
                    'error': research_result.get('error', 'ì¡°ì‚¬ ì‹¤íŒ¨'),
                    'index': index
                }
                
        except Exception as e:
            logger.error(f"íšŒì‚¬ ì²˜ë¦¬ ì˜¤ë¥˜ ({company.get('íšŒì‚¬ëª…')}): {str(e)}")
            return {
                'company': company,
                'error': f'ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}',
                'index': index
            }

@app.route('/api/batch-process', methods=['POST'])
@login_required
def batch_process():
    """ì—¬ëŸ¬ íšŒì‚¬ ì¼ê´„ ì²˜ë¦¬ API - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        companies = data.get('companies', [])
        max_workers = data.get('max_workers', 1)  # ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (RPM ì œí•œ ëŒ€ì‘ ìœ„í•´ ìˆœì°¨ ì²˜ë¦¬)
        user_template = data.get('user_template', None)  # ì‚¬ìš©ì ë¬¸ì•ˆ ë˜ëŠ” ìš”ì²­ì‚¬í•­
        user_input_mode = data.get('user_input_mode', 'template')  # 'request' ë˜ëŠ” 'template'
        
        # ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ (ë³‘ë ¬ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)
        user_info = {
            'name': current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸",
            'email': current_user.email if current_user and current_user.is_authenticated else "ocean@portone.io",
            'company_nickname': current_user.company_nickname if current_user and current_user.is_authenticated else "PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €",
            'phone': current_user.phone if current_user and current_user.is_authenticated else "010-2580-2580"
        }
        logger.info(f"ğŸ“§ ë°°ì¹˜ ì²˜ë¦¬ ìš”ì²­ì: {user_info['name']} ({user_info['email']})")
        
        if not companies:
            return jsonify({'error': 'ì²˜ë¦¬í•  íšŒì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # âš ï¸ ëŒ€ëŸ‰ ì²˜ë¦¬ ì œí•œ: í•œ ë²ˆì— ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ
        MAX_BATCH_SIZE = 50
        if len(companies) > MAX_BATCH_SIZE:
            return jsonify({
                'error': f'í•œ ë²ˆì— ìµœëŒ€ {MAX_BATCH_SIZE}ê°œê¹Œì§€ë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. í˜„ì¬: {len(companies)}ê°œ',
                'suggestion': f'ë°ì´í„°ë¥¼ {MAX_BATCH_SIZE}ê°œì”© ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.'
            }), 400
        
        logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(companies)}ê°œ íšŒì‚¬, {max_workers}ê°œ ë™ì‹œ ì‘ì—…")
        if user_template:
            if user_input_mode == 'request':
                logger.info(f"ìš”ì²­ì‚¬í•­ ëª¨ë“œ: {len(user_template)}ì - ê¸°ë³¸ ìƒì„± + ìš”ì²­ì‚¬í•­ ë°˜ì˜")
            else:
                logger.info(f"ë¬¸ì•ˆ ëª¨ë“œ: {len(user_template)}ì - ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  + ì‚¬ìš©ì ë³¸ë¬¸")
        else:
            logger.info("SSR ëª¨ë“œ: ë‰´ìŠ¤ í›„í‚¹ + 4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨ + AI ì¶”ì²œ")
        start_time = time.time()
        
        # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ê° íšŒì‚¬ì— ëŒ€í•´ ì²˜ë¦¬ ì‘ì—… ì œì¶œ (user_template, user_input_mode, user_info ì „ë‹¬)
            future_to_company = {
                executor.submit(process_single_company, company, i, user_template, user_input_mode, user_info): (company, i)
                for i, company in enumerate(companies)
            }
            
            results = []
            completed = 0
            total = len(companies)
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ ìˆ˜ì§‘
            for future in concurrent.futures.as_completed(future_to_company):
                company, index = future_to_company[future]
                try:
                    result = future.result()
                    results.append(result)
                    completed += 1
                    
                    logger.info(f"ì§„í–‰ë¥ : {completed}/{total} ({completed/total*100:.1f}%) - {get_company_name(company) or 'Unknown'}")
                    
                except Exception as e:
                    logger.error(f"íšŒì‚¬ {get_company_name(company) or 'Unknown'} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    results.append({
                        'company': company,
                        'error': f'ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}',
                        'index': index
                    })
                    completed += 1
        
        # ì¸ë±ìŠ¤ ìˆœì„œë¡œ ì •ë ¬
        results.sort(key=lambda x: x.get('index', 0))
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, í‰ê·  {processing_time/len(companies):.2f}ì´ˆ/íšŒì‚¬")
        
        # ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥
        try:
            for result in results:
                if 'emails' in result and result['emails'].get('success'):
                    company = result.get('company', {})
                    company_name = get_company_name(company) or 'Unknown'
                    company_email = get_email(company)
                    
                    # ìƒì„±ëœ ê° ì´ë©”ì¼ íƒ€ì… ê¸°ë¡
                    variations = result['emails'].get('variations', {})
                    for email_type in variations.keys():
                        email_gen = EmailGeneration(
                            user_id=current_user.id,
                            company_name=company_name,
                            company_email=company_email,
                            email_type=email_type,
                            generation_mode='ssr' if not user_template else ('user_request' if user_input_mode == 'request' else 'user_template')
                        )
                        db.session.add(email_gen)
            
            db.session.commit()
            logger.info(f"ğŸ“Š {current_user.email}: {len(results)}ê°œ íšŒì‚¬, ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
            # ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜
        
        return jsonify({
            'success': True,
            'results': results,
            'total_processed': len(results),
            'processing_time': round(processing_time, 2),
            'parallel_workers': max_workers,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ì¼ê´„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return jsonify({'error': f'ì¼ê´„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/api/refine-email', methods=['POST'])
@login_required
def refine_email():
    """ì´ë©”ì¼ ë¬¸ì•ˆ ê°œì„  (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        current_email = data.get('current_email', '')
        refinement_request = data.get('refinement_request', '')
        company_data = data.get('company_data', {})
        
        if not current_email or not refinement_request:
            return jsonify({
                'success': False,
                'error': 'í˜„ì¬ ì´ë©”ì¼ ë‚´ìš©ê³¼ ê°œì„  ìš”ì²­ì‚¬í•­ì´ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # "ë‹¤ì‹œ ì‘ì„±" í‚¤ì›Œë“œ ê°ì§€ - ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¬ì‹¤í–‰
        regenerate_keywords = ['ë‹¤ì‹œ ì‘ì„±', 'ì¬ìƒì„±', 'ë‹¤ì‹œ ìƒì„±', 'ì²˜ìŒë¶€í„°', 'ìƒˆë¡œ ë§Œë“¤', 'ì „ì²´ ì¬ìƒì„±', 'ì™„ì „íˆ ë‹¤ì‹œ']
        should_regenerate = any(keyword in refinement_request for keyword in regenerate_keywords)
        
        if should_regenerate:
            logger.info(f"ğŸ”„ 'ë‹¤ì‹œ ì‘ì„±' ìš”ì²­ ê°ì§€ - ì „ì²´ ë¡œì§ ì¬ì‹¤í–‰")
            
            # company_dataê°€ ì—†ìœ¼ë©´ sessionì—ì„œ ê°€ì ¸ì˜¤ê¸°
            if not company_data:
                from flask import session
                session_data = session.get('chat_session', {})
                company_data = session_data.get('company_data', {})
            
            if not company_data or 'íšŒì‚¬ëª…' not in company_data:
                return jsonify({
                    'success': False,
                    'error': 'íšŒì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íšŒì‚¬ ì¡°ì‚¬ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”.'
                }), 400
            
            # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¬ì‹¤í–‰ - ğŸ†• ë™ì  ì—´ ë§¤í•‘ ì‚¬ìš©
            logger.info(f"íšŒì‚¬ëª…: {get_company_name(company_data) or 'Unknown'} - ì „ì²´ ë¬¸ì•ˆ ì¬ìƒì„± ì‹œì‘")
            
            # generate_email_with_gemini_and_cases í•¨ìˆ˜ í˜¸ì¶œ
            result = generate_email_with_gemini_and_cases(
                company_data=company_data,
                research_data=company_data.get('research_data', {}),
                user_info={'name': current_user.name if current_user else 'ì˜¤ì¤€í˜¸'}
            )
            
            if result and result.get('success'):
                logger.info(f"âœ… ì „ì²´ ë¬¸ì•ˆ ì¬ìƒì„± ì™„ë£Œ")
                return jsonify({
                    'success': True,
                    'regenerated': True,
                    'variations': result.get('variations', {}),
                    'recommended': result.get('recommended', {}),
                    'timestamp': datetime.now().isoformat()
                })
            else:
                logger.error(f"âŒ ì „ì²´ ë¬¸ì•ˆ ì¬ìƒì„± ì‹¤íŒ¨")
                return jsonify({
                    'success': False,
                    'error': 'ë¬¸ì•ˆ ì¬ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                }), 500
        
        # ì¼ë°˜ ê°œì„  ìš”ì²­
        # Gemini 2.5 Proë¡œ ì´ë©”ì¼ ê°œì„  ìš”ì²­
        refined_email = refine_email_with_gemini(current_email, refinement_request)
        
        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
        user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
        refined_email = refined_email.replace('{user_name}', user_name)
        refined_email = refined_email.replace('ì˜¤ì¤€í˜¸', user_name)
        refined_email = refined_email.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
        
        return jsonify({
            'success': True,
            'refined_email': refined_email,
            'regenerated': False,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ì´ë©”ì¼ ê°œì„  ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/analyze-news', methods=['POST'])
def analyze_news():
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ë¥¼ ë¶„ì„í•˜ì—¬ í˜ì¸ í¬ì¸íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±"""
    try:
        data = request.json
        news_url = data.get('news_url', '')
        company_name = data.get('company_name', '')
        current_email = data.get('current_email', '')
        
        if not news_url:
            return jsonify({
                'success': False,
                'error': 'ë‰´ìŠ¤ ê¸°ì‚¬ URLì´ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # URL ìœ íš¨ì„± ê²€ì‚¬
        if not is_valid_url(news_url):
            return jsonify({
                'success': False,
                'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤.'
            }), 400
        
        # ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš© ìŠ¤í¬ë˜í•‘
        logger.info(f"ë‰´ìŠ¤ ë¶„ì„ ìš”ì²­ - URL: {news_url}, íšŒì‚¬: {company_name}")
        article_content = scrape_news_article(news_url)
        
        if not article_content:
            logger.error(f"ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {news_url}")
            return jsonify({
                'success': False,
                'error': 'ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
            }), 400
        
        logger.info(f"ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ - ì œëª©: {article_content.get('title', '')[:50]}..., ë³¸ë¬¸ ê¸¸ì´: {len(article_content.get('content', ''))}ì")
        
        # ê¸°ì‚¬ ë‚´ìš© ê´€ë ¨ì„± ê²€ì¦
        relevance_score = check_article_relevance(article_content, company_name)
        logger.info(f"ê¸°ì‚¬ ê´€ë ¨ì„± ì ìˆ˜: {relevance_score}/10")
        
        # íšŒì‚¬ ì •ë³´ ì¡°íšŒ (ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼ í™œìš©)
        company_info = get_existing_company_info(company_name)
        if company_info:
            logger.info(f"ê¸°ì¡´ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
        
        # ê¸°ì‚¬ ë‚´ìš© ê¸°ë°˜ í˜ì¸ í¬ì¸íŠ¸ ë¶„ì„ ë° ë©”ì¼ ìƒì„±
        analyzed_email = generate_email_from_news_analysis(
            article_content, 
            company_name, 
            current_email,
            news_url,
            company_info,
            relevance_score
        )
        
        return jsonify({
            'success': True,
            'analyzed_email': analyzed_email,
            'article_summary': article_content.get('summary', ''),
            'pain_points': article_content.get('pain_points', []),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def scrape_article_content(url):
    """
    ê°œë³„ ë¸”ë¡œê·¸ ê¸€ì˜ ìƒì„¸ ë‚´ìš© ìŠ¤í¬ë˜í•‘
    
    Args:
        url: ë¸”ë¡œê·¸ ê¸€ URL
    
    Returns:
        str: ê¸€ ë‚´ìš©
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # article íƒœê·¸ ì°¾ê¸°
        article = soup.find('article')
        if article:
            # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (HTML íƒœê·¸ ì œê±°)
            content = article.get_text(separator=' ', strip=True)
            return content[:5000]  # ìµœëŒ€ 5000ìë¡œ ì œí•œ
        
        return ''
    except Exception as e:
        logger.error(f"   ê¸€ ë‚´ìš© ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ({url}): {str(e)}")
        return ''

def scrape_portone_blog_category(category_url, category_name, max_pages=5):
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤í¬ë˜í•‘ (2025ë…„ HTML ê¸°ë°˜ êµ¬ì¡°)
    
    Args:
        category_url: ì¹´í…Œê³ ë¦¬ URL (ì˜ˆ: https://blog.portone.io/?filter=êµ­ë‚´%20ê²°ì œ)
        category_name: ì¹´í…Œê³ ë¦¬ëª… (OPI, Recon ë“±)
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
    
    Returns:
        list: ë¸”ë¡œê·¸ ê¸€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        import time
        
        logger.info(f"ğŸ“° [{category_name}] ìŠ¤í¬ë˜í•‘ ì‹œì‘: {category_url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        all_posts = []
        seen_links = set()
        
        for page in range(1, max_pages + 1):
            # í˜ì´ì§€ URL êµ¬ì„±
            if page == 1:
                page_url = category_url
            else:
                separator = '&' if '?' in category_url else '?'
                page_url = f"{category_url}{separator}page={page}"
            
            logger.info(f"   í˜ì´ì§€ {page}/{max_pages} ìŠ¤í¬ë˜í•‘...")
            
            try:
                response = requests.get(page_url, headers=headers, timeout=15)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # a íƒœê·¸ì—ì„œ ë¸”ë¡œê·¸ ë§í¬ ì¶”ì¶œ
                links = soup.find_all('a', href=True)
                page_posts_count = 0
                
                for link_elem in links:
                    try:
                        href = link_elem.get('href', '')
                        
                        # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë§í¬ íŒ¨í„´ (ì˜ˆ: /opi_business-am/)
                        if (href.startswith('/') and 
                            not href.startswith('/?') and 
                            not href.startswith('/category') and 
                            href.endswith('/') and 
                            len(href) > 3 and
                            href not in seen_links):
                            
                            # ì œëª© ì°¾ê¸°
                            title_elem = link_elem.find(['h3', 'h2', 'span', 'p'])
                            title = title_elem.get_text(strip=True) if title_elem else ''
                            if not title:
                                title = link_elem.get_text(strip=True)
                            
                            # ìœ íš¨í•œ ì œëª©ì¸ì§€ í™•ì¸
                            if title and len(title) > 10:
                                full_link = f"https://blog.portone.io{href}"
                                seen_links.add(href)
                                
                                logger.info(f"      âœ… {title[:40]}...")
                                
                                # ìƒì„¸ ë‚´ìš© ìŠ¤í¬ë˜í•‘
                                content = ''
                                try:
                                    content = scrape_article_content(full_link)
                                except:
                                    pass
                                
                                summary = content[:200] if content else title
                                
                                all_posts.append({
                                    'title': title,
                                    'link': full_link,
                                    'summary': summary,
                                    'content': content,
                                    'category': category_name
                                })
                                page_posts_count += 1
                                
                                # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€
                                time.sleep(0.3)
                                
                    except Exception as e:
                        continue
                
                logger.info(f"   í˜ì´ì§€ {page}: {page_posts_count}ê°œ ê¸€ ë°œê²¬")
                
                # ë” ì´ìƒ ê¸€ì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if page_posts_count == 0:
                    break
                
            except Exception as e:
                logger.error(f"   í˜ì´ì§€ {page} ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        logger.info(f"ğŸ“Š [{category_name}] ì´ {len(all_posts)}ê°œ ê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_posts
        
    except Exception as e:
        logger.error(f"[{category_name}] ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return []

def scrape_portone_blog_initial():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì „ì²´ ë°ì´í„° ìŠ¤í¬ë˜í•‘ (ë°°ê²½ì§€ì‹ í™•ë³´)
    - OPI (êµ­ë‚´ ê²°ì œ): 15í˜ì´ì§€ (ì£¼ìš” ì¹´í…Œê³ ë¦¬)
    - Recon (ë§¤ì¶œ ë§ˆê°): 10í˜ì´ì§€
    - PS (í”Œë«í¼ ì •ì‚°): 10í˜ì´ì§€
    - ê¸€ë¡œë²Œ ê²°ì œ: 10í˜ì´ì§€
    - ê²°ì œ íŠ¸ë Œë“œ/ë‰´ìŠ¤: 10í˜ì´ì§€
    """
    # Flask app context ë‚´ì—ì„œ ì‹¤í–‰ (PostgreSQL ì ‘ê·¼ì„ ìœ„í•´ í•„ìˆ˜)
    with app.app_context():
        try:
            from portone_blog_cache import save_blog_cache, extract_keywords_from_post
            
            logger.info("ğŸš€ í¬íŠ¸ì› ë¸”ë¡œê·¸ ì „ì²´ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ë°°ê²½ì§€ì‹ í™•ë³´)")
            
            all_posts = []
            
            # 1. OPI (êµ­ë‚´ ê²°ì œ) - 15í˜ì´ì§€ (ê°€ì¥ ì¤‘ìš”)
            opi_url = 'https://blog.portone.io/?filter=%EA%B5%AD%EB%82%B4%20%EA%B2%B0%EC%A0%9C'
            opi_posts = scrape_portone_blog_category(opi_url, 'OPI', max_pages=15)
            all_posts.extend(opi_posts)
            logger.info(f"ğŸ“Š OPI ë¸”ë¡œê·¸: {len(opi_posts)}ê°œ ìˆ˜ì§‘")
            
            # 2. Recon (ë§¤ì¶œ ë§ˆê°) - 10í˜ì´ì§€
            recon_url = 'https://blog.portone.io/?filter=%EB%A7%A4%EC%B6%9C%20%EB%A7%88%EA%B0%90'
            recon_posts = scrape_portone_blog_category(recon_url, 'Recon', max_pages=10)
            all_posts.extend(recon_posts)
            logger.info(f"ğŸ“Š Recon ë¸”ë¡œê·¸: {len(recon_posts)}ê°œ ìˆ˜ì§‘")
            
            # 3. PS (í”Œë«í¼ ì •ì‚°) - 10í˜ì´ì§€
            ps_url = 'https://blog.portone.io/category/news/?filter=%ED%94%8C%EB%9E%AB%ED%8F%BC%20%EC%A0%95%EC%82%B0'
            ps_posts = scrape_portone_blog_category(ps_url, 'PS', max_pages=10)
            all_posts.extend(ps_posts)
            logger.info(f"ğŸ“Š PS ë¸”ë¡œê·¸: {len(ps_posts)}ê°œ ìˆ˜ì§‘")
            
            # 4. ê¸€ë¡œë²Œ ê²°ì œ - 10í˜ì´ì§€
            global_url = 'https://blog.portone.io/?filter=%EA%B8%80%EB%A1%9C%EB%B2%8C%20%EA%B2%B0%EC%A0%9C'
            global_posts = scrape_portone_blog_category(global_url, 'OPI', max_pages=10)
            all_posts.extend(global_posts)
            logger.info(f"ğŸ“Š ê¸€ë¡œë²Œ ê²°ì œ ë¸”ë¡œê·¸: {len(global_posts)}ê°œ ìˆ˜ì§‘")
            
            # 5. ê²°ì œ íŠ¸ë Œë“œ/ë‰´ìŠ¤ - 10í˜ì´ì§€
            news_url = 'https://blog.portone.io/category/news/'
            news_posts = scrape_portone_blog_category(news_url, 'OPI', max_pages=10)
            all_posts.extend(news_posts)
            logger.info(f"ğŸ“Š ê²°ì œ íŠ¸ë Œë“œ/ë‰´ìŠ¤: {len(news_posts)}ê°œ ìˆ˜ì§‘")
            
            # í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ
            logger.info("ğŸ” ë¸”ë¡œê·¸ ê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            for post in all_posts:
                keywords, industry_tags = extract_keywords_from_post(post)
                post['keywords'] = keywords
                post['industry_tags'] = industry_tags
            
            # DBì— ì €ì¥ (ê¸°ì¡´ ë¸”ë¡œê·¸ ìœ ì§€í•˜ê³  ìƒˆ ë¸”ë¡œê·¸ ì¶”ê°€)
            if all_posts:
                save_blog_cache(all_posts, replace_all=False)
                logger.info(f"âœ… ë¸”ë¡œê·¸ ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(all_posts)}ê°œ ì¶”ê°€/ì—…ë°ì´íŠ¸ (PostgreSQL)")
                
                # ì „ì²´ ë¸”ë¡œê·¸ ê°œìˆ˜ í™•ì¸
                from portone_blog_cache import load_blog_cache
                total_cached = load_blog_cache()
                if total_cached:
                    logger.info(f"ğŸ“š ì´ ë°°ê²½ì§€ì‹: {len(total_cached)}ê°œ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… (ëˆ„ì , PostgreSQL)")
                
                return all_posts
            else:
                logger.warning("âš ï¸ ìŠ¤í¬ë˜í•‘ëœ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤")
                return []
            
        except Exception as e:
            logger.error(f"ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return []

def scrape_portone_blog_incremental():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì¦ë¶„ ìŠ¤í¬ë˜í•‘ (ìƒˆë¡œìš´ ê¸€ë§Œ)
    - ê¸°ì¡´ DBì— ì—†ëŠ” ìƒˆ ê¸€ë§Œ í™•ì¸ ë° ìŠ¤í¬ë˜í•‘
    - ë§¤ì¼ ìë™ ì‹¤í–‰ ì‹œ íš¨ìœ¨ì 
    
    Returns:
        list: ìƒˆë¡œ ì¶”ê°€ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    with app.app_context():
        try:
            from portone_blog_cache import get_existing_blog_links, check_for_new_posts, save_blog_cache, extract_keywords_from_post
            
            logger.info("ğŸ” ë¸”ë¡œê·¸ ì¦ë¶„ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ìƒˆ ê¸€ë§Œ í™•ì¸)")
            
            # 1. ê¸°ì¡´ DBì— ìˆëŠ” ë§í¬ë“¤ ì¡°íšŒ
            existing_links = get_existing_blog_links()
            
            if not existing_links:
                logger.info("ğŸ“ DBê°€ ë¹„ì–´ìˆìŒ - ì „ì²´ ìŠ¤í¬ë˜í•‘ í•„ìš”")
                return scrape_portone_blog_initial()
            
            # 2. ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒˆ ê¸€ í™•ì¸ (ìµœê·¼ 2í˜ì´ì§€ë§Œ)
            categories = [
                ('https://blog.portone.io/?filter=%EA%B5%AD%EB%82%B4%20%EA%B2%B0%EC%A0%9C', 'OPI'),
                ('https://blog.portone.io/?filter=%EB%A7%A4%EC%B6%9C%20%EB%A7%88%EA%B0%90', 'Recon'),
                ('https://blog.portone.io/category/news/?filter=%ED%94%8C%EB%9E%AB%ED%8F%BC%20%EC%A0%95%EC%82%B0', 'PS'),
                ('https://blog.portone.io/?filter=%EA%B8%80%EB%A1%9C%EB%B2%8C%20%EA%B2%B0%EC%A0%9C', 'OPI'),
            ]
            
            all_new_links = []
            for category_url, category_name in categories:
                new_links = check_for_new_posts(category_url, existing_links, max_check_pages=2)
                if new_links:
                    logger.info(f"ğŸ“° [{category_name}] ìƒˆ ê¸€ {len(new_links)}ê°œ ë°œê²¬")
                    all_new_links.extend([(link, category_name) for link in new_links])
            
            if not all_new_links:
                logger.info("âœ… ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ê¸€ ì—†ìŒ")
                return []
            
            logger.info(f"ğŸ“š ì´ {len(all_new_links)}ê°œ ìƒˆ ê¸€ ë°œê²¬ - ìŠ¤í¬ë˜í•‘ ì‹œì‘")
            
            # 3. ìƒˆ ê¸€ë§Œ ìŠ¤í¬ë˜í•‘
            new_posts = []
            for link, category in all_new_links:
                try:
                    content = scrape_article_content(link)
                    if content:
                        post = {
                            'title': content.split('\n')[0] if content else link,
                            'link': link,
                            'summary': content[:200] if len(content) > 200 else content,
                            'content': content,
                            'category': category
                        }
                        
                        # í‚¤ì›Œë“œ ì¶”ì¶œ
                        keywords, industry_tags = extract_keywords_from_post(post)
                        post['keywords'] = keywords
                        post['industry_tags'] = industry_tags
                        
                        new_posts.append(post)
                        logger.info(f"   âœ… {post['title'][:50]}...")
                except Exception as e:
                    logger.error(f"   âŒ ê¸€ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ({link}): {str(e)}")
            
            # 4. DBì— ì €ì¥ (ê¸°ì¡´ ê¸€ì€ ìœ ì§€, ìƒˆ ê¸€ë§Œ ì¶”ê°€)
            if new_posts:
                save_blog_cache(new_posts, replace_all=False)
                logger.info(f"âœ… ì¦ë¶„ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(new_posts)}ê°œ ìƒˆ ê¸€ ì¶”ê°€")
            
            return new_posts
            
        except Exception as e:
            logger.error(f"ì¦ë¶„ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return []

def get_blog_content_for_email():
    """
    ë©”ì¼ ìƒì„±ì— ì‚¬ìš©í•  ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ìš°ì„ )
    
    Returns:
        str: í¬ë§·íŒ…ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸ 
    """
    from portone_blog_cache import load_blog_cache, format_blog_content_for_email, get_blog_cache_age
    
    # ìºì‹œì—ì„œ ë¡œë“œ ì‹œë„
    cached_posts = load_blog_cache()
    
    if cached_posts:
        cache_age = get_blog_cache_age()
        if cache_age and cache_age < 24:  # 24ì‹œê°„ ì´ë‚´ë©´ ìºì‹œ ì‚¬ìš©
            logger.info(f"ğŸ“š ë¸”ë¡œê·¸ ìºì‹œ ì‚¬ìš© (ì—…ë°ì´íŠ¸ëœ ì§€ {cache_age:.1f}ì‹œê°„)")
            return format_blog_content_for_email(cached_posts)
        else:
            logger.info("â° ë¸”ë¡œê·¸ ìºì‹œê°€ ì˜¤ë˜ë¨ (24ì‹œê°„ ì´ìƒ)")
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ìŠ¤í¬ë˜í•‘
    logger.info("ğŸ”„ ë¸”ë¡œê·¸ ìƒˆë¡œ ìŠ¤í¬ë˜í•‘...")
    new_posts = scrape_portone_blog(max_posts=5)
    
    if new_posts:
        return format_blog_content_for_email(new_posts)
    elif cached_posts:
        # ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì˜¤ë˜ëœ ìºì‹œë¼ë„ ì‚¬ìš©
        logger.info("âš ï¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, ì˜¤ë˜ëœ ìºì‹œ ì‚¬ìš©")
        return format_blog_content_for_email(cached_posts)
    else:
        return ""

@app.route('/api/chat-reply', methods=['POST'])
@login_required
def chat_reply():
    """
    ììœ ë¡œìš´ ì±—ë´‡ - ê³ ê° ë‹µë³€/ë°˜ë°•ì— ëŒ€í•œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„± (ë¡œê·¸ì¸ í•„ìš”)
    
    ì‚¬ìš© ì‚¬ë¡€:
    1. ê³ ê°ì˜ ë¶€ì •ì  ë‹µë³€ì— ëŒ€í•œ ë°˜ë°• ë©”ì¼
    2. ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ë©”ì¼
    3. ììœ ë¡œìš´ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±
    """
    try:
        data = request.json
        user_context = data.get('context', '')  # ê³ ê° ë‹µë³€/ìƒí™© ì„¤ëª…
        company_name = data.get('company_name', '')
        email_name = data.get('email_name', 'ë‹´ë‹¹ìë‹˜')
        
        if not user_context:
            return jsonify({'error': 'ì»¨í…ìŠ¤íŠ¸(ê³ ê° ë‹µë³€ ë˜ëŠ” ìƒí™©)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
        
        logger.info(f"ğŸ’¬ ì±—ë´‡ ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹œì‘ - {company_name}")
        logger.info(f"   ì…ë ¥ ì»¨í…ìŠ¤íŠ¸: {user_context[:100]}...")
        
        # í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ìš°ì„ )
        blog_content = get_blog_content_for_email()
        logger.info(f"   ğŸ“š ë¸”ë¡œê·¸ ì½˜í…ì¸ : {'ì‚¬ìš©' if blog_content else 'ì—†ìŒ'}")
        
        # ì„œë¹„ìŠ¤ ì†Œê°œì„œ(ì¼€ì´ìŠ¤ ìŠ¤í„°ë””) ë¡œë“œ - ê¸°ë³¸ ì¼€ì´ìŠ¤ ì‚¬ìš©
        from case_database import PORTONE_CASES, format_case_for_email
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ ì¼€ì´ìŠ¤ ì„ íƒ
        context_lower = user_context.lower()
        selected_case_ids = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¼€ì´ìŠ¤ ì„ íƒ
        if 'pg' in context_lower or 'ê²°ì œ' in context_lower or 'ë¹„ìš©' in context_lower:
            selected_case_ids.append('development_resource_saving')
        if 'ì‹œê°„' in context_lower or 'ë°”ë¹ ' in context_lower or 'ê°œë°œ' in context_lower:
            selected_case_ids.append('quick_setup')
        if 'ì‹¤íŒ¨' in context_lower or 'ì˜¤ë¥˜' in context_lower:
            selected_case_ids.append('payment_failure_recovery')
        
        # ìµœì†Œ 2ê°œ ì¼€ì´ìŠ¤ ë³´ì¥
        if len(selected_case_ids) == 0:
            selected_case_ids = ['development_resource_saving', 'payment_failure_recovery']
        elif len(selected_case_ids) == 1:
            selected_case_ids.append('multi_pg_management')
        
        # ìµœëŒ€ 3ê°œë¡œ ì œí•œ
        selected_case_ids = selected_case_ids[:3]
        
        # ê° ì¼€ì´ìŠ¤ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ê²°í•©
        case_details = "\n".join([format_case_for_email(case_id) for case_id in selected_case_ids])
        
        # ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ì™€ ë¸”ë¡œê·¸ ì½˜í…ì¸  ê²°í•©
        full_context = case_details + blog_content
        
        # Geminië¡œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
        result = generate_persuasive_reply(
            context=user_context,
            company_name=company_name,
            email_name=email_name,
            case_examples=full_context
        )
        
        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
        if result.get('success') and result.get('email', {}).get('body'):
            user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
            result['email']['body'] = result['email']['body'].replace('ì˜¤ì¤€í˜¸', user_name)
            result['email']['body'] = result['email']['body'].replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
        
        if result.get('success'):
            logger.info(f"âœ… {company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì™„ë£Œ")
            return jsonify(result)
        else:
            logger.error(f"âŒ {company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹¤íŒ¨: {result.get('error')}")
            return jsonify(result), 500
            
    except Exception as e:
        logger.error(f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'error': f'ì±—ë´‡ ì˜¤ë¥˜: {str(e)}',
            'success': False
        }), 500

def classify_user_intent(user_message):
    """
    ì‚¬ìš©ì ìš”ì²­ì˜ ì˜ë„ë¥¼ Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
    
    Returns:
        dict: {
            'intent': ìš”ì²­ ìœ í˜•,
            'parameters': ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°,
            'confidence': ì‹ ë¢°ë„
        }
    """
    try:
        logger.info(f"ğŸ” ì‚¬ìš©ì ìš”ì²­ ë¶„ì„: {user_message[:100]}...")
        
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì´ë©”ì¼ ì±—ë´‡ ìš”ì²­ì…ë‹ˆë‹¤. ìš”ì²­ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì‚¬ìš©ì ìš”ì²­:**
{user_message}

**ê°€ëŠ¥í•œ ìš”ì²­ ìœ í˜•:**
1. **regenerate_with_sales_change**: íŒë§¤ ìƒí’ˆì„ ë³€ê²½í•´ì„œ ë©”ì¼ ì¬ìƒì„±
   - ì˜ˆ: "OPIë¡œ ë‹¤ì‹œ ì¨ì¤˜", "ì¬ë¬´ìë™í™” ì œí’ˆìœ¼ë¡œ ë°”ê¿”ì¤˜", "recon ìƒí’ˆìœ¼ë¡œ ë³€ê²½", "prismìœ¼ë¡œ ì†Œê°œí•´ì¤˜"
   - íŒŒë¼ë¯¸í„°: sales_point (opi, recon, prism, ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê° ì¤‘ í•˜ë‚˜)

2. **change_tone**: í†¤ì´ë‚˜ ìŠ¤íƒ€ì¼ ë³€ê²½
   - ì˜ˆ: "ë” ì¹œê·¼í•˜ê²Œ", "ì „ë¬¸ì ìœ¼ë¡œ", "ìºì£¼ì–¼í•˜ê²Œ", "ê³µì†í•˜ê²Œ"
   - íŒŒë¼ë¯¸í„°: tone (casual, professional, friendly, formal)

3. **refine_content**: íŠ¹ì • ë¶€ë¶„ ê°œì„ 
   - ì˜ˆ: "ì œëª©ì„ ë” ì„íŒ©íŠ¸ìˆê²Œ", "ë³¸ë¬¸ ì§§ê²Œ", "ìˆ˜ì¹˜ ê°•ì¡°í•´ì¤˜"
   - íŒŒë¼ë¯¸í„°: refinement_request (êµ¬ì²´ì  ìš”ì²­ì‚¬í•­)

4. **persuasive_reply**: ê³ ê° ë°˜ë°•/ë¶€ì • ë‹µë³€ì— ëŒ€í•œ ì¬ì„¤ë“
   - ì˜ˆ: "ë¹„ìš©ì´ ë¶€ë‹´ëœë‹¤ê³  í–ˆì–´", "ì§€ê¸ˆì€ ë°”ë¹ ì„œ ì–´ë µëŒ€"
   - íŒŒë¼ë¯¸í„°: customer_response (ê³ ê° ë‹µë³€)

5. **question**: ì¼ë°˜ ì§ˆë¬¸ì´ë‚˜ ì •ë³´ ìš”ì²­
   - ì˜ˆ: "í¬íŠ¸ì›ì´ ë­ì•¼?", "OPIê°€ ë­”ì§€ ì„¤ëª…í•´ì¤˜"

6. **other**: ê¸°íƒ€ ìš”ì²­

**íšŒì‚¬ëª… ì¶”ì¶œ:**
- íšŒì‚¬ëª…ì´ ì–¸ê¸‰ë˜ë©´ ì¶”ì¶œ (ì˜ˆ: "í† ìŠ¤", "ì¿ íŒ¡", "ë„¤ì´ë²„" ë“±)

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:**
{{
  "intent": "ìš”ì²­ ìœ í˜• (ìœ„ 6ê°€ì§€ ì¤‘ í•˜ë‚˜)",
  "parameters": {{
    "sales_point": "opi/recon/prism/ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°/null",
    "tone": "í†¤ ì„¤ëª… ë˜ëŠ” null",
    "refinement_request": "ê°œì„  ìš”ì²­ì‚¬í•­ ë˜ëŠ” null",
    "customer_response": "ê³ ê° ë‹µë³€ ë˜ëŠ” null",
    "company_name": "íšŒì‚¬ëª… ë˜ëŠ” null"
  }},
  "confidence": 0.0-1.0,
  "reasoning": "íŒë‹¨ ê·¼ê±° ê°„ë‹¨íˆ"
}}
"""

        model = genai.GenerativeModel('gemini-3-pro-preview')
        response = model.generate_content(prompt)
        
        if not response or not response.text:
            raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # JSON íŒŒì‹±
        import re
        response_text = response.text.strip()
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        elif '{' in response_text and '}' in response_text:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text
        
        intent_data = json.loads(json_str)
        
        logger.info(f"âœ… ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent_data.get('intent')} (ì‹ ë¢°ë„: {intent_data.get('confidence')})")
        logger.info(f"   ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°: {intent_data.get('parameters')}")
        
        return intent_data
        
    except Exception as e:
        logger.error(f"ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        # Fallback: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­
        return fallback_intent_classification(user_message)

def fallback_intent_classification(user_message):
    """
    Gemini ì‹¤íŒ¨ ì‹œ í´ë°±: ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
    """
    message_lower = user_message.lower()
    
    # sales_point ë³€ê²½ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['opi', 'one payment infra', 'ê²°ì œ ì¸í”„ë¼']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'opi', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['recon', 'ì¬ë¬´ìë™í™”', 'ì¬ë¬´ ìë™í™”', 'ì •ì‚°']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'recon', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['prism', 'í”„ë¦¬ì¦˜', 'ì˜¤í”ˆë§ˆì¼“', 'ë©€í‹°ì±„ë„', 'ë‹¤ì¤‘ì±„ë„', 'ì •ì‚° í†µí•©', 'ì¿ íŒ¡', '11ë²ˆê°€']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'prism', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['ì¸ì•±ìˆ˜ìˆ˜ë£Œ', 'ê²Œì„', 'd2c', 'ì›¹ìƒì ']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # í†¤ ë³€ê²½ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ì¹œê·¼', 'ìºì£¼ì–¼', 'ë¶€ë“œëŸ½', 'í¸í•˜ê²Œ']):
        return {
            'intent': 'change_tone',
            'parameters': {'tone': 'friendly', 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['ì „ë¬¸ì ', 'í”„ë¡œí˜ì…”ë„', 'ê³µì‹ì ']):
        return {
            'intent': 'change_tone',
            'parameters': {'tone': 'professional', 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ì¬ì„¤ë“ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ë¹„ìš©', 'ë¶€ë‹´', 'ë°”ë¹ ', 'ê±°ì ˆ', 'ì•ˆëœë‹¤', 'ì–´ë µë‹¤']):
        return {
            'intent': 'persuasive_reply',
            'parameters': {'customer_response': user_message, 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ê°œì„  ìš”ì²­ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ê°œì„ ', 'ìˆ˜ì •', 'ë°”ê¿”', 'ë‹¤ì‹œ', 'ë”', 'ì§§ê²Œ', 'ê¸¸ê²Œ']):
        return {
            'intent': 'refine_content',
            'parameters': {'refinement_request': user_message, 'company_name': None},
            'confidence': 0.5,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ê¸°ë³¸: ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜
    return {
        'intent': 'question',
        'parameters': {'company_name': None},
        'confidence': 0.3,
        'reasoning': 'Default fallback'
    }

@app.route('/api/smart-chat', methods=['POST'])
@login_required
def smart_chat():
    """
    í†µí•© ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ - ë‹¤ì–‘í•œ ì‚¬ìš©ì ìš”ì²­ì„ ì´í•´í•˜ê³  ì²˜ë¦¬
    
    ìš”ì²­ ìœ í˜•:
    - ë©”ì¼ ì¬ìƒì„± (sales_point ë³€ê²½)
    - í†¤/ìŠ¤íƒ€ì¼ ë³€ê²½
    - ë¬¸ì•ˆ ê°œì„ 
    - ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
    - ì¼ë°˜ ì§ˆë¬¸
    """
    try:
        data = request.json
        user_message = data.get('message', '')
        session_data = data.get('session_data', {})  # ì´ì „ ìƒì„± ê²°ê³¼ ë“±
        
        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
        
        logger.info(f"ğŸ’¬ ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ ìš”ì²­: {user_message[:100]}...")
        
        # 1ë‹¨ê³„: ì‚¬ìš©ì ì˜ë„ íŒŒì•…
        intent_result = classify_user_intent(user_message)
        intent = intent_result.get('intent')
        params = intent_result.get('parameters', {})
        
        logger.info(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼: {intent} (ì‹ ë¢°ë„: {intent_result.get('confidence')})")
        
        # 2ë‹¨ê³„: ì˜ë„ì— ë”°ë¼ ì²˜ë¦¬
        if intent == 'regenerate_with_sales_change':
            # íŒë§¤ ìƒí’ˆ ë³€ê²½í•´ì„œ ë©”ì¼ ì¬ìƒì„±
            sales_point = params.get('sales_point')
            company_data = session_data.get('company_data', {})
            
            if not company_data:
                return jsonify({
                    'success': False,
                    'error': 'ì´ì „ ìƒì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë©”ì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.',
                    'intent': intent
                }), 400
            
            # sales_item í•„ë“œ ì—…ë°ì´íŠ¸ (CSVì˜ sales_item ì»¬ëŸ¼)
            company_data['sales_item'] = sales_point
            logger.info(f"ğŸ”„ íŒë§¤ ìƒí’ˆ ë³€ê²½: {sales_point} (company_data['sales_item'] ì—…ë°ì´íŠ¸)")
            
            # ë©”ì¼ ì¬ìƒì„±
            # ê¸°ì¡´ research_data ì¬ì‚¬ìš©
            research_data = session_data.get('research_data', {})
            
            result = generate_email_with_gemini(company_data, research_data)
            
            # ì œí’ˆëª… í‘œì‹œ ê°œì„ 
            product_name_map = {
                'opi': 'OPI (One Payment Infra)',
                'recon': 'Recon (ì¬ë¬´ìë™í™”)',
                'prism': 'Prism (ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©)',
                'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°': 'ê²Œì„ ì›¹ìƒì  (ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°)'
            }
            product_display_name = product_name_map.get(sales_point, sales_point.upper())
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': f'âœ… {product_display_name} ì œí’ˆìœ¼ë¡œ ë©”ì¼ì„ ì¬ìƒì„±í–ˆìŠµë‹ˆë‹¤!',
                'result': result,
                'sales_point': sales_point
            })
        
        elif intent == 'change_tone':
            # í†¤ ë³€ê²½
            tone = params.get('tone', '')
            current_email = session_data.get('current_email', {})
            
            if not current_email:
                return jsonify({
                    'success': False,
                    'error': 'ë³€ê²½í•  ì´ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            # í†¤ ë³€ê²½ ìš”ì²­ ìƒì„±
            refinement_request = f"ì´ë©”ì¼ì˜ í†¤ì„ {tone}ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”. ë‚´ìš©ì€ ìœ ì§€í•˜ë˜ í†¤ë§Œ ì¡°ì •í•©ë‹ˆë‹¤."
            
            # refine_email_with_user_request ì‚¬ìš©
            company_data = session_data.get('company_data', {})
            refined = refine_email_with_user_request(
                original_subject=current_email.get('subject', ''),
                original_body=current_email.get('body', ''),
                user_request=refinement_request,
                company_data=company_data
            )
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': f'âœ… í†¤ì„ {tone}ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤!',
                'result': refined
            })
        
        elif intent == 'refine_content':
            # ë¬¸ì•ˆ ê°œì„ 
            refinement_request = params.get('refinement_request', user_message)
            current_email = session_data.get('current_email', {})
            
            if not current_email:
                return jsonify({
                    'success': False,
                    'error': 'ê°œì„ í•  ì´ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            company_data = session_data.get('company_data', {})
            refined = refine_email_with_user_request(
                original_subject=current_email.get('subject', ''),
                original_body=current_email.get('body', ''),
                user_request=refinement_request,
                company_data=company_data
            )
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': 'âœ… ì´ë©”ì¼ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤!',
                'result': refined
            })
        
        elif intent == 'persuasive_reply':
            # ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
            company_name = params.get('company_name', session_data.get('company_data', {}).get('íšŒì‚¬ëª…', ''))
            customer_response = params.get('customer_response', user_message)
            email_name = session_data.get('company_data', {}).get('ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìë‹˜')
            
            if not company_name:
                return jsonify({
                    'success': False,
                    'error': 'íšŒì‚¬ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            # í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
            blog_content = get_blog_content_for_email()
            
            # ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
            from case_database import format_case_for_email
            selected_case_ids = ['development_resource_saving', 'payment_failure_recovery']
            case_details = "\n".join([format_case_for_email(case_id) for case_id in selected_case_ids])
            full_context = case_details + blog_content
            
            result = generate_persuasive_reply(
                context=customer_response,
                company_name=company_name,
                email_name=email_name,
                case_examples=full_context
            )
            
            # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
            if result.get('success') and result.get('email', {}).get('body'):
                user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
                result['email']['body'] = result['email']['body'].replace('ì˜¤ì¤€í˜¸', user_name)
            
            return jsonify({
                'success': result.get('success'),
                'intent': intent,
                'message': 'âœ… ì¬ì„¤ë“ ë©”ì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!' if result.get('success') else 'âŒ ìƒì„± ì‹¤íŒ¨',
                'result': result
            })
        
        elif intent == 'question':
            # ì¼ë°˜ ì§ˆë¬¸ - Geminië¡œ ë‹µë³€ ìƒì„±
            answer = answer_general_question(user_message)
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': answer,
                'result': {'answer': answer}
            })
        
        else:
            # ê¸°íƒ€ ìš”ì²­
            return jsonify({
                'success': False,
                'intent': intent,
                'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?',
                'confidence': intent_result.get('confidence')
            })
    
    except Exception as e:
        logger.error(f"ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'error': f'ì±—ë´‡ ì˜¤ë¥˜: {str(e)}',
            'success': False
        }), 500

def answer_general_question(question):
    """
    ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
    """
    try:
        prompt = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne)ì˜ ì œí’ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

**ì§ˆë¬¸:** {question}

**í¬íŠ¸ì› ì œí’ˆ ì •ë³´:**
- One Payment Infra (OPI): ê²°ì œ ì‹œìŠ¤í…œ í†µí•© ê´€ë¦¬, PGì‚¬ í†µí•©, 85% ë¦¬ì†ŒìŠ¤ ì ˆê°
- Recon (ì¬ë¬´ìë™í™”): ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ë§ˆê° ìë™í™”, ì •ì‚° ê´€ë¦¬
- Prism (ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©): ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° í”Œë«í¼ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ í•œ ëˆˆì— í†µí•©, ì¬ë¬´ ë§ˆê° ì‹œê°„ 90% ë‹¨ì¶•
- ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°: ê²Œì„ ì›¹ìƒì  êµ¬ì¶•, ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ(30%) íšŒí”¼

**ë‹µë³€ í˜•ì‹:**
- ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ (3-5ë¬¸ì¥)
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì˜ˆì‹œ í¬í•¨
- ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤

ë‹µë³€ë§Œ ì‘ì„±í•˜ì„¸ìš” (ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ì •ë³´ ì—†ì´):
"""
        
        model = genai.GenerativeModel('gemini-3-pro-preview')
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text.strip()
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route('/api/scrape-blog-initial', methods=['POST'])
def scrape_blog_initial():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘
    - OPI (êµ­ë‚´ ê²°ì œ): 5í˜ì´ì§€
    - Recon (ë§¤ì¶œ ë§ˆê°): 1í˜ì´ì§€
    """
    try:
        logger.info("ğŸš€ ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ìš”ì²­")
        
        blog_posts = scrape_portone_blog_initial()
        
        if blog_posts:
            return jsonify({
                'success': True,
                'message': f'ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ',
                'posts_count': len(blog_posts),
                'categories': {
                    'OPI': len([p for p in blog_posts if p.get('category') == 'OPI']),
                    'Recon': len([p for p in blog_posts if p.get('category') == 'Recon'])
                },
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨'
            }), 500
            
    except Exception as e:
        logger.error(f"ì´ˆê¸° ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/update-blog', methods=['POST'])
def update_blog():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸
    
    OPIì™€ Recon ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì—…ë°ì´íŠ¸
    """
    try:
        logger.info("ğŸ”„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ìš”ì²­")
        
        blog_posts = scrape_portone_blog_initial()
        
        if blog_posts:
            return jsonify({
                'success': True,
                'message': f'ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸ ì™„ë£Œ',
                'posts_count': len(blog_posts),
                'categories': {
                    'OPI': len([p for p in blog_posts if p.get('category') == 'OPI']),
                    'Recon': len([p for p in blog_posts if p.get('category') == 'Recon'])
                },
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨'
            }), 500
            
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/blog-cache-status', methods=['GET'])
def blog_cache_status():
    """
    ë¸”ë¡œê·¸ ìºì‹œ ìƒíƒœ í™•ì¸
    """
    try:
        from portone_blog_cache import load_blog_cache, get_blog_cache_age
        
        cached_posts = load_blog_cache()
        cache_age = get_blog_cache_age()
        
        return jsonify({
            'success': True,
            'has_cache': cached_posts is not None,
            'posts_count': len(cached_posts) if cached_posts else 0,
            'cache_age_hours': cache_age if cache_age else None,
            'cache_status': 'fresh' if cache_age and cache_age < 24 else 'stale' if cache_age else 'no_cache',
            'posts': cached_posts[:3] if cached_posts else [],  # ìµœê·¼ 3ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ìºì‹œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'service': 'email-generation',
        'timestamp': datetime.now().isoformat()
    })

# ë‰´ìŠ¤ ë¶„ì„ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ë¨¼ì € ì •ì˜
def is_valid_url(url):
    """URL ìœ íš¨ì„± ê²€ì‚¬"""
    import re
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pattern.match(url) is not None

def extract_content_from_soup(soup, url):
    """BeautifulSoup ê°ì²´ì—ì„œ ì œëª©ê³¼ ë³¸ë¬¸ ì¶”ì¶œ"""
    # í•œêµ­ ì£¼ìš” ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë³„ íŠ¹í™” ì„ íƒì
    site_specific_selectors = {
        'naver.com': {
            'title': ['h2#title', 'h3.tts_head', '.media_end_head_headline'],
            'content': ['#dic_area', '.go_trans._article_content', '#articleBodyContents']
        },
        'daum.net': {
            'title': ['.tit_view', '.txt_tit'],
            'content': ['.article_view', '.news_view']
        },
        'chosun.com': {
            'title': ['h1', 'title', '.article-header h1', '.news_title_text', '[property="og:title"]'],
            'content': ['#fusion-app article', '.story-news__article', '[data-type="article-body"]', '.par', '.news_text', 'article p', '.article-body']
        },
        'joins.com': {
            'title': ['.headline', '.article_title'],
            'content': ['#article_body', '.article_content']
        },
        'donga.com': {
            'title': ['.title', '.news_title'],
            'content': ['.news_view', '.article_txt']
        }
    }
    
    # ì¼ë°˜ì ì¸ ì„ íƒì (ëª¨ë“  ì‚¬ì´íŠ¸ ëŒ€ì‘)
    general_selectors = {
        'title': [
            'h1', 'h2', '.title', '.headline', '.article-title', '.news-title',
            '.post-title', '.entry-title', '[data-cy="article-headline"]',
            '.tit_view', '.news_ttl', '.article_head', '.news_headline'
        ],
        'content': [
            'article', '.article-content', '.news-content', '.post-content',
            '.entry-content', '.content', '#content', '.article-body',
            '.news-body', '.post-body', '.story-body', '.article-text',
            '[data-module="ArticleContent"]', '.article_body', '.news_content',
            '.view_txt', '.news_view', '.article_txt', '.par', '#newsContent'
        ]
    }
    
    title = ''
    content = ''
    
    # ì‚¬ì´íŠ¸ë³„ íŠ¹í™” ì„ íƒì ì‹œë„
    domain = url.lower()
    site_selectors = None
    for site, selectors in site_specific_selectors.items():
        if site in domain:
            site_selectors = selectors
            break
    
    # ì œëª© ì¶”ì¶œ - ë¨¼ì € meta íƒœê·¸ì—ì„œ ì‹œë„
    try:
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            title = og_title.get('content').strip()
            logger.info(f"OG íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ ì„±ê³µ: {title[:50]}...")
    except Exception as e:
        logger.debug(f"OG íƒœê·¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    # meta íƒœê·¸ì—ì„œ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ì„ íƒì ì‹œë„
    if not title:
        title_selectors = site_selectors['title'] if site_selectors else general_selectors['title']
        for selector in title_selectors:
            try:
                title_elem = soup.select_one(selector)
                if title_elem:
                    title = title_elem.get_text().strip()
                    if len(title) > 5:  # ì˜ë¯¸ìˆëŠ” ì œëª©ì¸ì§€ í™•ì¸
                        logger.info(f"ì œëª© ì¶”ì¶œ ì„±ê³µ: {title[:50]}...")
                        break
            except Exception as e:
                logger.debug(f"ì œëª© ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                continue
    
    # ë³¸ë¬¸ ì¶”ì¶œ - ì¡°ì„ ì¼ë³´ JSON ë°ì´í„°ì—ì„œ ë¨¼ì € ì‹œë„
    if 'chosun.com' in url.lower():
        try:
            # script íƒœê·¸ì—ì„œ Fusion.globalContent ì°¾ê¸°
            scripts = soup.find_all('script', id='fusion-metadata')
            for script in scripts:
                script_text = script.string
                if script_text and 'Fusion.globalContent' in script_text:
                    # JSON íŒŒì‹±
                    import json
                    import re
                    
                    # globalContent JSON ì¶”ì¶œ
                    match = re.search(r'Fusion\.globalContent=({.*?});', script_text, re.DOTALL)
                    if match:
                        json_str = match.group(1)
                        data = json.loads(json_str)
                        
                        # content_elementsì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ
                        if 'content_elements' in data:
                            content_parts = []
                            for elem in data['content_elements']:
                                if elem.get('type') == 'text' and elem.get('content'):
                                    content_parts.append(elem['content'])
                            
                            if content_parts:
                                content = ' '.join(content_parts)
                                logger.info(f"ì¡°ì„ ì¼ë³´ JSONì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ: {len(content)}ì")
        except Exception as e:
            logger.debug(f"ì¡°ì„ ì¼ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì„ íƒìë¡œ ì‹œë„
    if not content or len(content) < 300:
        content_selectors = site_selectors['content'] if site_selectors else general_selectors['content']
        for selector in content_selectors:
            try:
                content_elem = soup.select_one(selector)
                if content_elem:
                    # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±° (ë” í¬ê´„ì )
                    unwanted_selectors = [
                        'script', 'style', 'nav', 'header', 'footer', 'aside',
                        '.ad', '.advertisement', '.social-share', '.related-articles',
                        '.comment', '.reply', '.share', '.tag', '.category',
                        '.author', '.date', '.source', '.copyright', '.ad_area',
                        '.related_news', '.more_news', '.sns_area', '.util_area'
                    ]
                    
                    for unwanted_selector in unwanted_selectors:
                        for unwanted in content_elem.select(unwanted_selector):
                            unwanted.decompose()
                    
                    content = content_elem.get_text().strip()
                    content = ' '.join(content.split())  # ê³µë°± ì •ë¦¬
                    
                    if len(content) > 300:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
                        logger.info(f"ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ: {len(content)}ì (ì„ íƒì: {selector})")
                        break
            except Exception as e:
                logger.debug(f"ë³¸ë¬¸ ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                continue
    
    # ë³¸ë¬¸ì´ ì—¬ì „íˆ ì§§ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
    if len(content) < 300:
        logger.warning("ë³¸ë¬¸ì´ ì§§ì•„ì„œ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„")
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for unwanted_tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
            unwanted_tag.decompose()
        
        # ëª¨ë“  p íƒœê·¸ ë‚´ìš© ìˆ˜ì§‘
        paragraphs = soup.find_all('p')
        if paragraphs:
            content = ' '.join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 20])
        
        # ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸
        if len(content) < 300:
            content = soup.get_text()
            content = ' '.join(content.split())
    
    # ìµœì¢… ê²€ì¦
    if not title:
        # ë©”íƒ€ íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ ì‹œë„
        meta_title = soup.find('meta', property='og:title')
        if meta_title:
            title = meta_title.get('content', '').strip()
        else:
            title_tag = soup.find('title')
            if title_tag:
                title = title_tag.get_text().strip()
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê¸¸ì´ ì œí•œ
    content = content.replace('\n', ' ').replace('\t', ' ')
    content = ' '.join(content.split())  # ì¤‘ë³µ ê³µë°± ì œê±°
    
    logger.info(f"BeautifulSoup ìŠ¤í¬ë˜í•‘ ê²°ê³¼ - ì œëª©: {len(title)}ì, ë³¸ë¬¸: {len(content)}ì")
    
    return title, content

def scrape_news_article(url):
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš© ìŠ¤í¬ë˜í•‘ (Selenium í¬í•¨ ê°•í™”ëœ ë²„ì „)"""
    try:
        logger.info(f"ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {url}")
        
        # ë¨¼ì € ì¼ë°˜ requestsë¡œ ì‹œë„
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ ì‹œë„
        title, content = extract_content_from_soup(soup, url)
        
        # ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ Selenium ì‹œë„ (ì¡°ì„ ì¼ë³´ ë“± JavaScript ì‚¬ì´íŠ¸)
        if (not title or len(content) < 200) and ('chosun.com' in url or 'joins.com' in url):
            logger.info("ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, Seleniumìœ¼ë¡œ ì¬ì‹œë„")
            title, content = scrape_with_selenium(url)
        
        if not title and len(content) < 100:
            logger.error("ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: ì œëª©ê³¼ ë³¸ë¬¸ ëª¨ë‘ ë¶€ì¡±")
            return None
            
        return {
            'title': title or 'ì œëª© ì—†ìŒ',
            'content': content[:3000],  # ìµœëŒ€ 3000ìë¡œ í™•ì¥
            'url': url,
            'scraped_length': len(content)
        }
        
    except requests.exceptions.RequestException as e:
        logger.error(f"HTTP ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return None

def scrape_with_selenium(url):
    """Seleniumì„ ì‚¬ìš©í•œ ë™ì  ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        import time
        
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        time.sleep(3)
        
        # ì¡°ì„ ì¼ë³´ íŠ¹í™” ì„ íƒì
        if 'chosun.com' in url:
            try:
                # ì œëª© ëŒ€ê¸° ë° ì¶”ì¶œ
                title_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1, .article-header h1, .news_title_text"))
                )
                title = title_element.text.strip()
                
                # ë³¸ë¬¸ ì¶”ì¶œ
                content_selectors = [
                    ".story-news__article",
                    ".article-body", 
                    ".news-article-memo",
                    "[data-type='article-body']",
                    ".par"
                ]
                
                content = ""
                for selector in content_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            content = " ".join([elem.text.strip() for elem in elements])
                            if len(content) > 200:
                                break
                    except:
                        continue
                
                # ì—¬ì „íˆ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ ëª¨ë“  p íƒœê·¸ ìˆ˜ì§‘
                if len(content) < 200:
                    p_elements = driver.find_elements(By.TAG_NAME, "p")
                    content = " ".join([p.text.strip() for p in p_elements if len(p.text.strip()) > 20])
                
            except Exception as e:
                logger.warning(f"Selenium ì¡°ì„ ì¼ë³´ íŠ¹í™” ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                # ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ í´ë°±
                title = driver.find_element(By.TAG_NAME, "h1").text.strip() if driver.find_elements(By.TAG_NAME, "h1") else ""
                content = driver.find_element(By.TAG_NAME, "body").text.strip()
        
        driver.quit()
        
        logger.info(f"Selenium ìŠ¤í¬ë˜í•‘ ì„±ê³µ - ì œëª©: {len(title)}ì, ë³¸ë¬¸: {len(content)}ì")
        return title, content
        
    except ImportError:
        logger.warning("Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install selenium ì‹¤í–‰ í•„ìš”")
        return "", ""
    except Exception as e:
        logger.error(f"Selenium ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return "", ""

def check_article_relevance(article_content, company_name):
    """ê¸°ì‚¬ ë‚´ìš©ê³¼ PortOne ì†”ë£¨ì…˜ì˜ ê´€ë ¨ì„± ê²€ì¦"""
    try:
        title = article_content.get('title', '')
        content = article_content.get('content', '')
        
        # PortOne ê´€ë ¨ í‚¤ì›Œë“œë“¤
        portone_keywords = [
            'ê²°ì œ', 'í˜ì´ë¨¼íŠ¸', 'í•€í…Œí¬', 'ì´ì»¤ë¨¸ìŠ¤', 'ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸ì‡¼í•‘', 
            'ì •ì‚°', 'ìˆ˜ìˆ˜ë£Œ', 'ë§¤ì¶œ', 'ìˆ˜ìµ', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ìŠ¤íƒ€íŠ¸ì—…', 'ê¸°ì—…',
            'ë””ì§€í„¸', 'í”Œë«í¼', 'ì„œë¹„ìŠ¤', 'ì‹œìŠ¤í…œ', 'ì¸í”„ë¼', 'ì†”ë£¨ì…˜',
            'ê¸€ë¡œë²Œ', 'í•´ì™¸ì§„ì¶œ', 'í™•ì¥', 'ì„±ì¥', 'íˆ¬ì', 'ìê¸ˆì¡°ë‹¬'
        ]
        
        # ê´€ë ¨ì„± ì—†ëŠ” í‚¤ì›Œë“œë“¤ (ê°ì  ìš”ì†Œ)
        irrelevant_keywords = [
            'ì—°ì˜ˆ', 'ë°©ì†¡', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ìŒì•…', 'ê²Œì„ì½˜í…ì¸ ', 'ì›¹íˆ°',
            'ìŠ¤í¬ì¸ ', 'ì •ì¹˜', 'ì‚¬íšŒ', 'ë¬¸í™”', 'ì˜ˆìˆ ', 'ì—¬í–‰', 'ìŒì‹'
        ]
        
        text = (title + ' ' + content).lower()
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        relevant_count = sum(1 for keyword in portone_keywords if keyword in text)
        irrelevant_count = sum(1 for keyword in irrelevant_keywords if keyword in text)
        
        # ê¸°ë³¸ ì ìˆ˜ 5ì ì—ì„œ ì‹œì‘
        score = 5
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì  (ìµœëŒ€ 4ì )
        score += min(4, relevant_count * 0.5)
        
        # ë¹„ê´€ë ¨ í‚¤ì›Œë“œ ê°ì  (ìµœëŒ€ -3ì )
        score -= min(3, irrelevant_count * 1)
        
        # íšŒì‚¬ëª…ì´ ê¸°ì‚¬ì— ì§ì ‘ ì–¸ê¸‰ë˜ë©´ ê°€ì 
        if company_name.lower() in text:
            score += 2
        
        # 0-10 ë²”ìœ„ë¡œ ì œí•œ
        score = max(0, min(10, score))
        
        return round(score, 1)
        
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ê´€ë ¨ì„± ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return 5.0  # ê¸°ë³¸ê°’

def get_existing_company_info(company_name):
    """ê¸°ì¡´ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ ì¡°íšŒ"""
    try:
        # ë©”ëª¨ë¦¬ì—ì„œ íšŒì‚¬ ì •ë³´ ê²€ìƒ‰ (ê°„ë‹¨í•œ ìºì‹œ êµ¬í˜„)
        if hasattr(get_existing_company_info, 'cache'):
            if company_name in get_existing_company_info.cache:
                logger.info(f"ìºì‹œì—ì„œ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
                return get_existing_company_info.cache[company_name]
        
        # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ (ìµœê·¼ ì¡°ì‚¬ ê²°ê³¼)
        import os
        import json
        from datetime import datetime, timedelta
        
        cache_dir = "/tmp/company_cache"
        if not os.path.exists(cache_dir):
            return None
            
        cache_file = os.path.join(cache_dir, f"{company_name.replace(' ', '_')}.json")
        
        if os.path.exists(cache_file):
            # íŒŒì¼ì´ 24ì‹œê°„ ì´ë‚´ì— ìƒì„±ëœ ê²½ìš°ë§Œ ì‚¬ìš©
            file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_time < timedelta(hours=24):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    company_info = json.load(f)
                    logger.info(f"íŒŒì¼ ìºì‹œì—ì„œ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
                    return company_info
        
        return None
        
    except Exception as e:
        logger.error(f"ê¸°ì¡´ íšŒì‚¬ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None

def save_company_info_cache(company_name, company_info):
    """íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥"""
    try:
        import os
        import json
        
        # ë©”ëª¨ë¦¬ ìºì‹œ
        if not hasattr(get_existing_company_info, 'cache'):
            get_existing_company_info.cache = {}
        get_existing_company_info.cache[company_name] = company_info
        
        # íŒŒì¼ ìºì‹œ
        cache_dir = "/tmp/company_cache"
        os.makedirs(cache_dir, exist_ok=True)
        
        cache_file = os.path.join(cache_dir, f"{company_name.replace(' ', '_')}.json")
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(company_info, f, ensure_ascii=False, indent=2)
            
        logger.info(f"íšŒì‚¬ ì •ë³´ ìºì‹œ ì €ì¥: {company_name}")
        
    except Exception as e:
        logger.error(f"íšŒì‚¬ ì •ë³´ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

def generate_email_from_news_analysis(article_content, company_name, current_email, news_url, company_info=None, relevance_score=5.0):
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ì„ í†µí•œ í˜ì¸ í¬ì¸íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±"""
    try:
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            logger.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return generate_fallback_news_email(article_content, company_name, current_email, news_url)
        
        # íšŒì‚¬ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        company_context = ""
        if company_info:
            company_context = f"""
**íšŒì‚¬ ì •ë³´ (ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼):**
- íšŒì‚¬ëª…: {company_info.get('company_name', company_name)}
- ì—…ì¢…: {company_info.get('industry', 'ì •ë³´ ì—†ìŒ')}
- ì£¼ìš” ì‚¬ì—…: {company_info.get('business_description', 'ì •ë³´ ì—†ìŒ')}
- ê·œëª¨: {company_info.get('company_size', 'ì •ë³´ ì—†ìŒ')}
- íŠ¹ì´ì‚¬í•­: {company_info.get('special_notes', 'ì •ë³´ ì—†ìŒ')}
"""
        
        # Perplexityë¥¼ í†µí•œ ì¶”ê°€ ë¶„ì„ (ì„ íƒì )
        additional_context = ""
        try:
            perplexity_analysis = analyze_news_with_perplexity(article_content, company_name)
            if perplexity_analysis:
                additional_context = f"\n\n**Perplexity ì¶”ê°€ ë¶„ì„:**\n{perplexity_analysis}"
        except Exception as e:
            logger.warning(f"Perplexity ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ê´€ë ¨ì„±ì— ë”°ë¥¸ ì ‘ê·¼ ë°©ì‹ ê²°ì •
        if relevance_score < 4.0:
            approach_instruction = """
**âš ï¸ ë‚®ì€ ê´€ë ¨ì„± ê¸°ì‚¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ê¸°ì‚¬ ë‚´ìš©ì„ ì–µì§€ë¡œ PortOne ì†”ë£¨ì…˜ê³¼ ì—°ê²°í•˜ì§€ ë§ˆì„¸ìš”
- ëŒ€ì‹  ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë Œë“œë‚˜ ì‹œì¥ ë³€í™” ê´€ì ì—ì„œ ì ‘ê·¼
- "ìµœê·¼ ì—…ê³„ ë™í–¥ì„ ë³´ë©´..." ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘
- PortOne ì†”ë£¨ì…˜ì€ ê°„ëµí•˜ê²Œ ì†Œê°œí•˜ê³  ìƒë‹´ ì œì•ˆì— ì§‘ì¤‘
"""
        else:
            approach_instruction = """
**âœ… ë†’ì€ ê´€ë ¨ì„± ê¸°ì‚¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ê¸°ì‚¬ ë‚´ìš©ê³¼ PortOne ì†”ë£¨ì…˜ì˜ ì—°ê´€ì„±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ê¸°ì‚¬ì—ì„œ ë„ì¶œí•œ Pain Pointë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì†”ë£¨ì…˜ ì œì•ˆ
- ìµœì‹ ì„±ê³¼ ì‹œê¸‰ì„±ì„ ê°•ì¡°í•˜ì—¬ ì„¤ë“ë ¥ ê°•í™”
"""
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ {company_name}ì—ê²Œ ë³´ë‚¼ ê°œì¸í™”ëœ ì˜ì—… ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ê¸°ì‚¬ ê´€ë ¨ì„± ì ìˆ˜: {relevance_score}/10**
{approach_instruction}

**ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´:**
- ì œëª©: {article_content.get('title', '')}
- URL: {news_url}
- ë‚´ìš©: {article_content.get('content', '')}
- ë¶„ì„ ì‹œì : 2025ë…„ 9ì›” 17ì¼
{additional_context}

**í˜„ì¬ ë©”ì¼ ë¬¸ì•ˆ (ì°¸ê³ ìš©):**
{current_email}
{company_context}

**ë©”ì¼ ì‘ì„± ì§€ì¹¨:**
1. **ê´€ë ¨ì„± ê¸°ë°˜ ì ‘ê·¼**: 
   - ê´€ë ¨ì„± ì ìˆ˜ê°€ 4ì  ë¯¸ë§Œì´ë©´ ì–µì§€ ì—°ê²° ê¸ˆì§€
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë Œë“œ ê´€ì ì—ì„œ ì ‘ê·¼
   - ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ êµ¬ì²´ì  ì—°ê´€ì„± ì œì‹œ

2. **íšŒì‚¬ ì •ë³´ í™œìš©**: 
   - ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œìš©
   - íšŒì‚¬ì˜ ì—…ì¢…, ê·œëª¨, íŠ¹ì„±ì— ë§ì¶˜ ê°œì¸í™”
   - ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ë©”ì¼ ì§€ì–‘

3. **Pain Point ì¤‘ì‹¬ êµ¬ì„±**: 
   - ì‹¤ì œ ì—…ê³„ ì´ìŠˆì—ì„œ ë„ì¶œí•œ êµ¬ì²´ì  ì–´ë ¤ì›€
   - "í˜¹ì‹œ ì´ëŸ° ë¬¸ì œë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?" ì‹ ê³µê° ì ‘ê·¼
   - ì–µì§€ìŠ¤ëŸ¬ìš´ ë¬¸ì œ ì œê¸° ê¸ˆì§€

4. **PortOne ì†”ë£¨ì…˜ ì œì•ˆ**:
   - OPI: 85% ë¦¬ì†ŒìŠ¤ ì ˆê°, 2ì£¼ êµ¬ì¶•
   - ì¬ë¬´ìë™í™”: 90% ì—…ë¬´ ì‹œê°„ ë‹¨ì¶•
   - ê²Œì„ ì›¹ìƒì : ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ í•´ê²°
   - ìŠ¤ë§ˆíŠ¸ë¹Œë§: ê¸€ë¡œë²Œ ê²°ì œ ì§€ì›

5. **ì´ë©”ì¼ êµ¬ì¡°**:
   - ê°œì¸í™”ëœ ì¸ì‚¬ (30ë‹¨ì–´)
   - Pain Point ì œê¸° (60ë‹¨ì–´) 
   - í•´ê²°ì±… ì œì‹œ (80ë‹¨ì–´)
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸íŒ… ì œì•ˆ (30ë‹¨ì–´)

**ì£¼ì˜ì‚¬í•­:**
- ì´ 200-250ë‹¨ì–´ ë‚´ì™¸
- ì œëª© 7ë‹¨ì–´/41ì ì´ë‚´
- HTML íƒœê·¸ ì‚¬ìš© (<br>, <strong>, <em>)
- ê´€ë ¨ì„±ì´ ë‚®ìœ¼ë©´ ê¸°ì‚¬ ë‚´ìš© ìµœì†Œ ì–¸ê¸‰

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì œëª©: [ê°œì¸í™”ëœ ì œëª©]

[HTML í˜•ì‹ì˜ ë©”ì¼ ë³¸ë¬¸]
"""
        
        # Gemini API í˜¸ì¶œ
        import google.generativeai as genai
        genai.configure(api_key=gemini_api_key)
        
        model = genai.GenerativeModel('gemini-3-pro-preview')
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            logger.error("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return generate_fallback_news_email(article_content, company_name, current_email, news_url)
            
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ê¸°ë°˜ ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return generate_fallback_news_email(article_content, company_name, current_email, news_url)

def analyze_news_with_perplexity(article_content, company_name):
    """Perplexity AIë¥¼ í†µí•œ ë‰´ìŠ¤ ë¶„ì„ (ìµœì‹ ì„± ê°€ì¤‘ì¹˜ ì ìš©)"""
    try:
        perplexity_api_key = os.getenv('PERPLEXITY_API_KEY')
        if not perplexity_api_key:
            logger.warning("Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ìµœì‹ ì„± ê°•ì¡° í”„ë¡¬í”„íŠ¸
        current_date = "2025ë…„ 9ì›”"
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ {company_name}ê³¼ ê°™ì€ ê¸°ì—…ë“¤ì´ í˜„ì¬ ì§ë©´í•  ìˆ˜ ìˆëŠ” í˜ì¸ í¬ì¸íŠ¸ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ (ìµœì‹ ì„± ìš°ì„ ):**
- í˜„ì¬ ì‹œì : {current_date}
- ìµœì‹  ì—…ê³„ ë™í–¥ê³¼ íŠ¸ë Œë“œ ìš°ì„  ë¶„ì„
- ê¸´ê¸‰ì„±ê³¼ ì‹œê¸‰ì„±ì´ ë†’ì€ ì´ìŠˆ ì¤‘ì‹¬ ê²€í† 

**ë‰´ìŠ¤ ê¸°ì‚¬:**
ì œëª©: {article_content.get('title', '')}
ë‚´ìš©: {article_content.get('content', '')}

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
1. **ìµœì‹  ì—…ê³„ ë™í–¥ ë¶„ì„**: {current_date} ê¸°ì¤€ìœ¼ë¡œ ì´ ë‰´ìŠ¤ê°€ ì—…ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
2. **í˜„ì¬ ì§„í–‰í˜• í˜ì¸ í¬ì¸íŠ¸**: ì§€ê¸ˆ ì´ ìˆœê°„ ê¸°ì—…ë“¤ì´ ê²ªê³  ìˆëŠ” êµ¬ì²´ì ì¸ ì–´ë ¤ì›€
3. **ì‹œê¸‰í•œ ëŒ€ì‘ í•„ìš”ì„±**: ë¹ ë¥¸ ì‹œì¼ ë‚´ í•´ê²°í•´ì•¼ í•  ê³¼ì œë“¤
4. **ê²°ì œ/í•€í…Œí¬ ì—°ê´€ì„±**: ê²°ì œ ì‹œìŠ¤í…œ, ì¬ë¬´ ìë™í™”, ì»¤ë¨¸ìŠ¤ ê´€ë ¨ ì´ìŠˆ
5. **ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ**: í˜„ì¬ ìƒí™©ì—ì„œ ë¹ ë¥´ê²Œ í™œìš© ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ ë‹ˆì¦ˆ

**ì‘ë‹µ í˜•ì‹:**
- 300ë‹¨ì–´ ë‚´ì™¸
- ìµœì‹ ì„±ê³¼ ê¸´ê¸‰ì„± ì¤‘ì‹¬ì˜ ë¶„ì„
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- "í˜„ì¬", "ì§€ê¸ˆ", "ìµœê·¼", "2025ë…„ ë“¤ì–´" ë“±ì˜ ì‹œê°„ì  í‘œí˜„ í™œìš©
"""
        
        headers = {
            'Authorization': f'Bearer {perplexity_api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.1-sonar-large-128k-online',
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'max_tokens': 500,
            'temperature': 0.3
        }
        
        response = requests.post(
            'https://api.perplexity.ai/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        
        return None
        
    except Exception as e:
        logger.error(f"Perplexity ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return None

def generate_fallback_news_email(article_content, company_name, current_email, news_url):
    """API ì‹¤íŒ¨ ì‹œ í´ë°± ë‰´ìŠ¤ ê¸°ë°˜ ë©”ì¼ ìƒì„± (ìµœì‹ ì„± ê°•ì¡°)"""
    title = article_content.get('title', 'ìµœì‹  ì—…ê³„ ë™í–¥')
    current_date = "2025ë…„ 9ì›”"
    
    return f"""ì œëª©: {company_name} ìµœì‹  ì—…ê³„ ë™í–¥ ëŒ€ì‘ ë°©ì•ˆ

<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜.<br>
PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ë°©ê¸ˆ ì „ "<strong>{title}</strong>" ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë´¤ëŠ”ë°,<br>
{current_date} ë“¤ì–´ ì´ëŸ° ì—…ê³„ ë³€í™”ê°€ ê°€ì†í™”ë˜ê³  ìˆì–´<br>
{company_name}ì—ì„œë„ í˜„ì¬ ì´ëŸ° ê³ ë¯¼ì´ ìˆìœ¼ì‹¤ ê²ƒ ê°™ì•„ ì—°ë½ë“œë¦½ë‹ˆë‹¤.</p>

<p><strong>ì§€ê¸ˆ ì´ ì‹œì ì—ì„œ</strong> ë§ì€ ê¸°ì—…ë“¤ì´ ê²ªê³  ìˆëŠ” í˜„ì‹¤ì ì¸ ì–´ë ¤ì›€ë“¤:<br>
â€¢ ê¸‰ë³€í•˜ëŠ” ì‹œì¥ í™˜ê²½ì— ë¹ ë¥´ê²Œ ëŒ€ì‘í•´ì•¼ í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬ì¶• ì••ë°•<br>
â€¢ í˜„ì¬ ì§„í–‰í˜•ì¸ ê²°ì œ ì¸í”„ë¼ í˜„ëŒ€í™” ë° íš¨ìœ¨ì„± ê°œì„  í•„ìš”ì„±<br>
â€¢ ë‹¹ì¥ í•„ìš”í•œ ìš´ì˜ ë¹„ìš© ì ˆê°ê³¼ ì„œë¹„ìŠ¤ í’ˆì§ˆ í–¥ìƒì˜ ë”œë ˆë§ˆ</p>

<p><strong>PortOneì˜ One Payment Infra</strong>ë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:<br>
âœ… <strong>85% ë¦¬ì†ŒìŠ¤ ì ˆê°</strong> - ê°œë°œ ë° ìš´ì˜ ë¶€ë‹´ ëŒ€í­ ê°ì†Œ<br>
âœ… <strong>2ì£¼ ë‚´ êµ¬ì¶• ì™„ë£Œ</strong> - ì—…ê³„ ë³€í™” ì†ë„ì— ë§ì¶˜ ì‹ ì†í•œ ëŒ€ì‘<br>
âœ… <strong>100ë§Œì› ìƒë‹¹ ë¬´ë£Œ ì»¨ì„¤íŒ…</strong> - í˜„ì¬ ìƒí™© ë§ì¶¤ ì „ë¬¸ê°€ ë¶„ì„</p>

<p><strong>ì´ë²ˆ ì£¼ ì¤‘</strong> í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´<br>
{company_name}ì´ í˜„ì¬ ì§ë©´í•œ ê³¼ì œì— í¬íŠ¸ì›ì´<br>
ì–´ë–»ê²Œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ì§€ êµ¬ì²´ì ì¸ ë°©ì•ˆì„ ì œì•ˆí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>
{user_name} ë“œë¦¼</p>

<p><small>ì°¸ê³  ë‰´ìŠ¤ (9ì›” 17ì¼ í™•ì¸): <a href="{news_url}">{title}</a></small></p>"""

# ===== ì›¹ ì¸í„°í˜ì´ìŠ¤ ë¼ìš°íŠ¸ =====

@app.route('/')
@login_required
def index():
    """ë£¨íŠ¸ ê²½ë¡œ - index.html ì œê³µ (ì±—ë´‡ ìŠ¤íƒ€ì¼ UI) - ë¡œê·¸ì¸ í•„ìš”"""
    # ìºì‹œ ë²„ìŠ¤íŒ…ì„ ìœ„í•œ ë²„ì „ ë²ˆí˜¸ (í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„)
    import time
    cache_version = str(int(time.time()))
    return render_template('index.html', user=current_user, cache_version=cache_version)

@app.route('/script.js')
def serve_script():
    """script.js ì •ì  íŒŒì¼ ì œê³µ"""
    return send_from_directory('.', 'script.js')

@app.route('/api/send-email', methods=['POST'])
@login_required
def send_email():
    """
    ì´ë©”ì¼ ë°œì†¡ API
    ë¡œê·¸ì¸ëœ ì‚¬ìš©ìì˜ ì´ë©”ì¼ì„ ë°œì‹ ìë¡œ ì‚¬ìš©í•˜ê³ ,
    ì‚¬ìš©ìì˜ ì„œëª…ì„ ë³¸ë¬¸ ëì— ìë™ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    try:
        data = request.json
        to_email = data.get('to_email')
        to_name = data.get('to_name')
        subject = data.get('subject')
        body = data.get('body')
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if not all([to_email, subject, body]):
            return jsonify({
                'success': False,
                'error': 'í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 400
        
        # í˜„ì¬ ë¡œê·¸ì¸ëœ ì‚¬ìš©ì ì •ë³´
        from_email = current_user.email
        from_name = current_user.name
        user_signature = current_user.email_signature or ''  # ì„œëª… ê°€ì ¸ì˜¤ê¸°
        
        logger.info(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ìš”ì²­: {from_email} -> {to_email}")
        logger.info(f"   ì œëª©: {subject}")
        logger.info(f"   ë°›ëŠ” ì‚¬ëŒ: {to_name}")
        
        # ë³¸ë¬¸ì— ì„œëª… ì¶”ê°€
        if user_signature:
            # ì„œëª…ì˜ ìƒëŒ€ ê²½ë¡œ ì´ë¯¸ì§€ë¥¼ ì ˆëŒ€ URLë¡œ ë³€ê²½
            base_url = request.url_root.rstrip('/')  # http://example.com
            absolute_signature = user_signature.replace(
                'src="/static/',
                f'src="{base_url}/static/'
            )
            
            # HTML ì„œëª…ì„ ë³¸ë¬¸ ëì— ì¶”ê°€ (ì„œëª…ì— ì´ë¯¸ <br><br> í¬í•¨)
            full_body = f"{body}{absolute_signature}"
            logger.info("âœï¸  ì‚¬ìš©ì ì„œëª… ì¶”ê°€ë¨ (ì´ë¯¸ì§€ ì ˆëŒ€ URL ì ìš©)")
        else:
            full_body = body
            logger.warning("âš ï¸  ì‚¬ìš©ì ì„œëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # SendGrid APIë¥¼ ì‚¬ìš©í•œ ì´ë©”ì¼ ë°œì†¡ (Railway í™˜ê²½ í˜¸í™˜)
        sendgrid_api_key = current_user.get_sendgrid_api_key()
        
        if sendgrid_api_key:
            # SendGrid API ì‚¬ìš© (Railwayì—ì„œ SMTP í¬íŠ¸ê°€ ì°¨ë‹¨ë˜ë¯€ë¡œ HTTP API ì‚¬ìš©)
            try:
                import requests
                
                logger.info(f"ğŸ“§ SendGrid APIë¡œ ì´ë©”ì¼ ë°œì†¡ ì¤‘...")
                
                # SendGrid API ìš”ì²­
                response = requests.post(
                    'https://api.sendgrid.com/v3/mail/send',
                    headers={
                        'Authorization': f'Bearer {sendgrid_api_key}',
                        'Content-Type': 'application/json'
                    },
                    json={
                        'personalizations': [{
                            'to': [{'email': to_email, 'name': to_name}],
                            'bcc': [{'email': from_email}]  # ë°œì†¡ìë¥¼ BCCì— ì¶”ê°€í•˜ì—¬ Gmail ë³´ë‚¸í¸ì§€í•¨ì— ìë™ ì €ì¥
                        }],
                        'from': {
                            'email': from_email,
                            'name': from_name
                        },
                        'subject': subject,
                        'content': [{
                            'type': 'text/html',
                            'value': full_body
                        }]
                    },
                    timeout=30
                )
                
                if response.status_code == 202:
                    logger.info(f"âœ… SendGrid API ë°œì†¡ ì„±ê³µ: {to_email} (BCC: {from_email})")
                    return jsonify({
                        'success': True,
                        'message': 'ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤ (SendGrid API).\nğŸ“§ ë°œì†¡í•œ ë©”ì¼ì´ ë‚´ Gmail ë³´ë‚¸í¸ì§€í•¨ì—ë„ ì €ì¥ë©ë‹ˆë‹¤.',
                        'from': from_email,
                        'to': to_email,
                        'bcc': from_email,
                        'signature_included': bool(user_signature),
                        'method': 'SendGrid API'
                    })
                elif response.status_code == 401:
                    # API í‚¤ ì¸ì¦ ì‹¤íŒ¨
                    logger.error(f"âŒ SendGrid API ì¸ì¦ ì‹¤íŒ¨ (401): {response.text}")
                    return jsonify({
                        'success': False,
                        'error': 'âŒ SendGrid API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nì„¤ì • í˜ì´ì§€ì—ì„œ ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nğŸ’¡ SendGrid ëŒ€ì‹œë³´ë“œì—ì„œ API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•˜ì„¸ìš”.\n(Settings â†’ API Keys)'
                    }), 401
                elif response.status_code == 403:
                    # ë°œì‹ ì ì¸ì¦ ë˜ëŠ” API í‚¤ ê¶Œí•œ ë¬¸ì œ
                    logger.error(f"âŒ SendGrid API 403 ì˜¤ë¥˜: {response.text}")
                    error_text = response.text.lower()
                    
                    if 'verified sender identity' in error_text or 'sender identity' in error_text:
                        # ë°œì‹ ì ì¸ì¦ ë¬¸ì œ
                        return jsonify({
                            'success': False,
                            'error': f'''âŒ ë°œì‹ ì ì´ë©”ì¼ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤!

SendGridì—ì„œ "{from_email}" ì£¼ì†Œë¥¼ ì¸ì¦í•´ì£¼ì„¸ìš”.

ğŸ“ ì¸ì¦ ë°©ë²•:
1. https://app.sendgrid.com/ ë¡œê·¸ì¸
2. Settings â†’ Sender Authentication
3. "Verify a Single Sender" í´ë¦­
4. ë°œì‹ ì ì •ë³´ ì…ë ¥ (From Email: {from_email})
5. ì¸ì¦ ì´ë©”ì¼ í™•ì¸ í›„ Verify ë²„íŠ¼ í´ë¦­

âœ… ì¸ì¦ ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!'''
                        }), 403
                    else:
                        # ê¸°íƒ€ ê¶Œí•œ ë¬¸ì œ
                        return jsonify({
                            'success': False,
                            'error': 'âŒ SendGrid API í‚¤ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n\nAPI í‚¤ë¥¼ "Full Access" ê¶Œí•œìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.'
                        }), 403
                else:
                    logger.error(f"âŒ SendGrid API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                    return jsonify({
                        'success': False,
                        'error': f'SendGrid API ì˜¤ë¥˜ ({response.status_code}): {response.text}'
                    }), 500
                    
            except Exception as e:
                logger.error(f"âŒ SendGrid API ë°œì†¡ ì‹¤íŒ¨: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': f'SendGrid API ë°œì†¡ ì‹¤íŒ¨: {str(e)}'
                }), 500
        
        # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ë¡œ SMTP ì‹œë„ (ë¡œì»¬ í™˜ê²½ìš©)
        gmail_app_password = current_user.get_gmail_app_password()
        
        if gmail_app_password:
            # ì‹¤ì œ Gmail SMTP ë°œì†¡ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
            import smtplib
            from email.mime.text import MIMEText
            from email.mime.multipart import MIMEMultipart
            
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = f"{from_name} <{from_email}>"
            msg['To'] = to_email
            msg['Bcc'] = from_email  # ë°œì†¡ìë¥¼ BCCì— ì¶”ê°€í•˜ì—¬ Gmail ë³´ë‚¸í¸ì§€í•¨ì— ìë™ ì €ì¥
            
            # HTML ë³¸ë¬¸ ì¶”ê°€
            html_part = MIMEText(full_body, 'html', 'utf-8')
            msg.attach(html_part)
            
            # Railway í™˜ê²½ì—ì„œ ì—¬ëŸ¬ SMTP ë°©ë²• ì‹œë„
            smtp_methods = [
                # ë°©ë²• 1: SMTP_SSL (í¬íŠ¸ 465)
                {'name': 'SMTP_SSL 465', 'method': 'ssl', 'port': 465},
                # ë°©ë²• 2: SMTP with STARTTLS (í¬íŠ¸ 587)
                {'name': 'SMTP STARTTLS 587', 'method': 'starttls', 'port': 587},
            ]
            
            last_error = None
            for method_config in smtp_methods:
                try:
                    logger.info(f"ğŸ”„ {method_config['name']} ì‹œë„ ì¤‘...")
                    
                    if method_config['method'] == 'ssl':
                        # SSL ë°©ì‹ (í¬íŠ¸ 465)
                        with smtplib.SMTP_SSL('smtp.gmail.com', method_config['port'], timeout=30) as server:
                            server.login(from_email, gmail_app_password)
                            server.send_message(msg)
                    else:
                        # STARTTLS ë°©ì‹ (í¬íŠ¸ 587)
                        with smtplib.SMTP('smtp.gmail.com', method_config['port'], timeout=30) as server:
                            server.ehlo()
                            server.starttls()
                            server.ehlo()
                            server.login(from_email, gmail_app_password)
                            server.send_message(msg)
                    
                    logger.info(f"âœ… ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ ({method_config['name']}): {to_email} (BCC: {from_email})")
                    
                    return jsonify({
                        'success': True,
                        'message': f'ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤ ({method_config["name"]}).\nğŸ“§ ë°œì†¡í•œ ë©”ì¼ì´ ë‚´ Gmail ë³´ë‚¸í¸ì§€í•¨ì—ë„ ì €ì¥ë©ë‹ˆë‹¤.',
                        'from': from_email,
                        'to': to_email,
                        'bcc': from_email,
                        'signature_included': bool(user_signature),
                        'smtp_method': method_config['name']
                    })
                    
                except Exception as e:
                    last_error = str(e)
                    logger.warning(f"âš ï¸  {method_config['name']} ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
            logger.error(f"âŒ ëª¨ë“  SMTP ë°©ë²• ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
            return jsonify({
                'success': False,
                'error': f'ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: SMTP í¬íŠ¸ ì°¨ë‹¨ë¨.\n\nğŸ’¡ Railway í™˜ê²½ì—ì„œëŠ” SendGrid APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.\nê´€ë¦¬ìì—ê²Œ SENDGRID_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì„ ìš”ì²­í•˜ì„¸ìš”.'
            }), 500
        else:
            # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜
            logger.warning(f"âš ï¸  {from_email} ì‚¬ìš©ìì˜ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤")
            logger.info(f"ğŸ“§ [ì‹œë®¬ë ˆì´ì…˜] ë°œì†¡: {to_email}")
            logger.info(f"   ë³¸ë¬¸ ê¸¸ì´: {len(full_body)} ë¬¸ì")
            
            return jsonify({
                'success': False,
                'error': 'Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.',
                'from': from_email,
                'to': to_email,
                'signature_included': bool(user_signature)
            }), 400
        
    except Exception as e:
        logger.error(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


@app.route('/api/user/settings', methods=['GET', 'POST'])
@login_required
def user_settings():
    """
    ì‚¬ìš©ì ì„¤ì • API
    GET: í˜„ì¬ ì„¤ì • ì¡°íšŒ
    POST: ì„¤ì • ì—…ë°ì´íŠ¸ (Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ë“±)
    """
    if request.method == 'GET':
        return jsonify({
            'success': True,
            'user': {
                'email': current_user.email,
                'name': current_user.name,
                'name_en': current_user.name_en,
                'phone': current_user.phone,
                'has_gmail_password': bool(current_user.gmail_app_password),
                'has_sendgrid_api_key': bool(current_user.sendgrid_api_key),
                'has_signature': bool(current_user.email_signature)
            }
        })
    
    # POST - ì„¤ì • ì—…ë°ì´íŠ¸
    try:
        data = request.json
        gmail_password = data.get('gmail_app_password')
        sendgrid_key = data.get('sendgrid_api_key')
        
        updated = False
        messages = []
        
        if gmail_password:
            # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì—…ë°ì´íŠ¸
            current_user.set_gmail_app_password(gmail_password.replace(' ', ''))  # ê³µë°± ì œê±°
            updated = True
            messages.append('Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
            logger.info(f"âœ… {current_user.email} Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì„¤ì • ì™„ë£Œ")
        
        if sendgrid_key:
            # SendGrid API í‚¤ ì—…ë°ì´íŠ¸
            current_user.set_sendgrid_api_key(sendgrid_key.strip())
            updated = True
            messages.append('SendGrid API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
            logger.info(f"âœ… {current_user.email} SendGrid API í‚¤ ì„¤ì • ì™„ë£Œ")
        
        if updated:
            db.session.commit()
            return jsonify({
                'success': True,
                'message': ' '.join(messages)
            })
        
        return jsonify({
            'success': False,
            'error': 'ì—…ë°ì´íŠ¸í•  ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.'
        }), 400
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ì • ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': f'ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


@app.route('/api-docs')
def api_docs():
    """API ë¬¸ì„œ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>PortOne ì´ë©”ì¼ ìƒì„± API - ë¬¸ì„œ</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                max-width: 800px;
                margin: 50px auto;
                padding: 20px;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
            }
            .container {
                background: white;
                border-radius: 16px;
                padding: 40px;
                box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            }
            h1 { color: #4f46e5; margin-bottom: 10px; }
            h2 { color: #7c3aed; font-size: 1.5em; margin-top: 30px; }
            .info { background: #f0f9ff; padding: 15px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #4f46e5; }
            .endpoint { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; }
            .method { display: inline-block; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.9em; margin-right: 10px; }
            .post { background: #10b981; color: white; }
            .get { background: #3b82f6; color: white; }
            code { background: #f1f5f9; padding: 2px 6px; border-radius: 4px; font-family: 'Courier New', monospace; }
            .test-form { background: #f8f9fa; padding: 20px; border-radius: 8px; margin-top: 20px; }
            input, textarea { width: 100%; padding: 10px; margin: 10px 0; border: 1px solid #ddd; border-radius: 4px; font-size: 14px; }
            button { background: #4f46e5; color: white; padding: 12px 24px; border: none; border-radius: 8px; cursor: pointer; font-size: 16px; font-weight: bold; }
            button:hover { background: #4338ca; }
            .result { background: white; border: 2px solid #4f46e5; padding: 15px; border-radius: 8px; margin-top: 20px; white-space: pre-wrap; font-family: monospace; max-height: 400px; overflow-y: auto; }
            .status { display: inline-block; width: 10px; height: 10px; border-radius: 50%; margin-right: 5px; }
            .status.ok { background: #10b981; }
            .status.error { background: #ef4444; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš€ PortOne ì´ë©”ì¼ ìƒì„± API</h1>
            <p style="color: #64748b;">AI ê¸°ë°˜ ê°œì¸í™” ì´ë©”ì¼ ë¬¸ì•ˆ ìƒì„± ì„œë¹„ìŠ¤</p>
            
            <div class="info">
                <strong>âœ… ì„œë²„ ìƒíƒœ:</strong> <span class="status ok"></span> ì‹¤í–‰ ì¤‘ (í¬íŠ¸: 5001)
            </div>
            
            <h2>ğŸ“¡ ì‚¬ìš© ê°€ëŠ¥í•œ API ì—”ë“œí¬ì¸íŠ¸</h2>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/health</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/research-company</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">Perplexityë¡œ íšŒì‚¬ ì •ë³´ ì¡°ì‚¬</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/generate-email</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">Geminië¡œ ì´ë©”ì¼ ë¬¸ì•ˆ 4ê°œ ìƒì„±</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/refine-email</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ê¸°ì¡´ ì´ë©”ì¼ ë¬¸ì•ˆ ê°œì„  (URL í¬í•¨ ê°€ëŠ¥)</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/analyze-news</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ë‰´ìŠ¤ ê¸°ì‚¬ URL ë¶„ì„</p>
            </div>
            
            <h2>ğŸ§ª API í…ŒìŠ¤íŠ¸</h2>
            
            <div class="test-form">
                <h3>ì´ë©”ì¼ ê°œì„  í…ŒìŠ¤íŠ¸</h3>
                <label><strong>í˜„ì¬ ì´ë©”ì¼ ë³¸ë¬¸:</strong></label>
                <textarea id="currentEmail" rows="4" placeholder="ê°œì„ í•  ì´ë©”ì¼ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...">ì•ˆë…•í•˜ì„¸ìš”, ABC íšŒì‚¬ ë‹´ë‹¹ìë‹˜.

PortOneì˜ ê²°ì œ ì†”ë£¨ì…˜ì„ ì†Œê°œë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.</textarea>
                
                <label><strong>ê°œì„  ìš”ì²­ (URL í¬í•¨ ê°€ëŠ¥):</strong></label>
                <input type="text" id="refinementRequest" placeholder="ì˜ˆ: ë” ì¹œê·¼í•˜ê²Œ ë§Œë“¤ì–´ì¤˜ ë˜ëŠ” ë‰´ìŠ¤ URL">
                
                <button onclick="testRefine()">ğŸš€ AIë¡œ ê°œì„ í•˜ê¸°</button>
                
                <div id="result" style="display: none;"></div>
            </div>
            
            <div style="margin-top: 30px; padding: 20px; background: #fef3c7; border-radius: 8px; border-left: 4px solid #f59e0b;">
                <strong>ğŸ’¡ ì°¸ê³ :</strong> Google Apps Script ì—°ë™ì€ ë³„ë„ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                <br>Fì—´ì´ "claude ê°œì¸í™” ë©”ì¼"ì¸ ê²½ìš° ì´ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
            </div>
        </div>
        
        <script>
            async function testRefine() {
                const currentEmail = document.getElementById('currentEmail').value;
                const refinementRequest = document.getElementById('refinementRequest').value;
                
                if (!refinementRequest) {
                    alert('ê°œì„  ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!');
                    return;
                }
                
                const resultDiv = document.getElementById('result');
                resultDiv.style.display = 'block';
                resultDiv.innerHTML = '<div style="text-align: center; padding: 20px;"><strong>â³ AIê°€ ì´ë©”ì¼ì„ ê°œì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤...</strong></div>';
                resultDiv.className = 'result';
                
                try {
                    const response = await fetch('/api/refine-email', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            session_id: 'test_' + Date.now(),
                            current_email: currentEmail,
                            refinement_request: refinementRequest
                        })
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        resultDiv.innerHTML = '<strong style="color: #10b981;">âœ… ê°œì„  ì™„ë£Œ!</strong><br><br>' + 
                                            '<div style="background: white; padding: 15px; border-radius: 8px;">' + 
                                            result.refined_email.replace(/\\n/g, '<br>') + '</div>';
                    } else {
                        resultDiv.innerHTML = '<strong style="color: #ef4444;">âŒ ì˜¤ë¥˜ ë°œìƒ</strong><br><br>' + result.error;
                    }
                } catch (error) {
                    resultDiv.innerHTML = '<strong style="color: #ef4444;">âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜</strong><br><br>' + error.message;
                }
            }
        </script>
    </body>
    </html>
    """

def scheduled_blog_update():
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    í•˜ë£¨ 2ë²ˆ (ì˜¤ì „ 9ì‹œ, ì˜¤í›„ 6ì‹œ) ì‹¤í–‰ë¨
    
    ì¦ë¶„ ìŠ¤í¬ë˜í•‘ ì‚¬ìš©: ìƒˆë¡œìš´ ê¸€ë§Œ í™•ì¸í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    """
    # Flask app context ë‚´ì—ì„œ ì‹¤í–‰ (PostgreSQL ì ‘ê·¼ì„ ìœ„í•´ í•„ìˆ˜)
    with app.app_context():
        try:
            logger.info("â° ìŠ¤ì¼€ì¤„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹œì‘ (ì¦ë¶„ ìŠ¤í¬ë˜í•‘)")
            
            from portone_blog_cache import get_blog_cache_age, load_blog_cache
            
            # ìºì‹œ ìƒíƒœ í™•ì¸
            cache_age = get_blog_cache_age()
            cached_posts = load_blog_cache()
            
            if cache_age is None:
                # DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ìŠ¤í¬ë˜í•‘
                logger.info("ğŸ“ DB ë¹„ì–´ìˆìŒ - ì „ì²´ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰")
                blog_posts = scrape_portone_blog_initial()
                if blog_posts:
                    logger.info(f"âœ… ì´ˆê¸° ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(blog_posts)}ê°œ ê¸€")
            else:
                # ì¦ë¶„ ìŠ¤í¬ë˜í•‘ (ìƒˆ ê¸€ë§Œ í™•ì¸)
                logger.info(f"ğŸ” ì¦ë¶„ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (í˜„ì¬ ìºì‹œ: {len(cached_posts) if cached_posts else 0}ê°œ, ë‚˜ì´: {cache_age:.1f}ì‹œê°„)")
                new_posts = scrape_portone_blog_incremental()
                
                if new_posts:
                    logger.info(f"âœ… ì¦ë¶„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(new_posts)}ê°œ ìƒˆ ê¸€ ì¶”ê°€")
                else:
                    logger.info("âœ… ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ê¸€ ì—†ìŒ - DB ìµœì‹  ìƒíƒœ ìœ ì§€")
                    
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

# ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
scheduler = BackgroundScheduler()

# í•˜ë£¨ 2ë²ˆ ì‹¤í–‰: ì˜¤ì „ 9ì‹œ, ì˜¤í›„ 6ì‹œ
scheduler.add_job(
    func=scheduled_blog_update,
    trigger=CronTrigger(hour='9,18', minute='0'),
    id='blog_update_job',
    name='ë¸”ë¡œê·¸ ìë™ ì—…ë°ì´íŠ¸',
    replace_existing=True
)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
scheduler.start()
logger.info("â° ë¸”ë¡œê·¸ ìë™ ì—…ë°ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨ (ë§¤ì¼ 9ì‹œ, 18ì‹œ ì‹¤í–‰)")

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ
atexit.register(lambda: scheduler.shutdown())

if __name__ == '__main__':
    # API í‚¤ í™•ì¸
    if not os.getenv('PERPLEXITY_API_KEY'):
        logger.warning("PERPLEXITY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if not os.getenv('GEMINI_API_KEY'):
        logger.warning("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.info("ğŸš€ ì´ë©”ì¼ ìƒì„± ì±—ë´‡ ì„œë²„ ì‹œì‘")
    logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
    logger.info("- POST /api/research-company: íšŒì‚¬ ì¡°ì‚¬")
    logger.info("- POST /api/generate-email: ì´ë©”ì¼ ìƒì„±")
    logger.info("- POST /api/batch-process: ì¼ê´„ ì²˜ë¦¬")
    logger.info("- POST /api/refine-email: ì´ë©”ì¼ ê°œì„ ")
    logger.info("- POST /api/chat-reply: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± (ì±—ë´‡)")
    logger.info("- POST /api/smart-chat: í†µí•© ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ (NEW! ğŸ¤–)")
    logger.info("  â†’ íŒë§¤ ìƒí’ˆ ë³€ê²½, í†¤ ë³€ê²½, ë¬¸ì•ˆ ê°œì„ , ì¬ì„¤ë“, ì§ˆë¬¸ ë‹µë³€")
    logger.info("- POST /api/analyze-news: ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„")
    logger.info("- POST /api/test-scraping: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    logger.info("- POST /api/update-blog: ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸")
    logger.info("- GET /api/blog-cache-status: ë¸”ë¡œê·¸ ìºì‹œ ìƒíƒœ í™•ì¸")
    logger.info("- GET /api/health: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸")
    
    # Flask ì„œë²„ ì‹œì‘
    app.run(host='0.0.0.0', port=8000, debug=True, use_reloader=False)
