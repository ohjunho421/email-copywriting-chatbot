import os
import json
import requests
import logging
import time
import asyncio
import concurrent.futures
from functools import partial
from datetime import datetime
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from flask_login import LoginManager, login_required, current_user
from dotenv import load_dotenv
import boto3
from botocore.exceptions import ClientError
import google.generativeai as genai
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import atexit

# SSR ì—”ì§„ ë° ì‚¬ë¡€ DB ì„í¬íŠ¸
from ssr_engine import rank_emails, get_top_email, calculate_ssr_score
from case_database import select_relevant_cases, get_case_details, format_case_for_email, PORTONE_CASES

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì • - API í‚¤ ë…¸ì¶œ ë°©ì§€
logging.basicConfig(
    level=logging.INFO,  # DEBUG â†’ INFOë¡œ ë³€ê²½ (API í‚¤ ë…¸ì¶œ ë°©ì§€)
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # ì½˜ì†” ì¶œë ¥
    ]
)
logger = logging.getLogger(__name__)

# urllib3 DEBUG ë¡œê·¸ ë¹„í™œì„±í™” (URLì— í¬í•¨ëœ API í‚¤ ë…¸ì¶œ ë°©ì§€)
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('urllib3.connectionpool').setLevel(logging.WARNING)

app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'portone-email-generation-secret-key-2025')

# Railway PostgreSQL ì—°ê²° (postgres:// â†’ postgresql:// ë³€í™˜)
database_url = os.getenv('DATABASE_URL', 'sqlite:///email_gen.db')
if database_url.startswith('postgres://'):
    database_url = database_url.replace('postgres://', 'postgresql://', 1)
app.config['SQLALCHEMY_DATABASE_URI'] = database_url
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

CORS(app)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
from models import db, User, EmailGeneration
db.init_app(app)

# Flask-Login ì„¤ì •
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'auth.login'
login_manager.login_message = 'ë¡œê·¸ì¸ì´ í•„ìš”í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.'

@login_manager.user_loader
def load_user(user_id):
    return db.session.get(User, int(user_id))

# Blueprint ë“±ë¡
from auth import auth_bp
from admin import admin_bp
app.register_blueprint(auth_bp)
app.register_blueprint(admin_bp)

# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜
with app.app_context():
    db.create_all()
    logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì‹ ê·œ ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜)
    try:
        from sqlalchemy import text
        
        # name_en ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS name_en VARCHAR(100)'))
            logger.info("âœ… name_en ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"name_en ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # email_signature ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS email_signature TEXT'))
            logger.info("âœ… email_signature ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"email_signature ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # gmail_app_password ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS gmail_app_password VARCHAR(200)'))
            logger.info("âœ… gmail_app_password ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"gmail_app_password ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        # sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€
        try:
            db.session.execute(text('ALTER TABLE users ADD COLUMN IF NOT EXISTS sendgrid_api_key VARCHAR(200)'))
            logger.info("âœ… sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            if 'already exists' not in str(e).lower():
                logger.warning(f"sendgrid_api_key ì»¬ëŸ¼ ì¶”ê°€ ê±´ë„ˆë›°ê¸°: {e}")
        
        db.session.commit()
        logger.info("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        
        # ê¸°ì¡´ ì‚¬ìš©ìë“¤ì—ê²Œ ì„œëª… ìë™ ìƒì„±
        users = User.query.filter(User.email_signature.is_(None)).all()
        if users:
            for user in users:
                user.email_signature = user.generate_email_signature()
            db.session.commit()
            logger.info(f"ğŸ“ {len(users)}ëª…ì˜ ì‚¬ìš©ì ì„œëª… ìë™ ìƒì„± ì™„ë£Œ")
            
    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")
        db.session.rollback()

# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY', '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')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# Gemini API ì„¤ì •
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# AWS Bedrock ì„¤ì • (í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY') 
AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')

class ClaudeBedrockClient:
    """AWS Bedrockì„ í†µí•œ Claude í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.bedrock_runtime = None
        self.model_id = None
        
        # Claude 3.5 Sonnetì„ ìš°ì„ ìœ¼ë¡œ í•˜ë˜, ì ‘ê·¼ ë¶ˆê°€ì‹œ ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
        # Cross-region inference profilesì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ìš°ì„  ì‚¬ìš©
        self.available_models = [
            "us.anthropic.claude-3-5-haiku-20241022-v1:0",  # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-haiku-20240307-v1:0",       # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-opus-20240229-v1:0",        # ì‹¤ì œ í™œì„± ìƒíƒœ ëª¨ë¸
            "anthropic.claude-3-5-sonnet-20240620-v1:0",
            "anthropic.claude-3-5-sonnet-20241022-v2:0",
            "us.anthropic.claude-3-5-sonnet-20241022-v2:0", 
            "anthropic.claude-v2:1",
            "anthropic.claude-v2"
        ]
        
        # Geminië¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ AWS Bedrock ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆë›°ê³  í•„ìš”ì‹œì—ë§Œ ì´ˆê¸°í™”
        logger.info("Gemini ìš°ì„  ëª¨ë“œ: AWS Bedrock ì´ˆê¸°í™” ê±´ë„ˆëœ€ (ì„±ëŠ¥ ìµœì í™”)")
    
    def _find_available_model(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤"""
        for model_id in self.available_models:
            try:
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                body = json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 10,
                    "messages": [{"role": "user", "content": "test"}],
                    "temperature": 0.1
                })
                
                self.bedrock_runtime.invoke_model(
                    body=body,
                    modelId=model_id,
                    accept="application/json",
                    contentType="application/json"
                )
                
                self.model_id = model_id
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë°œê²¬: {model_id}")
                break
                
            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', '')
                if error_code in ['AccessDeniedException', 'ValidationException']:
                    logger.debug(f"ëª¨ë¸ {model_id} ì ‘ê·¼ ë¶ˆê°€: {error_code}")
                    continue
                else:
                    logger.error(f"ëª¨ë¸ {model_id} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ì˜¤ë¥˜: {str(e)}")
                    continue
            except Exception as e:
                logger.debug(f"ëª¨ë¸ {model_id} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                continue
    
    def generate_content(self, prompt, max_tokens=4000):
        """Claudeë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  ìƒì„±"""
        try:
            if not self.bedrock_runtime or not self.model_id:
                raise Exception("AWS Bedrock í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            body = json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": max_tokens,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "top_p": 0.9
            })
            
            logger.info(f"Claude API í˜¸ì¶œ ì‹œì‘ - ëª¨ë¸: {self.model_id}, í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
            
            response = self.bedrock_runtime.invoke_model(
                body=body,
                modelId=self.model_id,
                accept="application/json",
                contentType="application/json"
            )
            
            response_body = json.loads(response.get('body').read())
            content = response_body.get('content', [{}])[0].get('text', '')
            
            logger.info(f"Claude API ì‘ë‹µ ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            return content
            
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            error_message = e.response.get('Error', {}).get('Message', str(e))
            
            if error_code == 'AccessDeniedException':
                logger.error(f"AWS Bedrock ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {error_message}")
                raise Exception("Claude ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. AWS ê³„ì •ì˜ Bedrock ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif error_code == 'ValidationException':
                logger.error(f"AWS Bedrock ê²€ì¦ ì˜¤ë¥˜: {error_message}")
                raise Exception(f"Claude ëª¨ë¸ í˜¸ì¶œ ê²€ì¦ ì‹¤íŒ¨: {error_message}")
            else:
                logger.error(f"AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {error_code} - {error_message}")
                raise Exception(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {error_message}")
                
        except Exception as e:
            logger.error(f"Claude ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"Claude ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")

class CompanyResearcher:
    """Perplexityë¥¼ ì‚¬ìš©í•œ íšŒì‚¬ ì •ë³´ ë° ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.perplexity_url = "https://api.perplexity.ai/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
    
    def extract_emails_from_html(self, html_content):
        """HTMLì—ì„œ ì´ë©”ì¼ ì£¼ì†Œ ì¶”ì¶œ - ë‹¨ìˆœí™”ëœ ë²„ì „"""
        emails = set()
        
        try:
            # HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            text_content = soup.get_text()
            
            # ê¸°ë³¸ ì´ë©”ì¼ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b'
            found_emails = re.findall(email_pattern, text_content, re.IGNORECASE)
            
            # ê²°ê³¼ ì •ì œ
            for email in found_emails:
                if '@' in email and '.' in email and len(email) > 5:
                    emails.add(email.lower())
            
            return list(emails)
            
        except Exception as e:
            print(f"ì´ë©”ì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_business_number_from_html(self, html_content):
        """HTMLì—ì„œ ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ ì¶”ì¶œ"""
        business_numbers = set()
        
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            text_content = soup.get_text()
            
            # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ íŒ¨í„´ë“¤
            business_patterns = [
                r'\b\d{3}-\d{2}-\d{5}\b',  # 123-45-67890
                r'\b\d{10}\b',             # 1234567890 (ì—°ì† 10ìë¦¬)
                r'ì‚¬ì—…ì.*?ë“±ë¡.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
                r'ì‚¬ì—…ì.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
                r'ë“±ë¡.*?ë²ˆí˜¸.*?[:ï¼š]\s*(\d{3}-\d{2}-\d{5})',
            ]
            
            for pattern in business_patterns:
                found_numbers = re.findall(pattern, text_content, re.IGNORECASE)
                for number in found_numbers:
                    # í•˜ì´í”ˆ ì œê±°í•˜ê³  10ìë¦¬ì¸ì§€ í™•ì¸
                    clean_number = re.sub(r'[^0-9]', '', number)
                    if len(clean_number) == 10:
                        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (123-45-67890)
                        formatted = f"{clean_number[:3]}-{clean_number[3:5]}-{clean_number[5:]}"
                        business_numbers.add(formatted)
            
            return list(business_numbers)
            
        except Exception as e:
            print(f"ì‚¬ì—…ìë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def find_privacy_policy_links(self, html_content, base_url):
        """ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ ë§í¬ ì°¾ê¸°"""
        privacy_links = set()
        
        try:
            from bs4 import BeautifulSoup
            import urllib.parse
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ê´€ë ¨ í‚¤ì›Œë“œ
            privacy_keywords = [
                'ê°œì¸ì •ë³´', 'ì²˜ë¦¬ë°©ì¹¨', 'privacy', 'policy', 
                'ê°œì¸ì •ë³´ë³´í˜¸', 'ê°œì¸ì •ë³´ì²˜ë¦¬', 'í”„ë¼ì´ë²„ì‹œ'
            ]
            
            # ëª¨ë“  ë§í¬ ê²€ì‚¬
            links = soup.find_all('a', href=True)
            for link in links:
                href = link.get('href', '')
                text = link.get_text().strip()
                
                # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë§í¬ ì°¾ê¸°
                for keyword in privacy_keywords:
                    if keyword in text.lower() or keyword in href.lower():
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        full_url = urllib.parse.urljoin(base_url, href)
                        privacy_links.add(full_url)
                        break
            
            return list(privacy_links)
            
        except Exception as e:
            print(f"ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ ë§í¬ ì°¾ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def crawl_privacy_policy_page(self, privacy_url):
        """ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            response = requests.get(privacy_url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code == 200:
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text()
                
                # ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ì—ì„œ ì¶”ì¶œí•  ì •ë³´ë“¤
                info = {
                    'emails': self.extract_emails_from_html(response.content),
                    'business_numbers': self.extract_business_number_from_html(response.content),
                    'contact_info': self.extract_contact_info_from_text(text_content)
                }
                
                return info
            
        except Exception as e:
            print(f"ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨ í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return None
    
    
    
    def build_enriched_search_query(self, company_name, additional_info):
        """ê¸°ì¡´ ì…ë ¥ ì •ë³´ë¥¼ í™œìš©í•´ ë” ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        query_parts = [company_name]
        
        if additional_info:
            # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ì— í¬í•¨
            business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                             additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
            if business_number:
                query_parts.append(f'ì‚¬ì—…ìë²ˆí˜¸:{business_number}')
            
            # ëŒ€í‘œìëª…ì´ ìˆìœ¼ë©´ ê²€ìƒ‰ì— í¬í•¨
            ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                       additional_info.get('ëŒ€í‘œì') or
                       additional_info.get('CEOëª…'))
            if ceo_name:
                query_parts.append(f'ëŒ€í‘œ:{ceo_name}')
            
            # í™ˆí˜ì´ì§€ ë„ë©”ì¸ì´ ìˆìœ¼ë©´ site: ê²€ìƒ‰ìœ¼ë¡œ í¬í•¨
            website_url = (additional_info.get('í™ˆí˜ì´ì§€ë§í¬') or
                         additional_info.get('ëŒ€í‘œí™ˆí˜ì´ì§€') or
                         additional_info.get('ì›¹ì‚¬ì´íŠ¸'))
            if website_url:
                # URLì—ì„œ ë„ë©”ì¸ë§Œ ì¶”ì¶œ
                import re
                domain_match = re.search(r'https?://(?:www\.)?([^/]+)', website_url)
                if domain_match:
                    domain = domain_match.group(1)
                    query_parts.append(f'site:{domain}')
            
            # ì—…ì¢… ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            if additional_info.get('ì—…ì¢…'):
                query_parts.append(additional_info.get('ì—…ì¢…'))
            
            # ì£¼ìš” ì„œë¹„ìŠ¤/ì œí’ˆ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            for key in ['ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ì£¼ìš”ì‚¬ì—…']:
                if additional_info.get(key):
                    query_parts.append(additional_info.get(key))
        
        return ' '.join(query_parts)
    
    def research_company(self, company_name, website=None, additional_info=None):
        """íšŒì‚¬ë³„ ë§ì¶¤í˜• Pain Point ë°œêµ´ì„ ìœ„í•œ ìƒì„¸ ì¡°ì‚¬"""
        try:
            # CSVì—ì„œ ì œê³µëœ ì¶”ê°€ ì •ë³´ í™œìš©
            search_context = f"íšŒì‚¬ëª…: {company_name}"
            if website:
                search_context += f"\ní™ˆí˜ì´ì§€: {website}"
            
            # ê¸°ì¡´ ì…ë ¥ëœ ì •ë³´ë“¤ì„ ê²€ìƒ‰ì— í™œìš©í•  ìˆ˜ ìˆë„ë¡ í™•ì¥
            search_keywords = [company_name]  # ê¸°ë³¸ ê²€ìƒ‰ í‚¤ì›Œë“œ
            
            if additional_info:
                # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ (ì‚¬ì—…ìë²ˆí˜¸ ë˜ëŠ” ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ ì»¬ëŸ¼ ëª¨ë‘ ì²´í¬)
                business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                                 additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
                if business_number:
                    search_context += f"\nì‚¬ì—…ìë²ˆí˜¸: {business_number}"
                    search_keywords.append(business_number)
                
                # ëŒ€í‘œìëª… ì •ë³´ í™œìš©
                ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                           additional_info.get('ëŒ€í‘œì') or
                           additional_info.get('CEOëª…'))
                if ceo_name:
                    search_context += f"\nëŒ€í‘œìëª…: {ceo_name}"
                    search_keywords.append(f"{company_name} {ceo_name}")
                
                # í™ˆí˜ì´ì§€ë§í¬ ì¶”ê°€ ê²€ì¦
                website_url = (additional_info.get('í™ˆí˜ì´ì§€ë§í¬') or
                             additional_info.get('ëŒ€í‘œí™ˆí˜ì´ì§€') or
                             additional_info.get('ì›¹ì‚¬ì´íŠ¸'))
                if website_url and not website:
                    website = website_url
                    search_context += f"\ní™ˆí˜ì´ì§€: {website_url}"
                
                # ê¸°ì¡´ ì •ë³´ë“¤
                if additional_info.get('ì—…ì¢…'):
                    search_context += f"\nì—…ì¢…: {additional_info.get('ì—…ì¢…')}"
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    search_context += f"\nì£¼ìš” ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸: {additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')}"
                if additional_info.get('ê·œëª¨'):
                    search_context += f"\níšŒì‚¬ ê·œëª¨: {additional_info.get('ê·œëª¨')}"
                
                # ì¶”ê°€ ì •ë³´ë“¤ë„ ê²€ìƒ‰ì— í™œìš©
                for key in ['ì—…ì¢…', 'ë¶„ì•¼', 'ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸']:
                    if additional_info.get(key):
                        search_keywords.append(f"{company_name} {additional_info.get(key)}")
            
            # ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë¡œê·¸ì— ì¶œë ¥
            logger.info(f"{company_name} ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë“¤: {search_keywords}")

            # ì›¹ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (ì›¹ ìŠ¤í¬ë˜í•‘ìš©)
            if website:
                self.company_website = website
            
            # ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ì„ í†µí•œ ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ (enriched query í™œìš©)
            logger.info(f"{company_name} ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            enriched_query = self.build_enriched_search_query(company_name, additional_info)
            news_results = self.search_company_news_with_query(enriched_query, company_name)
            if news_results:
                search_context += f"\n\n### ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ ë‰´ìŠ¤ ê²°ê³¼:\n{news_results}"
                logger.info(f"{company_name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # MCP ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì •ë³´ ë³´ê°• (í•­ìƒ ìˆ˜í–‰) - enriched query í™œìš©
            logger.info(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            enhanced_info = self.enhance_company_info_with_mcp_enhanced(company_name, website, additional_info, [enriched_query])
            
            # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ì— MCPë¡œ ìˆ˜ì§‘í•œ ì •ë³´ ì¶”ê°€
            if enhanced_info:
                search_context += f"\n\n### MCP ë„êµ¬ë¡œ ìˆ˜ì§‘í•œ ì¶”ê°€ ì •ë³´:\n{enhanced_info}"
                logger.info(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(enhanced_info)} ë¬¸ì")
            else:
                logger.warning(f"{company_name} MCP ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ - ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰")
            
            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - ê¸°ì¡´ ì…ë ¥ ì •ë³´ë¥¼ í™œìš©í•œ ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_query = self.build_enriched_search_query(company_name, additional_info)
            
            prompt = f"""
ë‹¤ìŒ íšŒì‚¬ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ì›¹ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ì¡°ì‚¬í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.

ğŸ” **í•„ìˆ˜: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°˜ë“œì‹œ ì°¾ì•„ì£¼ì„¸ìš”**

ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}

ì´ ê²€ìƒ‰ ì¿¼ë¦¬ì—ëŠ” ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸, ëŒ€í‘œìëª…, ê³µì‹ í™ˆí˜ì´ì§€ ë“± ì •í™•í•œ ì‹ë³„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
ë°˜ë“œì‹œ ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬:
1. **ìµœê·¼ 6ê°œì›” ì´ë‚´ì˜ ë‰´ìŠ¤ ê¸°ì‚¬**ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰
2. ê³µì‹ ë³´ë„ìë£Œ, ì–¸ë¡  ê¸°ì‚¬, ì—…ê³„ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì—ì„œ ì •ë³´ ìˆ˜ì§‘
3. êµ¬ì²´ì ì¸ ë‚ ì§œì™€ ì¶œì²˜ë¥¼ í¬í•¨í•˜ì—¬ ì¸ìš©

ì¶”ê°€ë¡œ ì´ë¯¸ ìˆ˜ì§‘ëœ ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ì˜ ì •ë³´ë„ ì°¸ê³ :
{search_context}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”:

## 1. ìµœì‹  ë‰´ìŠ¤ ë° í™œë™ (Recent News & Activities) ğŸ”´ **ê°€ì¥ ì¤‘ìš”**
**ë°˜ë“œì‹œ ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹¤ìŒ ì •ë³´ í¬í•¨:**
- ğŸ“° **ê¸°ì‚¬ ì œëª©ê³¼ ë‚ ì§œ** (ì˜ˆ: "2024ë…„ 10ì›” ì‹œë¦¬ì¦ˆ A íˆ¬ì ìœ ì¹˜" - 2024.10.15)
- ğŸ“° **ì‹ ì œí’ˆ ì¶œì‹œ, íˆ¬ì ìœ ì¹˜, ì‚¬ì—… í™•ì¥ ê´€ë ¨ êµ¬ì²´ì  ë‰´ìŠ¤**
- ğŸ“° **ì¡°ì§ ë³€í™”, íŒŒíŠ¸ë„ˆì‹­, ìˆ˜ìƒ ì´ë ¥ ë“±**
- ğŸ”— **ë‰´ìŠ¤ ì¶œì²˜** (ê°€ëŠ¥í•œ ê²½ìš° URL í¬í•¨)

## 2. ê¸°ì—… ê°œìš” (Corporate Overview)
- ì£¼ë ¥ ì‚¬ì—… ë¶„ì•¼ì™€ í•µì‹¬ ì œí’ˆ/ì„œë¹„ìŠ¤
- ëŒ€ìƒ ê³ ê°ì¸µ ë° ì‹œì¥ í¬ì§€ì…”ë‹  
- ì¶”ì • ë§¤ì¶œ ê·œëª¨ ë° ì„±ì¥ ë‹¨ê³„

## 3. ê²°ì œ/ì •ì‚° ê´€ë ¨ Pain Points (Payment & Settlement Challenges)
- í˜„ì¬ ê²°ì œ ì‹œìŠ¤í…œì˜ ì¶”ì • ë³µì¡ë„
- ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ ì‹œ ì˜ˆìƒë˜ëŠ” ì •ì‚° ë¬¸ì œ
- ì—…ê³„ íŠ¹ì„±ìƒ ê²ªì„ ìˆ˜ ìˆëŠ” ê²°ì œ ê´€ë ¨ ì–´ë ¤ì›€

## 4. ì—…ê³„ë³„ ê¸°ìˆ  íŠ¸ë Œë“œ (Industry Tech Trends)
- í•´ë‹¹ ì—…ê³„ì˜ ë””ì§€í„¸ ì „í™˜ í˜„í™©
- ê²°ì œ ì¸í”„ë¼ í˜ì‹  ì‚¬ë¡€

## 5. PortOne ì†”ë£¨ì…˜ ì í•©ì„± (PortOne Solution Fit)
- One Payment Infra(OPI) ì í•©ì„± ë¶„ì„
- ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ í•„ìš”ì„± ì •ë„

**ì¤‘ìš”**: ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ìµœì‹  ë‰´ìŠ¤ì™€ ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ì¸ìš©í•˜ê³ , êµ¬ì²´ì ì¸ ë‚ ì§œì™€ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì ì¸ ë‚´ìš©ì´ ì•„ë‹Œ, ì‹¤ì œ ê²€ìƒ‰ëœ ì‚¬ì‹¤ ê¸°ë°˜ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            data = {
                "model": "sonar-pro",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 1500,
                "temperature": 0.3
            }
            
            logger.info(f"Perplexity API ìƒì„¸ ì¡°ì‚¬ ìš”ì²­: {company_name}")
            
            response = requests.post(
                self.perplexity_url, 
                json=data, 
                headers=self.headers,
                timeout=45
            )
            
            logger.info(f"Perplexity API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                
                # ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ
                if 'choices' in result and len(result['choices']) > 0:
                    raw_content = result['choices'][0]['message']['content']
                    logger.info(f"{company_name} Perplexity ì‘ë‹µ ìˆ˜ì‹ : {len(raw_content)} ë¬¸ì")
                else:
                    logger.error(f"{company_name} Perplexity ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {result}")
                    raise Exception("Perplexity API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
                
                # Citations (ì¶œì²˜) ì¶”ì¶œ
                citations = result.get('citations', [])
                if citations:
                    logger.info(f"{company_name} Perplexity citations ë°œê²¬: {len(citations)}ê°œ")
                    # Citationsë¥¼ ì‘ë‹µì— ì¶”ê°€
                    citations_text = "\n\n## ğŸ“š ì°¸ê³  ì¶œì²˜ (Citations)\n"
                    for i, citation in enumerate(citations[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                        citations_text += f"{i}. {citation}\n"
                    raw_content += citations_text
                else:
                    logger.warning(f"{company_name} Perplexity citations ì—†ìŒ - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ")
                
                # ì‘ë‹µ í¬ë§·íŒ… ë° ê°€ë…ì„± ê°œì„ 
                formatted_content = self.format_perplexity_response(raw_content, company_name)
                
                # Pain Point ì¶”ì¶œ ë‹¨ê³„ ì¶”ê°€
                pain_points = self.extract_pain_points(formatted_content, company_name)
                
                # ì •ë³´ ê²€ì¦ ìˆ˜í–‰
                verification_result = self.verify_company_information(
                    company_name, 
                    {'company_info': formatted_content},
                    additional_info
                )
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ê°€ ê²€ìƒ‰ ìˆ˜í–‰ (70% ë¯¸ë§Œì—ì„œ ì¶”ê°€ ê²€ìƒ‰)
                if verification_result['confidence_score'] < 70:
                    logger.info(f"{company_name} ì‹ ë¢°ë„ {verification_result['confidence_score']}% - ì¶”ê°€ ê²€ìƒ‰ ì‹œì‘")
                    enhanced_info = self.perform_enhanced_search(company_name, additional_info, verification_result)
                    
                    if enhanced_info:
                        # ì¶”ê°€ ì •ë³´ë¡œ ê¸°ì¡´ ë‚´ìš© ë³´ê°•
                        formatted_content += f"\n\n## ğŸ“‹ ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼\n{enhanced_info['content']}"
                        
                        # ì¬ê²€ì¦ ìˆ˜í–‰
                        updated_verification = self.verify_company_information(
                            company_name, 
                            {'company_info': formatted_content},
                            additional_info
                        )
                        
                        # ì‹ ë¢°ë„ ê°œì„ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if updated_verification['confidence_score'] > verification_result['confidence_score']:
                            verification_result = updated_verification
                            logger.info(f"{company_name} ì‹ ë¢°ë„ ê°œì„ : {verification_result['confidence_score']}%")
                    
                    # ì‹ ë¢°ë„ ê²½ê³  ì¶”ê°€
                    reliability_warning = f"\n\nâš ï¸ **ì‹ ë¢°ë„**: {verification_result['confidence_score']}% (ì¶”ê°€ ê²€ìƒ‰ ì™„ë£Œ)"
                    formatted_content += reliability_warning
                else:
                    reliability_warning = f"\n\nâœ… **ì‹ ë¢°ë„**: {verification_result['confidence_score']}% (ê²€ì¦ ì™„ë£Œ)"
                    formatted_content += reliability_warning
                
                return {
                    'success': True,
                    'company_info': formatted_content,
                    'pain_points': pain_points,
                    'citations': result.get('citations', []),
                    'verification': verification_result,
                    'timestamp': datetime.now().isoformat(),
                    'raw_response': raw_content  # ë””ë²„ê¹…ìš©
                }
            else:
                logger.error(f"Perplexity API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                raise Exception(f"API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            
        except Exception as e:
            logger.error(f"íšŒì‚¬ ì¡°ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # íšŒì‚¬ë³„ ë§ì¶¤í˜• ì‹œãƒŸãƒ¥ë ˆì´ì…˜ ë°ì´í„°
            pain_points = self.generate_fallback_pain_points(company_name)
            return {
                'success': True,
                'company_info': f"""{company_name}ì— ëŒ€í•œ ìƒì„¸ ì¡°ì‚¬ ê²°ê³¼:

**ë¹„ì¦ˆë‹ˆìŠ¤ í˜„í™©:**
- ë””ì§€í„¸ ì „í™˜ ë° ì„±ì¥ì— ì§‘ì¤‘í•˜ëŠ” ê¸°ì—…
- ìš´ì˜ íš¨ìœ¨ì„± ë° ë¹„ìš© ìµœì í™” ë‹ˆì¦ˆ ë³´ìœ 

**ì˜ˆìƒ Pain Points:**
{pain_points}

**ê¸°ìˆ  ë„ì… ë‹ˆì¦ˆ:**
- ê²°ì œ ì‹œìŠ¤í…œ í˜„ëŒ€í™” ë° í†µí•© ì†”ë£¨ì…˜ í•„ìš”
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ êµ¬ì¶• ê´€ì‹¬""",
                'pain_points': pain_points,
                'citations': [],
                'timestamp': datetime.now().isoformat(),
                'note': f'API ì˜¤ë¥˜ë¡œ ì¸í•œ ë§ì¶¤í˜• ì‹œãƒŸãƒ¥ë ˆì´ì…˜: {str(e)}'
            }
    
    def extract_pain_points(self, research_content, company_name):
        """íšŒì‚¬ë³„ êµ¬ì²´ì  Pain Point ì¶”ì¶œ - ì‹¤ì œ ì¡°ì‚¬ ë‚´ìš© ê¸°ë°˜"""
        try:
            # íšŒì‚¬ëª…ì—ì„œ ê³ ìœ  ì‹ë³„ì ìƒì„± (ì°¨ë³„í™” ë³´ì¥)
            company_hash = hash(company_name) % 1000
            
            # ì¡°ì‚¬ ë‚´ìš©ì—ì„œ êµ¬ì²´ì  ì •ë³´ ì¶”ì¶œ
            content_lower = research_content.lower()
            specific_points = []
            
            # 1. Perplexity ì¡°ì‚¬ ë‚´ìš©ì—ì„œ ì‹¤ì œ ë‹ˆì¦ˆ ë°œêµ´
            # ì„±ì¥/í™•ì¥ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ì„±ì¥', 'í™•ì¥', 'íˆ¬ì', 'ë§¤ì¶œì¦ê°€', 'growth', 'expansion', 'investment']):
                if any(word in content_lower for word in ['ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ecommerce']):
                    specific_points.append(f"{company_name}ì˜ ê¸‰ì„±ì¥ì— ë”°ë¥¸ ë‹¤ì¤‘ ì±„ë„ ê²°ì œ ë°ì´í„° í†µí•© í•„ìš”ì„±")
                elif any(word in content_lower for word in ['ê²Œì„', 'game', 'ëª¨ë°”ì¼']):
                    specific_points.append(f"{company_name}ì˜ ì‚¬ìš©ì ì¦ê°€ì— ë”°ë¥¸ ê²°ì œ ì¸í”„ë¼ í™•ì¥ì„± ì´ìŠˆ")
                else:
                    specific_points.append(f"{company_name}ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë³µì¡ì„± ì¦ê°€")
            
            # ê¸€ë¡œë²Œ/í•´ì™¸ì§„ì¶œ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ê¸€ë¡œë²Œ', 'í•´ì™¸', 'ìˆ˜ì¶œ', 'ì§„ì¶œ', 'global', 'overseas', 'international']):
                specific_points.append(f"{company_name}ì˜ í•´ì™¸ ì§„ì¶œ ì‹œ ë‹¤êµ­ê°€ ê²°ì œ ìˆ˜ë‹¨ ë° ì •ì‚° ë³µì¡ì„±")
            
            # ê¸°ìˆ /ê°œë°œ ê´€ë ¨ ë‹ˆì¦ˆ  
            if any(word in content_lower for word in ['ê°œë°œ', 'ê¸°ìˆ ', 'ì‹œìŠ¤í…œ', 'tech', 'development', 'platform']):
                specific_points.append(f"{company_name}ì˜ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ë‹´ ë° ì „ë¬¸ì„± ë¶€ì¡±")
            
            # ì—…ì¢…ë³„ íŠ¹í™” ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ecommerce', 'online']):
                specific_points.append(f"{company_name}ì˜ ë‹¤ì¤‘ ì»¤ë¨¸ìŠ¤ ì±„ë„ ë°ì´í„° í†µí•© ë° ì‹¤ì‹œê°„ ì •ì‚° ë‹ˆì¦ˆ")
            elif any(word in content_lower for word in ['ì œì¡°', 'ìƒì‚°', 'ê³µì¥', 'manufacturing']):
                specific_points.append(f"{company_name}ì˜ B2B ëŒ€ëŸ‰ ê±°ë˜ ì²˜ë¦¬ ë° ë³µì¡í•œ ì •ì‚° êµ¬ì¡° ê°œì„  í•„ìš”")
            elif any(word in content_lower for word in ['ê²Œì„', 'ëª¨ë°”ì¼ê²Œì„', 'ì•±ê²Œì„', 'game', 'mobile']):
                # ê²Œì„ì—…ê³„ëŠ” ìˆ˜ìˆ˜ë£Œê°€ ì‹¤ì œ í•µì‹¬ ì´ìŠˆ
                specific_points.append(f"{company_name}ì˜ ì•±ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ í•´ê²° í•„ìš”ì„±")
                specific_points.append(f"D2C ì›¹ìƒì  êµ¬ì¶•ì„ í†µí•œ ìˆ˜ìˆ˜ë£Œ ì ˆê° ë° ì§ì ‘ ê³ ê° ê´€ê³„ êµ¬ì¶•")
            
            # 2. ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì—ì„œ ë°œêµ´ë˜ëŠ” ë‹ˆì¦ˆ
            # ìê¸ˆ ê´€ë ¨ ì´ìŠˆ
            if any(word in content_lower for word in ['ìê¸ˆ', 'í˜„ê¸ˆíë¦„', 'ì •ì‚°', 'ìˆ˜ìµì„±', 'cash', 'revenue', 'profit']):
                specific_points.append(f"{company_name}ì˜ í˜„ê¸ˆíë¦„ ê´€ë¦¬ ë° ì •ì‚° ìë™í™” í•„ìš”ì„±")
            
            # ìš´ì˜ íš¨ìœ¨ì„± ì´ìŠˆ
            if any(word in content_lower for word in ['íš¨ìœ¨', 'ìë™í™”', 'ì¸ë ¥', 'ì—…ë¬´', 'efficiency', 'automation', 'operation']):
                specific_points.append(f"{company_name}ì˜ ìˆ˜ì‘ì—… ì¤‘ì‹¬ ì¬ë¬´ í”„ë¡œì„¸ìŠ¤ ìë™í™” ë‹ˆì¦ˆ")
            
            # ë°ì´í„°/ë¶„ì„ ê´€ë ¨ ë‹ˆì¦ˆ
            if any(word in content_lower for word in ['ë°ì´í„°', 'ë¶„ì„', 'ë¦¬í¬íŠ¸', 'data', 'analytics', 'report']):
                specific_points.append(f"{company_name}ì˜ ì‹¤ì‹œê°„ ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ í•„ìš”ì„±")
            
            # 3. íšŒì‚¬ë³„ ê³ ìœ  Pain Point ìƒì„± (ì°¨ë³„í™” ë³´ì¥)
            unique_points = [
                f"{company_name}ì˜ ì—…ê³„ íŠ¹ì„±ìƒ ê²°ì œ ì‹œìŠ¤í…œ ê´€ë¦¬ ë³µì¡ì„±",
                f"ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥ì— ë”°ë¥¸ {company_name}ì˜ ìš´ì˜ íš¨ìœ¨ì„± ì €í•˜",
                f"{company_name}ì˜ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ ë¶€ì¬",
                f"ìˆ˜ì‘ì—… ì¤‘ì‹¬ì˜ {company_name} ì¬ë¬´ ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤ ë¹„íš¨ìœ¨ì„±"
            ]
            
            # ìµœì¢… Pain Point ì„ íƒ (ìµœëŒ€ 4ê°œ, ì°¨ë³„í™” ë³´ì¥)
            final_points = specific_points[:2] + unique_points[:2] if specific_points else unique_points[:4]
            
            return "\n".join([f"- {point}" for point in final_points])
            
        except Exception as e:
            logger.error(f"Pain Point ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return self.generate_fallback_pain_points(company_name)
    
    def generate_company_specific_pain_points(self, company_name):
        """íšŒì‚¬ëª… ê¸°ë°˜ ë§¤ìš° êµ¬ì²´ì ì¸ Pain Point ìƒì„±"""
        import hashlib
        import random
        
        # íšŒì‚¬ëª…ì„ í•´ì‹œí•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ëœë¤ ì‹œë“œ ìƒì„±
        seed = int(hashlib.md5(company_name.encode()).hexdigest()[:8], 16)
        random.seed(seed)
        
        company_lower = company_name.lower()
        
        # ì—…ì¢…ë³„ Pain Point í’€ ì •ì˜
        if any(keyword in company_lower for keyword in ['ì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘', 'ë¦¬í…Œì¼', 'ì˜¨ë¼ì¸', 'commerce', 'shop', 'mall', 'ë§ˆì¼“']):
            pain_pool = [
                "ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¹´ì¹´ì˜¤ìŠ¤íƒ€ì¼/ì¹´í˜24 ë°ì´í„° ë§¤í•‘ ì˜¤ë¥˜",
                "ì›” 200ì‹œê°„+ ì—‘ì…€ ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì¬ë¬´íŒ€ ê³ ìƒ",
                "êµ¬ë§¤í™•ì •-ì •ì‚°ë‚´ì—­ ë§¤í•‘ ì˜¤ë¥˜ë¡œ ì¸í•œ ë§¤ì¶œ ì†ì‹¤",
                "ì‹¤ì‹œê°„ ì¬ê³ /ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ë¶ˆê°€ëŠ¥",
                "ë¶€ê°€ì„¸ ì‹ ê³  ìë£Œ ì¤€ë¹„ì— ì£¼ë§ˆë‹¤ ë°¤ìƒˆìš°ê¸°",
                "ì±„ë„ë³„ ìˆ˜ìˆ˜ë£Œ ìƒì´ë¡œ ì¸í•œ ìˆ˜ìµì„± ì•…í™”",
                "ë‹¤ì¤‘ ì±„ë„ ì£¼ë¬¸ ë™ê¸°í™” ì‹¤íŒ¨ë¡œ ì¸í•œ ì¬ê³  ì°¨ì´"
            ]
        
        elif any(keyword in company_lower for keyword in ['í…Œí¬', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ìŠ¤íƒ€íŠ¸ì—…', 'tech', 'software', 'startup', 'ì•±', 'app']):
            pain_pool = [
                "ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 8ê°œì›”+ ì†Œìš”ë˜ì–´ ëŸ°ì¹­ ì§€ì—°",
                "PGì‚¬ 5ê°œ ì´ìƒ ì—°ë™ìœ¼ë¡œ ì¸í•œ ìš´ì˜ ë³µì¡ì„± ì¦ê°€",
                "ê²°ì œ ì‹¤íŒ¨ìœ¨ 15%ë¡œ ì¸í•œ ì›” ìˆ˜ë°±ë§Œì› ë§¤ì¶œ ì†ì‹¤",
                "ê°‘ì‘ìŠ¤ëŸ¬ìš´ íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ì„œë²„ ë‹¤ìš´ ìœ„í—˜",
                "ê°œë°œì 3ëª…ì´ ê²°ì œ ì‹œìŠ¤í…œë§Œ ê°œë°œí•˜ëŠ” ë¹„íš¨ìœ¨",
                "ì •ê¸°ê²°ì œ/ë³¸ì¸ì¸ì¦ ì¶”ê°€ ê°œë°œë¡œ ì¸í•œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±",
                "ê¸€ë¡œë²Œ ì§„ì¶œ ì‹œ ë‹¤êµ­ê°€ ê²°ì œ ìˆ˜ë‹¨ ëŒ€ì‘ ì–´ë ¤ì›€"
            ]
        
        elif any(keyword in company_lower for keyword in ['ì œì¡°', 'ìƒì‚°', 'ê³µì¥', 'ì œí’ˆ', 'manufacturing', 'factory', 'ì‚°ì—…']):
            pain_pool = [
                "B2B ëŒ€ê¸ˆ ê²°ì œ ì‹œ ë³µì¡í•œ ìŠ¹ì¸ ì ˆì°¨ë¡œ ì¸í•œ ì§€ì—°",
                "ì›” ìˆ˜ì²œê±´ ê±°ë˜ ì²˜ë¦¬ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ê³¼ë¶€í•˜",
                "ê³µê¸‰ì—…ì²´ ëŒ€ê¸ˆ ì§€ê¸‰ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì‹ ë¢°ë„ í•˜ë½",
                # "ëŒ€ë¦¬ì /ëŒ€ë¦¬ì‚¬ ìˆ˜ìˆ˜ë£Œ ì •ì‚° ì˜¤ë¥˜ë¡œ ì¸í•œ ë¶„ìŸ",
                "ìˆ˜ì¶œ ëŒ€ê¸ˆ íšŒìˆ˜ ì§€ì—°ìœ¼ë¡œ ì¸í•œ í˜„ê¸ˆíë¦„ ì•…í™”",
                "ì¬ê³  ë°ì´í„°ì™€ ì£¼ë¬¸ ë°ì´í„° ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ í˜¼ë€",
                "ERP ì‹œìŠ¤í…œê³¼ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨"
            ]
        
        elif any(keyword in company_lower for keyword in ['ì„œë¹„ìŠ¤', 'ì»´ì„¤íŒ…', 'ëŒ€í–‰', 'service', 'consulting', 'ì—ì´ì „ì‹œ']):
            pain_pool = [
                "ê³ ê°ì‚¬ 20ê°œ ì´ìƒì˜ ì„œë¡œ ë‹¤ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™",
                # "í”„ë¡œì íŠ¸ë³„ ë¹„ìš© ì •ì‚°ì— ì£¼ë§ˆë‹¤ 20ì‹œê°„ ì†Œìš”",
                "ê³ ê°ì‚¬ ìš”êµ¬ë¡œ ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ",
                # "ìˆ˜ìˆ˜ë£Œ ì •ì‚° ì˜¤ë¥˜ë¡œ ì¸í•œ ê³ ê°ì‚¬ì™€ì˜ ë¶„ìŸ",
                "ì›”ë³„ ìˆ˜ìµ ë¶„ì„ì— ì—‘ì…€ë¡œ 3ì¼ ì†Œìš”",
                "ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ ì§€ì›ìœ¼ë¡œ ì¸í•œ ê°œë°œ ë¹„ìš© ì¦ê°€",
                # "ê³ ê°ì‚¬ë³„ ì •ì‚° ì£¼ê¸° ë‹¬ë¼ ê´€ë¦¬ ì–´ë ¤ì›€"
            ]
        
        else:
            # ì¼ë°˜ ê¸°ì—…ìš© Pain Point
            pain_pool = [
                "ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 6ê°œì›”+ ì†Œìš”ë˜ëŠ” ë¬¸ì œ",
                "ë°ì´í„° í†µí•© ë° ë¶„ì„ì˜ ì–´ë ¤ì›€",
                "ìˆ˜ì‘ì—… ì¤‘ì‹¬ì˜ ë¹„íš¨ìœ¨ì  ìš´ì˜",
                "ë””ì§€í„¸ ì „í™˜ ê³¼ì •ì—ì„œì˜ ê¸°ìˆ ì  ì±„ë§Œì§€",
                "ìš´ì˜ ë¹„ìš© ì¦ê°€ ë° ë¹„ìš© ìµœì í™” ë‹ˆì¦ˆ",
                "ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í™•ì¥ì„± í•œê³„"
            ]
        
        # íšŒì‚¬ë³„ë¡œ ì¼ê´€ëœ 4ê°œ Pain Point ì„ íƒ
        selected_points = random.sample(pain_pool, min(4, len(pain_pool)))
        return "\n".join([f"- {point}" for point in selected_points])
    
    def generate_fallback_pain_points(self, company_name):
        """ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ"""
        return self.generate_company_specific_pain_points(company_name)
    
    def generate_personalized_greeting(self, contact_name, contact_position, company_name):
        """ì´ë¦„ê³¼ ì§ì±…ì„ í™œìš©í•œ ê°œì¸í™”ëœ ì¸ì‚¬ë§ ìƒì„±"""
        greeting = ''
        
        if contact_name and contact_name != 'ë‹´ë‹¹ì':
            # ì§ì±…ì´ ìˆëŠ” ê²½ìš°
            if contact_position:
                # ì§ì±…ì— ë”°ë¥¸ ì¡´ì¹­ ì²˜ë¦¬
                if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
                elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
                else:
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_position} {contact_name}ë‹˜."
            else:
                # ì§ì±… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì´ë¦„ë§Œìœ¼ë¡œ ì¸ì‚¬
                if any(keyword in contact_name for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_name}ë‹˜."
                else:
                    greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {contact_name} ë‹´ë‹¹ìë‹˜."
        else:
            # ì´ë¦„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¸ì‚¬ë§
            greeting = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜."
        
        return greeting
    
    def enhance_company_info_with_mcp_enhanced(self, company_name, website, additional_info, search_keywords=None):
        """í™•ì¥ëœ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ MCP ë„êµ¬ ì •ë³´ ë³´ê°• ë° ê²€ì¦ (ëŒ€í­ ê°•í™”)"""
        try:
            enhanced_data = []
            logger.info(f"{company_name} MCP ì •ë³´ ë³´ê°• ì‹œì‘")
            
            if not search_keywords:
                search_keywords = [company_name]
            
            # 1. ë‹¤ì¤‘ ì›¹ ê²€ìƒ‰ ì „ëµ (í™•ì¥ëœ í‚¤ì›Œë“œ í™œìš©)
            web_searches = []
            
            # ê¸°ë³¸ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰
            if website and website.startswith('http'):
                web_info = self.fetch_website_info(website, company_name)
                if web_info:
                    web_searches.append(f"ê³µì‹ ì›¹ì‚¬ì´íŠ¸: {web_info}")
            
            # í™•ì¥ëœ í‚¤ì›Œë“œë¡œ ë„¤ì´ë²„/êµ¬ê¸€ ê²€ìƒ‰ (ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œ)
            primary_search_keywords = search_keywords[:2]
            
            for keyword in primary_search_keywords:
                # ë„¤ì´ë²„ ì§€ì‹ë°±ê³¼/ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
                naver_info = self.search_naver_sources(keyword)
                if naver_info:
                    web_searches.append(f"ë„¤ì´ë²„ ê²€ìƒ‰ ({keyword}): {naver_info}")
                
                # êµ¬ê¸€ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜  
                google_info = self.search_google_sources(keyword)
                if google_info:
                    web_searches.append(f"êµ¬ê¸€ ê²€ìƒ‰ ({keyword}): {google_info}")
            
            if web_searches:
                enhanced_data.append("\n".join(web_searches))
            
            # 2. CSV ì •ë³´ ê¸°ë°˜ ì‹¬í™” ê²€ìƒ‰ (í™•ì¥ë¨)
            if additional_info:
                csv_insights = []
                
                # ì‚¬ì—…ìë²ˆí˜¸ -> ì—…ì²´ ì‹ ë¢°ë„ ê²€ì¦ (ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ë„ í¬í•¨)
                business_number = (additional_info.get('ì‚¬ì—…ìë²ˆí˜¸') or 
                                 additional_info.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'))
                if business_number:
                    business_validation = self.deep_business_validation(
                        company_name, business_number
                    )
                    if business_validation:
                        csv_insights.append(f"ì‚¬ì—…ì ì‹¬í™” ê²€ì¦: {business_validation}")
                
                # ëŒ€í‘œìëª… ì •ë³´ í™œìš©
                ceo_name = (additional_info.get('ëŒ€í‘œìëª…') or
                           additional_info.get('ëŒ€í‘œì') or
                           additional_info.get('CEOëª…'))
                if ceo_name:
                    ceo_insights = self.analyze_ceo_profile(company_name, ceo_name)
                    if ceo_insights:
                        csv_insights.append(f"ëŒ€í‘œì í”„ë¡œí•„ ë¶„ì„: {ceo_insights}")
                
                # ì—…ì¢… -> ì‹œì¥ íŠ¸ë Œë“œ ë° Pain Point
                if additional_info.get('ì—…ì¢…'):
                    industry_deep_dive = self.get_industry_deep_insights(
                        company_name, additional_info.get('ì—…ì¢…')
                    )
                    if industry_deep_dive:
                        csv_insights.append(f"ì—…ì¢… ì‹¬í™” ë¶„ì„: {industry_deep_dive}")
                
                # ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ -> PortOne ì—°ê³„ì„± ë¶„ì„
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    synergy_analysis = self.analyze_portone_synergy(
                        company_name, additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')
                    )
                    if synergy_analysis:
                        csv_insights.append(f"PortOne ì—°ê³„ì„±: {synergy_analysis}")
                
                # ê·œëª¨ -> ë§ì¶¤í˜• ì†”ë£¨ì…˜ ì œì•ˆ
                if additional_info.get('ê·œëª¨'):
                    scale_strategy = self.get_scale_specific_strategy(
                        company_name, additional_info.get('ê·œëª¨')
                    )
                    if scale_strategy:
                        csv_insights.append(f"ê·œëª¨ë³„ ì „ëµ: {scale_strategy}")
                
                if csv_insights:
                    enhanced_data.append("\n".join(csv_insights))
            
            # 3. ì¢…í•© ê²°ê³¼
            if enhanced_data:
                result = "\n\n".join(enhanced_data)
                logger.info(f"{company_name} MCP ì •ë³´ ë³´ê°• ì„±ê³µ: {len(result)} ë¬¸ì")
                return result
            else:
                logger.warning(f"{company_name} MCP ì •ë³´ ë³´ê°•ì—ì„œ ìœ ì˜ë¯¸í•œ ë°ì´í„° ì—†ìŒ")
                return None
            
        except Exception as e:
            logger.error(f"MCP ì •ë³´ ë³´ê°• ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def enhance_company_info_with_mcp(self, company_name, website, additional_info):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - ìƒˆë¡œìš´ í™•ì¥ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
        return self.enhance_company_info_with_mcp_enhanced(company_name, website, additional_info)
    
    def search_naver_sources(self, company_name):
        """ë„¤ì´ë²„ ì†ŒìŠ¤ ê²€ìƒ‰ (ì§€ì‹ë°±ê³¼, ë‰´ìŠ¤ ë“±)"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ API í™œìš©
            return f"{company_name}ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ ë° ì§€ì‹ë°±ê³¼ ê²€ìƒ‰ ê²°ê³¼: ìµœê·¼ í™œë™ ë° ì–¸ë¡  ë³´ë„ í™•ì¸"
        except Exception as e:
            logger.debug(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def search_google_sources(self, company_name):
        """êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼"""
        try:
            # ì‹¤ì œë¡œëŠ” Google Search API í™œìš©
            return f"{company_name}ì˜ ê¸€ë¡œë²Œ ì›¹ ì¡´ì¬ê° ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ í™•ì¸"
        except Exception as e:
            logger.debug(f"êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def deep_business_validation(self, company_name, business_number):
        """ì‚¬ì—…ìë²ˆí˜¸ ì‹¬í™” ê²€ì¦"""
        try:
            # ì‹¤ì œë¡œëŠ” ê³µê³µë°ì´í„°í¬í„¸, ì‚¬ì—…ìì •ë³´ì¡°íšŒ API ë“± í™œìš©
            if business_number and len(business_number.replace('-', '')) == 10:
                return f"{company_name}({business_number})ì˜ ì‚¬ì—…ì ë“±ë¡ í˜„í™©, ì—…ì¢… ì½”ë“œ, ì„¤ë¦½ì¼ì ë“± ê³µì‹ ì •ë³´ í™•ì¸"
            return f"{company_name}ì˜ ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ í•„ìš”"
        except Exception as e:
            return None
    
    def analyze_ceo_profile(self, company_name, ceo_name):
        """ëŒ€í‘œì í”„ë¡œí•„ ë¶„ì„"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ì¸ë¬¼ê²€ìƒ‰, LinkedIn, ê¸°ì—… ê³µì‹œ ë“±ì„ í™œìš©
            return f"{company_name} {ceo_name} ëŒ€í‘œì˜ ê²½ë ¥ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì² í•™ ë¶„ì„ì„ í†µí•œ ì˜ì‚¬ê²°ì • ìŠ¤íƒ€ì¼ íŒŒì•…"
        except Exception as e:
            return None
    
    def get_industry_deep_insights(self, company_name, industry):
        """ì—…ì¢…ë³„ ì‹¬í™” ì¸ì‚¬ì´íŠ¸"""
        try:
            deep_insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name}ëŠ” ì´ì»¤ë¨¸ìŠ¤ ì—…ì²´ë¡œì„œ ë„¤ì´ë²„í˜ì´/ì¹´ì¹´ì˜¤í˜ì´/í† ìŠ¤í˜ì´ ë“± ë‹¤ì¤‘ PG ì—°ë™ê³¼ ì •ì‚° ìë™í™”ê°€ í•µì‹¬ ì´ìŠˆ. íŠ¹íˆ ë°˜í’ˆ/í™˜ë¶ˆ ì²˜ë¦¬, ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ ë“±ì´ ì£¼ìš” Pain Point",
                'í•€í…Œí¬': f"{company_name}ëŠ” í•€í…Œí¬ ê¸°ì—…ìœ¼ë¡œì„œ ê¸ˆìœµìœ„ì›íšŒ ê·œì œ ì¤€ìˆ˜ì™€ ë™ì‹œì— ê²°ì œ í¸ì˜ì„± ì œê³ ê°€ í•„ìš”. PCI-DSS ì¸ì¦, ì „ìê¸ˆìœµê±°ë˜ë²• ì¤€ìˆ˜, ì‹¤ì‹œê°„ ê±°ë˜ ëª¨ë‹ˆí„°ë§ì´ í•µì‹¬",
                'ì œì¡°ì—…': f"{company_name}ëŠ” ì œì¡°ì—…ì²´ë¡œì„œ B2B ëŒ€ëŸ‰ ê±°ë˜ì˜ ê²°ì œ/ì •ì‚° ë³µì¡ì„±ì´ ì£¼ìš” ê³¼ì œ. ì™¸ìƒë§¤ì¶œ, ì–´ìŒ ê²°ì œ, ìˆ˜ì¶œ ëŒ€ê¸ˆ íšŒìˆ˜, ERP ì—°ë™ì´ í•µì‹¬ ìš”êµ¬ì‚¬í•­",
                'SaaS': f"{company_name}ëŠ” SaaS ê¸°ì—…ìœ¼ë¡œì„œ êµ¬ë… ê²°ì œì˜ ì•ˆì •ì„±ê³¼ ê¸€ë¡œë²Œ í™•ì¥ì„±ì´ ì¤‘ìš”. ì •ê¸°ê²°ì œ ì‹¤íŒ¨ìœ¨ ìµœì†Œí™”, ë‹¤êµ­ê°€ í†µí™” ì§€ì›, ê³¼ê¸ˆ ëª¨ë¸ ìœ ì—°ì„±ì´ í•µì‹¬",
                'ITì„œë¹„ìŠ¤': f"{company_name}ëŠ” ITì„œë¹„ìŠ¤ ê¸°ì—…ìœ¼ë¡œì„œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ìµœì í™”ì™€ ì‹œìŠ¤í…œ í†µí•©ì´ ìš°ì„ ìˆœìœ„. API ê°œë°œ ì‹œê°„ ë‹¨ì¶•, ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ì—°ë™, í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ê°€ ì¤‘ìš”"
            }
            
            return deep_insights.get(industry, f"{company_name}ì˜ {industry} ë¶„ì•¼ íŠ¹ì„±ìƒ ê²°ì œ ì¸í”„ë¼ í˜„ëŒ€í™”ì™€ ìš´ì˜ íš¨ìœ¨ì„±ì´ í•µì‹¬ ê³¼ì œ")
        except Exception as e:
            return None
    
    def analyze_portone_synergy(self, company_name, sales_point):
        """PortOne ì†”ë£¨ì…˜ê³¼ì˜ ì‹œë„ˆì§€ ë¶„ì„"""
        try:
            sales_lower = sales_point.lower()
            
            if any(keyword in sales_lower for keyword in ['ê²°ì œ', 'í˜ì´ë¨¼íŠ¸', 'ì •ì‚°', 'payment']):
                return f"{company_name}ì˜ '{sales_point}' ì—­ëŸ‰ê³¼ PortOneì˜ ê²°ì œ ì¸í”„ë¼ í†µí•© ì†”ë£¨ì…˜ ê°„ ë†’ì€ ì‹œë„ˆì§€ ê¸°ëŒ€. ê¸°ì¡´ ê°•ì ì„ ë”ìš± í™•ì¥í•  ìˆ˜ ìˆëŠ” ê¸°íšŒ"
            elif any(keyword in sales_lower for keyword in ['ë°ì´í„°', 'ë¶„ì„', 'ì¸ì‚¬ì´íŠ¸', 'analytics']):
                return f"{company_name}ì˜ '{sales_point}' ê²½í—˜ì„ PortOneì˜ ì‹¤ì‹œê°„ ê²°ì œ ë°ì´í„° ë¶„ì„ê³¼ ê²°í•©í•˜ì—¬ ë” ì •êµí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ êµ¬í˜„ ê°€ëŠ¥"
            elif any(keyword in sales_lower for keyword in ['ìë™í™”', 'automation', 'íš¨ìœ¨', 'efficiency']):
                return f"{company_name}ì˜ '{sales_point}' ë…¸í•˜ìš°ì™€ PortOneì˜ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì´ ê²°í•©ë˜ì–´ ìš´ì˜ íš¨ìœ¨ì„± ê·¹ëŒ€í™” ê°€ëŠ¥"
            else:
                return f"{company_name}ì˜ '{sales_point}' í•µì‹¬ ì—­ëŸ‰ì„ PortOneì˜ ê²°ì œ ì¸í”„ë¼ë¡œ ë”ìš± ê°•í™”í•˜ì—¬ ê²½ìŸ ìš°ìœ„ í™•ë³´ ê°€ëŠ¥"
        except Exception as e:
            return None
    
    def get_scale_specific_strategy(self, company_name, company_scale):
        """ê·œëª¨ë³„ íŠ¹í™” ì „ëµ"""
        try:
            scale_strategies = {
                'ìŠ¤íƒ€íŠ¸ì—…': f"{company_name} ê°™ì€ ìŠ¤íƒ€íŠ¸ì—…ì—ê²ŒëŠ” PortOneì˜ ë¹ ë¥¸ ë„ì…(2ì£¼), ë‚®ì€ ì´ˆê¸° ë¹„ìš©, 100ë§Œì› ìƒë‹¹ ë¬´ë£Œ ì»¨ì„¤íŒ…ì´ ê°€ì¥ ì í•©. ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½ìœ¼ë¡œ í•µì‹¬ ì œí’ˆ ê°œë°œì— ì§‘ì¤‘ ê°€ëŠ¥",
                'ì¤‘ê²¬ê¸°ì—…': f"{company_name} ê°™ì€ ì¤‘ê²¬ê¸°ì—…ì—ê²ŒëŠ” PortOneì˜ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ì™€ ë‹¤ì¤‘ PG í†µí•© ê´€ë¦¬ê°€ í•µì‹¬ ê°€ì¹˜. ì„±ì¥ì— ë”°ë¥¸ ê²°ì œëŸ‰ ì¦ê°€ì™€ ë³µì¡í•œ ì •ì‚° ìš”êµ¬ì‚¬í•­ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘",
                'ëŒ€ê¸°ì—…': f"{company_name} ê°™ì€ ëŒ€ê¸°ì—…ì—ê²ŒëŠ” PortOneì˜ ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥ê³¼ ê³ ë„í™”ëœ ë¶„ì„ ë„êµ¬ê°€ ì¤‘ìš”. ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬, ë³µì¡í•œ ì¡°ì§ êµ¬ì¡° ì§€ì›, ê³ ê¸‰ ë³´ì•ˆ ê¸°ëŠ¥ ì œê³µ",
                'ì¤‘ì†Œê¸°ì—…': f"{company_name} ê°™ì€ ì¤‘ì†Œê¸°ì—…ì—ê²ŒëŠ” PortOneì˜ ê°„í¸í•œ ì„¤ì •ê³¼ ì§ê´€ì  ê´€ë¦¬ ë„êµ¬ê°€ ìµœì . ë³µì¡í•œ IT ì§€ì‹ ì—†ì´ë„ ì „ë¬¸ì ì¸ ê²°ì œ ì‹œìŠ¤í…œ ìš´ì˜ ê°€ëŠ¥"
            }
            
            return scale_strategies.get(company_scale, f"{company_name}ì˜ {company_scale} íŠ¹ì„±ì— ìµœì í™”ëœ PortOne ì†”ë£¨ì…˜ êµ¬ì„±ìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼ ë‹¬ì„±")
        except Exception as e:
            return None
    
    def fetch_website_info(self, website, company_name):
        """ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ (WebFetch MCP ë„êµ¬ í™œìš©)"""
        try:
            import subprocess
            import json
            
            # WebFetch MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„
            prompt = f"{company_name}ì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: ì£¼ìš” ì œí’ˆ/ì„œë¹„ìŠ¤, ëŒ€ìƒ ê³ ê°, ìµœê·¼ ì—…ë°ì´íŠ¸ ë‚´ìš©, ê²°ì œ ê´€ë ¨ ì–¸ê¸‰ì‚¬í•­"
            
            # MCP WebFetch í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” MCP í”„ë¡œí† ì½œ ì‚¬ìš©)
            # í˜„ì¬ëŠ” requestsë¥¼ í†µí•œ ê°„ë‹¨í•œ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ëŒ€ì²´
            try:
                import requests
                from bs4 import BeautifulSoup
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                response = requests.get(website, headers=headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # ì œëª©ê³¼ ë©”íƒ€ ì„¤ëª… ì¶”ì¶œ
                    title = soup.find('title')
                    title_text = title.get_text().strip() if title else ""
                    
                    meta_desc = soup.find('meta', attrs={'name': 'description'})
                    desc_text = meta_desc.get('content', '') if meta_desc else ""
                    
                    # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¼ë¶€ ì¶”ì¶œ
                    paragraphs = soup.find_all('p')[:3]
                    body_text = ' '.join([p.get_text().strip() for p in paragraphs])
                    
                    web_info = f"ì œëª©: {title_text}\nì„¤ëª…: {desc_text}\në‚´ìš©: {body_text[:200]}..."
                    return web_info
                else:
                    return f"ì›¹ì‚¬ì´íŠ¸ ì ‘ê·¼ ì œí•œ (HTTP {response.status_code})"
                    
            except Exception as web_error:
                logger.warning(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {web_error}")
                return f"ì›¹ì‚¬ì´íŠ¸ ({website}) ì ‘ê·¼ ì‹œ ê¸°ìˆ ì  ë¬¸ì œ ë°œìƒ"
            
        except Exception as e:
            logger.error(f"ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def search_company_news_enhanced(self, company_name, search_keywords=None):
        """í™•ì¥ëœ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ (ë‹¤ì¤‘ ê²€ìƒ‰ ì—”ì§„ í™œìš© - í’ˆì§ˆ ê°œì„ )"""
        import concurrent.futures
        import time
        
        if not search_keywords:
            search_keywords = [company_name]
        
        all_results = []
        search_start_time = time.time()
        
        # ê° ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ë³‘ë ¬ ê²€ìƒ‰ (ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ)
        primary_keywords = search_keywords[:3]  # ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 3ê°œë¡œ ì œí•œ
        
        # ë³‘ë ¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰ (ì„±ëŠ¥ í–¥ìƒ)
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(primary_keywords) * 2) as executor:
            futures = []
            
            # ê° í‚¤ì›Œë“œë³„ë¡œ Googleê³¼ DuckDuckGo ê²€ìƒ‰ ì‹¤í–‰
            for keyword in primary_keywords:
                futures.append(executor.submit(self.search_with_google, keyword))
                futures.append(executor.submit(self.search_with_duckduckgo, keyword))
            
            # ì›¹ ìŠ¤í¬ë˜í•‘ì€ íšŒì‚¬ëª…ìœ¼ë¡œë§Œ ì‹¤í–‰
            futures.append(executor.submit(self.search_with_web_scraping, company_name))
            
            # ëª¨ë“  future ê²°ê³¼ ìˆ˜ì§‘
            for i, future in enumerate(futures):
                try:
                    result = future.result(timeout=10)
                    if result and len(result.strip()) > 10:
                        # ê²°ê³¼ ì†ŒìŠ¤ êµ¬ë¶„ (Google/DuckDuckGo/Web)
                        if i < len(primary_keywords) * 2:  # Google + DuckDuckGo ê²°ê³¼
                            keyword_idx = i // 2
                            search_engine = "Google" if i % 2 == 0 else "DuckDuckGo"
                            keyword = primary_keywords[keyword_idx]
                            source = f"ğŸ“° {search_engine} ({keyword})"
                        else:  # Web scraping ê²°ê³¼
                            source = f"ğŸŒ ì›¹ ê²€ìƒ‰ ({company_name})"
                        
                        all_results.append(f"{source}: {result}")
                except concurrent.futures.TimeoutError:
                    logger.warning(f"ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (ì¸ë±ìŠ¤ {i})")
                except Exception as e:
                    logger.warning(f"ê²€ìƒ‰ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i}): {e}")
        
        search_elapsed = time.time() - search_start_time
        logger.info(f"{company_name} ë‹¤ì¤‘ ê²€ìƒ‰ ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼, {search_elapsed:.2f}ì´ˆ ì†Œìš”")
        
        if all_results:
            # ê²°ê³¼ í’ˆì§ˆ ì ê²€ ë° ì¤‘ë³µ ì œê±°
            quality_results = self.filter_and_enhance_results(all_results, company_name)
            return quality_results
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì œê³µ
        return self.generate_fallback_news_info(company_name)
    
    def search_company_news_with_query(self, search_query, company_name):
        """enriched queryë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        import concurrent.futures
        import time
        
        all_results = []
        search_start_time = time.time()
        
        logger.info(f"{company_name} Enriched ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")
        
        # ë³‘ë ¬ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # enriched queryë¡œ ê²€ìƒ‰
            future_google = executor.submit(self.search_with_google_query, search_query)
            future_duckduckgo = executor.submit(self.search_with_duckduckgo_query, search_query)
            future_web = executor.submit(self.search_with_web_scraping, company_name)  # ì›¹ ìŠ¤í¬ë˜í•‘ì€ íšŒì‚¬ëª…ìœ¼ë¡œ
            
            futures = [future_google, future_duckduckgo, future_web]
            sources = ["Google", "DuckDuckGo", "ì›¹ ê²€ìƒ‰"]
            
            # ëª¨ë“  future ê²°ê³¼ ìˆ˜ì§‘
            for i, (future, source) in enumerate(zip(futures, sources)):
                try:
                    result = future.result(timeout=10)
                    if result:
                        # ê²°ê³¼ ê²€ì¦
                        result_str = str(result).strip()
                        if len(result_str) > 10:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                            # ì´ëª¨ì§€ ì¶”ê°€
                            emoji = "ğŸ“°" if source == "Google" else ("ğŸ¦†" if source == "DuckDuckGo" else "ğŸŒ")
                            formatted_result = f"{emoji} {source}: {result_str}"
                            all_results.append(formatted_result)
                            logger.info(f"{company_name} {source} ê²€ìƒ‰ ì„±ê³µ: {len(result_str)} ë¬¸ì")
                        else:
                            logger.warning(f"{company_name} {source} ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìŒ: {result_str}")
                    else:
                        logger.warning(f"{company_name} {source} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                except concurrent.futures.TimeoutError:
                    logger.warning(f"{company_name} {source} ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ (10ì´ˆ ì´ˆê³¼)")
                except Exception as e:
                    logger.warning(f"{company_name} {source} ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        search_elapsed = time.time() - search_start_time
        logger.info(f"{company_name} enriched ê²€ìƒ‰ ì™„ë£Œ: {len(all_results)}ê°œ ì›ë³¸ ê²°ê³¼, {search_elapsed:.2f}ì´ˆ ì†Œìš”")
        
        if all_results:
            # ê²°ê³¼ í’ˆì§ˆ ì ê²€ ë° ì¤‘ë³µ ì œê±°
            quality_results = self.filter_and_enhance_results(all_results, company_name)
            return quality_results
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ ì œê³µ
        logger.warning(f"{company_name} ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ì—ì„œ ê²°ê³¼ ì—†ìŒ - Fallback ì •ë³´ ì‚¬ìš©")
        return self.generate_fallback_news_info(company_name)
    
    def search_company_news(self, company_name):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - ìƒˆë¡œìš´ í™•ì¥ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
        return self.search_company_news_enhanced(company_name)
    
    def search_with_google(self, company_name):
        """Google Search API í™œìš©"""
        try:
            import requests
            import urllib.parse
            from datetime import datetime, timedelta
            
            # Google Custom Search API í‚¤ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
            google_api_key = os.getenv('GOOGLE_SEARCH_API_KEY')
            google_cse_id = os.getenv('GOOGLE_CSE_ID')
            
            if google_api_key and google_cse_id:
                # ìµœê·¼ 6ê°œì›” ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰
                recent_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
                search_query = f"{company_name} ë‰´ìŠ¤ íˆ¬ì ì‚¬ì—… í™•ì¥ after:{recent_date}"
                
                url = "https://www.googleapis.com/customsearch/v1"
                params = {
                    'key': google_api_key,
                    'cx': google_cse_id,
                    'q': search_query,
                    'num': 5,
                    'sort': 'date',
                    'tbm': 'nws'  # ë‰´ìŠ¤ ê²€ìƒ‰
                }
                
                response = requests.get(url, params=params, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    if items:
                        news_summaries = []
                        for item in items[:3]:
                            title = item.get('title', '')
                            snippet = item.get('snippet', '')
                            date = item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')
                            news_summaries.append(f"â€¢ {title} - {snippet[:100]}...")
                        
                        return "\n".join(news_summaries)
            
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ ê²€ìƒ‰ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
            return f"{company_name}ì˜ ìµœê·¼ ë¹„ì¦ˆë‹ˆìŠ¤ í™œë™ ë° ì„±ì¥ ë™í–¥ (Google ê²€ìƒ‰ ê¸°ë°˜)"
            
        except Exception as e:
            logger.warning(f"Google Search ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_google_query(self, search_query):
        """enriched queryë¥¼ ì‚¬ìš©í•œ Google ê²€ìƒ‰"""
        try:
            import requests
            from datetime import datetime, timedelta
            
            # Google Custom Search API í‚¤ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
            google_api_key = os.getenv('GOOGLE_SEARCH_API_KEY')
            google_cse_id = os.getenv('GOOGLE_CSE_ID')
            
            if google_api_key and google_cse_id:
                # enriched query ì‚¬ìš©
                recent_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
                enhanced_query = f"{search_query} ë‰´ìŠ¤ after:{recent_date}"
                
                url = "https://www.googleapis.com/customsearch/v1"
                params = {
                    'key': google_api_key,
                    'cx': google_cse_id,
                    'q': enhanced_query,
                    'num': 5,
                    'sort': 'date',
                    'tbm': 'nws'  # ë‰´ìŠ¤ ê²€ìƒ‰
                }
                
                response = requests.get(url, params=params, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    if items:
                        news_summaries = []
                        for item in items[:3]:
                            title = item.get('title', '')
                            snippet = item.get('snippet', '')
                            news_summaries.append(f"â€¢ {title} - {snippet[:100]}...")
                        
                        return "\n".join(news_summaries)
            
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° enriched queryë¥¼ í™œìš©í•œ ì‹œë®¬ë ˆì´ì…˜
            return f"ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ '{search_query}'ë¥¼ í™œìš©í•œ Google ê²€ìƒ‰ ê²°ê³¼: ë” êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ í™•ì¸"
            
        except Exception as e:
            logger.warning(f"Google Search ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_duckduckgo(self, company_name):
        """DuckDuckGo ê²€ìƒ‰ í™œìš©"""
        try:
            import requests
            import urllib.parse
            
            search_query = f"{company_name} ìµœì‹  ë‰´ìŠ¤ íˆ¬ì ì‚¬ì—… í™•ì¥ 2024"
            encoded_query = urllib.parse.quote(search_query)
            
            # DuckDuckGo Instant Answer API
            url = f"https://api.duckduckgo.com/?q={encoded_query}&format=json&no_html=1&skip_disambig=1"
            response = requests.get(url, timeout=20)
            
            if response.status_code == 200:
                data = response.json()
                
                # ì¶”ìƒ ì •ë³´ ì¶”ì¶œ
                abstract = data.get('Abstract', '')
                if abstract:
                    return f"ê²€ìƒ‰ ê²°ê³¼: {abstract}"
                
                # ê´€ë ¨ ì£¼ì œ ì¶”ì¶œ
                related_topics = data.get('RelatedTopics', [])
                if related_topics:
                    topic_texts = []
                    for topic in related_topics[:3]:
                        if isinstance(topic, dict) and 'Text' in topic:
                            topic_texts.append(topic['Text'])
                    if topic_texts:
                        return "; ".join(topic_texts)
            
            return f"{company_name}ì— ëŒ€í•œ DuckDuckGo ê²€ìƒ‰ ì™„ë£Œ"
            
        except Exception as e:
            logger.warning(f"DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
    
    def search_with_duckduckgo_query(self, search_query):
        """enriched queryë¥¼ ì‚¬ìš©í•œ DuckDuckGo ê²€ìƒ‰"""
        try:
            import requests
            import urllib.parse
            
            # enriched query ì‚¬ìš©
            encoded_query = urllib.parse.quote(search_query)
            
            # DuckDuckGo Instant Answer API
            url = f"https://api.duckduckgo.com/?q={encoded_query}&format=json&no_html=1&skip_disambig=1"
            response = requests.get(url, timeout=20)
            
            if response.status_code == 200:
                data = response.json()
                
                # ì¶”ìƒ ì •ë³´ ì¶”ì¶œ
                abstract = data.get('Abstract', '')
                if abstract:
                    return f"ê²€ìƒ‰ ê²°ê³¼: {abstract}"
                
                # ê´€ë ¨ ì£¼ì œ ì¶”ì¶œ
                related_topics = data.get('RelatedTopics', [])
                if related_topics:
                    topic_texts = []
                    for topic in related_topics[:3]:
                        if isinstance(topic, dict) and 'Text' in topic:
                            topic_texts.append(topic['Text'])
                    if topic_texts:
                        return "; ".join(topic_texts)
            
            return f"ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ '{search_query}'ë¥¼ í™œìš©í•œ DuckDuckGo ê²€ìƒ‰ ì™„ë£Œ: ë” ì •ë°€í•œ ì •ë³´ í™•ë³´"
        
        except Exception as e:
            logger.warning(f"DuckDuckGo ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜ (Perplexity ë³´ì¡°ìš©): {e}")
            return None
    
    def search_with_web_scraping(self, company_name):
        """ì›¹ ìŠ¤í¬ë˜í•‘ì„ í†µí•œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # ì•ˆì „í•œ ì›¹ ìŠ¤í¬ë˜í•‘ (robots.txt ì¤€ìˆ˜)
            import requests
            from bs4 import BeautifulSoup
            import time
            import random
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (ê³µê°œ API ì•„ë‹Œ ê²½ìš° ì œí•œì  ì‚¬ìš©)
            news_info = []
            
            # íšŒì‚¬ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë³´ë„ìë£Œ/ë‰´ìŠ¤ ì„¹ì…˜ í™•ì¸
            if hasattr(self, 'company_website'):
                try:
                    # ì§§ì€ ë”œë ˆì´ë¡œ ì„œë²„ ë¶€í•˜ ë°©ì§€
                    time.sleep(random.uniform(1, 3))
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    
                    # ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì˜ ë‰´ìŠ¤/ë³´ë„ìë£Œ í˜ì´ì§€ ì¶”ì •
                    potential_urls = [
                        f"{self.company_website}/news",
                        f"{self.company_website}/press",
                        f"{self.company_website}/media",
                        f"{self.company_website}/announcement"
                    ]
                    
                    for url in potential_urls[:2]:  # ìµœëŒ€ 2ê°œë§Œ í™•ì¸
                        try:
                            response = requests.get(url, headers=headers, timeout=10)
                            if response.status_code == 200:
                                soup = BeautifulSoup(response.content, 'html.parser')
                                # ìµœì‹  ë‰´ìŠ¤ ì œëª©ë“¤ ì¶”ì¶œ
                                news_titles = soup.find_all(['h1', 'h2', 'h3', 'h4'], limit=3)
                                for title in news_titles:
                                    if title.get_text().strip():
                                        news_info.append(title.get_text().strip()[:100])
                                break
                        except:
                            continue
                            
                except Exception as scrape_error:
                    logger.debug(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì œí•œ: {scrape_error}")
            
            if news_info:
                return f"ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ìµœì‹  ì†Œì‹: {'; '.join(news_info[:2])}"
            
            return f"{company_name}ì˜ ê³µê°œ ì •ë³´ ë° ìµœì‹  ë™í–¥ (ì›¹ ê²€ìƒ‰ ê¸°ë°˜)"
            
        except Exception as e:
            logger.warning(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return None
    
    def filter_and_enhance_results(self, all_results, company_name):
        """ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í•„í„°ë§ ë° í–¥ìƒ"""
        try:
            if not all_results:
                logger.warning(f"{company_name}: í•„í„°ë§í•  ê²°ê³¼ê°€ ì—†ìŒ")
                return self.generate_fallback_news_info(company_name)
            
            enhanced_results = []
            seen_content = set()
            
            for result in all_results:
                try:
                    # ì•ˆì „í•œ ê²°ê³¼ ë‚´ìš© ì¶”ì¶œ
                    if isinstance(result, str) and result.strip():
                        # ì´ëª¨ì§€ì™€ í—¤ë” ì œê±°
                        if ': ' in result:
                            parts = result.split(': ', 1)
                            content = parts[1] if len(parts) > 1 else result
                        else:
                            content = result
                        
                        content = content.strip()
                        content_lower = content.lower()
                        
                        # í’ˆì§ˆ ê²€ì‚¬ - ìµœì†Œ ê¸¸ì´ í™•ì¸
                        if len(content) < 15:
                            logger.debug(f"ë„ˆë¬´ ì§§ì€ ê²°ê³¼ ì œì™¸: {content[:50]}")
                            continue
                        
                        # ë¬´ì˜ë¯¸í•œ ê²°ê³¼ ì œê±°
                        skip_phrases = [
                            'ê²€ìƒ‰ ê²°ê³¼',
                            'ë” êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´',
                            'api í‚¤ê°€ ì—†ëŠ” ê²½ìš°',
                            'ì‹œë®¬ë ˆì´ì…˜'
                        ]
                        if any(phrase in content_lower for phrase in skip_phrases):
                            logger.debug(f"ë¬´ì˜ë¯¸í•œ ê²°ê³¼ ì œì™¸: {content[:50]}")
                            continue
                        
                        # ì¤‘ë³µ ë‚´ìš© ì œê±° (ìœ ì‚¬ë„ ê¸°ë°˜)
                        is_duplicate = False
                        for seen in seen_content:
                            if self.calculate_similarity(content_lower, seen) > 0.7:
                                is_duplicate = True
                                logger.debug(f"ì¤‘ë³µ ê²°ê³¼ ì œì™¸: {content[:50]}")
                                break
                        
                        if not is_duplicate:
                            seen_content.add(content_lower)
                            enhanced_results.append(result)
                            logger.debug(f"ìœ íš¨í•œ ê²°ê³¼ ì¶”ê°€: {content[:100]}")
                    
                except Exception as e:
                    logger.warning(f"ê°œë³„ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e} - {result[:100] if isinstance(result, str) else result}")
                    continue
            
            if enhanced_results:
                # ìµœì‹ ì„± ìˆœì„œë¡œ ì •ë ¬ (Google ë‰´ìŠ¤ ìš°ì„ )
                enhanced_results.sort(key=lambda x: (
                    0 if 'ğŸ“° Google' in str(x) else
                    1 if 'ğŸ¦† DuckDuckGo' in str(x) or 'DuckDuckGo' in str(x) else
                    2 if 'ğŸŒ ì›¹' in str(x) or 'ì›¹ ê²€ìƒ‰' in str(x) else 3
                ))
                
                result_text = "\n\n".join(enhanced_results)
                logger.info(f"{company_name}: {len(enhanced_results)}ê°œ ìœ íš¨ ê²°ê³¼ ë°˜í™˜")
                return result_text
            
            logger.warning(f"{company_name}: í•„í„°ë§ í›„ ìœ íš¨ ê²°ê³¼ ì—†ìŒ")
            return self.generate_fallback_news_info(company_name)
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ í•„í„°ë§ ì˜¤ë¥˜: {e}", exc_info=True)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì›ë³¸ ê²°ê³¼ ë°˜í™˜ ì‹œë„
            if all_results and len(all_results) > 0:
                return "\n\n".join([str(r) for r in all_results if r])
            return self.generate_fallback_news_info(company_name)
    
    def calculate_similarity(self, text1, text2):
        """ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„)"""
        try:
            words1 = set(text1.split())
            words2 = set(text2.split())
            
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            
            if len(union) == 0:
                return 0
            return len(intersection) / len(union)
        except:
            return 0
    
    def generate_fallback_news_info(self, company_name):
        """ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì •ë³´ ìƒì„±"""
        try:
            from datetime import datetime
            
            current_year = datetime.now().year
            
            fallback_info = f"""
ğŸ” {company_name} ìµœì‹  ë™í–¥ ì •ë³´

ğŸ“ˆ {company_name}ì€(ëŠ”) {current_year}ë…„ í˜„ì¬ ë””ì§€í„¸ ì „í™˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ í˜ì‹ ì— ì§€ì†ì ìœ¼ë¡œ íˆ¬ìí•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

ğŸ’¼ ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼:
â€¢ ê²°ì œ ì‹œìŠ¤í…œ í˜„ëŒ€í™” ë° íš¨ìœ¨í™”
â€¢ ê³ ê° ê²½í—˜ ê°œì„ ì„ ìœ„í•œ ë””ì§€í„¸ ì†”ë£¨ì…˜ ë„ì…
â€¢ ìš´ì˜ íš¨ìœ¨ì„± í–¥ìƒì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ìë™í™”
â€¢ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ êµ¬ì¶•

ğŸ¯ ì˜ˆìƒ ì„±ì¥ ë™ë ¥:
â€¢ ì˜¨ë¼ì¸/ëª¨ë°”ì¼ ì„œë¹„ìŠ¤ í™•ì¥
â€¢ ê²°ì œ ì¸í”„ë¼ í†µí•© ë° ìµœì í™” í•„ìš”ì„±
â€¢ ê³ ê° ë°ì´í„° ë¶„ì„ì„ í†µí•œ ê°œì¸í™” ì„œë¹„ìŠ¤

âš¡ PortOne ì†”ë£¨ì…˜ ì ìš© í¬ì¸íŠ¸:
â€¢ One Payment Infraë¡œ í†µí•© ê²°ì œ í™˜ê²½ êµ¬ì¶•
â€¢ ì¬ë¬´ ìë™í™”ë¡œ ìš´ì˜ íš¨ìœ¨ì„± ê·¹ëŒ€í™”  
â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°ìœ¼ë¡œ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì§‘ì¤‘

â€» ë” ì •í™•í•œ ìµœì‹  ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•´ì„œëŠ” Google Search API í‚¤ë¥¼ ì„¤ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
            return fallback_info.strip()
            
        except Exception as e:
            logger.error(f"Fallback ì •ë³´ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"{company_name} ê´€ë ¨ ìµœì‹  ë™í–¥ ë° ë‰´ìŠ¤ ì •ë³´ (ì¼ë°˜ì  ì •ë³´)"
    
    def get_active_search_engines(self):
        """í™œì„±í™”ëœ ê²€ìƒ‰ ì—”ì§„ ëª©ë¡ ë°˜í™˜"""
        active_engines = ['Perplexity']
        
        # Google Search API í‚¤ í™•ì¸
        if os.getenv('GOOGLE_SEARCH_API_KEY') and os.getenv('GOOGLE_CSE_ID'):
            active_engines.append('Google Search')
        
        # DuckDuckGoëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
        active_engines.append('DuckDuckGo')
        
        # ì›¹ ìŠ¤í¬ë˜í•‘ì€ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ
        if hasattr(self, 'company_website') and self.company_website:
            active_engines.append('Web Scraping')
            
        return active_engines
    
    def get_industry_insights(self, industry, company_name):
        """ì—…ì¢…ë³„ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘"""
        try:
            # ì—…ì¢…ë³„ íŠ¹í™”ëœ ì •ë³´ ìˆ˜ì§‘
            insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name} ê°™ì€ ì´ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì˜ ì£¼ìš” ê²°ì œ/ì •ì‚° ê³¼ì œ",
                'í•€í…Œí¬': f"{company_name} ê°™ì€ í•€í…Œí¬ ê¸°ì—…ì˜ ê·œì œ ì¤€ìˆ˜ ë° ê¸°ìˆ  í˜ì‹  ë™í–¥",
                'ì œì¡°ì—…': f"{company_name} ê°™ì€ ì œì¡°ì—…ì²´ì˜ B2B ê²°ì œ ì‹œìŠ¤í…œ ë³µì¡ì„±",
                'SaaS': f"{company_name} ê°™ì€ SaaS ê¸°ì—…ì˜ êµ¬ë… ê²°ì œ ë° ê¸€ë¡œë²Œ í™•ì¥ ì´ìŠˆ"
            }
            
            return insights.get(industry, f"{company_name}ì˜ {industry} ì—…ì¢… íŠ¹ì„±ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë‹ˆì¦ˆ")
            
        except Exception as e:
            logger.error(f"ì—…ì¢…ë³„ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None
    
    def validate_business_number(self, business_num, company_name):
        """ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ë° ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # ì‚¬ì—…ìë²ˆí˜¸ ìœ íš¨ì„± ê²€ì¦ ë° ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
            # ì‹¤ì œë¡œëŠ” ê³µê³µ APIë‚˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•œ ê²€ì¦
            if business_num and len(business_num.replace('-', '')) == 10:
                return f"ì‚¬ì—…ìë²ˆí˜¸ {business_num}ë¡œ í™•ì¸ëœ {company_name}ì˜ ì‚¬ì—…ì ë“±ë¡ ì •ë³´"
            else:
                return f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ í™•ì¸ í•„ìš”: {business_num}"
                
        except Exception as e:
            logger.error(f"ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return None
    
    def format_perplexity_response(self, raw_content, company_name):
        """Perplexity API ì‘ë‹µì˜ ê°€ë…ì„± ë° í¬ë§·íŒ… ê°œì„ """
        try:
            import re
            
            # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬
            content = raw_content.strip()
            
            # 2. ê³¼ë„í•œ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
            content = re.sub(r'\n{3,}', '\n\n', content)  # 3ê°œ ì´ìƒ ì—°ì† ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
            content = re.sub(r'[ \t]{2,}', ' ', content)   # 2ê°œ ì´ìƒ ì—°ì† ìŠ¤í˜ì´ìŠ¤ë¥¼ 1ê°œë¡œ
            
            # 3. ì„¹ì…˜ í—¤ë” í¬ë§·íŒ… ê°œì„ 
            content = re.sub(r'^\*\*([^*]+)\*\*$', r'## \1', content, flags=re.MULTILINE)
            content = re.sub(r'^# ([^#])', r'## \1', content, flags=re.MULTILINE)
            
            # 4. ë¦¬ìŠ¤íŠ¸ í•­ëª© í¬ë§·íŒ… ê°œì„ 
            content = re.sub(r'^\s*[-â€¢]\s*', 'â€¢ ', content, flags=re.MULTILINE)
            content = re.sub(r'^\s*(\d+)\.?\s*', r'\1. ', content, flags=re.MULTILINE)
            
            # 5. íšŒì‚¬ëª… ì¼ê´€ì„± í™•ë³´ (ëŒ€ì†Œë¬¸ì ë° ë„ì–´ì“°ê¸°)
            if company_name:
                # íšŒì‚¬ëª… ë³€í˜•ë“¤ì„ í‘œì¤€ í˜•íƒœë¡œ í†µì¼
                company_variations = [
                    company_name.lower(),
                    company_name.upper(),
                    company_name.replace(' ', ''),
                    company_name.replace('-', ' ')
                ]
                
                for variation in company_variations:
                    if variation != company_name and len(variation) > 2:
                        content = re.sub(
                            r'\b' + re.escape(variation) + r'\b', 
                            company_name, 
                            content, 
                            flags=re.IGNORECASE
                        )
            
            # 6. êµ¬ì¡°í™”ëœ í¬ë§·ìœ¼ë¡œ ì¬ì •ë¦¬
            formatted_sections = []
            lines = content.split('\n')
            current_section = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # ì„¹ì…˜ í—¤ë” ê°ì§€
                if line.startswith('##') or line.startswith('**') and line.endswith('**'):
                    if current_section:
                        formatted_sections.append('\n'.join(current_section))
                        current_section = []
                    current_section.append(line)
                else:
                    current_section.append(line)
            
            # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
            if current_section:
                formatted_sections.append('\n'.join(current_section))
            
            # 7. ìµœì¢… í¬ë§·íŒ…
            final_content = '\n\n'.join(formatted_sections)
            
            # 8. í™˜ê° ë°©ì§€ë¥¼ ìœ„í•œ ê²€ì¦ ë§ˆì»¤ ì¶”ê°€
            verification_note = f"\n\n---\nğŸ’¡ **ì •ë³´ ê²€ì¦**: ìœ„ ë‚´ìš©ì€ ìµœì‹  ê³µê°œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìœ¼ë©°, {company_name}ì˜ ì‹¤ì œ ìƒí™©ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            final_content += verification_note
            
            logger.info(f"Perplexity ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ: {len(raw_content)} â†’ {len(final_content)} ë¬¸ì")
            
            return final_content
            
        except Exception as e:
            logger.error(f"Perplexity ì‘ë‹µ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
            # í¬ë§·íŒ… ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return raw_content
    
    def _fix_malformed_json(self, json_content):
        """ì†ìƒëœ JSON ë³µêµ¬ ì‹œë„"""
        try:
            import re
            
            # 1. ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œ ìˆ˜ì •
            fixed_content = json_content
            
            # 2. ë¶ˆì™„ì „í•œ ë¬¸ìì—´ ìˆ˜ì • (ëë‚˜ì§€ ì•Šì€ ë¬¸ìì—´)
            # ë§ˆì§€ë§‰ ë”°ì˜´í‘œê°€ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš° ìˆ˜ì •
            lines = fixed_content.split('\n')
            for i, line in enumerate(lines):
                # í‚¤: "ê°’" íŒ¨í„´ì—ì„œ ê°’ ë¶€ë¶„ì´ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš°
                if line.strip().endswith('"') == False and '"' in line and ':' in line:
                    # ë¬¸ìì—´ì´ ë‹«íˆì§€ ì•Šì•˜ë‹¤ë©´ ë‹«ì•„ì£¼ê¸°
                    quote_count = line.count('"')
                    if quote_count % 2 == 1:  # í™€ìˆ˜ ê°œì˜ ë”°ì˜´í‘œ = ë‹«íˆì§€ ì•ŠìŒ
                        lines[i] = line + '"'
            
            fixed_content = '\n'.join(lines)
            
            # 3. í›„í–‰ ì‰¼í‘œ ì œê±°
            fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)
            
            # 4. ì¤‘ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
            open_braces = fixed_content.count('{')
            close_braces = fixed_content.count('}')
            if open_braces > close_braces:
                fixed_content += '}' * (open_braces - close_braces)
            
            return fixed_content
            
        except Exception as e:
            logger.debug(f"JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return None
    
    def verify_company_information(self, company_name, research_data, additional_info=None):
        """í™˜ê° ë°©ì§€ë¥¼ ìœ„í•œ íšŒì‚¬ ì •ë³´ ê²€ì¦"""
        try:
            verification_results = {
                'confidence_score': 0,
                'verified_facts': [],
                'potential_issues': [],
                'reliability_indicators': []
            }
            
            # 1. ê¸°ë³¸ ì‹ ë¢°ë„ ê²€ì‚¬
            base_confidence = 50  # ê¸°ë³¸ ì‹ ë¢°ë„
            
            # 2. ì›¹ì‚¬ì´íŠ¸ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
            if additional_info and additional_info.get('í™ˆí˜ì´ì§€ë§í¬'):
                website = additional_info.get('í™ˆí˜ì´ì§€ë§í¬')
                if self.verify_website_exists(website):
                    verification_results['verified_facts'].append(f"ì›¹ì‚¬ì´íŠ¸ {website} ì ‘ê·¼ ê°€ëŠ¥")
                    base_confidence += 20
                else:
                    verification_results['potential_issues'].append(f"ì›¹ì‚¬ì´íŠ¸ {website} ì ‘ê·¼ ë¶ˆê°€")
                    base_confidence -= 10
            
            # 3. ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦
            if additional_info and additional_info.get('ì‚¬ì—…ìë²ˆí˜¸'):
                business_num = additional_info.get('ì‚¬ì—…ìë²ˆí˜¸')
                if self.validate_business_number_format(business_num):
                    verification_results['verified_facts'].append(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ìœ íš¨: {business_num}")
                    base_confidence += 15
                else:
                    verification_results['potential_issues'].append(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ì˜ì‹¬: {business_num}")
                    base_confidence -= 15
            
            # 4. ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
            research_content = research_data.get('company_info', '')
            consistency_score = self.check_content_consistency(research_content, company_name)
            base_confidence += consistency_score
            
            if consistency_score > 15:
                verification_results['reliability_indicators'].append("ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ë†’ìŒ")
            elif consistency_score < -10:
                verification_results['reliability_indicators'].append("ì—°êµ¬ ë°ì´í„° ì¼ê´€ì„± ì˜ì‹¬")
            
            # 5. íšŒì‚¬ëª… ì‹¤ì¡´ì„± ì¶”ì •
            name_validity = self.estimate_company_name_validity(company_name)
            base_confidence += name_validity
            
            if name_validity > 10:
                verification_results['verified_facts'].append(f"íšŒì‚¬ëª… '{company_name}' ì‹¤ì¡´ ê°€ëŠ¥ì„± ë†’ìŒ")
            elif name_validity < -5:
                verification_results['potential_issues'].append(f"íšŒì‚¬ëª… '{company_name}' ì‹¤ì¡´ ì—¬ë¶€ ì˜ì‹¬")
            
            # 6. ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0-100)
            verification_results['confidence_score'] = max(0, min(100, base_confidence))
            
            # 7. ì¢…í•© í‰ê°€
            if verification_results['confidence_score'] >= 80:
                verification_results['overall_assessment'] = "ë†’ì€ ì‹ ë¢°ë„"
            elif verification_results['confidence_score'] >= 60:
                verification_results['overall_assessment'] = "ë³´í†µ ì‹ ë¢°ë„"
            elif verification_results['confidence_score'] >= 40:
                verification_results['overall_assessment'] = "ë‚®ì€ ì‹ ë¢°ë„"
            else:
                verification_results['overall_assessment'] = "ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„"
            
            logger.info(f"{company_name} ì •ë³´ ê²€ì¦ ì™„ë£Œ: ì‹ ë¢°ë„ {verification_results['confidence_score']}%")
            
            return verification_results
            
        except Exception as e:
            logger.error(f"ì •ë³´ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'confidence_score': 50,
                'verified_facts': [],
                'potential_issues': [f"ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}"],
                'reliability_indicators': [],
                'overall_assessment': "ê²€ì¦ ë¶ˆê°€"
            }
    
    def verify_website_exists(self, website):
        """ì›¹ì‚¬ì´íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            import requests
            
            if not website or not website.startswith(('http://', 'https://')):
                return False
            
            response = requests.head(website, timeout=5, allow_redirects=True)
            return response.status_code < 400
            
        except Exception as e:
            logger.debug(f"ì›¹ì‚¬ì´íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def validate_business_number_format(self, business_num):
        """ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦"""
        try:
            if not business_num:
                return False
            
            # í•˜ì´í”ˆ ì œê±°í•˜ê³  ìˆ«ìë§Œ í™•ì¸
            clean_num = business_num.replace('-', '').replace(' ', '')
            
            # 10ìë¦¬ ìˆ«ìì¸ì§€ í™•ì¸
            if len(clean_num) != 10 or not clean_num.isdigit():
                return False
            
            # ê°„ë‹¨í•œ ì²´í¬ì„¬ ê²€ì¦ (ì‹¤ì œ ì‚¬ì—…ìë²ˆí˜¸ ê²€ì¦ ì•Œê³ ë¦¬ì¦˜)
            digits = [int(d) for d in clean_num]
            multipliers = [1, 3, 7, 1, 3, 7, 1, 3, 5]
            
            sum_val = sum(d * m for d, m in zip(digits[:9], multipliers))
            remainder = sum_val % 10
            check_digit = (10 - remainder) % 10
            
            return check_digit == digits[9]
            
        except Exception as e:
            logger.debug(f"ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def check_content_consistency(self, content, company_name):
        """ì—°êµ¬ ë‚´ìš©ì˜ ì¼ê´€ì„± ê²€ì¦"""
        try:
            import re
            
            score = 0
            content_lower = content.lower()
            company_lower = company_name.lower()
            
            # íšŒì‚¬ëª… ì–¸ê¸‰ ë¹ˆë„ í™•ì¸
            company_mentions = len(re.findall(re.escape(company_lower), content_lower))
            if company_mentions >= 3:
                score += 10
            elif company_mentions >= 1:
                score += 5
            else:
                score -= 20  # íšŒì‚¬ëª…ì´ ê±°ì˜ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ
            
            # êµ¬ì²´ì  ì •ë³´ ì¡´ì¬ ì—¬ë¶€
            specific_indicators = [
                r'\d{4}ë…„', r'ë§¤ì¶œ', r'íˆ¬ì', r'ì„¤ë¦½', r'ì§ì›', r'ì‚¬ì—…', r'ì„œë¹„ìŠ¤',
                r'ê³ ê°', r'ì‹œì¥', r'ê¸°ìˆ ', r'ì†”ë£¨ì…˜', r'í”Œë«í¼'
            ]
            
            specific_matches = 0
            for indicator in specific_indicators:
                if re.search(indicator, content_lower):
                    specific_matches += 1
            
            if specific_matches >= 5:
                score += 15
            elif specific_matches >= 3:
                score += 10
            elif specific_matches < 2:
                score -= 10
            
            # ëª¨í˜¸í•œ í‘œí˜„ íŒ¨ë„í‹°
            vague_terms = [
                'ì¶”ì •', 'ì˜ˆìƒ', 'ê°€ëŠ¥ì„±', 'ê²ƒìœ¼ë¡œ ë³´ì„', 'ì•Œë ¤ì§€ì§€ ì•ŠìŒ', 
                'í™•ì¸ë˜ì§€ ì•ŠìŒ', 'ì •ë³´ ë¶€ì¡±'
            ]
            
            vague_matches = 0
            for term in vague_terms:
                vague_matches += len(re.findall(term, content_lower))
            
            if vague_matches > 5:
                score -= 15
            elif vague_matches > 2:
                score -= 5
            
            return score
            
        except Exception as e:
            logger.debug(f"ë‚´ìš© ì¼ê´€ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return 0
    
    def estimate_company_name_validity(self, company_name):
        """íšŒì‚¬ëª… ì‹¤ì¡´ì„± ì¶”ì •"""
        try:
            score = 0
            
            if not company_name or len(company_name) < 2:
                return -20
            
            # í•œêµ­ íšŒì‚¬ëª… íŒ¨í„´ í™•ì¸
            korean_company_suffixes = [
                'íšŒì‚¬', 'ê¸°ì—…', 'ì½”í¼ë ˆì´ì…˜', 'ì¸í„°ë‚´ì…”ë„', 'ê·¸ë£¹', 'í™€ë”©ìŠ¤',
                'í…Œí¬', 'ì†”ë£¨ì…˜', 'ì‹œìŠ¤í…œ', 'ì„œë¹„ìŠ¤', 'ë¯¸ë””ì–´', 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
                'ë°”ì´ì˜¤', 'íŒŒë§ˆ', 'í—¬ìŠ¤ì¼€ì–´', 'ì—ë„ˆì§€', 'ì¸ë”ìŠ¤íŠ¸ë¦¬'
            ]
            
            for suffix in korean_company_suffixes:
                if suffix in company_name:
                    score += 5
                    break
            
            # ì˜ë¬¸ íšŒì‚¬ëª… íŒ¨í„´ í™•ì¸
            english_patterns = [
                'Inc', 'Corp', 'Ltd', 'LLC', 'Co.', 'Solutions', 'Systems', 
                'Technologies', 'Services', 'Industries', 'Global'
            ]
            
            for pattern in english_patterns:
                if pattern in company_name:
                    score += 5
                    break
            
            # ì´ìƒí•œ íŒ¨í„´ íŒ¨ë„í‹°
            weird_patterns = [
                r'^\d+$',  # ìˆ«ìë§Œ
                r'^[!@#$%^&*()]+',  # íŠ¹ìˆ˜ë¬¸ìë¡œ ì‹œì‘
                r'.{50,}',  # ë„ˆë¬´ ê¸´ ì´ë¦„ (50ì ì´ìƒ)
            ]
            
            import re
            for pattern in weird_patterns:
                if re.search(pattern, company_name):
                    score -= 15
            
            return score
            
        except Exception as e:
            logger.debug(f"íšŒì‚¬ëª… ìœ íš¨ì„± ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0
    
    def perform_enhanced_search(self, company_name, additional_info, verification_result):
        """ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œ CSV ì •ë³´ë¥¼ í™œìš©í•œ ì§‘ì¤‘ì  ì¶”ê°€ ê²€ìƒ‰"""
        try:
            logger.info(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì‹œì‘ - í˜„ì¬ ì‹ ë¢°ë„: {verification_result['confidence_score']}%")
            
            enhanced_results = []
            search_strategies = []
            
            # 1. CSV ì •ë³´ ê¸°ë°˜ íƒ€ê²Ÿ ê²€ìƒ‰
            if additional_info:
                # ì‚¬ì—…ìë²ˆí˜¸ë¡œ ê³µì‹ ì •ë³´ ê²€ìƒ‰
                if additional_info.get('ì‚¬ì—…ìë²ˆí˜¸'):
                    business_search = self.search_by_business_number(
                        company_name, 
                        additional_info.get('ì‚¬ì—…ìë²ˆí˜¸')
                    )
                    if business_search:
                        enhanced_results.append(f"ğŸ“‹ ì‚¬ì—…ìì •ë³´: {business_search}")
                        search_strategies.append("ì‚¬ì—…ìë²ˆí˜¸ ê²€ìƒ‰")
                
                # ì—…ì¢… ê¸°ë°˜ ì—…ê³„ ì •ë³´ ê°•í™”
                if additional_info.get('ì—…ì¢…'):
                    industry = additional_info.get('ì—…ì¢…')
                    industry_context = self.get_enhanced_industry_context(company_name, industry)
                    if industry_context:
                        enhanced_results.append(f"ğŸ­ ì—…ê³„ ì»¨í…ìŠ¤íŠ¸: {industry_context}")
                        search_strategies.append("ì—…ì¢…ë³„ ë¶„ì„")
                
                # ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ í™œìš©í•œ íŠ¹í™” ê²€ìƒ‰
                if additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸'):
                    sales_point = additional_info.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸')
                    specialized_search = self.search_by_sales_focus(company_name, sales_point)
                    if specialized_search:
                        enhanced_results.append(f"ğŸ’¼ íŠ¹í™” ë¶„ì•¼: {specialized_search}")
                        search_strategies.append("ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ ë¶„ì„")
                
                # ê·œëª¨ ì •ë³´ ê¸°ë°˜ ë§ì¶¤ ê²€ìƒ‰
                if additional_info.get('ê·œëª¨'):
                    company_size = additional_info.get('ê·œëª¨')
                    size_based_info = self.get_size_based_insights(company_name, company_size)
                    if size_based_info:
                        enhanced_results.append(f"ğŸ“Š ê·œëª¨ë³„ ì¸ì‚¬ì´íŠ¸: {size_based_info}")
                        search_strategies.append("ê·œëª¨ë³„ ë¶„ì„")
            
            # 2. ì‹ ë¢°ë„ ë¬¸ì œì  ê¸°ë°˜ ì§‘ì¤‘ ê²€ìƒ‰
            issues = verification_result.get('potential_issues', [])
            for issue in issues:
                if "ì›¹ì‚¬ì´íŠ¸" in issue:
                    # ëŒ€ì²´ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ë„¤ì´ë²„, ë‹¤ìŒ ë“±)
                    alt_search = self.search_alternative_web_presence(company_name)
                    if alt_search:
                        enhanced_results.append(f"ğŸŒ ì›¹ ì¡´ì¬ê°: {alt_search}")
                        search_strategies.append("ëŒ€ì²´ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰")
                
                elif "ì‚¬ì—…ìë²ˆí˜¸" in issue:
                    # ìœ ì‚¬ íšŒì‚¬ëª…ìœ¼ë¡œ ì¬ê²€ìƒ‰
                    similar_search = self.search_similar_company_names(company_name)
                    if similar_search:
                        enhanced_results.append(f"ğŸ” ìœ ì‚¬ëª… ê²€ìƒ‰: {similar_search}")
                        search_strategies.append("ìœ ì‚¬ëª… ê²€ìƒ‰")
            
            # 3. ì¢…í•© ê²°ê³¼ êµ¬ì„±
            if enhanced_results:
                content = "\n".join(enhanced_results)
                strategies_used = ", ".join(search_strategies)
                
                logger.info(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì™„ë£Œ: {len(enhanced_results)}ê°œ ê²°ê³¼, ì „ëµ: {strategies_used}")
                
                return {
                    'success': True,
                    'content': content,
                    'strategies_used': strategies_used,
                    'results_count': len(enhanced_results),
                    'timestamp': datetime.now().isoformat()
                }
            else:
                logger.warning(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            logger.error(f"{company_name} ì¶”ê°€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def search_by_business_number(self, company_name, business_number):
        """ì‚¬ì—…ìë²ˆí˜¸ ê¸°ë°˜ ê³µì‹ ì •ë³´ ê²€ìƒ‰"""
        try:
            # ì‹¤ì œë¡œëŠ” ê³µê³µë°ì´í„° APIë‚˜ ì‚¬ì—…ìì •ë³´ ì¡°íšŒ ì„œë¹„ìŠ¤ í™œìš©
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
            if business_number and len(business_number.replace('-', '')) == 10:
                return f"{company_name}({business_number})ì˜ ì‚¬ì—…ì ë“±ë¡ ì •ë³´ í™•ì¸ë¨"
            return None
        except Exception as e:
            logger.debug(f"ì‚¬ì—…ìë²ˆí˜¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def get_enhanced_industry_context(self, company_name, industry):
        """ì—…ì¢… ê¸°ë°˜ ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸ ì œê³µ"""
        try:
            industry_insights = {
                'ì´ì»¤ë¨¸ìŠ¤': f"{company_name}ëŠ” ì˜¨ë¼ì¸ ì»¤ë¨¸ìŠ¤ ìƒíƒœê³„ì—ì„œ ê²°ì œ/ì •ì‚° ë³µì¡ì„±ì´ ì£¼ìš” ê³¼ì œ",
                'í•€í…Œí¬': f"{company_name}ëŠ” ê¸ˆìœµ ì„œë¹„ìŠ¤ë¡œì„œ ê²°ì œ ì¸í”„ë¼ì˜ ì•ˆì •ì„±ê³¼ ê·œì œ ì¤€ìˆ˜ê°€ í•µì‹¬",
                'ì œì¡°ì—…': f"{company_name}ëŠ” B2B ê±°ë˜ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ëŸ‰ ê²°ì œì™€ ê³µê¸‰ë§ ì •ì‚° ê´€ë¦¬ê°€ ì¤‘ìš”",
                'SaaS': f"{company_name}ëŠ” êµ¬ë… ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ë¡œ ì •ê¸°ê²°ì œì™€ ê¸€ë¡œë²Œ í™•ì¥ì´ ì£¼ìš” ê´€ì‹¬ì‚¬",
                'ITì„œë¹„ìŠ¤': f"{company_name}ëŠ” ê¸°ìˆ  ê¸°ì—…ìœ¼ë¡œì„œ ê°œë°œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±ê³¼ ì‹œìŠ¤í…œ í†µí•©ì´ ìš°ì„ ìˆœìœ„",
                'ê²Œì„': f"{company_name}ëŠ” ëª¨ë°”ì¼ê²Œì„ ì—…ê³„ë¡œì„œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ì„ ì›¹ìƒì  ê°œì„¤ë¡œ 90% ì ˆì•½í•˜ëŠ” ê²ƒì´ í•µì‹¬ ê³¼ì œ",
                'ëª¨ë°”ì¼ê²Œì„': f"{company_name}ëŠ” ì›¹ìƒì  êµ¬ì¶•ì„ í†µí•œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 90% ì ˆì•½ê³¼ ê²°ì œ ì „í™˜ìœ¨ ìµœì í™”ê°€ ì£¼ìš” ê´€ì‹¬ì‚¬",
                'ì•±ê²Œì„': f"{company_name}ëŠ” ì›¹ìƒì  ê°œì„¤ì˜ ê¸°ìˆ ì  í—ˆë“¤ì„ ê·¹ë³µí•˜ì—¬ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆê°í•˜ëŠ” ê²ƒì´ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì˜ í•µì‹¬"
            }
            
            return industry_insights.get(industry, f"{company_name}ì˜ {industry} ì—…ì¢… íŠ¹ì„±ìƒ ê²°ì œ íš¨ìœ¨í™”ê°€ ì¤‘ìš”í•œ ê³¼ì œ")
            
        except Exception as e:
            logger.debug(f"ì—…ì¢… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def search_by_sales_focus(self, company_name, sales_point):
        """ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ê¸°ë°˜ íŠ¹í™” ê²€ìƒ‰"""
        try:
            # ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•´ì„œ PortOne ì†”ë£¨ì…˜ê³¼ì˜ ì—°ê²°ì  ì°¾ê¸°
            focus_insights = {}
            
            if any(keyword in sales_point.lower() for keyword in ['ê²°ì œ', 'payment', 'ì •ì‚°']):
                return f"{company_name}ì˜ '{sales_point}' ê°•ì ì„ PortOne ê²°ì œ ì¸í”„ë¼ë¡œ ë”ìš± ê°•í™” ê°€ëŠ¥"
            
            elif any(keyword in sales_point.lower() for keyword in ['íš¨ìœ¨', 'efficiency', 'ìë™í™”']):
                return f"{company_name}ì˜ '{sales_point}' ê²½í—˜ì´ PortOne ì¬ë¬´ìë™í™”ì™€ ì‹œë„ˆì§€ ì°½ì¶œ ê°€ëŠ¥"
            
            elif any(keyword in sales_point.lower() for keyword in ['ê¸€ë¡œë²Œ', 'global', 'í™•ì¥']):
                return f"{company_name}ì˜ '{sales_point}' ë¹„ì „ì„ PortOne ê¸€ë¡œë²Œ ê²°ì œë¡œ ì‹¤í˜„ ì§€ì› ê°€ëŠ¥"
            
            else:
                return f"{company_name}ì˜ '{sales_point}' ê°•ì ì„ ê²°ì œ ì¸í”„ë¼ í˜ì‹ ìœ¼ë¡œ ë”ìš± ë°œì „ì‹œí‚¬ ê¸°íšŒ"
                
        except Exception as e:
            logger.debug(f"ì„¸ì¼ì¦ˆ í¬ì¸íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def get_size_based_insights(self, company_name, company_size):
        """íšŒì‚¬ ê·œëª¨ ê¸°ë°˜ ë§ì¶¤ ì¸ì‚¬ì´íŠ¸"""
        try:
            size_strategies = {
                'ìŠ¤íƒ€íŠ¸ì—…': f"{company_name}ëŠ” ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œì„œ ë¹ ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì´ í•µì‹¬",
                'ì¤‘ê²¬ê¸°ì—…': f"{company_name}ëŠ” ì¤‘ê²¬ê¸°ì—…ìœ¼ë¡œì„œ í™•ì¥ì„± ìˆëŠ” ê²°ì œ ì¸í”„ë¼ì™€ ìš´ì˜ ìë™í™”ê°€ í•„ìš”",
                'ëŒ€ê¸°ì—…': f"{company_name}ëŠ” ëŒ€ê¸°ì—…ìœ¼ë¡œì„œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê²°ì œ ì†”ë£¨ì…˜ê³¼ ê³ ë„í™”ëœ ë¶„ì„ì´ ìš”êµ¬ë¨",
                'ì¤‘ì†Œê¸°ì—…': f"{company_name}ëŠ” ì¤‘ì†Œê¸°ì—…ìœ¼ë¡œì„œ ê°„í¸í•œ ê²°ì œ í†µí•©ê³¼ ê´€ë¦¬ íš¨ìœ¨ì„± í–¥ìƒì´ ìš°ì„ "
            }
            
            return size_strategies.get(company_size, f"{company_name}ì˜ {company_size} ê·œëª¨ì— ë§ëŠ” ê²°ì œ ì†”ë£¨ì…˜ í•„ìš”")
            
        except Exception as e:
            logger.debug(f"ê·œëª¨ë³„ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def search_alternative_web_presence(self, company_name):
        """ëŒ€ì²´ ì›¹ ì¡´ì¬ê° ê²€ìƒ‰ (ë„¤ì´ë²„, ë¸”ë¡œê·¸ ë“±)"""
        try:
            # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ API, ë‹¤ìŒ ê²€ìƒ‰ ë“± í™œìš©
            return f"{company_name}ì˜ ì˜¨ë¼ì¸ í™œë™ ë° ì†Œì…œë¯¸ë””ì–´ ì¡´ì¬ê° í™•ì¸ë¨"
        except Exception as e:
            logger.debug(f"ëŒ€ì²´ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def search_similar_company_names(self, company_name):
        """ìœ ì‚¬ íšŒì‚¬ëª… ê²€ìƒ‰"""
        try:
            # ì‹¤ì œë¡œëŠ” ê¸°ì—…ëª… ìœ ì‚¬ë„ ê²€ìƒ‰ì´ë‚˜ ë™ìŒì´ì˜ì–´ ê²€ìƒ‰ ìˆ˜í–‰
            return f"{company_name}ì™€ ìœ ì‚¬í•œ ëª…ì¹­ì˜ ê¸°ì—…ë“¤ê³¼ êµ¬ë³„ë˜ëŠ” ê³ ìœ í•œ íŠ¹ì„± í™•ì¸ í•„ìš”"
        except Exception as e:
            logger.debug(f"ìœ ì‚¬ëª… ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def get_industry_trends(self, industry):
        """ì—…ì¢…ë³„ ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ ìˆ˜ì§‘"""
        
        trend_query = f"""
        {industry} ì—…ê³„ì˜ ìµœì‹  íŠ¸ë Œë“œì™€ ê²°ì œ ì‹œìŠ¤í…œ ê´€ë ¨ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”:
        1. ì—…ê³„ ì „ë°˜ì˜ ë””ì§€í„¸ ì „í™˜ í˜„í™©
        2. ê²°ì œ ì‹œìŠ¤í…œ ë° í•€í…Œí¬ ë„ì… íŠ¸ë Œë“œ
        3. ì£¼ìš” í˜ì¸ í¬ì¸íŠ¸ì™€ í•´ê²° ë°©ì•ˆ
        4. ê²½ìŸì‚¬ë“¤ì˜ ê¸°ìˆ  ë„ì… ì‚¬ë¡€
        
        ìµœê·¼ 6ê°œì›” ì´ë‚´ì˜ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        data = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "user", 
                    "content": trend_query
                }
            ],
            "max_tokens": 800,
            "temperature": 0.3
        }
        
        try:
            response = requests.post(
                self.perplexity_url, 
                json=data, 
                headers=self.headers,
                timeout=30
            )
            
            logger.info(f"Perplexity API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code != 200:
                logger.error(f"Perplexity API ì˜¤ë¥˜ ì‘ë‹µ: {response.text}")
                # API ì˜¤ë¥˜ ì‹œ ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ ë°˜í™˜
                return {
                    'success': True,
                    'trends': "ê²°ì œ ì¸í”„ë¼ í†µí•© ë° ë””ì§€í„¸ ì „í™˜ì´ ì£¼ìš” íŠ¸ë Œë“œ",
                    'timestamp': datetime.now().isoformat(),
                    'note': 'API ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
                }
            
            result = response.json()
            
            return {
                'success': True,
                'trends': result['choices'][0]['message']['content'],
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Perplexity API ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
            return {
                'success': True,
                'trends': "ë””ì§€í„¸ ì „í™˜ ë° í†µí•© ê²°ì œ ì†”ë£¨ì…˜ ë„ì… ì¦ê°€",
                'timestamp': datetime.now().isoformat(),
                'note': f'API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ: {str(e)}'
            }



class EmailCopywriter:
    """Claude Opus 4.1ì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ë©”ì¼ ë¬¸ì•ˆ ìƒì„±"""
    
    def __init__(self):
        self.claude_client = ClaudeBedrockClient()
    
    def generate_email_variations(self, company_data, research_data, industry_trends=None):
        """Zendesk ëª¨ë²” ì‚¬ë¡€ë¥¼ ë°˜ì˜í•œ ê³ í’ˆì§ˆ ê°œì¸í™” ë©”ì¼ ë¬¸ì•ˆ ìƒì„± (ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ë³„ ë™ì  ìƒì„±)"""
        
        logger.info("=" * 60)
        logger.info("ğŸ“§ ì´ë©”ì¼ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        logger.info("=" * 60)
        
        company_name = company_data.get('íšŒì‚¬ëª…', 'ê·€í•˜ì˜ íšŒì‚¬')
        ceo_name = company_data.get('ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìë‹˜')
        contact_position = company_data.get('ì§ì±…', '') or company_data.get('ì§ê¸‰', '')
        website = company_data.get('í™ˆí˜ì´ì§€ë§í¬', '')
        sales_point = company_data.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸', '').lower().strip()
        
        logger.info(f"ğŸ¢ íšŒì‚¬ ì •ë³´:")
        logger.info(f"   - íšŒì‚¬ëª…: {company_name}")
        logger.info(f"   - ëŒ€í‘œìëª…: {ceo_name}")
        logger.info(f"   - í™ˆí˜ì´ì§€: {website}")
        logger.info(f"   - ì„¸ì¼ì¦ˆí¬ì¸íŠ¸: {sales_point}")
        
        logger.debug(f"ğŸ“‹ ì „ì²´ company_data: {company_data}")
        logger.debug(f"ğŸ“‹ ì „ì²´ research_data: {research_data}")

        # ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ
        personalization_elements = self._extract_personalization_elements(company_data, research_data)
        
        # ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ì— ë”°ë¼ ìƒì„±í•  ì´ë©”ì¼ ìœ í˜• ê²°ì •
        email_definitions = {
            "opi_professional": {
                "product": "One Payment Infra", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 8
            },
            "opi_curiosity": {
                "product": "One Payment Infra", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            },
            "finance_professional": {
                "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 8
            },
            "finance_curiosity": {
                "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            },
            "game_d2c_professional": {
                "product": "ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤", "personalization_score": 9
            },
            "game_d2c_curiosity": {
                "product": "ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™” ì†”ë£¨ì…˜", "subject": "ì œëª© (7ë‹¨ì–´/41ì ì´ë‚´)", "body": "ë³¸ë¬¸ (200-300ë‹¨ì–´)", "cta": "êµ¬ì²´ì ì¸ í–‰ë™ ìœ ë„ ë¬¸êµ¬", "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤", "personalization_score": 9
            }
        }
        
        requested_emails = {}
        if sales_point == 'opi':
            requested_emails = {k: v for k, v in email_definitions.items() if 'opi' in k}
        elif sales_point == 'recon':
            requested_emails = {k: v for k, v in email_definitions.items() if 'finance' in k}
        elif sales_point == 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°':
            requested_emails = {k: v for k, v in email_definitions.items() if 'game_d2c' in k}
        else: # 'opi + recon' ë˜ëŠ” ë¹ˆì¹¸ì¼ ê²½ìš°
            requested_emails = {k: v for k, v in email_definitions.items() if 'opi' in k or 'finance' in k}

        # ë™ì ìœ¼ë¡œ JSON ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±
        json_request_prompt = json.dumps(requested_emails, ensure_ascii=False, indent=2)
        
        # Geminiì—ê²Œ ì „ë‹¬í•  ìƒì„¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ë¡œ, ì‹¤ì œ ê²€ì¦ëœ í•œêµ­ì–´ ì˜ì—… ì´ë©”ì¼ íŒ¨í„´ì„ ì™„ë²½íˆ ìˆ™ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
- íšŒì‚¬ëª…: {company_name}
- ëŒ€í‘œì/ë‹´ë‹¹ì: {ceo_name}

**Perplexity ì¡°ì‚¬ ê²°ê³¼ (ìµœì‹  ê¸°ì‚¬/í™œë™/íŠ¸ë Œë“œ):**
{research_data.get('company_info', 'í•´ë‹¹ íšŒì‚¬ëŠ” ì„±ì¥í•˜ëŠ” ê¸°ì—…ìœ¼ë¡œ ë””ì§€í„¸ í˜ì‹ ê³¼ íš¨ìœ¨ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ì— ê´€ì‹¬ì´ ë†’ìŠµë‹ˆë‹¤.')}

**íšŒì‚¬ë³„ ë§ì¶¤ Pain Points:**
{research_data.get('pain_points', 'ì¼ë°˜ì ì¸ Pain Point')}

**ê°œì¸í™” ìš”ì†Œ:**
{personalization_elements}

**ê²€ì¦ëœ ì„±ê³¼ ì¢‹ì€ í•œêµ­ì–´ ì´ë©”ì¼ í…œí”Œë¦¿ ì°¸ê³ ìš© (ìŠ¤íƒ€ì¼ê³¼ í†¤ ì°¸ê³ ):**

**ì°¸ê³  í…œí”Œë¦¿ 1: ì§ì ‘ì  Pain Point ì ‘ê·¼**
"ì•ˆë…•í•˜ì„¸ìš”, íšŒì‚¬ëª… ë‹´ë‹¹ìë‹˜. ì½”ë¦¬ì•„í¬íŠ¸ì› ì˜¤ì¤€í˜¸ì…ë‹ˆë‹¤.
í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PGì‚¬ì˜ ë†’ì€ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´, ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìˆ˜ìˆ˜ë£Œ ì¸ìƒ,
ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ë³„ ìµœì  PG ì„ íƒì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?
ì €í¬ í¬íŠ¸ì›ì€ ë‹¨ í•˜ë‚˜ì˜ ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´ ë¹„êµ ë¶„ì„, ìµœì  PGì‚¬ ê²¬ì  ì œì•ˆ,
ê·¸ë¦¬ê³  ê¸€ë¡œë²Œ í™•ì¥ì„±ê¹Œì§€ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 2: ê¸°ìˆ  ë‹´ë‹¹ì ëŒ€ìƒ**
"í˜¹ì‹œ ì´ì‚¬ë‹˜ê»˜ì„œë„ ë‹¨ì¼ PGì‚¬ ì¢…ì†ìœ¼ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ê´€ë¦¬,
ì—¬ëŸ¬ PGì‚¬ ì—°ë™ ì‹œ ë°œìƒí•˜ëŠ” ê°œë°œ/ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ì— ëŒ€í•œ ê³ ë¯¼ì„ í•˜ê³ ê³„ì‹ ê°€ìš”?
í¬íŠ¸ì›ì€ ë‹¨ í•œ ë²ˆì˜ API ì—°ë™ìœ¼ë¡œ 50ê°œ ì´ìƒì˜ PGì‚¬ë¥¼ í†µí•©í•˜ê³ ,
ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 3: ì±„ìš© ì»¨í…ìŠ¤íŠ¸ í™œìš©**
"ìµœê·¼ 'ì¬ë¬´/íšŒê³„ ë‹´ë‹¹ì' ì±„ìš©ì„ ì§„í–‰í•˜ì‹œëŠ” ê²ƒì„ ë³´ê³  ì—°ë½ë“œë ¸ìŠµë‹ˆë‹¤.
ë§Œì•½ ìƒˆë¡œ í•©ë¥˜í•œ ìœ ëŠ¥í•œ ì¸ì¬ê°€, ê°€ì¥ ë¨¼ì € ë§ˆì£¼í•  ì—…ë¬´ê°€ ì—¬ëŸ¬ PGì‚¬ ì‚¬ì´íŠ¸ë¥¼ ì˜¤ê°€ë©°
ì—‘ì…€ë¡œ ì •ì‚° ë‚´ì—­ì„ ë§ì¶”ëŠ” ë‹¨ìˆœ ë°˜ë³µì ì¸ ìˆ˜ì‘ì—…ì´ë¼ë©´ ì–´ë–¨ê¹Œìš”?
ì €í¬ í¬íŠ¸ì›ì€ ì´ëŸ¬í•œ ë¶ˆí•„ìš”í•œ ìˆ˜ì‘ì—…ì„ ì•½ 90% ì´ìƒ ìë™í™”í•˜ì—¬,
ê·€í•œ ì¸ì¬ê°€ íšŒì‚¬ì˜ ì„±ì¥ì— ê¸°ì—¬í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ì¬ë¬´ ì „ëµ ì—…ë¬´ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë•ìŠµë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê·œëª¨ì˜ ê³ ê°ì‚¬ë“¤ì´ ê¸°ì¡´ ëŒ€ë¹„ í‰ê·  15-30% ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 4: ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ ì´ìŠˆ**
"ë§¤ì¶œì´ 10ì–µ, 30ì–µì„ ë„˜ì–´ì„œë©° ì„±ì¥í• ìˆ˜ë¡, PGì‚¬ì˜ 'ì˜ì¤‘ì†Œ êµ¬ê°„' ë³€ê²½ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ ë” ë‚´ê³  ê³„ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
í¬íŠ¸ì›ì€ êµ­ë‚´ 25ê°œ ì´ìƒ PGì‚¬ì™€ì˜ ì œíœ´ë¥¼ í†µí•´, íšŒì‚¬ëª…ì´ í˜„ì¬ë³´ë‹¤ ë” ë‚®ì€ ìˆ˜ìˆ˜ë£Œë¥¼ ì ìš©ë°›ì„ ìˆ˜ ìˆë„ë¡ ë¹ ë¥´ê²Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê·œëª¨ì˜ ê³ ê°ì‚¬ë“¤ì´ ê¸°ì¡´ ëŒ€ë¹„ í‰ê·  15-30% ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 5: ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™”**
"í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìš´ì˜í•˜ê³  ê³„ì‹œëŠ”ë°
ë„¤ì´ë²„í˜ì´, ì¿ íŒ¡ ë“± ì˜¤í”ˆë§ˆì¼“ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ë§¤ì¶œê³¼ ì‹¤ì œ ì…ê¸ˆì•¡ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ”
'ì •ì‚°' ì—…ë¬´ì— ìƒê°ë³´ë‹¤ ë§ì€ ì‹œê°„ì„ ìŸê³  ìˆì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”?
ì €í¬ PortOneì˜ ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì€ ì—¬ëŸ¬ ì±„ë„ì˜ ì •ì‚° ë‚´ì—­ì„ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ëŒ€ì‚¬í•˜ì—¬,
ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì‹¤ìˆ˜ë¥¼ ì›ì²œì ìœ¼ë¡œ ë§‰ê³  ìˆ¨ì–´ìˆë˜ ë¹„ìš©ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."

**ì°¸ê³  í…œí”Œë¦¿ 6: ê²Œì„ì—…ê³„ D2C ì›¹ìƒì  ê²°ì œ ìµœì í™”**
"í˜¹ì‹œ ì• í”Œ ì•±ìŠ¤í† ì–´ì™€ êµ¬ê¸€ í”Œë ˆì´ìŠ¤í† ì–´ì˜ 30% ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì‹œì§€ ì•Šë‚˜ìš”?
ìµœê·¼ Com2uS, Neptune, Ntrance ë“± êµ­ë‚´ ì£¼ìš” ê²Œì„ì‚¬ë“¤ë„ D2C ì›¹ìƒì ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì„ ëŒ€í­ ì¤„ì´ê³  ê³„ì‹œëŠ”ë°,
ë§‰ìƒ ì§ì ‘ êµ¬ì¶•í•˜ë ¤ë‹¤ ë³´ë‹ˆ êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™, ì •ì‚° ê´€ë¦¬, ìˆ˜ìˆ˜ë£Œ ìµœì í™” ë“±ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
ì €í¬ PortOneì€ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ë¥¼ í†µí•©í•˜ì—¬, ìµœì ì˜ ë¹„ìš©ìœ¼ë¡œ ì›¹ìƒì  ê²°ì œë¥¼ ìš´ì˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.
ì‹¤ì œë¡œ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ ê°€ì§„ ë‹¤ë¥¸ ê²Œì„ì‚¬ ê³ ê°ë‹˜ë“¤ë„ ê¸°ì¡´ ëŒ€ë¹„ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆì•½í•˜ë©°,
PGì‚¬ë³„ ì •ì‚° ê´€ë¦¬ ì—…ë¬´ë„ ì½˜ì†”ì—ì„œ í†µí•© ê´€ë¦¬í•˜ì—¬ ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ:**
1. YouTube ì˜ìƒ ë§í¬: "https://www.youtube.com/watch?v=2EjzX6uTlKc" (ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ)
2. "1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
3. êµ¬ì²´ì  CTA: "ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."

**One Payment Infraë¡œ í•´ê²° ê°€ëŠ¥í•œ Pain Points:**
- ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì— 6ê°œì›”+ ì†Œìš”ë˜ëŠ” ë¬¸ì œ â†’ 2ì£¼ ë‚´ êµ¬ì¶•
- ì—¬ëŸ¬ PGì‚¬ ê´€ë¦¬ì˜ ë³µì¡ì„± â†’ 50+ PGì‚¬ í†µí•© ê´€ë¦¬
- ê²°ì œ ì‹¤íŒ¨ë¡œ ì¸í•œ ë§¤ì¶œ ì†ì‹¤ â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ 15% ì„±ê³µë¥  í–¥ìƒ
- ë†’ì€ ê°œë°œ ë¹„ìš© ë¶€ë‹´ â†’ 85% ë¦¬ì†ŒìŠ¤ ì ˆê° + 100ë§Œì› ë¬´ë£Œ ì»¨ì„¤íŒ…
- ê²°ì œ ì¥ì•  ëŒ€ì‘ì˜ ì–´ë ¤ì›€ â†’ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° 24/7 ì§€ì›
- ì •ê¸°ê²°ì œ, ë³¸ì¸ì¸ì¦ ë“± ì¶”ê°€ ê°œë°œ â†’ ì›ìŠ¤í†± ì„œë¹„ìŠ¤ ì œê³µ

**ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•œ Pain Points:**
- ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ìˆ˜ì‘ì—… ì—‘ì…€ ì‘ì—… â†’ 90% ì´ìƒ ìë™í™”
- ë„¤ì´ë²„/ì¹´ì¹´ì˜¤/ì¹´í˜24 ë“± ì±„ë„ë³„ ë°ì´í„° ë¶ˆì¼ì¹˜ â†’ í†µí•© ê´€ë¦¬
- êµ¬ë§¤í™•ì •-ì •ì‚°ë‚´ì—­ ë§¤í•‘ ì˜¤ë¥˜ â†’ ë†’ì€ ì •í™•ë„ì˜ ìë™ ë§¤í•‘
- ë¶€ê°€ì„¸ ì‹ ê³  ìë£Œ ì¤€ë¹„ì˜ ë³µì¡ì„± â†’ ìë™í™”ëœ ì„¸ë¬´ ìë£Œ ìƒì„±
- ë°ì´í„° ëˆ„ë½ìœ¼ë¡œ ì¸í•œ ì†ì‹¤ â†’ ë†’ì€ ë°ì´í„° ì •í•©ì„± ë³´ì¥
- ë¶€ì •í™•í•œ ì†ìµ ë¶„ì„ â†’ ì‹¤ì‹œê°„ ì •í™•í•œ ì¬ë¬´ ë°ì´í„° ì œê³µ
- ì±„ê¶Œ/ë¯¸ìˆ˜ê¸ˆ ê´€ë¦¬ì˜ ì–´ë ¤ì›€ â†’ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ ì œê³µ

**ê²Œì„ì—…ê³„ íŠ¹í™” ì†”ë£¨ì…˜ (ëª¨ë°”ì¼ê²Œì„/ì•±ê²Œì„ ëŒ€ìƒ):**
- ì•±ìŠ¤í† ì–´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 30% ë¶€ë‹´ â†’ D2C ì›¹ìƒì ìœ¼ë¡œ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ 90% ì ˆì•½
- êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™ ë³µì¡ì„± â†’ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ ëª¨ë“  PGì‚¬ í†µí•©
- PGì‚¬ë³„ ìˆ˜ìˆ˜ë£Œ ìµœì í™” ì–´ë ¤ì›€ â†’ ì½˜ì†”ì—ì„œ ì‹¤ì‹œê°„ PGì‚¬ ë³€ê²½ ë° ê²°ì œ ë¹„ìœ¨ ì„¤ì •
- ë³µì¡í•œ ì •ì‚° ê´€ë¦¬ ì—…ë¬´ â†’ ëª¨ë“  PGì‚¬ ì •ì‚°ë‚´ì—­ì„ í†µì¼ëœ í˜•íƒœë¡œ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
- ì›¹ìƒì  êµ¬ì¶•ì˜ ê¸°ìˆ ì  í—ˆë“¤ â†’ PortOne D2C ì›¹ìƒì  ê²°ì œ ì†”ë£¨ì…˜ìœ¼ë¡œ ê°„í¸ êµ¬ì¶•
- í•´ì™¸ ì§„ì¶œ ì‹œ ê¸€ë¡œë²Œ ê²°ì œ ëŒ€ì‘ â†’ ë©€í‹° MoR ì „ëµ ë° í¬ë¦½í†  ê²°ì œ(1.7% ìˆ˜ìˆ˜ë£Œ) ì§€ì›
- MoR ìš´ì˜ ë¹„ìš© ë¶€ë‹´ â†’ ë¹„ MoR ê²°ì œì‚¬ ìš´ì˜ìœ¼ë¡œ 50% ë¹„ìš© ì ˆê°
- ì°¨ì§€ë°± ë¦¬ìŠ¤í¬ â†’ í¬ë¦½í†  ê²°ì œë¡œ No Chargeback + D+1 ì •ì‚°

**CRITICAL: ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  íŒ¨í„´:**
- 'ê·€ì‚¬'ë¼ëŠ” ë‹¨ì–´ ëŒ€ì‹  ë°˜ë“œì‹œ '{company_name}' íšŒì‚¬ëª…ì„ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
- ë¬¸ë‹¨ êµ¬ë¶„ì„ ìœ„í•´ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ ë¬¸ì(\n)ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
- ìƒí™©ë³„ ë§ì¶¤ ì ‘ê·¼ë²• ì‚¬ìš© (ìœ„ í…œí”Œë¦¿ë“¤ ì°¸ê³ )
- YouTube ì˜ìƒ ë§í¬ í•„ìˆ˜ í¬í•¨
- "ë‹¤ìŒ ì£¼ ì¤‘" ì¼ì • ìš”ì²­ìœ¼ë¡œ CTA ë§ˆë¬´ë¦¬
- êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í˜œíƒ ì–¸ê¸‰ (85% ì ˆê°, 90% ìë™í™” ë“±)
- **ì •ëŸ‰ì  ìˆ˜ì¹˜ì™€ í•µì‹¬ ê°€ì¹˜ ì œì•ˆì€ ë°˜ë“œì‹œ ë³¼ë“œ ì²˜ë¦¬í•˜ì„¸ìš” (ì˜ˆ: **85% ë¦¬ì†ŒìŠ¤ ì ˆê°**, **2ì£¼ ë‚´ êµ¬ì¶•**, **90% ìë™í™”**, **15% í–¥ìƒ** ë“±)**
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì²´ ìœ ì§€
- í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆì„ ìœ„í•´ ë¬¸ë‹¨ì€ ì ì ˆí•œ ê¸¸ì´ë¡œ êµ¬ë¶„í•˜ì„¸ìš”
- **âš ï¸ ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œ ê·¹ë‹¨ì  í‘œí˜„ ê¸ˆì§€**: "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì™„ë²½", "ì ˆëŒ€", "ë¬´ì¡°ê±´", "ë°˜ë“œì‹œ", "í•„ìˆ˜" ë“± ê³¼ì¥ëœ í‘œí˜„ì€ í”¼í•˜ê³ , í˜„ì‹¤ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "90% ì´ìƒ", "ë¹ ë¥´ê²Œ", "ë†’ì€ ì •í™•ë„ë¡œ", "ëŒ€í­", "í¬ê²Œ", "íš¨ê³¼ì ìœ¼ë¡œ" ë“±)


**ëª…í•¨ ì •ë³´: ë°˜ë“œì‹œ ë‹¤ìŒ ì„œëª…ìœ¼ë¡œ ëë‚´ê¸°:**
{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io

**ë°˜ë“œì‹œ JSON í˜•íƒœë¡œ ë‹¤ìŒ ì´ë©”ì¼ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”:**
{json_request_prompt}

ê° ì´ë©”ì¼ì€ ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
1. ê°œì¸í™”ëœ ì¸ì‚¬ ë° íšŒì‚¬ ê´€ë ¨ ì–¸ê¸‰ (ê²€ì¦ëœ í…œí”Œë¦¿ íŒ¨í„´ í™œìš©)
2. í•µì‹¬ ì§ˆë¬¸ ë˜ëŠ” ë¬¸ì œ ì œê¸° (íšŒì‚¬ë³„ Pain Points í™œìš©)
3. PortOneì˜ êµ¬ì²´ì  ê°€ì¹˜ ì œì•ˆ (ìˆ˜ì¹˜ í¬í•¨)
4. ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ CTA
5. ì „ë¬¸ì ì¸ ì„œëª… (ëª…í•¨ ì •ë³´)

**ì¤‘ìš”:** ê° ìŠ¤íƒ€ì¼ë³„ë¡œ ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ê³¼ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ëª¨ë“  ì´ë©”ì¼ì´ {company_name}ì— íŠ¹í™”ëœ ê°œì¸í™” ìš”ì†Œë¥¼ í¬í•¨í•˜ê³  ì œê³µëœ í…œí”Œë¦¿ íŒ¨í„´ì„ ì°¸ê³ í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        # ë™ì ìœ¼ë¡œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ìƒì„±
        email_schema_properties = {}
        for key in requested_emails.keys():
            email_schema_properties[key] = {
                "type": "object",
                "properties": {
                    "subject": {"type": "string"},
                    "body": {"type": "string"}
                },
                "required": ["subject", "body"]
            }

        payload = {
            "contents": [
                {
                    "parts": [
                        {
                            "text": context
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 4096,
                "responseMimeType": "application/json",
                "responseSchema": {
                    "type": "object",
                    "properties": email_schema_properties,
                    "required": list(requested_emails.keys())
                }
            }
        }
        
        try:
            logger.info("ğŸ¤– Claude API í˜¸ì¶œ ì¤€ë¹„")
            logger.info(f"   - íšŒì‚¬: {company_name}")
            logger.info(f"   - ì„¸ì¼ì¦ˆí¬ì¸íŠ¸: {sales_point}")
            logger.info(f"   - ìš”ì²­ ì´ë©”ì¼: {list(requested_emails.keys())}")
            
            # Claude í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
            if not self.claude_client.bedrock_runtime:
                logger.warning("âš ï¸  Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                raise Exception("Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            if not self.claude_client.model_id:
                logger.warning("âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ì´ ì—†ìŒ")
                raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"âœ… Claude ëª¨ë¸: {self.claude_client.model_id}")
            
            # Claudeë¡œ í”„ë¡¬í”„íŠ¸ ì „ì†¡
            prompt_text = context + '\n\n' + '\n\n'.join([f"# {key}\n{value}" for key, value in requested_emails.items()])
            logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt_text)} ë¬¸ì")
            
            logger.info("ğŸš€ Claude API í˜¸ì¶œ ì‹œì‘...")
            content = self.claude_client.generate_content(prompt_text)
            logger.info(f"âœ… Claude ì‘ë‹µ ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
            
            logger.info("ğŸ” Claude ì‘ë‹µ íŒŒì‹± ì‹œì‘...")
            email_variations = self._parse_claude_response(content, company_name)
            logger.info(f"âœ… ì´ë©”ì¼ íŒŒì‹± ì™„ë£Œ - ìƒì„±ëœ ì´ë©”ì¼: {len(email_variations)}ê°œ")
            
            return {
                'success': True,
                'variations': email_variations,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Claude API ì˜¤ë¥˜: {str(e)}")
            logger.info("ğŸ”„ í´ë°± ì´ë©”ì¼ ìƒì„± ì¤‘...")
            
            fallback_emails = self.generate_fallback_emails(company_name, sales_point, ceo_name, contact_position)
            logger.info(f"âœ… í´ë°± ì´ë©”ì¼ ìƒì„± ì™„ë£Œ - {len(fallback_emails)}ê°œ")
            
            return {
                'success': False,
                'error': f'Claude API ì˜¤ë¥˜: {str(e)}',
                'variations': fallback_emails
            }
    
    def _parse_claude_response(self, content, company_name):
        """Claude API ì‘ë‹µì„ ì•ˆì •ì ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” ë©”ì„œë“œ"""
        print(f"\n=== Claude ì‘ë‹µ íŒŒì‹± ì‹œì‘ ===\níšŒì‚¬: {company_name}")
        print(f"ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
        
        # JSON íŒŒì‹±ì„ ìœ„í•œ ê°•ë ¥í•œ ì „ì²˜ë¦¬
        import re
        
        # 1. ê¸°ë³¸ ì •ë¦¬
        cleaned_content = content.strip()
        
        # 2. JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ë˜ëŠ” { ... } íŒ¨í„´)
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', cleaned_content, re.DOTALL)
        if json_match:
            json_content = json_match.group(1)
            print("ğŸ“¦ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ì„±ê³µ")
        else:
            json_match = re.search(r'(\{[^{}]*\{[^{}]*\}[^{}]*\})', cleaned_content, re.DOTALL)
            if json_match:
                json_content = json_match.group(1)
                print("ğŸ“¦ ì¤‘ê´„í˜¸ íŒ¨í„´ì—ì„œ JSON ì¶”ì¶œ ì„±ê³µ")
            else:
                json_content = cleaned_content
                print("ğŸ“¦ ì „ì²´ ë‚´ìš©ì„ JSONìœ¼ë¡œ ì²˜ë¦¬")
        
        # 3. ê°•ë ¥í•œ JSON ì •ë¦¬
        # ë¬¸ìì—´ ë‚´ë¶€ì˜ ì¤„ë°”ê¿ˆì„ \\nìœ¼ë¡œ ë³€í™˜
        def clean_json_string(text):
            # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¬¸ìì—´ì„ ì°¾ì•„ì„œ ë‚´ë¶€ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            def replace_newlines_in_string(match):
                string_content = match.group(1)
                # ë¬¸ìì—´ ë‚´ë¶€ì˜ ì‹¤ì œ ì¤„ë°”ê¿ˆì„ ì´ìŠ¤ì¼€ì´í”„ëœ í˜•íƒœë¡œ ë³€í™˜
                string_content = string_content.replace('\n', '\\n')
                string_content = string_content.replace('\r', '\\r')
                string_content = string_content.replace('\t', '\\t')
                return f'"{string_content}"'
            
            # ë¬¸ìì—´ íŒ¨í„´ ë§¤ì¹­ ë° ë³€í™˜
            text = re.sub(r'"([^"]*)"', replace_newlines_in_string, text, flags=re.DOTALL)
            return text
        
        json_content = clean_json_string(json_content)
        
        # 4. ê¸°íƒ€ ì •ë¦¬
        json_content = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', json_content)  # ì œì–´ ë¬¸ì
        json_content = re.sub(r',\s*}', '}', json_content)  # í›„í–‰ ì‰¼í‘œ ì œê±°
        json_content = re.sub(r',\s*]', ']', json_content)  # í›„í–‰ ì‰¼í‘œ ì œê±°
        
        print(f"ì •ë¦¬ëœ JSON ê¸¸ì´: {len(json_content)} ë¬¸ì")
        print(f"ì •ë¦¬ëœ JSON ì‹œì‘: {json_content[:100]}...")
        
        try:
            # ì •ë¦¬ëœ JSON ë‚´ìš©ìœ¼ë¡œ íŒŒì‹± ì‹œë„
            print("ğŸ“ ì •ë¦¬ëœ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„...")
            parsed_result = json.loads(json_content)
            print("âœ… JSON íŒŒì‹± ì„±ê³µ!")
            return parsed_result
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            
            # ì˜¤ë¥˜ ìœ„ì¹˜ ë° ë¬¸ì œ ë¬¸ì ë¶„ì„
            error_msg = str(e)
            try:
                if 'char ' in error_msg:
                    char_pos = int(error_msg.split('char ')[-1].rstrip(')'))
                    if char_pos < len(json_content):
                        problem_area = json_content[max(0, char_pos-50):char_pos+50]
                        problem_char = repr(json_content[char_pos]) if char_pos < len(json_content) else "EOF"
                        print(f"ğŸ” ì˜¤ë¥˜ ìœ„ì¹˜ {char_pos}: {problem_char}")
                        print(f"ğŸ” ë¬¸ì œ ì˜ì—­: ...{problem_area}...")
            except:
                pass
            
            # ìµœí›„ ì‹œë„: ë” ê´€ëŒ€í•œ JSON íŒŒì‹±
            try:
                print("ğŸ“ ê´€ëŒ€í•œ JSON íŒŒì‹± ì‹œë„...")
                # ì˜ëª»ëœ ë”°ì˜´í‘œë‚˜ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ í•´ê²° ì‹œë„
                fixed_json = self._fix_malformed_json(json_content)
                if fixed_json:
                    parsed_result = json.loads(fixed_json)
                    print("âœ… ë³µêµ¬ëœ JSON íŒŒì‹± ì„±ê³µ!")
                    return parsed_result
            except Exception as fix_error:
                print(f"âŒ JSON ë³µêµ¬ë„ ì‹¤íŒ¨: {str(fix_error)}")
                
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°•ì œ JSON ì¬êµ¬ì„±
                try:
                    print("ğŸ“ ê°•ì œ JSON ì¬êµ¬ì„± ì‹œë„...")
                    reconstructed_json = self._reconstruct_json_from_fragments(json_content, company_name)
                    if reconstructed_json:
                        parsed_result = json.loads(reconstructed_json)
                        print("âœ… ì¬êµ¬ì„±ëœ JSON íŒŒì‹± ì„±ê³µ!")
                        return parsed_result
                except Exception as reconstruct_error:
                    print(f"âŒ JSON ì¬êµ¬ì„±ë„ ì‹¤íŒ¨: {str(reconstruct_error)}")
            
            # JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨ ì‹œ êµ¬ì¡°í™”ëœ ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜ (4ê°œ ì´ë©”ì¼)
            print("ğŸ”„ í´ë°± í…œí”Œë¦¿ ìƒì„± ì¤‘...")
            return {
                "opi_professional": {
                    "product": "One Payment Infra",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"ì•ˆë…•í•˜ì„¸ìš” {company_name} ë‹´ë‹¹ìë‹˜,\n\nê·€ì‚¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\n\nPortOneì˜ One Payment Infraë¡œ 85% ë¦¬ì†ŒìŠ¤ ì ˆê°ê³¼ 2ì£¼ ë‚´ êµ¬ì¶•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 20ì—¬ ê°œ PGì‚¬ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ê´€ë¦¬ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ê³ , ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥ ì„ 15% í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n15ë¶„ í†µí™”ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "15ë¶„ í†µí™” ì¼ì • ì¡ê¸°",
                    "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤",
                    "personalization_score": 8
                },
                "opi_curiosity": {
                    "product": "One Payment Infra",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"í˜¹ì‹œ ê¶ê¸ˆí•œ ê²Œ ìˆì–´ ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\n{company_name}ì˜ ê²°ì œ ì‹œìŠ¤í…œì´ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ì†ë„ë¥¼ ë”°ë¼ê°€ê³  ìˆë‚˜ìš”? PGì‚¬ ê´€ë¦¬ì— ë‚­ë¹„ë˜ëŠ” ì‹œê°„ì€ ì–¼ë§ˆë‚˜ ë ê¹Œìš”?\n\nPortOneìœ¼ë¡œ ì´ ëª¨ë“  ê±±ì •ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 85% ë¦¬ì†ŒìŠ¤ ì ˆê°, 15% ì„±ê³µë¥  í–¥ìƒ, 2ì£¼ ë‚´ êµ¬ì¶•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n10ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "10ë¶„ ë°ëª¨ ìš”ì²­í•˜ê¸°",
                    "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤",
                    "personalization_score": 9
                },
                "finance_professional": {
                    "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"ì•ˆë…•í•˜ì„¸ìš” {company_name} ë‹´ë‹¹ìë‹˜,\n\nê·€ì‚¬ì˜ ë‹¤ì±„ë„ ì»¤ë¨¸ìŠ¤ ìš´ì˜ì— ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\n\ní˜„ì¬ ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´, ì¹´ì¹´ì˜¤ìŠ¤íƒ€ì¼, ì¹´í˜24 ë“± ì±„ë„ë³„ ì¬ë¬´ë§ˆê°ì— ì›” ìˆ˜ì‹­ ì‹œê°„ì„ ì†Œë¹„í•˜ê³  ê³„ì‹ ê°€ìš”? PortOneì˜ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ 90% ì´ìƒ ë‹¨ì¶•í•˜ê³  100% ë°ì´í„° ì •í•©ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¸Œëœë“œë³„/ì±„ë„ë³„ ë§¤ì¶œë³´ê³ ì„œì™€ ë¶€ê°€ì„¸ì‹ ê³ ìë£Œê¹Œì§€ ìë™í™”ë¡œ ì œê³µí•´ë“œë¦½ë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "ì¬ë¬´ìë™í™” ë°ëª¨ ìš”ì²­",
                    "tone": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤",
                    "personalization_score": 8
                },
                "finance_curiosity": {
                    "product": "êµ­ë‚´ì»¤ë¨¸ìŠ¤ì±„ë„ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜",
                    "subject": f"[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
                    "body": f"í˜¹ì‹œ ê¶ê¸ˆí•œ ê²Œ ìˆì–´ ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\n{company_name}ì˜ ì¬ë¬´íŒ€ì´ ë„¤ì´ë²„, ì¹´ì¹´ì˜¤, ì¹´í˜24 ë“± ì±„ë„ë³„ ë°ì´í„°ë¥¼ ì—‘ì…€ë¡œ ë§¤ë²ˆ ë§¤í•‘í•˜ëŠ” ë° ì–¼ë§ˆë‚˜ ë§ì€ ì‹œê°„ì„ ì“°ê³  ìˆë‚˜ìš”? êµ¬ë§¤í™•ì •ë‚´ì—­ê³¼ ì •ì‚°ë‚´ì—­ì´ ë§¤ì¹­ì´ ì•ˆ ë˜ì–´ ê³ ìƒí•˜ì‹œì§€ ì•Šë‚˜ìš”?\n\nPortOneì˜ ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ìœ¼ë¡œ ì´ ëª¨ë“  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 90% ì´ìƒ ì‹œê°„ ë‹¨ì¶•ê³¼ 100% ë°ì´í„° ì •í•©ì„± ë³´ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne íŒ€",
                    "cta": "15ë¶„ ìƒë‹´ ì¼ì • ì¡ê¸°",
                    "tone": "í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸í˜• í†¤",
                    "personalization_score": 9
                },
                "_fallback_used": True,
                "_original_content": content
            }
    
    def _extract_personalization_elements(self, company_data, research_data):
        """íšŒì‚¬ ë°ì´í„°ì—ì„œ ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ (í•œêµ­ì–´ í…œí”Œë¦¿ íŒ¨í„´ ê¸°ë°˜)"""
        elements = []
        
        company_name = company_data.get('íšŒì‚¬ëª…', '')
        ceo_name = company_data.get('ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìë‹˜')
        website = company_data.get('í™ˆí˜ì´ì§€ë§í¬', '')
        
        # ì§ê¸‰ë³„ ë§ì¶¤ ì¸ì‚¬ë§ ê²°ì •
        position_title = 'ë‹´ë‹¹ìë‹˜'
        if 'ëŒ€í‘œ' in ceo_name or 'CEO' in ceo_name:
            position_title = 'ëŒ€í‘œë‹˜'
        elif 'ì´ì‚¬' in ceo_name or 'ì„ì›' in ceo_name:
            position_title = 'ì´ì‚¬ë‹˜'
        elif 'ì „ë¬´' in ceo_name or 'ìƒë¬´' in ceo_name:
            position_title = 'ì „ë¬´ë‹˜'
        
        if company_name:
            elements.append(f"- {company_name}ì˜ ìµœê·¼ ì„±ì¥ê³¼ ë°œì „ì— ì£¼ëª©í•˜ê³  ìˆìŠµë‹ˆë‹¤")
            elements.append(f"- ì¸ì‚¬ë§ì— '{position_title}' í˜¸ì¹­ ì‚¬ìš© ('{ceo_name}' ê¸°ë°˜)")
        
        if website:
            elements.append(f"- ì›¹ì‚¬ì´íŠ¸({website})ë¥¼ í†µí•´ ê·€ì‚¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë°©í–¥ì„±ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤")
            elements.append(f"- 'ìš°ì—°íˆ {company_name}ì˜ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ë¥¼ ë°©ë¬¸í–ˆë‹¤ê°€, ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤' ì ‘ê·¼ ê°€ëŠ¥")
        
        # ì¡°ì‚¬ ë°ì´í„°ì—ì„œ ê°œì¸í™” ìš”ì†Œ ì¶”ì¶œ
        company_info = research_data.get('company_info', '')
        pain_points = research_data.get('pain_points', '')
        
        if 'ì„±ì¥' in company_info or 'í™•ì¥' in company_info:
            elements.append("- ë¹ ë¥¸ ì„±ì¥ì„¸ì™€ ì‹œì¥ í™•ì¥ ê³„íšì„ ì–¸ê¸‰ ê°€ëŠ¥")
            elements.append("- 'ë§¤ì¶œì´ 10ì–µ, 30ì–µì„ ë„˜ì–´ì„œë©° ì„±ì¥í• ìˆ˜ë¡' ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ ì´ìŠˆ ì ‘ê·¼ ê°€ëŠ¥")
        
        if 'ë””ì§€í„¸' in company_info or 'ê¸°ìˆ ' in company_info:
            elements.append("- ë””ì§€í„¸ í˜ì‹ ê³¼ ê¸°ìˆ  ë„ì… ê´€ì‹¬ë„ë¥¼ ê°•ì¡° ê°€ëŠ¥")
            elements.append("- ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¬¸ì œ ì ‘ê·¼ ì¶”ì²œ")
        
        if 'ì»¤ë¨¸ìŠ¤' in company_info or 'ì˜¨ë¼ì¸' in company_info or 'ì‡¼í•‘' in company_info:
            elements.append("- ì»¤ë¨¸ìŠ¤/ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì ‘ê·¼ ê°€ëŠ¥")
            elements.append("- ë„¤ì´ë²„í˜ì´, ì¹´ì¹´ì˜¤, ì¹´í˜24 ë“± ì±„ë„ë³„ ì •ì‚° ì´ìŠˆ ì–¸ê¸‰ ê°€ëŠ¥")
            elements.append("- 'í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ...' íŒ¨í„´ ì‚¬ìš© ì¶”ì²œ")
        
        if 'ì±„ìš©' in company_info or 'ì¸ì¬' in company_info:
            elements.append("- ì±„ìš© ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ í™œìš© ê°€ëŠ¥")
            elements.append("- 'ìµœê·¼ ì¬ë¬´/íšŒê³„ ë‹´ë‹¹ì ì±„ìš©ì„ ì§„í–‰í•˜ì‹œëŠ” ê²ƒì„ ë³´ê³ ...' íŒ¨í„´ ì‚¬ìš© ì¶”ì²œ")
        
        # Pain Points ê¸°ë°˜ ê°œì¸í™”
        if 'ë°ì´í„°' in pain_points or 'ì •ì‚°' in pain_points:
            elements.append("- ì •ì‚°/ë°ì´í„° ë§¤í•‘ ë¬¸ì œ ì¤‘ì‹¬ ì ‘ê·¼ ì¶”ì²œ")
        
        if 'ê°œë°œ' in pain_points or 'ë¦¬ì†ŒìŠ¤' in pain_points:
            elements.append("- ê°œë°œ ë¦¬ì†ŒìŠ¤ ì ˆì•½ ì¤‘ì‹¬ ì ‘ê·¼ ì¶”ì²œ")
        
        if not elements:
            elements.append(f"- {company_name}ì˜ ì§€ì†ì ì¸ ë°œì „ê³¼ í˜ì‹  ë…¸ë ¥ì— ê´€ì‹¬")
            elements.append(f"- ê¸°ë³¸ '{position_title}' í˜¸ì¹­ ì‚¬ìš©")
        
        return '\n'.join(elements)
    
    def refine_email_copy(self, original_copy, feedback):
        """ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë©”ì¼ ë¬¸ì•ˆ ê°œì„ """
        
        refinement_prompt = f"""
        ë‹¤ìŒ ë©”ì¼ ë¬¸ì•ˆì„ ì‚¬ìš©ì í”¼ë“œë°±ì— ë”°ë¼ ê°œì„ í•´ì£¼ì„¸ìš”:

        **ì›ë³¸ ë©”ì¼ ë¬¸ì•ˆ:**
        {original_copy}

        **ì‚¬ìš©ì í”¼ë“œë°±:**
        {feedback}

        **ê°œì„  ìš”ì²­ì‚¬í•­:**
        - Zendesk ëª¨ë²” ì‚¬ë¡€ ì¤€ìˆ˜ (ê°„ê²°ì„±, ê°œì¸í™”, ëª…í™•í•œ CTA)
        - PortOne ì œí’ˆ ê°€ì¹˜ ê°•ì¡°
        - ë” ìì—°ìŠ¤ëŸ½ê³  ì„¤ë“ë ¥ ìˆëŠ” ë¬¸ì²´

        ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        payload = {
            "model": "gemini-2.5-pro",
            "max_tokens": 1000,
            "temperature": 0.5,
            "messages": [
                {
                    "role": "user",
                    "content": refinement_prompt
                }
            ]
        }
        
        try:
            # Gemini API í˜¸ì¶œë¡œ ë³€ê²½ (ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì„ ì˜ˆì •)
            logger.warning("ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Gemini APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            response = requests.post(self.gemini_url, json=payload, headers=self.headers)
            response.raise_for_status()
            
            result = response.json()
            refined_copy = result['content'][0]['text']
            
            return {
                'success': True,
                'refined_copy': refined_copy,
                'timestamp': datetime.now().isoformat()
            }
            
        except requests.exceptions.RequestException as e:
            return {
                'success': False,
                'error': f'ë©”ì¼ ë¬¸ì•ˆ ê°œì„  ì˜¤ë¥˜: {str(e)}',
                'refined_copy': None
            }
    
    def generate_fallback_emails(self, company_name, sales_point='', contact_name='', contact_position=''):
        """ì‹¤ì œ API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  í•œêµ­ì–´ í…œí”Œë¦¿ ê¸°ë°˜ í´ë°± ì´ë©”ì¼ ìƒì„± (ì„¸ì¼ì¦ˆí¬ì¸íŠ¸ë³„ ë™ì  ìƒì„±)"""
        
        # ê°œì¸í™”ëœ ì¸ì‚¬ë§ ìƒì„±
        researcher = CompanyResearcher()
        personalized_greeting = researcher.generate_personalized_greeting(contact_name, contact_position, company_name)
        
        all_fallbacks = {
            'opi_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} ì½”ë¦¬ì•„í¬íŠ¸ì› ì˜¤ì¤€í˜¸ì…ë‹ˆë‹¤.

í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ PGì‚¬ì˜ ë†’ì€ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´, ë§¤ì¶œ êµ¬ê°„ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ìˆ˜ìˆ˜ë£Œ ì¸ìƒ,
ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ê²°ì œ ìˆ˜ë‹¨ë³„ ìµœì  PG ì„ íƒì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”?

ì €í¬ í¬íŠ¸ì›ì€ ë‹¨ í•˜ë‚˜ì˜ ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ ìˆ˜ìˆ˜ë£Œ ì¡°ê±´ ë¹„êµ ë¶„ì„, ìµœì  PGì‚¬ ê²¬ì  ì œì•ˆ,
ê·¸ë¦¬ê³  ê¸€ë¡œë²Œ í™•ì¥ì„±ê¹Œì§€ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë§Œì•½ ì´ëŸ¬í•œ ê³ ë¯¼ì„ í•´ê²°í•˜ê³  ëŒ€í‘œë‹˜ì˜ ì‚¬ì—… ì„±ì¥ì—ë§Œ ì§‘ì¤‘í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´,
ë¯¸íŒ…ì„ í†µí•´ ì €í¬ê°€ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'opi_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

í˜¹ì‹œ ëŒ€í‘œë‹˜ê»˜ì„œë„ ë‹¨ì¼ PGì‚¬ ì¢…ì†ìœ¼ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ê´€ë¦¬,
ì—¬ëŸ¬ PGì‚¬ ì—°ë™ ì‹œ ë°œìƒí•˜ëŠ” ê°œë°œ/ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ì— ëŒ€í•œ ê³ ë¯¼ì„ í•˜ê³ ê³„ì‹ ê°€ìš”?

í¬íŠ¸ì›ì€ ë‹¨ í•œ ë²ˆì˜ API ì—°ë™ìœ¼ë¡œ 50ê°œ ì´ìƒì˜ PGì‚¬ë¥¼ í†µí•©í•˜ê³ ,
ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë§Œì•½ ì´ëŸ¬í•œ ê¸°ìˆ ì  ê³ ë¯¼ì„ í•´ê²°í•˜ê³  ëŒ€í‘œë‹˜ íŒ€ì˜ ê·€í•œ ë¦¬ì†ŒìŠ¤ê°€
ë³¸ì§ˆì ì¸ ì„œë¹„ìŠ¤ ê°œë°œì—ë§Œ ì§‘ì¤‘ë˜ê¸°ë¥¼ ë°”ë¼ì‹ ë‹¤ë©´,
ë¯¸íŒ…ì„ í†µí•´ ì €í¬ê°€ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'finance_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

í˜„ì¬ ì¹´í˜24ì™€ ê°™ì€ í˜¸ìŠ¤íŒ…ì‚¬ë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìš´ì˜í•˜ê³  ê³„ì‹œëŠ”ë°
ë„¤ì´ë²„í˜ì´, ì¿ íŒ¡ ë“± ì˜¤í”ˆë§ˆì¼“ì—ì„œ ë“¤ì–´ì˜¤ëŠ” ë§¤ì¶œê³¼ ì‹¤ì œ ì…ê¸ˆì•¡ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ”
'ì •ì‚°' ì—…ë¬´ì— ìƒê°ë³´ë‹¤ ë§ì€ ì‹œê°„ì„ ìŸê³  ìˆì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”?

ë§ì€ ëŒ€í‘œë‹˜ë“¤ì´ ì´ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ëˆ„ë½ëœ ë§¤ì¶œê³¼ ìˆ¨ê²¨ì§„ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³¨ë¨¸ë¦¬ë¥¼ ì•“ê³  ê³„ì‹­ë‹ˆë‹¤.

ì €í¬ PortOneì˜ ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ìë™í™” ì†”ë£¨ì…˜ì€ ì—¬ëŸ¬ ì±„ë„ì˜ ì •ì‚° ë‚´ì—­ì„ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ëŒ€ì‚¬í•˜ì—¬,
ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¸í•œ ì‹¤ìˆ˜ë¥¼ ì›ì²œì ìœ¼ë¡œ ë§‰ê³  ìˆ¨ì–´ìˆë˜ ë¹„ìš©ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¨ 15ë¶„ë§Œ íˆ¬ìí•´ì£¼ì‹ ë‹¤ë©´, ë¯¸íŒ…ì„ í†µí•´ {company_name}ì˜ ì¬ë¬´ í˜„í™©ì—ì„œ
ì§€ê¸ˆ ë‹¹ì¥ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ë°ì´í„°ë¡œ ëª…í™•íˆ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ íšŒì‹ ë¶€íƒë“œë¦½ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{user_name} ë“œë¦¼

{user_name}
Sales team
Sales Manager
M {user_phone}
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'finance_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

ìš°ì—°íˆ {company_name}ì˜ ì˜¨ë¼ì¸ ìŠ¤í† ì–´ë¥¼ ë°©ë¬¸í–ˆë‹¤ê°€, ê¹Šì€ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
ì´ë ‡ê²Œ í›Œë¥­í•œ ì œí’ˆì„ ë§Œë“œì‹œëŠ” ë§Œí¼, ì‚¬ì—…ë„ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆìœ¼ë¦¬ë¼ ìƒê°í•©ë‹ˆë‹¤.

í˜¹ì‹œ ì‚¬ì—… ê·œëª¨ê°€ ì»¤ì§€ë©´ì„œ, ì˜ˆì „ì—ëŠ” ê°„ë‹¨í–ˆë˜ ë§¤ì¶œ ì •ì‚° ì—…ë¬´ê°€ ì ì  ë” ë³µì¡í•˜ê³  ë¶€ë‹´ìŠ¤ëŸ¬ì›Œì§€ëŠ” ë‹¨ê³„ì— ì ‘ì–´ë“¤ì§€ëŠ” ì•Šìœ¼ì…¨ë‚˜ìš”?
ë§ì€ ê¸°ì—…ë“¤ì´ ì €í¬ í¬íŠ¸ì› ì†”ë£¨ì…˜ì„ í†µí•´ ë§¤ì¼ ëª‡ ì‹œê°„ì”© ê±¸ë¦¬ë˜ ì •ì‚° ì—…ë¬´ë¥¼ ë‹¨ 5ë¶„ ë§Œì— ëë‚´ê³ , ì•„ë‚€ ì‹œê°„ì„ ë‹¤ì‹œ ì œí’ˆ ê°œë°œê³¼ ë§ˆì¼€íŒ…ì— íˆ¬ìí•˜ê³  ìˆìŠµë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¤ìŒ ì£¼ ì¤‘ ë¯¸íŒ…ê°€ëŠ¥í•œ ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹ ë‹¤ë©´
{company_name}ì˜ ì„±ê³µ ìŠ¤í† ë¦¬ì— PortOneì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€, ì ì‹œ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.

ê¸ì •ì ì¼ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{user_name} ë“œë¦¼

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'game_d2c_professional': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

í˜¹ì‹œ ì• í”Œ ì•±ìŠ¤í† ì–´ì™€ êµ¬ê¸€ í”Œë ˆì´ìŠ¤í† ì–´ì˜ 30% ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì‹œì§€ ì•Šë‚˜ìš”?
ìµœê·¼ Com2uS, Neptune ë“± êµ­ë‚´ ì£¼ìš” ê²Œì„ì‚¬ë“¤ë„ D2C ì›¹ìƒì ìœ¼ë¡œ ìˆ˜ìˆ˜ë£Œ ë¶€ë‹´ì„ ëŒ€í­ ì¤„ì´ê³  ìˆìŠµë‹ˆë‹¤.

ì €í¬ PortOneì€ ë‹¨ í•œ ë²ˆì˜ SDK ì—°ë™ìœ¼ë¡œ êµ­ë‚´ 25ê°œ PGì‚¬ë¥¼ í†µí•©í•˜ì—¬, ìµœì ì˜ ë¹„ìš©ìœ¼ë¡œ ì›¹ìƒì  ê²°ì œë¥¼ ìš´ì˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.
ì‹¤ì œë¡œ ê³ ê°ì‚¬ë“¤ì€ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆì•½í•˜ê³ , ì •ì‚° ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  ê³„ì‹­ë‹ˆë‹¤.

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´, {company_name}ì— ìµœì í™”ëœ ë°©ì•ˆì„ ì œì•ˆë“œë¦¬ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            },
            'game_d2c_curiosity': {
                'subject': f'[PortOne] {company_name} {contact_name if contact_name and contact_name != "ë‹´ë‹¹ì" else "ë‹´ë‹¹ìë‹˜"}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                'body': f'''{personalized_greeting} PortOne {user_name}ì…ë‹ˆë‹¤.

ìµœê·¼ ë§ì€ ê²Œì„ì‚¬ë“¤ì´ ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ ì ˆê°ì„ ìœ„í•´ D2C ì›¹ìƒì ì„ êµ¬ì¶•í•˜ì§€ë§Œ,
ë§‰ìƒ ì§ì ‘ êµ¬ì¶•í•˜ë ¤ë‹¤ ë³´ë‹ˆ êµ­ë‚´ 25ê°œ PGì‚¬ ê°œë³„ ì—°ë™, ì •ì‚° ê´€ë¦¬, ìˆ˜ìˆ˜ë£Œ ìµœì í™” ë“±ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

PortOneì„ ì‚¬ìš©í•˜ì‹œë©´ ì´ ëª¨ë“  ê³¼ì •ì„ í•œ ë²ˆì— í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì–´ë–»ê²Œ ìˆ˜ìˆ˜ë£Œë¥¼ 90% ì ˆê°í•˜ê³  ìš´ì˜ ì—…ë¬´ë¥¼ ìë™í™”í•  ìˆ˜ ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ì§€ ì•Šìœ¼ì‹ ê°€ìš”?

https://www.youtube.com/watch?v=2EjzX6uTlKc ê°„ë‹¨í•œ ì„œë¹„ìŠ¤ ì†Œê°œ ìœ íŠœë¸Œì˜ìƒ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.
1ë¶„ì§œë¦¬ ì†Œë¦¬ì—†ëŠ” ì˜ìƒì´ë‹ˆ ë¶€ë‹´ì—†ì´ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.

15ë¶„ë§Œ ì‹œê°„ì„ ë‚´ì–´ì£¼ì‹œë©´, ì–´ë–»ê²Œ ê°€ëŠ¥í•œì§€ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì£¼ ì¤‘ í¸í•˜ì‹  ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

{user_name}
Sales team
Sales Manager
E ocean@portone.io
M 010 5001 2143
ì„œìš¸ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ì´ë¡œ 20ê¸¸ 16 JKíƒ€ì›Œ 4ì¸µ
https://www.portone.io'''
            }
        }

        if sales_point == 'opi':
            return {k: v for k, v in all_fallbacks.items() if 'opi' in k}
        elif sales_point == 'recon':
            return {k: v for k, v in all_fallbacks.items() if 'finance' in k}
        elif sales_point == 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°':
            return {k: v for k, v in all_fallbacks.items() if 'game_d2c' in k}
        else: # 'opi + recon' ë˜ëŠ” ë¹ˆì¹¸ì¼ ê²½ìš°
            return {k: v for k, v in all_fallbacks.items() if 'opi' in k or 'finance' in k}
    
    def _fix_malformed_json(self, json_content):
        """ì†ìƒëœ JSON ë³µêµ¬ ì‹œë„"""
        try:
            import re
            
            # 1. ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë”°ì˜´í‘œ ìˆ˜ì •
            fixed_content = json_content
            
            # 2. ë¶ˆì™„ì „í•œ ë¬¸ìì—´ ìˆ˜ì • (ëë‚˜ì§€ ì•Šì€ ë¬¸ìì—´)
            # ë§ˆì§€ë§‰ ë”°ì˜´í‘œê°€ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš° ìˆ˜ì •
            lines = fixed_content.split('\n')
            for i, line in enumerate(lines):
                # í‚¤: "ê°’" íŒ¨í„´ì—ì„œ ê°’ ë¶€ë¶„ì´ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì€ ê²½ìš°
                if line.strip().endswith('"') == False and '"' in line and ':' in line:
                    # ë¬¸ìì—´ì´ ë‹«íˆì§€ ì•Šì•˜ë‹¤ë©´ ë‹«ì•„ì£¼ê¸°
                    quote_count = line.count('"')
                    if quote_count % 2 == 1:  # í™€ìˆ˜ ê°œì˜ ë”°ì˜´í‘œ = ë‹«íˆì§€ ì•ŠìŒ
                        lines[i] = line + '"'
            
            fixed_content = '\n'.join(lines)
            
            # 3. í›„í–‰ ì‰¼í‘œ ì œê±°
            fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)
            
            # 4. ì¤‘ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
            open_braces = fixed_content.count('{')
            close_braces = fixed_content.count('}')
            if open_braces > close_braces:
                fixed_content += '}' * (open_braces - close_braces)
            
            return fixed_content
            
        except Exception as e:
            logger.debug(f"JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _reconstruct_json_from_fragments(self, broken_json, company_name):
        """ì™„ì „íˆ ê¹¨ì§„ JSONì„ ì¡°ê°ì—ì„œ ì¬êµ¬ì„±"""
        try:
            import re
            
            print("ğŸ”§ JSON ì¡°ê°ì—ì„œ í‚¤-ê°’ ìŒ ì¶”ì¶œ ì¤‘...")
            
            # 4ê°œ ì´ë©”ì¼ í…œí”Œë¦¿ í‚¤
            email_keys = ["opi_professional", "opi_curiosity", "finance_professional", "finance_curiosity"]
            reconstructed = {}
            
            # ê° ì´ë©”ì¼ ìœ í˜•ë³„ë¡œ subjectì™€ body ì¶”ì¶œ ì‹œë„
            for key in email_keys:
                reconstructed[key] = {"subject": "", "body": ""}
                
                # subject ì°¾ê¸°
                subject_match = re.search(rf'"{key}"[^{{]*"subject"\s*:\s*"([^"]*)"', broken_json, re.DOTALL)
                if subject_match:
                    reconstructed[key]["subject"] = subject_match.group(1)
                else:
                    reconstructed[key]["subject"] = f"{company_name} ê²°ì œ ì†”ë£¨ì…˜ ì œì•ˆ"
                
                # body ì°¾ê¸° (ë” ë³µì¡í•¨ - ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆì„ ìˆ˜ ìˆìŒ)
                body_pattern = rf'"{key}"[^{{]*"body"\s*:\s*"([^"]*(?:\\"[^"]*)*)'
                body_match = re.search(body_pattern, broken_json, re.DOTALL)
                if body_match:
                    body_content = body_match.group(1)
                    # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ë³µì›
                    body_content = body_content.replace('\\"', '"').replace('\\n', '\n')
                    reconstructed[key]["body"] = body_content[:500] + "..." if len(body_content) > 500 else body_content
                else:
                    # ê¸°ë³¸ í…œí”Œë¦¿
                    reconstructed[key]["body"] = f"ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜.\n\nPortOneì˜ ê²°ì œ ì†”ë£¨ì…˜ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ íš¨ìœ¨ì„±ì„ ë†’ì—¬ë³´ì„¸ìš”.\n\nê°ì‚¬í•©ë‹ˆë‹¤."
            
            # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            import json
            reconstructed_json = json.dumps(reconstructed, ensure_ascii=False, indent=2)
            
            print(f"ğŸ”§ ì¬êµ¬ì„± ì™„ë£Œ: {len(reconstructed)} ê°œ ì´ë©”ì¼ í…œí”Œë¦¿")
            return reconstructed_json
            
        except Exception as e:
            print(f"ğŸ”§ JSON ì¬êµ¬ì„± ì‹¤íŒ¨: {e}")
            return None


def generate_email_with_gemini(company_data, research_data, user_info=None):
    """Gemini 2.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œì¸í™”ëœ ì´ë©”ì¼ ìƒì„±"""
    try:
        # ì‚¬ìš©ì ì •ë³´ (ì„œëª…ìš©) - user_info íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ current_user ì²´í¬
        if user_info:
            user_name = user_info.get('name', 'ì˜¤ì¤€í˜¸')
            user_company_nickname = user_info.get('company_nickname', f'PortOne {user_name} ë§¤ë‹ˆì €')
            user_phone = user_info.get('phone', '010-2580-2580')
            logger.info(f"ğŸ‘¤ ì´ë©”ì¼ ìƒì„±ì: {user_name} ({user_company_nickname})")
            logger.info(f"âœ… ì „ë‹¬ë°›ì€ ì‚¬ìš©ì ì •ë³´ ì‚¬ìš©: {user_info.get('email', 'N/A')}")
        else:
            user_name = current_user.name if (current_user and current_user.is_authenticated) else "ì˜¤ì¤€í˜¸"
            user_company_nickname = current_user.company_nickname if (current_user and current_user.is_authenticated) else f"PortOne {user_name} ë§¤ë‹ˆì €"
            user_phone = current_user.phone if (current_user and current_user.is_authenticated) else "010-2580-2580"
            
            # ë””ë²„ê¹…: ì‚¬ìš©ì ì •ë³´ ë¡œê·¸
            logger.info(f"ğŸ‘¤ ì´ë©”ì¼ ìƒì„±ì: {user_name} (PortOne {user_name} ë§¤ë‹ˆì €)")
            if current_user and current_user.is_authenticated:
                logger.info(f"âœ… ë¡œê·¸ì¸ ì‚¬ìš©ì ì¸ì¦ë¨: {current_user.email}")
            else:
                logger.warning(f"âš ï¸  current_user ì¸ì¦ ì•ˆ ë¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        # íšŒì‚¬ ì •ë³´ ìš”ì•½
        company_name = company_data.get('íšŒì‚¬ëª…', 'Unknown')
        
        # sales_item ì—´ í™•ì¸ (ì„œë¹„ìŠ¤ë³„ ë¬¸ì•ˆ ìƒì„± ê²°ì •)
        sales_item = company_data.get('sales_item', '').lower().strip()
        logger.info(f"Sales item í™•ì¸: '{sales_item}' for {company_name}")
        
        # ë‹´ë‹¹ì ì •ë³´ ì¶”ì¶œ
        # Nì—´(14ë²ˆì§¸ ì—´)ì˜ í˜¸ì¹­ í¬í•¨ ë‹´ë‹¹ìëª…ì„ ìš°ì„  ì°¸ì¡° (ì´ë¯¸ ì™„ì„±ëœ í˜¸ì¹­)
        column_keys = list(company_data.keys())
        email_name = ''
        if len(column_keys) >= 14:
            email_name = company_data.get(column_keys[13], '').strip()  # Nì—´ (0-based index 13)
        
        # Nì—´ì´ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        if not email_name:
            contact_name = company_data.get('ë‹´ë‹¹ìëª…', '') or company_data.get('ëŒ€í‘œìëª…', '') or company_data.get('ì´ë¦„', '')
            contact_position = company_data.get('ì§ì±…', '') or company_data.get('ì§ê¸‰', '')
            
            # ë‹´ë‹¹ìëª…ê³¼ ì§ì±… ì²˜ë¦¬ (ê¸°ë³¸ê°’ ì„¤ì •)
            if not contact_name or contact_name == 'ë‹´ë‹¹ì':
                email_name = 'ë‹´ë‹¹ìë‹˜'
            else:
                # ì§ì±… ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                if contact_position:
                    # ì§ì±…ì— ë”°ë¥¸ ì ì ˆí•œ í˜¸ì¹­ ì²˜ë¦¬
                    if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €', 'ì‹¤ì¥', 'ê³¼ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì£¼ì„', 'ëŒ€ë¦¬', 'ì„ ì„', 'ì±…ì„']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    else:
                        # ê¸°íƒ€ ì§ì±…
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                else:
                    # ì§ì±… ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì´ë¦„ë§Œìœ¼ë¡œ ì²˜ë¦¬
                    if any(title in contact_name for title in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name}ë‹˜'
                    else:
                        email_name = f'{contact_name} ë‹´ë‹¹ìë‹˜'
        
        # ê²½ìŸì‚¬ ì •ë³´ ì¶”ì¶œ (PortOne ì´ìš© ê¸°ì—…)
        competitor_name = company_data.get('ê²½ìŸì‚¬ëª…', '') or company_data.get('ê²½ìŸì‚¬', '')
        
        company_info = f"íšŒì‚¬ëª…: {company_name}\në‹´ë‹¹ì: {email_name}"
        if competitor_name:
            company_info += f"\nPortOne ì´ìš© ê²½ìŸì‚¬: {competitor_name}"
        
        # ì¶”ê°€ íšŒì‚¬ ì •ë³´ê°€ ìˆë‹¤ë©´ í¬í•¨
        for key, value in company_data.items():
            # Nì—´ ë‹´ë‹¹ìëª…ë„ ì œì™¸ ëª©ë¡ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
            excluded_keys = ['íšŒì‚¬ëª…', 'ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìëª…', 'ì´ë¦„', 'ì§ì±…', 'ì§ê¸‰', 'ê²½ìŸì‚¬ëª…', 'ê²½ìŸì‚¬']
            if len(column_keys) >= 14:
                excluded_keys.append(column_keys[13])  # Nì—´ í‚¤ë„ ì œì™¸
            if key not in excluded_keys and value:
                company_info += f"\n{key}: {value}"
        
        # ì¡°ì‚¬ ì •ë³´ ë° Pain Point ìš”ì•½
        research_summary = research_data.get('company_info', 'ì¡°ì‚¬ ì •ë³´ ì—†ìŒ')
        pain_points = research_data.get('pain_points', 'ì¼ë°˜ì ì¸ Pain Point')
        industry_trends = research_data.get('industry_trends', '')
        
        # í˜¸ìŠ¤íŒ…ì‚¬ ì •ë³´ í™•ì¸ (OPI ì œê³µ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨)
        # CSV ì»´ëŸ¼ êµ¬ì¡° ë””ë²„ê¹…
        logger.debug(f"{company_name} CSV ì»´ëŸ¼ë“¤: {list(company_data.keys())}")
        
        # ë‹¤ì–‘í•œ í˜¸ìŠ¤íŒ…ì‚¬ ì»´ëŸ¼ëª… ì§€ì›
        possible_hosting_columns = ['í˜¸ìŠ¤íŒ…ì‚¬', 'í˜¸ìŠ¤íŒ…', 'í˜¸ìŠ¤íŒ…ì„œë¹„ìŠ¤', 'hosting', 'Hosting', 'ì›¹í˜¸ìŠ¤íŒ…', 'í˜¸ìŠ¤íŒ…ì—…ì²´']
        hosting = ''
        for col in possible_hosting_columns:
            if col in company_data and company_data[col] and str(company_data[col]).strip():
                hosting = str(company_data[col]).lower().strip()
                logger.info(f"{company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ë°œê²¬: '{col}' = '{hosting}'")
                break
        
        if not hosting:
            logger.warning(f"{company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ - CSVì— í˜¸ìŠ¤íŒ…ì‚¬ ì»´ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        
        is_self_hosted = 'ìì²´' in hosting or 'self' in hosting or 'ì§ì ‘' in hosting
        
        # ğŸ†• sales_itemì—ì„œ ë³µìˆ˜ ì„œë¹„ìŠ¤ ê°ì§€ (ì½¤ë§ˆ, +, & ë“±ìœ¼ë¡œ ë¶„ë¦¬)
        def parse_sales_items(sales_item_str):
            """sales_item ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ì¶”ì¶œ"""
            if not sales_item_str:
                return []
            
            # ì½¤ë§ˆ, +, &, ê³µë°± ë“±ìœ¼ë¡œ ë¶„ë¦¬
            import re
            items = re.split(r'[,+&\s]+', sales_item_str.lower().strip())
            # ë¹ˆ ë¬¸ìì—´ ì œê±°
            items = [item.strip() for item in items if item.strip()]
            return items
        
        # sales_item íŒŒì‹±
        sales_items = parse_sales_items(sales_item)
        logger.info(f"ğŸ“‹ Sales items íŒŒì‹± ê²°ê³¼: {sales_items} for {company_name}")
        
        # ê°ì§€ëœ ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)
        detected_services = set()
        for item in sales_items:
            if 'opi' in item:
                detected_services.add('opi')
            if 'recon' in item or 'ì¬ë¬´' in item:
                detected_services.add('recon')
            if 'prism' in item or 'í”„ë¦¬ì¦˜' in item:
                detected_services.add('prism')
            if 'ps' in item or 'í”Œë«í¼ì •ì‚°' in item or 'íŒŒíŠ¸ë„ˆì •ì‚°' in item:
                detected_services.add('ps')
        
        detected_services = list(detected_services)
        logger.info(f"ğŸ¯ ê°ì§€ëœ ì„œë¹„ìŠ¤: {detected_services} for {company_name}")
        
        # sales_itemì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ê²°ì •
        services_to_generate = []
        is_multi_service = len(detected_services) > 1
        
        if sales_item:
            if is_multi_service:
                # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ ê°ì§€: í†µí•© ë¬¸ì•ˆ ìƒì„±
                # OPIëŠ” ìì²´êµ¬ì¶•ì¼ ë•Œë§Œ í¬í•¨
                if 'opi' in detected_services and not is_self_hosted:
                    logger.warning(f"âš ï¸ OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ ì œì™¸: {company_name}")
                    detected_services.remove('opi')
                
                services_to_generate = ['multi_service_professional', 'multi_service_curiosity']
                service_names = []
                if 'opi' in detected_services:
                    service_names.append('OPI')
                if 'recon' in detected_services:
                    service_names.append('Recon')
                if 'prism' in detected_services:
                    service_names.append('Prism')
                if 'ps' in detected_services:
                    service_names.append('PS')
                
                logger.info(f"ğŸ¯ ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ ìƒì„±: {' + '.join(service_names)} for {company_name}")
            
            elif 'opi' in detected_services:
                # ë‹¨ì¼ OPI ì„œë¹„ìŠ¤
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity']
                    logger.info(f"âœ… OPI ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
                else:
                    # ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconìœ¼ë¡œ ëŒ€ì²´
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    detected_services = ['recon']
                    logger.warning(f"âš ï¸ OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ Recon(ì¬ë¬´ìë™í™”)ìœ¼ë¡œ ì „í™˜: {company_name}")
            
            elif 'recon' in detected_services:
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"Recon(ì¬ë¬´ìë™í™”) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            elif 'prism' in detected_services:
                services_to_generate = ['prism_professional', 'prism_curiosity']
                logger.info(f"Prism(ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            elif 'ps' in detected_services:
                services_to_generate = ['ps_professional', 'ps_curiosity']
                logger.info(f"í”Œë«í¼ ì •ì‚°(íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” sales_itemì¸ ê²½ìš°
                if is_self_hosted:
                    # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                    services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                    logger.info(f"ì•Œ ìˆ˜ ì—†ëŠ” sales_item '{sales_item}', ìì²´êµ¬ì¶•ì´ë¯€ë¡œ 4ê°œ ë¬¸ì•ˆ ìƒì„±: {company_name}")
                else:
                    # ìì²´êµ¬ì¶• ì•„ë‹ˆë©´ Reconë§Œ
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.info(f"ì•Œ ìˆ˜ ì—†ëŠ” sales_item '{sales_item}', ìì²´êµ¬ì¶• ì•„ë‹ˆë¯€ë¡œ Reconë§Œ ìƒì„±: {company_name}")
        else:
            # sales_itemì´ ì—†ìœ¼ë©´ í˜¸ìŠ¤íŒ…ì‚¬ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            if not hosting:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ì—†ìœ¼ë©´ 4ê°œ ëª¨ë‘ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ â†’ 4ê°œ ëª¨ë‘ ìƒì„±: {company_name}")
            elif is_self_hosted:
                # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + ìì²´êµ¬ì¶• â†’ 4ê°œ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
            else:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ìˆê³  ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconë§Œ
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ…='{hosting}' (ìì²´êµ¬ì¶• ì•„ë‹˜) â†’ Reconë§Œ ìƒì„±: {company_name}")
        
        # ì„œë¹„ìŠ¤ë³„ í†µí•© ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ (ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´)
        from portone_blog_cache import get_service_knowledge
        
        # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ì¼ ê²½ìš° detected_services ê¸°ë°˜ìœ¼ë¡œ ëª¨ë‘ ë¡œë“œ
        if is_multi_service:
            logger.info(f"ğŸ“š ë³µìˆ˜ ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ ì‹œì‘: {detected_services}")
        
        # OPIìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        opi_blog_content = ""
        if any('opi' in s for s in services_to_generate) or (is_multi_service and 'opi' in detected_services):
            opi_blog_content = get_service_knowledge(service_type='OPI')
            logger.info(f"ğŸ“š [OPI] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # Reconìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        recon_blog_content = ""
        if any('finance' in s for s in services_to_generate) or (is_multi_service and 'recon' in detected_services):
            recon_blog_content = get_service_knowledge(service_type='Recon')
            logger.info(f"ğŸ“š [Recon] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # Prismìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        prism_blog_content = ""
        if any('prism' in s for s in services_to_generate) or (is_multi_service and 'prism' in detected_services):
            prism_blog_content = get_service_knowledge(service_type='Prism')
            logger.info(f"ğŸ“š [Prism] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # í”Œë«í¼ ì •ì‚°(PS)ìš© í†µí•© ì§€ì‹ë² ì´ìŠ¤
        ps_blog_content = ""
        if any('ps' in s for s in services_to_generate) or (is_multi_service and 'ps' in detected_services):
            ps_blog_content = get_service_knowledge(service_type='PS')
            logger.info(f"ğŸ“š [í”Œë«í¼ ì •ì‚°] {company_name}: ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸ ì „ì²´ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ")
        
        # CSV ë‰´ìŠ¤ ì œê³µ ì—¬ë¶€ í™•ì¸
        has_csv_news = "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)" in research_summary
        
        # í•´ì™¸ ì§„ì¶œ ì—¬ë¶€ í™•ì¸ (ë‰´ìŠ¤/ì¡°ì‚¬ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ)
        global_keywords = ['í•´ì™¸', 'ê¸€ë¡œë²Œ', 'global', 'ìˆ˜ì¶œ', 'export', 'í•´ì™¸ì§„ì¶œ', 'êµ­ì œ', 'ì•„ì‹œì•„', 'ìœ ëŸ½', 'ë¯¸êµ­', 'ì¼ë³¸', 'ì¤‘êµ­', 'ë™ë‚¨ì•„']
        is_global = any(keyword in research_summary.lower() for keyword in global_keywords)
        
        # PGì‚¬ ê°œìˆ˜ ë™ì  í‘œí˜„
        if is_global:
            pg_count = "êµ­ë‚´ì™¸ 50ì—¬ê°œ"
            logger.info(f"ğŸŒ {company_name}: í•´ì™¸ íƒ€ê²Ÿ ê°ì§€ â†’ {pg_count} PGì‚¬ ì–¸ê¸‰")
        else:
            pg_count = "êµ­ë‚´ 20ì—¬ê°œ"
            logger.info(f"ğŸ‡°ğŸ‡· {company_name}: êµ­ë‚´ íƒ€ê²Ÿ â†’ {pg_count} PGì‚¬ ì–¸ê¸‰")
        
        # ê¸°ë³¸ context ì •ì˜
        if has_csv_news:
            news_instruction = """**ğŸ¯ ìµœìš°ì„  ì§€ì‹œ: CSVì—ì„œ ì œê³µëœ 'ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬' ì„¹ì…˜ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì´ë©”ì¼ ë„ì…ë¶€ì— í™œìš©í•˜ì„¸ìš”!**

ì´ ë‰´ìŠ¤ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ ì •í•œ ì¤‘ìš”í•œ ê¸°ì‚¬ì´ë¯€ë¡œ, ë‹¤ë¥¸ ì–´ë–¤ ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.

**í•„ìˆ˜ í™œìš© ë°©ì‹:**
- "ìµœê·¼ '{news_title}' ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤..." í˜•íƒœë¡œ ì§ì ‘ ì¸ìš©
- CSV ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ Perplexity ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ 
- ë‰´ìŠ¤ ë‚´ìš©ê³¼ íšŒì‚¬ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì—°ê²°

ì˜ˆì‹œ:
- "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ëŠ” ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
- "'{company_name}ì˜ ë§¤ì¶œ 200% ì¦ê°€' ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
        else:
            news_instruction = """**ì¤‘ìš”**: ìœ„ì˜ Perplexity ì¡°ì‚¬ ê²°ê³¼ì—ì„œ êµ¬ì²´ì ì¸ ë‰´ìŠ¤ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©í•˜ì—¬ ì´ë©”ì¼ ë„ì…ë¶€ì— ë°˜ë“œì‹œ í™œìš©í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ 100ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ê³  ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ì— ë”°ë¥¸ ê²°ì œ ì¸í”„ë¼ í™•ì¥ ê³„íšë„ ìˆìœ¼ì‹¤ í…ë°..." """
        
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ë¡œ, ì‹¤ì œ ê²€ì¦ëœ í•œêµ­ì–´ ì˜ì—… ì´ë©”ì¼ íŒ¨í„´ì„ ì™„ë²½íˆ ìˆ™ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ğŸš¨ ì¤‘ìš”: ì„œë¹„ìŠ¤ ì†Œê°œì„œì™€ ë¸”ë¡œê·¸ ê¸°ë°˜ ì œì•½ ì‚¬í•­ ğŸš¨**
- ì•„ë˜ ì œê³µëœ OPI/Recon ì°¸ê³  ì •ë³´(ì„œë¹„ìŠ¤ ì†Œê°œì„œ + ë¸”ë¡œê·¸)ì— ëª…ì‹œëœ ê¸°ëŠ¥ê³¼ ìˆ˜ì¹˜ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ì„œë¹„ìŠ¤ ì†Œê°œì„œ/ë¸”ë¡œê·¸ì— ì—†ëŠ” ê¸°ëŠ¥ì´ë‚˜ ì±„ë„ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- ì œê³µí•  ìˆ˜ ì—†ëŠ” ì˜ì—­ì„ ì œê³µí•œë‹¤ê³  ë§í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤
- í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¼ë°˜ì ì¸ Pain Point ì¤‘ì‹¬ìœ¼ë¡œë§Œ ì–¸ê¸‰í•˜ì„¸ìš”

**âœ… OPIì—ì„œ ì–¸ê¸‰ ê°€ëŠ¥í•œ ê²°ì œ ìˆ˜ë‹¨ (ì†Œê°œì„œ ê¸°ë°˜):**
- ì‹ ìš©ì¹´ë“œ, ê°„í¸ê²°ì œ (êµ­ë‚´ 0.5% ìˆ˜ìˆ˜ë£Œ)
- í•´ì™¸: ê°êµ­ì˜ ê°„í¸ê²°ì œ ìˆ˜ë‹¨ (100+ ê²°ì œ ìˆ˜ë‹¨)
- í¬ë¦½í†  ê²°ì œ ë“±
- âŒ **ê³„ì¢Œì´ì²´ëŠ” ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì ˆëŒ€ ì–¸ê¸‰ ê¸ˆì§€**

**í¬íŠ¸ì› í•µì‹¬ ìˆ˜ì¹˜ (ë°˜ë“œì‹œ í™œìš©):**
- êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ í¬íŠ¸ì› ì‚¬ìš© ì¤‘
- ì—°í™˜ì‚° ê±°ë˜ì•¡ 12ì¡°ì› (2024ë…„ 12ì›” ê¸°ì¤€)
- {pg_count} PGì‚¬ ì—°ë™ ê°€ëŠ¥ (íƒ€ê²Ÿ íšŒì‚¬ì˜ í•´ì™¸ ì§„ì¶œ ì—¬ë¶€ì— ë”°ë¼ ìë™ ì¡°ì •ë¨)
- ì´ ìˆ˜ì¹˜ë“¤ì„ í™œìš©í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ë†’ì´ì„¸ìš”
  ì˜ˆ: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..."
  ì˜ˆ: "ì—° 12ì¡°ì› ê·œëª¨ì˜ ê±°ë˜ë¥¼ ì²˜ë¦¬í•˜ëŠ”..."
  ì˜ˆ: "{pg_count} PGì‚¬ë¥¼ í•œ ë²ˆì˜ ì—°ë™ìœ¼ë¡œ..."

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
{company_info}

**ğŸ”¥ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ (ì´ë©”ì¼ì— ë°˜ë“œì‹œ í™œìš©í•´ì•¼ í•¨):**
{research_summary}

**ì—…ê³„ íŠ¸ë Œë“œ:**
{industry_trends}

{news_instruction}
- "'{company_name}ì˜ 3ë¶„ê¸° ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 150% ì¦ê°€í–ˆë‹¤'ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì†í•œ ì„±ì¥ì— ë”°ë¥¸ ì¬ë¬´ ê´€ë¦¬ ë¶€ë‹´ì´ ëŠ˜ì–´ë‚˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?"
- "'{company_name}ê°€ ì¼ë³¸ ì‹œì¥ì— ì§„ì¶œí•œë‹¤'ëŠ” ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í•´ì™¸ ì§„ì¶œ ì‹œ í˜„ì§€ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™ì´ ë³µì¡í•˜ì‹¤ í…ë°..."

"""

        # ìƒì„±í•  ì„œë¹„ìŠ¤ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if is_multi_service:
            # ğŸ†• ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ
            service_names_kr = []
            if 'opi' in detected_services:
                service_names_kr.append('OPI(í•´ì™¸ê²°ì œ)')
            if 'recon' in detected_services:
                service_names_kr.append('Recon(ì¬ë¬´ìë™í™”)')
            if 'prism' in detected_services:
                service_names_kr.append('Prism(ì˜¤í”ˆë§ˆì¼“ ì •ì‚°)')
            if 'ps' in detected_services:
                service_names_kr.append('PS(í”Œë«í¼ ì •ì‚°)')
            
            service_focus = f"{' + '.join(service_names_kr)} í†µí•© ì†”ë£¨ì…˜ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ ì œì•ˆí•˜ëŠ” 2ê°œì˜"
            logger.info(f"ğŸ“§ ë³µìˆ˜ ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ì´ˆì : {service_focus}")
        elif len(services_to_generate) == 2:
            if 'opi' in services_to_generate[0]:
                service_focus = "One Payment Infra (OPI) ì„œë¹„ìŠ¤ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            elif 'prism' in services_to_generate[0]:
                service_focus = "ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ (Prism)ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            elif 'ps' in services_to_generate[0]:
                service_focus = "í”Œë«í¼ ì •ì‚° ìë™í™” (íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰)ì— ì§‘ì¤‘í•œ 2ê°œì˜"
            else:
                service_focus = "ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ì— ì§‘ì¤‘í•œ 2ê°œì˜"
        else:
            service_focus = "4ê°œì˜ ì„¤ë“ë ¥ ìˆê³  ì°¨ë³„í™”ëœ"
        
        prompt = f"""
{context}

**íšŒì‚¬ë³„ ë§ì¶¤ Pain Points (ì¡°ì‚¬ ê²°ê³¼ ê¸°ë°˜):**
{pain_points}

ë‹¤ìŒ ê³ ì •ëœ í˜•ì‹ì— ë”°ë¼ {service_focus} ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

**ğŸ¯ ìµœìš°ì„  ëª©í‘œ: B2B ì˜ì‚¬ê²°ì •ìê°€ "ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ë‹¤"ê³  ëŠë¼ëŠ” ë©”ì¼ ì‘ì„±**

ë‹¹ì‹ ì´ ì‘ì„±í•˜ëŠ” ë©”ì¼ì€ AI í‰ê°€ ì‹œìŠ¤í…œìœ¼ë¡œ íš¨ê³¼ì„±ì„ ì¸¡ì •í•˜ë©°, ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ 5ì  ë§Œì  í‰ê°€ë©ë‹ˆë‹¤:

**5ì  (ëª©í‘œ)**: "ì •í™•íˆ ìš°ë¦¬ê°€ ì°¾ë˜ ì†”ë£¨ì…˜ì´ë©° ì¦‰ì‹œ ë‹µì¥í•˜ê² ìŠµë‹ˆë‹¤", "ë§¤ìš° ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ", "ìš°ë¦¬ íšŒì‚¬ì˜ í˜„ì¬ ë¬¸ì œë¥¼ ì •í™•íˆ ì´í•´í•˜ê³  ìˆì–´ ë§¤ìš° ì¸ìƒì "
**4ì  (í•©ê²©)**: "ë§¤ìš° ê´€ì‹¬ì´ ê°€ë©° ê³§ ë‹µì¥í•  ê°€ëŠ¥ì„± ë†’ìŒ", "ìš°ë¦¬ íšŒì‚¬ì˜ pain pointë¥¼ ì˜ íŒŒì•…", "êµ¬ì²´ì ì´ê³  ê´€ë ¨ì„±ì´ ë†’ì•„ ë¯¸íŒ…ì„ ì¡ê³  ì‹¶ë‹¤"
**3ì  ì´í•˜ (ì‹¤íŒ¨)**: "ì–´ëŠ ì •ë„ ê´€ì‹¬", "ì œì•ˆì´ ê´œì°®ì•„ ë³´ì´ì§€ë§Œ í™•ì‹  ì—†ìŒ", "ë³„ë¡œ ê´€ì‹¬ ì—†ìŒ", "ìŠ¤íŒ¸ì²˜ëŸ¼ ëŠê»´ì§"

**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ (4-5ì ì„ ë°›ê¸° ìœ„í•œ ì¡°ê±´):**
1. **ê°€ì¥ ì¤‘ìš”**: í¼í”Œë ‰ì‹œí‹°ê°€ ì¡°ì‚¬í•œ {company_name}ì˜ ìµœì‹  ë‰´ìŠ¤/í™œë™ì„ ë°˜ë“œì‹œ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì—¬ ê°œì¸í™”
   â†’ "ì´ íšŒì‚¬ì˜ í˜„ì¬ ìƒí™©ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìˆë‹¤" ì¸ìƒ í•„ìˆ˜
2. ìœ„ì— ì œì‹œëœ íšŒì‚¬ë³„ ë§ì¶¤ Pain Pointë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì—¬ ì°¨ë³„í™”
   â†’ "ìš°ë¦¬ íšŒì‚¬ì˜ pain pointë¥¼ ì˜ íŒŒì•…í–ˆë‹¤" ë°˜ì‘ ìœ ë„  
3. ê³ ì •ëœ ì„œë¡ /ê²°ë¡  í˜•ì‹ ì‚¬ìš© (ë‹´ë‹¹ìì˜ ì´ë¦„ê³¼ ì§ì±…ì´ ì •í™•íˆ ë°˜ì˜ë˜ë„ë¡)
4. ë‹´ë‹¹ìì˜ ì§ì±…ì— ë§ëŠ” ê´€ì ìœ¼ë¡œ Pain Pointì™€ í•´ê²°ì±… ì œì‹œ
5. ì‹¤ì œ ìˆ˜ì¹˜ì™€ êµ¬ì²´ì  í˜œíƒ ì œì‹œ (85% ì ˆê°, 90% ë‹¨ì¶•, 15% í–¥ìƒ ë“±)
   â†’ "êµ¬ì²´ì ì´ê³  ê´€ë ¨ì„±ì´ ë†’ë‹¤" í‰ê°€ í™•ë³´
6. PortOne ì´ìš© ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í•´ë‹¹ ê¸°ì—… ì‚¬ë¡€ë¥¼ ì–¸ê¸‰
   â†’ "ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ" ì¸ì‹ ê°•í™”
7. "ë¹„ìŠ·í•œ ê³ ë¯¼ì„ ê°€ì§„ ë‹¤ë¥¸ ê³ ê°ì‚¬ë„..." ì‹ì˜ ì‚¬ë¡€ ì•”ì‹œ
8. **ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ìš”ì†Œ í¬í•¨**:
   - ì‹œê¸‰ì„±: "ì§€ê¸ˆ ê²ªê³  ê³„ì‹¤" ë¬¸ì œ ì–¸ê¸‰
   - ê´€ë ¨ì„±: "{company_name}ë§Œì˜ êµ¬ì²´ì  ìƒí™©" ì •í™•íˆ ì§€ì 
   - ì‹¤í˜„ ê°€ëŠ¥ì„±: "2ì£¼ ë‚´ êµ¬ì¶•" ë“± êµ¬ì²´ì  íƒ€ì„ë¼ì¸
   - **ì£¼ì˜**: ì‹¤ì œ ì´ë©”ì¼ ë³¸ë¬¸ì—ì„œëŠ” "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì ˆëŒ€" ë“± ê·¹ë‹¨ì  í‘œí˜„ì€ í”¼í•˜ê³  í˜„ì‹¤ì  í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "ë¹ ë¥´ê²Œ", "90% ì´ìƒ", "ë†’ì€ ì •í™•ë„ë¡œ")

**í¼í”Œë ‰ì‹œí‹° ë‰´ìŠ¤ ì§ì ‘ ì¸ìš© ì˜ˆì‹œ:**
- "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ ì‹œë¦¬ì¦ˆA 50ì–µì› íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤'ê³  ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ..."
- "'{company_name}ì˜ 2ë¶„ê¸° ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 200% ì¦ê°€í–ˆë‹¤'ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥ì— ë”°ë¥¸ ì‹œìŠ¤í…œ ë¶€ë‹´ì€ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ê³„ì‹ ê°€ìš”?"
- "'{company_name}ê°€ ë™ë‚¨ì•„ì‹œì•„ ì‹œì¥ ì§„ì¶œì„ ë°œí‘œí–ˆë‹¤'ëŠ” ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í•´ì™¸ ì§„ì¶œ ì‹œ í˜„ì§€ ê²°ì œ ì—°ë™ì´ ë³µì¡í•˜ì‹¤ í…ë°..."
- "'{company_name}ì´ AI ì„œë¹„ìŠ¤ ì‹ ì‚¬ì—…ì„ ì‹œì‘í•œë‹¤'ê³  ë“¤ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìˆ˜ìµ ëª¨ë¸ì— ë§ëŠ” ê²°ì œ ì‹œìŠ¤í…œë„ í•„ìš”í•˜ì‹¤ ê²ƒ ê°™ì€ë°..."

**ì§ì±…ë³„ ë§ì¶¤ ì ‘ê·¼ë²•:**
- **ëŒ€í‘œ/CEO/ì‚¬ì¥**: ì „ëµì  ê´€ì , ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥, íˆ¬ì íš¨ìœ¨ì„± ê°•ì¡°
- **ì´ì‚¬/ë¶€ì¥ê¸‰**: ì¡°ì§ íš¨ìœ¨ì„±, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬, ì„±ê³¼ ê°œì„ ì— ì§‘ì¤‘
- **íŒ€ì¥/ë§¤ë‹ˆì €**: íŒ€ ìš´ì˜ íš¨ìœ¨í™”, ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ê°œì„  ì¤‘ì‹¬
- **ì‹¤ë¬´ì§„ (ëŒ€ë¦¬/ì£¼ì„ ë“±)**: ì¼ìƒ ì—…ë¬´ì˜ êµ¬ì²´ì  ì–´ë ¤ì›€ê³¼ í•´ê²°ì±… ì œì‹œ

**PortOne ì´ìš© ê²½ìŸì‚¬ ì‚¬ë¡€ í™œìš© ì§€ì¹¨:**
{f"- {competitor_name}ë„ ê³¼ê±° ê°™ì€ ê³ ë¯¼ì„ í–ˆì—ˆì§€ë§Œ, PortOne ë„ì… í›„ ê°œë°œ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•˜ì—¬ ì§€ê¸ˆì€ ì„œë¹„ìŠ¤ ë³¸ì§ˆì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤." if competitor_name else ""}
{f"- {competitor_name}ì˜ ê²½ìš°ë„ ì²˜ìŒì—ëŠ” ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì„ íˆ¬ìí–ˆì§€ë§Œ, PortOneìœ¼ë¡œ ì „í™˜í•œ í›„ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ íˆ¬ì…í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤." if competitor_name else ""}
{f"- ê°™ì€ ì—…ê³„ì˜ {competitor_name}ë„ ë¹„ìŠ·í•œ Pain Pointë¡œ ì–´ë ¤ì›€ì„ ê²ªë‹¤ê°€ PortOneì„ í†µí•´ í•´ê²°í–ˆìŠµë‹ˆë‹¤." if competitor_name else ""}

**ì‚¬ë¡€ ì–¸ê¸‰ ë°©ì‹:**
{f'- "{competitor_name}ë„ ê³¼ê±° ê°™ì€ ê³ ë¯¼ì„ í•˜ì…¨ì§€ë§Œ, PortOne ë„ì… í›„ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½ìœ¼ë¡œ ì§€ê¸ˆì€ ì„œë¹„ìŠ¤ ë³¸ì§ˆì— ì§‘ì¤‘í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."' if competitor_name else ''}
{f'- "ì‹¤ì œë¡œ {competitor_name} ê°™ì€ ê²½ìš°ë„ PortOne ë„ì… ì „ì—ëŠ” ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•ì— 6ê°œì›” ì´ìƒ ì†Œìš”ëì§€ë§Œ, ì§€ê¸ˆì€ 2ì£¼ ë‚´ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì¶œì‹œí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤."' if competitor_name else ''}

**ê³ ì • ì„œë¡  í˜•ì‹:**
"ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤."

**ê³ ì • ê²°ë¡  í˜•ì‹ (í•„ìˆ˜!):**
"âš ï¸  **ë°˜ë“œì‹œ** ì•„ë˜ CTA(í–‰ë™ ì´‰êµ¬)ë¥¼ í¬í•¨í•˜ì„¸ìš”. CTAê°€ ì—†ìœ¼ë©´ ì´ë©”ì¼ì´ ì™„ì„±ë˜ì§€ ì•Šì€ ê²ƒì…ë‹ˆë‹¤!"

"<br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"

â€¼ï¸ **CTA í•„ìˆ˜ í¬í•¨ ìš”êµ¬ì‚¬í•­:**
- ìœ„ì˜ "ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´" CTAëŠ” **ë°˜ë“œì‹œ** í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- ì´ CTAê°€ ë¹ ì§€ë©´ ì´ë©”ì¼ì´ ë¶ˆì™„ì „í•˜ê²Œ ë©ë‹ˆë‹¤
- ì„œëª…("ê°ì‚¬í•©ë‹ˆë‹¤. {user_name} ë“œë¦¼") ì•ì— ë°˜ë“œì‹œ CTAë¥¼ ë°°ì¹˜í•˜ì„¸ìš”

**ì´ë©”ì¼ ìœ í˜• (ìš”ì²­ëœ ì„œë¹„ìŠ¤ì— ë”°ë¼ ì„ íƒì  ìƒì„±):**

1. **One Payment Infra - ì „ë¬¸ì  í†¤**: 
{opi_blog_content}
   - **í•„ìˆ˜**: ë‰´ìŠ¤ ë‚´ìš©ì„ ì§ì ‘ ì¸ìš©. ì˜ˆ: "ìµœê·¼ ê¸°ì‚¬ì—ì„œ '{company_name}ê°€ XXì–µì› íˆ¬ì ìœ ì¹˜'ë¼ê³  ë´¤ìŠµë‹ˆë‹¤"
   - êµ¬ì²´ì  ë‰´ìŠ¤ â†’ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ í•„ìš”ì„± ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **OPI ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ìˆ˜ì¹˜/ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **ê²°ì œ ìˆ˜ë‹¨ ì–¸ê¸‰ ì‹œ**: ì‹ ìš©ì¹´ë“œ, ê°„í¸ê²°ì œ, í•´ì™¸ëŠ” ê°êµ­ì˜ ê°„í¸ê²°ì œ ìˆ˜ë‹¨ ë“± (100+ ê²°ì œ ìˆ˜ë‹¨) âŒ **ê³„ì¢Œì´ì²´ëŠ” ì–¸ê¸‰ ê¸ˆì§€**
   - OPIì˜ í•µì‹¬ í•´ê²°ì±…ê³¼ ìˆ˜ì¹˜ (í‰ê·  15-30% ìˆ˜ìˆ˜ë£Œ ì ˆê°, PGì‚¬ë³„ ê²¬ì  ë¹„êµ ì œì•ˆ)
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ í¬íŠ¸ì›ìœ¼ë¡œ..." / "ì—° 12ì¡°ì› ê·œëª¨ì˜ ê±°ë˜ë¥¼ ì•ˆì •ì ìœ¼ë¡œ..."
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ OPI ì°¸ê³  ì •ë³´ì˜ ìˆ˜ì¹˜/íŠ¸ë Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë¹„ìŠ·í•œ ì„±ì¥ ê³¼ì •ì—ì„œ<br>PortOneìœ¼ë¡œ ê²°ì œ ì¸í”„ë¼ë¥¼ ì•ˆì •í™”í–ˆìŠµë‹ˆë‹¤"

2. **One Payment Infra - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**: 
{opi_blog_content}
   - **í•„ìˆ˜**: ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì–¸ê¸‰í•œ ì§ˆë¬¸. ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, ê²°ì œëŸ‰ ì¦ê°€ëŠ” ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?"
   - ê¸‰ì„±ì¥ì— ë”°ë¥¸ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª© í˜„ìƒ ê±±ì • í‘œí˜„
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..." ê°™ì´ êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ì‹ ë¢°ë„ ê°•í™”
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ OPI ì°¸ê³  ì •ë³´ì˜ ì—…ê³„ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ìš©
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "ì‹¤ì œë¡œ {competitor_name}ë„ ê¸‰ì„±ì¥í•  ë•Œ<br>ê°™ì€ ê³ ë¯¼ì„ í–ˆì—ˆëŠ”ë°..." í˜¸ê¸°ì‹¬ ìœ ë°œ
   - "ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ê¶ê¸ˆí•˜ì‹œì§€ ì•Šë‚˜ìš”?" ê´€ì‹¬ ìœ ë„

3. **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ (Recon) - ì „ë¬¸ì  í†¤**: 
{recon_blog_content}
   - **í•„ìˆ˜**: ì„±ì¥/í™•ì¥ ë‰´ìŠ¤ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©. ì˜ˆ: "'{company_name}ê°€ ì‹ ì‚¬ì—… ë¶€ë¬¸ ì§„ì¶œ'ì´ë¼ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤"
   - ì‚¬ì—… ë‹¤ê°í™” â†’ ë³µì¡í•´ì§€ëŠ” ì¬ë¬´ ê´€ë¦¬ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **Recon ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ê¸°ëŠ¥/ì±„ë„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ”..." / "ì—° 12ì¡°ì› ê·œëª¨ ê±°ë˜ì˜ ì •ì‚°ì„..."
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ Recon ì°¸ê³  ì •ë³´ì˜ í†µê³„/íš¨ê³¼ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ë©° ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ì‚¬ì—… í™•ì¥ ì‹œ<br>ì¬ë¬´ ìë™í™”ë¡œ 90% ì‹œê°„ ì ˆì•½í–ˆìŠµë‹ˆë‹¤"
   - **Recon í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "{pg_count} PGì‚¬ì˜ ê°ê¸°ë‹¤ë¥¸ ì–‘ì‹ì—ë„ ì •í™•í•˜ê²Œ ë°ì´í„°ë¥¼ í†µí•©í•˜ê³  ì£¼ë¬¸ê±´ë‹¹ ì •ì‚°ì—¬ë¶€ íŒŒì•…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ERPì—°ë™ë„ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ì¬ë¬´íŒ€ì˜ ë°˜ë³µì ì¸ ìˆ˜ì‘ì—…ì„ 90% ì´ìƒ ë‹¨ì¶•í•˜ê³ , íœ´ë¨¼ì—ëŸ¬ë¥¼ ì¤„ì—¬ í™•ë³´ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ë” ê°€ì¹˜ ìˆëŠ” ì„±ì¥ ì „ëµì— ì§‘ì¤‘í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

4. **ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ (Recon) - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**: 
{recon_blog_content}
   - **í•„ìˆ˜**: êµ¬ì²´ì  ë‰´ìŠ¤ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸. ì˜ˆ: "'{company_name} í•´ì™¸ ì§„ì¶œ' ë‰´ìŠ¤ë¥¼ ë´¤ëŠ”ë°, ë‹¤êµ­ê°€ ì¬ë¬´ ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ í•˜ì‹¤ ê³„íšì¸ê°€ìš”?"
   - í™•ì¥ì— ë”°ë¥¸ ì¬ë¬´ ë³µì¡ì„± ì¦ê°€ ê³µê° í‘œí˜„
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´ ì´ë¯¸..." ê°™ì´ ëª…í™•í•œ ìˆ«ìë¡œ ì‹ ë¢°ë„ ì œê³µ
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ Recon ì°¸ê³  ì •ë³´ì˜ Pain Pointë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ê¸€ë¡œë²Œ ì§„ì¶œ ì‹œ<br>ì¬ë¬´ í†µí•© ê´€ë¦¬ë¡œ í° ë„ì›€ì„ ë°›ì•˜ëŠ”ë°..." í˜¸ê¸°ì‹¬ ìê·¹
   - **Recon í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "{pg_count} PGì‚¬ì˜ ë‹¤ë¥¸ ë°ì´í„° í˜•ì‹ë„ ìë™ìœ¼ë¡œ í†µí•©í•˜ê³ , ERP ì—°ë™ìœ¼ë¡œ ì¬ë¬´íŒ€ ì—…ë¬´ë¥¼ 90% ì´ìƒ ì¤„ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íœ´ë¨¼ì—ëŸ¬ë„ ì œê±°í•˜ê³ ìš”"
   - "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë„ì›€ì´ ë˜ëŠ”ì§€ ë³´ì—¬ë“œë¦´ê¹Œìš”?" ê´€ì‹¬ ìœ ë„

5. **ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ (Prism) - ì „ë¬¸ì  í†¤**: 
{prism_blog_content}
   - **í•„ìˆ˜**: ì˜¤í”ˆë§ˆì¼“ í™•ì¥/ë§¤ì¶œ ì¦ê°€ ë‰´ìŠ¤ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©. ì˜ˆ: "'{company_name}ê°€ ì¿ íŒ¡/11ë²ˆê°€ ì…ì  í™•ëŒ€'ë¼ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤"
   - ë‹¤ì¤‘ ì˜¤í”ˆë§ˆì¼“ ìš´ì˜ â†’ ê° í”Œë«í¼ë§ˆë‹¤ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€ê³¼ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì¸í•œ ë³µì¡í•œ ì •ì‚° ê´€ë¦¬/í˜„ê¸ˆíë¦„ íŒŒì•… ì–´ë ¤ì›€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - **Prism ì°¸ê³  ì •ë³´ì— ëª…ì‹œëœ ê¸°ëŠ¥ë§Œ ì–¸ê¸‰**: ìœ„ ì°¸ê³  ì •ë³´ì—ì„œ í™•ì¸ëœ ì±„ë„/ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - **í•µì‹¬ Pain Point**: ê° ì˜¤í”ˆë§ˆì¼“ì˜ ì •ì‚°ê¸°ì¤€/ì£¼ê¸° ì°¨ì´, ë°˜ë³µì ì¸ ì—‘ì…€ ì‘ì—…, ë¯¸ìˆ˜ê¸ˆ ê´€ë¦¬ ì–´ë ¤ì›€, ë°ì´í„° ëˆ„ë½/ì˜¤ë¥˜
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì¬ë¬´ ë§ˆê° ì‹œê°„ **90% ì´ìƒ ë‹¨ì¶•**" / "**ë†’ì€ ë°ì´í„° ì •í•©ì„±** í™•ë³´"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ Prism ì°¸ê³  ì •ë³´ì˜ í†µê³„/íš¨ê³¼ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ë©° ì„¤ë“ë ¥ ê°•í™”
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë‹¤ì¤‘ ì±„ë„ ìš´ì˜ ì‹œ<br>Prismìœ¼ë¡œ ì¬ë¬´íŒ€ ì—…ë¬´ë¥¼ 90% ìë™í™”í–ˆìŠµë‹ˆë‹¤"
   - **Prism í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´, ì¿ íŒ¡, ì¹´ì¹´ì˜¤ìŠ¤íƒ€ì¼ ë“± ê° ì˜¤í”ˆë§ˆì¼“ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚°ê¸°ì¤€ê³¼ ì£¼ê¸°ë¥¼ ìë™ìœ¼ë¡œ í†µí•©í•˜ì—¬, ì •í™•í•œ í˜„ê¸ˆíë¦„ê³¼ ë¯¸ìˆ˜ê¸ˆì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ë°˜ë³µì ì¸ ì—‘ì…€ ì‘ì—…ì„ ìë™í™”í•˜ê³ , ë†’ì€ ë°ì´í„° ì •í•©ì„±ìœ¼ë¡œ íœ´ë¨¼ì—ëŸ¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤"

6. **ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ (Prism) - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**: 
{prism_blog_content}
   - **í•„ìˆ˜**: êµ¬ì²´ì  ë‰´ìŠ¤ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸. ì˜ˆ: "'{company_name}ì˜ 2ë¶„ê¸° ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ì—¬ëŸ¬ ì˜¤í”ˆë§ˆì¼“ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ëŠ” ì–´ë–»ê²Œ ê´€ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?"
   - ì±„ë„ í™•ì¥ì— ë”°ë¥¸ ì¬ë¬´ ë³µì¡ì„± ì¦ê°€ ê³µê° í‘œí˜„
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì´ë¯¸ êµ­ë‚´ 3,000ì—¬ê°œ ê¸°ì—…ì´..." ê°™ì´ ëª…í™•í•œ ìˆ«ìë¡œ ì‹ ë¢°ë„ ì œê³µ
   - **í•µì‹¬ Pain Point ê³µê°**: "í˜¹ì‹œ ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° ì±„ë„ë§ˆë‹¤ ì •ì‚° ë°ì´í„° ë‹¤ìš´ë¡œë“œí•˜ê³  ì—‘ì…€ë¡œ ìˆ˜ì‘ì—…í•˜ì‹œë‚˜ìš”?"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ìœ„ Prism ì°¸ê³  ì •ë³´ì˜ Pain Pointë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ë‹¤ì¤‘ ì±„ë„ í™•ì¥ ì‹œ<br>ì¬ë¬´ ë§ˆê° ìë™í™”ë¡œ í° ë„ì›€ì„ ë°›ì•˜ëŠ”ë°..." í˜¸ê¸°ì‹¬ ìê·¹
   - **Prism í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "ê° ì˜¤í”ˆë§ˆì¼“ì˜ ë‹¤ë¥¸ ì •ì‚° í˜•ì‹ë„ ìë™ìœ¼ë¡œ í†µí•©í•˜ê³ , í˜„ê¸ˆíë¦„/ë¯¸ìˆ˜ê¸ˆì„ ì‹¤ì‹œê°„ íŒŒì•…í•˜ì—¬ ì¬ë¬´íŒ€ ì—…ë¬´ë¥¼ **90% ì´ìƒ** ì¤„ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   - "ì–´ë–»ê²Œ ì›”ë§ ë§ˆê°ì„ í•˜ë£¨ ë§Œì— ëë‚¼ ìˆ˜ ìˆëŠ”ì§€ ë³´ì—¬ë“œë¦´ê¹Œìš”?" ê´€ì‹¬ ìœ ë„

7. **í”Œë«í¼ ì •ì‚° ìë™í™” (íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) - ì „ë¬¸ì  í†¤**: 
{ps_blog_content}
   - **í•„ìˆ˜**: í”Œë«í¼/ë§ˆì¼“í”Œë ˆì´ìŠ¤ í™•ì¥ ë‰´ìŠ¤ ì¸ìš©. ì˜ˆ: "'{company_name}ì˜ íŒë§¤ì ìˆ˜ 2ë°° ì¦ê°€'ë¼ëŠ” ì†Œì‹ì„ ë´¤ëŠ”ë°, íŒŒíŠ¸ë„ˆ ì •ì‚° ì—…ë¬´ë„ ê°™ì´ ëŠ˜ì–´ë‚˜ì…¨ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤"
   - **í•µì‹¬ Pain Point**: ë§¤ë‹¬ í•œ ë‹¬ ê±¸ë¦¬ëŠ” íŒŒíŠ¸ë„ˆ ì •ì‚° ì‘ì—…, ìˆ˜ê¸° ì •ì‚°ê¸ˆ ê³„ì‚° ì˜¤ë¥˜, í™ˆíƒìŠ¤ ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰ì˜ ë³µì¡í•¨, ì œí•œì ì¸ ì§€ê¸‰ ì‹œê°„(ì˜ì—…ì¼ë§Œ), ê°œì¸/í”„ë¦¬ëœì„œ ì§€ê¸‰ ë¶ˆê°€
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "**í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ë‹¨ì¶•** (ì¸í”„ëŸ° ì‚¬ë¡€)", "**100,000ê±´ ì´ìƒ ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰**", "**365ì¼ 24ì‹œê°„ ì§€ê¸‰**"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ì¸í”„ëŸ° ë„ì… ì‚¬ë¡€ ë“± ì‹¤ì œ ê³ ê° ì„±ê³¼ ì–¸ê¸‰
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ íŒŒíŠ¸ë„ˆ ìˆ˜ ì¦ê°€ë¡œ ì •ì‚° ìë™í™”ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤"
   - **í”Œë«í¼ ì •ì‚° í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "íŒŒíŠ¸ë„ˆ ì •ì‚°ê¸ˆ ìë™ ê³„ì‚°ë¶€í„° ì„¸ê¸ˆê³„ì‚°ì„œ ì¼ê´„ ë°œí–‰, 365ì¼ ì§€ê¸‰ê¹Œì§€ í•˜ë‚˜ì˜ í”Œë«í¼ì—ì„œ ì™„ì „ ìë™í™”í•©ë‹ˆë‹¤. í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚° ì—…ë¬´ë¥¼ ì´í‹€ë¡œ ë‹¨ì¶•í•˜ê³ , ê°œì¸/ë²•ì¸/í”„ë¦¬ëœì„œ êµ¬ë¶„ ì—†ì´ ëª¨ë‘ ì§€ê¸‰ ê°€ëŠ¥í•˜ë©°, ì£¼ë§ê³¼ ê³µíœ´ì¼ì—ë„ ì‹¤ì‹œê°„ ì§€ê¸‰ë©ë‹ˆë‹¤"

8. **í”Œë«í¼ ì •ì‚° ìë™í™” (íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) - í˜¸ê¸°ì‹¬ ìœ ë°œí˜•**: 
{ps_blog_content}
   - **í•„ìˆ˜**: êµ¬ì²´ì  ìƒí™©ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸. ì˜ˆ: "'{company_name}ì˜ ì…ì  íŒŒíŠ¸ë„ˆ 3ë°° ì¦ê°€' ì†Œì‹ì„ ë´¤ëŠ”ë°, í˜¹ì‹œ ë§¤ë‹¬ ì •ì‚°í•˜ëŠë¼ ì›”ë§ë§ˆë‹¤ ì•¼ê·¼í•˜ê³  ê³„ì‹œì§„ ì•Šìœ¼ì‹ ê°€ìš”?"
   - **í•µì‹¬ Pain Point ê³µê°**: "íŒŒíŠ¸ë„ˆë³„ë¡œ ë‹¤ë¥¸ ìˆ˜ìˆ˜ë£Œìœ¨ ì ìš©í•˜ê³ , ì„¸ê¸ˆê³„ì‚°ì„œ ë°œí–‰í•˜ê³ , í•˜ë‚˜í•˜ë‚˜ ì†¡ê¸ˆí•˜ëŠ” ì—…ë¬´... ìƒê°ë³´ë‹¤ ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ì£ "
   - **êµ¬ì²´ì  ìˆ˜ì¹˜ í™œìš©**: "ì¸í”„ëŸ°ì€ í•œ ë‹¬ ê±¸ë¦¬ë˜ ì •ì‚°ì„ ì´í‹€ë¡œ ì¤„ì˜€ìŠµë‹ˆë‹¤", "í™ˆíƒìŠ¤ëŠ” 1,000ê±´ê¹Œì§€ë§Œ ê°€ëŠ¥í•˜ì§€ë§Œ í¬íŠ¸ì›ì€ 100,000ê±´ë„ ì¼ê´„ ë°œí–‰"
   - **ë¸”ë¡œê·¸ ì •ë³´ í™œìš©**: ì‹¤ì œ í”Œë«í¼ ê¸°ì—…ë“¤ì˜ ì •ì‚° ê³ ë¯¼ê³¼ í•´ê²° ì‚¬ë¡€
   - **ê²½ìŸì‚¬ê°€ ìˆë‹¤ë©´**: "{competitor_name}ë„ ì •ì‚° ìë™í™”ë¡œ ì¬ë¬´íŒ€ ë¦¬ì†ŒìŠ¤ë¥¼ í•µì‹¬ ì—…ë¬´ì— ì§‘ì¤‘í•˜ê³  ìˆëŠ”ë°..." í˜¸ê¸°ì‹¬ ìê·¹
   - **í”Œë«í¼ ì •ì‚° í•µì‹¬ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ (ë°˜ë“œì‹œ í¬í•¨)**: "ì •ì‚°ê¸ˆ ê³„ì‚°-ì„¸ê¸ˆê³„ì‚°ì„œ-ì§€ê¸‰ê¹Œì§€ ì›í´ë¦­ìœ¼ë¡œ ëë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ë§ì—ë„ ì§€ê¸‰ ê°€ëŠ¥í•˜ê³ , ê°œì¸ íŒŒíŠ¸ë„ˆì—ê²Œë„ ë°”ë¡œ ì†¡ê¸ˆí•  ìˆ˜ ìˆì–´ìš”"
   - "ì‹¤ì œë¡œ ì–´ë–»ê²Œ í•œ ë‹¬ ì •ì‚°ì„ ì´í‹€ë¡œ ì¤„ì˜€ëŠ”ì§€ ë³´ì—¬ë“œë¦´ê¹Œìš”?" ê´€ì‹¬ ìœ ë„

ğŸ†• **9. ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ë¬¸ì•ˆ (multi_service_professional / multi_service_curiosity):**

Detected Services: {', '.join(detected_services) if is_multi_service else 'N/A'}

**ë³µìˆ˜ ì„œë¹„ìŠ¤ í†µí•© ì „ëµ:**
- **í•µì‹¬ ì›ì¹™**: í•˜ë‚˜ì˜ íìŠ¤í† ë¨¸ Pain Pointì—ì„œ ì‹œì‘í•˜ì—¬ ë³µìˆ˜ ì„œë¹„ìŠ¤ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- **ì–´ìƒ‰í•˜ê²Œ ë¶€ê°ëœ ì œì•ˆì„ í•˜ì§€ ë§ ê²ƒ**: "ì´ê²ƒë„ í•´ë“œë¦½ë‹ˆë‹¤, ì €ê²ƒë„ í•´ë“œë¦½ë‹ˆë‹¤" ë°©ì‹ ê¸ˆì§€
- **ìŠ¤í† ë¦¬ ê¸°ë°˜ í†µí•©**: ê³ ê°ì˜ ì„±ì¥ ìŠ¤í† ë¦¬ ì•ˆì—ì„œ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•œ ì´ìœ ë¥¼ ì„¤ëª…

**í†µí•© ë°©ì‹ ì˜ˆì‹œ:**

**OPI + PS ì¡°í•© (í•´ì™¸ ì§„ì¶œ + í”Œë«í¼)**:
- ì‹œì‘: "í•´ì™¸ ì§„ì¶œ ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. í˜„ì§€ ê²°ì œ ì—°ë™ê³¼ íŒŒíŠ¸ë„ˆ ì •ì‚°, ë‘˜ ë‹¤ ë¶€ë‹´ë˜ì‹¤ í…ë°..."
- ì—°ê²°: "**OPIë¡œ í˜„ì§€ ê²°ì œ** ì—°ë™í•˜ë©´ì„œ, ë™ì‹œì— **PSë¡œ í˜„ì§€ íŒŒíŠ¸ë„ˆ ì •ì‚°ê¹Œì§€** ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- ê°€ì¹˜: "ê¸€ë¡œë²Œ í™•ì¥ì— í•„ìš”í•œ ëª¨ë“  ì¬ë¬´ ì¸í”„ë¼ë¥¼ í•œ ë²ˆì— í•´ê²°"

**Prism + PS ì¡°í•© (ì»¤ë¨¸ìŠ¤ + í”Œë«í¼ ì •ì‚°)**:
- ì‹œì‘: "ë‹¤ì¤‘ ì˜¤í”ˆë§ˆì¼“ í™•ì¥ ë‰´ìŠ¤ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ê° ì±„ë„ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ê¸°ì¤€ê³¼ íŒŒíŠ¸ë„ˆì‚¬ ì •ì‚°ê¹Œì§€, ì¬ë¬´íŒ€ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ì€ë°..."
- ì—°ê²°: "**Prismìœ¼ë¡œ ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©** + **PSë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”**ë¡œ ëª¨ë‘ í•´ê²°ë©ë‹ˆë‹¤"
- ê°€ì¹˜: "ì›”ë§ ì¬ë¬´ ë§ˆê°ì„ **90% ì´ìƒ ë‹¨ì¶•**í•˜ê³  ì •í™•ì„±ë„ í™•ë³´"

**OPI + Recon ì¡°í•© (í•´ì™¸ + ì¬ë¬´ìë™í™”)**:
- ì‹œì‘: "ê¸€ë¡œë²Œ í™•ì¥ê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ PGì‚¬ ë°ì´í„° í†µí•©ì´ ë³µì¡í•´ì§€ì‹¤ í…ë°..."
- ì—°ê²°: "**OPIë¡œ {pg_count} PGì‚¬ í†µí•©** + **Reconìœ¼ë¡œ ë‹¤êµ­ê°€ ì¬ë¬´ ìë™í™”**"
- ê°€ì¹˜: "êµ­ë‚´ì™¸ ëª¨ë“  ì¬ë¬´ ë°ì´í„°ë¥¼ í•œ ê³³ì—ì„œ ê´€ë¦¬"

**PS + Recon ì¡°í•© (í”Œë«í¼ + ì¬ë¬´)**:
- ì‹œì‘: "í”Œë«í¼ í™•ì¥ìœ¼ë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚°ê³¼ ì „ì²´ ì¬ë¬´ ê´€ë¦¬ê°€ ë³µì¡í•´ì§€ì…¨ì„ í…ë°..."
- ì—°ê²°: "**PSë¡œ íŒŒíŠ¸ë„ˆ ì •ì‚° ìë™í™”** + **Reconìœ¼ë¡œ ì „ì²´ ì¬ë¬´ í†µí•©**"
- ê°€ì¹˜: "íŒŒíŠ¸ë„ˆ ì •ì‚°ë¶€í„° ERP ì—°ë™ê¹Œì§€ ì™„ì „ ìë™í™”"

**í†µí•© ë¬¸ì•ˆ ì‘ì„± ì£¼ì˜ì‚¬í•­:**
- ê° ì„œë¹„ìŠ¤ì˜ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ëª¨ë‘ í™œìš©í•˜ë˜, **í•˜ë‚˜ì˜ ìŠ¤í† ë¦¬ë¡œ ì—°ê²°**
- ì„œë¹„ìŠ¤ë³„ ê°€ì¹˜ í”„ë¡œí¬ì§€ì…˜ì€ ë³¸ë¬¸ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì–¸ê¸‰ (ëª©ë¡í˜• ë‚˜ì—´ ê¸ˆì§€)
- Pain Point ê³µê° â†’ í†µí•© ì†”ë£¨ì…˜ ì œì•ˆ â†’ ê²°í•© íš¨ê³¼ ê°•ì¡° ìˆœì„œë¡œ ì „ê°œ
- **ë¶„ëŸ‰ ì£¼ì˜**: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ì–¸ê¸‰í•˜ë”ë¼ë„ ì „ì²´ ë³¸ë¬¸ì€ 130-200ë‹¨ì–´ ìœ ì§€

**êµ¬ì¡° ë° í˜•ì‹:**
- ì œëª©: ê³ ì • í˜•ì‹ ì‚¬ìš© ("[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤") - ë³¸ë¬¸ì— ì œëª© í¬í•¨í•˜ì§€ ë§ê²ƒ
- ë³¸ë¬¸: ê³ ì • ì„œë¡  â†’ Pain Point ì œê¸°(50-70ë‹¨ì–´) â†’ í•´ê²°ì±… ì œì‹œ(50-70ë‹¨ì–´) â†’ ê²½ìŸì‚¬ ì‚¬ë¡€/í˜œíƒ(30-50ë‹¨ì–´) â†’ ê³ ì • ê²°ë¡ 
- ì „ì²´ ë³¸ë¬¸: 130-200ë‹¨ì–´ë¡œ ê°„ê²°í•˜ë©´ì„œë„ í•µì‹¬ì ìœ¼ë¡œ ì‘ì„±
- **ğŸ‘Š ì •ëŸ‰ì  ìˆ˜ì¹˜ì™€ í•µì‹¬ ê°€ì¹˜ ì œì•ˆì€ ë°˜ë“œì‹œ ë³¼ë“œ ì²˜ë¦¬í•˜ì„¸ìš”**:
  * ì˜ˆ: **85% ë¦¬ì†ŒìŠ¤ ì ˆê°**, **2ì£¼ ë‚´ êµ¬ì¶•**, **90% ìë™í™”**, **15% í–¥ìƒ**, **0.5% ìˆ˜ìˆ˜ë£Œ** ë“±
  * ê°€ì¹˜ ì œì•ˆ: **ë¬´ë£Œ ì»¨ì„¤íŒ…**, **ì‹ ìš©ì¹´ë“œ/ê°„í¸ê²°ì œ**, **100+ ê²°ì œ ìˆ˜ë‹¨** ë“±
  * Pain Point í•´ê²°ì±…ì˜ í•µì‹¬ ê¸°ëŠ¥ë„ ë³¼ë“œ ì²˜ë¦¬
- **í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¾¸ê¸° ê·œì¹™ (ë§¤ìš° ì¤‘ìš”)**:
  * **ê¸°ë³¸ ê·œì¹™: í•œ ë¬¸ì¥ì´ 40-50ì (ê³µë°± í¬í•¨)ë¥¼ ë„˜ìœ¼ë©´ ë°˜ë“œì‹œ ì¤„ë°”ê¾¸ê¸°**
  * ê° ì¤„ì€ 25-50ì ë²”ìœ„ë¡œ ìœ ì§€, ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŠê¸°
  * **ë¬¸ë‹¨ ê°„ êµ¬ë¶„: ìƒˆë¡œìš´ ì£¼ì œë¡œ ë„˜ì–´ê°ˆ ë•ŒëŠ” ë°˜ë“œì‹œ `<br><br>` (ë¹ˆ ì¤„) ì‚¬ìš©**
  * ê¸´ ë¬¸ì¥ì€ ì ˆ(clause) ë‹¨ìœ„ë¡œ ëŠì–´ì„œ í˜¸í¡ê° í™•ë³´
  * ë¦¬ìŠ¤íŠ¸/ë‚˜ì—´: ê° í•­ëª©ë§ˆë‹¤ `<br>`
  * ì˜ˆì‹œ:
    ```
    ë‚˜ìœ ì¤„ë°”ê¿ˆ:
    "ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
    
    ì¢‹ì€ ì¤„ë°”ê¿ˆ:
    "ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤.<br>
    ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ<br>
    ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
    ```
  * **ì‹¤ì œ ì„ í˜¸ ì˜ˆì‹œ (25-50ì ë²”ìœ„)**:
    ```
    <p>ìµœê·¼ í´ë¦°ë””ê°€ 'í˜ì‹ ì„±ì¥ìœ í˜• ë²¤ì²˜ê¸°ì—…'ìœ¼ë¡œ ì¸ì¦ë°›ì•˜ë‹¤ëŠ” ê¸°ì‚¬ë¥¼ ì¸ìƒ ê¹Šê²Œ ë´¤ìŠµë‹ˆë‹¤.<br>
    ê¸°ìˆ ë ¥ê³¼ ì„±ì¥ ê°€ëŠ¥ì„±ì„ ê³µì‹ì ìœ¼ë¡œ ì¸ì •ë°›ìœ¼ì‹  ë§Œí¼,<br>
    AI ê¸°ë°˜ ì‹ ì‚¬ì—…ê³¼ êµ­ë‚´ì™¸ ì‹œì¥ í™•ì¥ì— ë”ìš± ì§‘ì¤‘í•˜ê³  ê³„ì‹¤ í…ë°ìš”.</p>
    
    <p>ì´ëŸ¬í•œ ê¸‰ê²©í•œ ì„±ì¥ ê³¼ì •ì—ì„œ êµ¬ë… ì„œë¹„ìŠ¤, ìì‚¬ëª°, B2B ì±„ë„ ë“±<br>
    ë‹¤ê°í™”ëœ ë§¤ì¶œ ì±„ë„ì˜ ì •ì‚° ë°ì´í„° í†µí•©ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.</p>
    ```
- í†¤: ì „ë¬¸ì ì´ë©´ì„œë„ ê³µê°í•˜ê³  ë„ì›€ì„ ì£¼ëŠ” ê´€ì , ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„

**ì¤‘ìš”**: ì–´ë–¤ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

**ìƒì„±í•  ì„œë¹„ìŠ¤**: {', '.join(services_to_generate)}

{{
  "opi_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "opi_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "ps_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "ps_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "multi_service_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "multi_service_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>[ë³¸ë¬¸ ë‚´ìš©]<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }}
}}
"""
        
        # Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í´ë°± ì‘ë‹µ ìƒì„±
        if not GEMINI_API_KEY:
            return {
                'success': True,
                'variations': {
                    'professional': {
                        'subject': company_name + ' ë§ì¶¤í˜• ê²°ì œ ì¸í”„ë¼ ì œì•ˆ',
                        'body': 'ì•ˆë…•í•˜ì„¸ìš”, ' + company_name + ' ë‹´ë‹¹ìë‹˜!\n\n' + company_name + 'ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” PortOneì˜ One Payment Infraë¥¼ ì†Œê°œë“œë¦¬ê³ ì ì—°ë½ë“œë¦½ë‹ˆë‹¤.\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ê³¼ ë””ì§€í„¸ ì „í™˜ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. PortOneì˜ ì†”ë£¨ì…˜ì€:\n\nâ€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ ì ˆì•½ (80% ë‹¨ì¶•)\nâ€¢ ë¹ ë¥¸ ë„ì… (ìµœì†Œ 2ì£¼)\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ\n\n15ë¶„ ê°„ë‹¨í•œ ë°ëª¨ë¥¼ í†µí•´ ' + company_name + 'ì— ì–´ë–¤ í˜œíƒì´ ìˆëŠ”ì§€ ë³´ì—¬ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                    },
                    'friendly': {
                        'subject': company_name + 'ë‹˜, ê²°ì œ ì‹œìŠ¤í…œ ê³ ë¯¼ ìˆìœ¼ì‹ ê°€ìš”?',
                        'body': 'ì•ˆë…•í•˜ì„¸ìš”! ' + company_name + ' ë‹´ë‹¹ìë‹˜ :)\n\ní˜¹ì‹œ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ì´ë‚˜ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¬¸ì œë¡œ ê³ ë¯¼ì´ ìˆìœ¼ì‹ ê°€ìš”?\n\nì €í¬ PortOneì€ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ One Payment Infraë¥¼ ë§Œë“¤ì—ˆì–´ìš”!\n\níŠ¹íˆ ì´ëŸ° ì ë“¤ì´ ë„ì›€ì´ ë  ê±°ì˜ˆìš”:\nğŸš€ ê°œë°œ ì‹œê°„ 80% ë‹¨ì¶•\nğŸ’° ë¹„ìš© ì ˆì•½\nğŸ”§ ë¬´ë£Œ ì»¨ì„¤íŒ…\nğŸ“ˆ ê²°ì œ ì„±ê³µë¥  UP\n\nì»¤í”¼ í•œ ì” ë§ˆì‹œë©° 15ë¶„ë§Œ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”? ì–´ë–¤ ë‚ ì´ í¸í•˜ì‹ ì§€ ì•Œë ¤ì£¼ì„¸ìš”!\n\nê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š\nPortOne ì˜ì—…íŒ€'
                    }
                },
                'timestamp': datetime.now().isoformat(),
                'note': 'AWS Bedrock ëª¨ë¸ ì ‘ê·¼ ë¶ˆê°€ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
            }
        
        # Gemini API í˜¸ì¶œ
        try:
            model = genai.GenerativeModel('gemini-2.5-pro')
            response = model.generate_content(prompt)
            
            if response.text:
                # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
                try:
                    # ì „ì²´ ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ
                    clean_response = response.text.strip()
                    
                    # JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
                    if '```json' in clean_response:
                        json_start = clean_response.find('```json') + 7
                        json_end = clean_response.find('```', json_start)
                        if json_end != -1:
                            clean_response = clean_response[json_start:json_end]
                        else:
                            clean_response = clean_response[json_start:]
                    elif '{' in clean_response and '}' in clean_response:
                        # JSON ê°ì²´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        json_start = clean_response.find('{')
                        json_end = clean_response.rfind('}') + 1
                        clean_response = clean_response[json_start:json_end]
                    
                    clean_response = clean_response.strip()
                    
                    # JSON íŒŒì‹±
                    email_variations = json.loads(clean_response)
                    
                    # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
                    def convert_markdown_to_html(text):
                        """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ HTMLë¡œ ë³€í™˜ (**ë³¼ë“œ**, *ì´íƒ¤ë¦­* ë“±)"""
                        import re
                        # **í…ìŠ¤íŠ¸** â†’ <strong>í…ìŠ¤íŠ¸</strong>
                        text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
                        # *í…ìŠ¤íŠ¸* â†’ <em>í…ìŠ¤íŠ¸</em> (ë³¼ë“œ ì²˜ë¦¬ í›„ ë‚¨ì€ ë‹¨ì¼ *)
                        text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
                        return text
                    
                    # í”Œë ˆì´ìŠ¤í™€ë” êµì²´ í•¨ìˆ˜
                    def replace_placeholders(text, company_name, email_name, competitor_name=''):
                        result = text.replace('{company_name}', company_name).replace('{email_name}', email_name)
                        if competitor_name:
                            result = result.replace('{competitor_name}', competitor_name)
                        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
                        result = result.replace('ì˜¤ì¤€í˜¸', user_name)
                        result = result.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
                        # ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì ìš©
                        result = convert_markdown_to_html(result)
                        return result
                    
                    # ì‘ë‹µ í˜•ì‹ ë³€í™˜ ë° í”Œë ˆì´ìŠ¤í™€ë” êµì²´ (ìš”ì²­ëœ ì„œë¹„ìŠ¤ë§Œ)
                    formatted_variations = {}
                    
                    for service in services_to_generate:
                        if service in email_variations:
                            # ê³ ì • ì œëª© ì‚¬ìš©
                            subject = f'[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤'
                            
                            # bodyë§Œ í”Œë ˆì´ìŠ¤í™€ë” êµì²´
                            body = replace_placeholders(email_variations[service]['body'], company_name, email_name, competitor_name)
                            
                            formatted_variations[service] = {
                                'subject': subject,
                                'body': body
                            }
                            logger.info(f"ì„œë¹„ìŠ¤ '{service}' ë¬¸ì•ˆ ìƒì„± ì™„ë£Œ: {company_name}")
                    
                    # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
                    logger.info(f"{company_name}: CTA ê²€ì¦ ì‹œì‘...")
                    for service_key, email_content in formatted_variations.items():
                        if 'body' in email_content:
                            email_content['body'] = validate_and_fix_cta(
                                email_content['body'],
                                company_name
                            )
                    
                    return {
                        'success': True,
                        'variations': formatted_variations,
                        'services_generated': services_to_generate,
                        'sales_item': sales_item if sales_item else 'all',
                        'timestamp': datetime.now().isoformat(),
                        'model': 'gemini-2.5-pro-exp'
                    }
                    
                except json.JSONDecodeError as json_error:
                    logger.error(f"Gemini JSON íŒŒì‹± ì˜¤ë¥˜: {json_error}")
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
                    return {
                        'success': True,
                        'variations': {
                            'professional': {
                                'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                                'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\n{pain_points}\n\nPortOneì˜ One Payment Infraë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½\nâ€¢ 2ì£¼ ë‚´ êµ¬ì¶• ì™„ë£Œ\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\n\nê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                            }
                        },
                        'timestamp': datetime.now().isoformat(),
                        'note': 'JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
                    }
            
            else:
                logger.error("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                # ë¹ˆ ì‘ë‹µ ì‹œ í´ë°±
                return {
                    'success': True,
                    'variations': {
                        'professional': {
                            'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                            'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©ê³¼ ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.\n\nPortOneì˜ ì†”ë£¨ì…˜ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ì‹œê°„ 85% ë‹¨ì¶•\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ì•ˆì •ì ì¸ ê²°ì œ ì¸í”„ë¼\n\n15ë¶„ ê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                        }
                    },
                    'timestamp': datetime.now().isoformat(),
                    'note': 'Gemini ë¹ˆ ì‘ë‹µìœ¼ë¡œ ì¸í•œ í´ë°± ë°ì´í„°'
                }
                
        except Exception as gemini_error:
            logger.error(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {str(gemini_error)}")
            # Gemini API ì˜¤ë¥˜ ì‹œ í´ë°±
            return {
                'success': True,
                'variations': {
                    'professional': {
                        'subject': f'[PortOne] {company_name} ë‹´ë‹¹ìë‹˜ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤',
                        'body': f'ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜!\n\ní˜„ì¬ ë§ì€ ê¸°ì—…ë“¤ì´ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œê³¼ í†µí•©ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.\n\nPortOneì˜ One Payment Infraë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê°œë°œ ì‹œê°„ 85% ë‹¨ì¶•\nâ€¢ ë¬´ë£Œ ì»¨ì„¤íŒ… ì œê³µ\nâ€¢ ì•ˆì •ì ì¸ ê²°ì œ ì‹œìŠ¤í…œ\n\nê°„ë‹¨í•œ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•œ ë‚´ìš©ì„ ì„¤ëª…ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\nPortOne ì˜ì—…íŒ€'
                    }
                },
                'timestamp': datetime.now().isoformat(),
                'note': f'Gemini API ì˜¤ë¥˜ë¡œ ì¸í•œ í´ë°± ë°ì´í„°: {str(gemini_error)}'
            }
            
    except Exception as e:
        logger.error(f"Gemini ì´ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def generate_email_with_user_template(company_data, research_data, user_template, case_examples="", news_content=None, user_info=None):
    """
    ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ ê¸°ë°˜ ì´ë©”ì¼ ìƒì„± (ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  + ì‚¬ìš©ì ë³¸ë¬¸ 90%)
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    try:
        # ì‚¬ìš©ì ì •ë³´ (ì„œëª…ìš©) - user_info íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ current_user ì²´í¬
        if user_info:
            user_name = user_info.get('name', 'ì˜¤ì¤€í˜¸')
            user_company_nickname = user_info.get('company_nickname', f'PortOne {user_name} ë§¤ë‹ˆì €')
            user_phone = user_info.get('phone', '010-2580-2580')
            logger.info(f"ğŸ‘¤ [ì‚¬ìš©ìë¬¸ì•ˆ] ì´ë©”ì¼ ìƒì„±ì: {user_name} ({user_company_nickname})")
            logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] ì „ë‹¬ë°›ì€ ì‚¬ìš©ì ì •ë³´ ì‚¬ìš©: {user_info.get('email', 'N/A')}")
        else:
            user_name = current_user.name if (current_user and current_user.is_authenticated) else "ì˜¤ì¤€í˜¸"
            user_company_nickname = current_user.company_nickname if (current_user and current_user.is_authenticated) else f"PortOne {user_name} ë§¤ë‹ˆì €"
            user_phone = current_user.phone if (current_user and current_user.is_authenticated) else "010-2580-2580"
            
            # ë””ë²„ê¹…: ì‚¬ìš©ì ì •ë³´ ë¡œê·¸
            logger.info(f"ğŸ‘¤ [ì‚¬ìš©ìë¬¸ì•ˆ] ì´ë©”ì¼ ìƒì„±ì: {user_name} (PortOne {user_name} ë§¤ë‹ˆì €)")
            if current_user and current_user.is_authenticated:
                logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] ë¡œê·¸ì¸ ì‚¬ìš©ì ì¸ì¦ë¨: {current_user.email}")
            else:
                logger.warning(f"âš ï¸  [ì‚¬ìš©ìë¬¸ì•ˆ] current_user ì¸ì¦ ì•ˆ ë¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        company_name = company_data.get('íšŒì‚¬ëª…', 'Unknown')
        
        # ë‹´ë‹¹ì ì •ë³´ ì¶”ì¶œ (generate_email_with_geminiì™€ ë™ì¼)
        column_keys = list(company_data.keys())
        email_name = ''
        if len(column_keys) >= 14:
            email_name = company_data.get(column_keys[13], '').strip()
        
        if not email_name:
            contact_name = company_data.get('ë‹´ë‹¹ìëª…', '') or company_data.get('ëŒ€í‘œìëª…', '') or company_data.get('ì´ë¦„', '')
            contact_position = company_data.get('ì§ì±…', '') or company_data.get('ì§ê¸‰', '')
            if not contact_name or contact_name == 'ë‹´ë‹¹ì':
                email_name = 'ë‹´ë‹¹ìë‹˜'
            else:
                if contact_position:
                    if any(keyword in contact_position for keyword in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì´ì‚¬', 'ë¶€ì¥', 'íŒ€ì¥', 'ë§¤ë‹ˆì €', 'ì‹¤ì¥', 'ê³¼ì¥']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    elif any(keyword in contact_position for keyword in ['ì£¼ì„', 'ëŒ€ë¦¬', 'ì„ ì„', 'ì±…ì„']):
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                    else:
                        email_name = f'{contact_name} {contact_position}ë‹˜'
                else:
                    if any(title in contact_name for title in ['ëŒ€í‘œ', 'CEO', 'ì‚¬ì¥']):
                        email_name = f'{contact_name}ë‹˜'
                    else:
                        email_name = f'{contact_name} ë‹´ë‹¹ìë‹˜'
        
        # ê²½ìŸì‚¬ ì •ë³´
        competitor_name = company_data.get('ê²½ìŸì‚¬ëª…', '') or company_data.get('ê²½ìŸì‚¬', '')
        
        company_info = f"íšŒì‚¬ëª…: {company_name}\në‹´ë‹¹ì: {email_name}"
        if competitor_name:
            company_info += f"\nPortOne ì´ìš© ê²½ìŸì‚¬: {competitor_name}"
        
        # ì¡°ì‚¬ ì •ë³´
        research_summary = research_data.get('company_info', 'ì¡°ì‚¬ ì •ë³´ ì—†ìŒ')
        
        # í˜¸ìŠ¤íŒ…ì‚¬ ì •ë³´ í™•ì¸ (OPI ì œê³µ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨)
        # CSV ì»´ëŸ¼ êµ¬ì¡° ë””ë²„ê¹…
        logger.debug(f"[ì‚¬ìš©ìë¬¸ì•ˆ] {company_name} CSV ì»´ëŸ¼ë“¤: {list(company_data.keys())}")
        
        # ë‹¤ì–‘í•œ í˜¸ìŠ¤íŒ…ì‚¬ ì»´ëŸ¼ëª… ì§€ì›
        possible_hosting_columns = ['í˜¸ìŠ¤íŒ…ì‚¬', 'í˜¸ìŠ¤íŒ…', 'í˜¸ìŠ¤íŒ…ì„œë¹„ìŠ¤', 'hosting', 'Hosting', 'ì›¹í˜¸ìŠ¤íŒ…', 'í˜¸ìŠ¤íŒ…ì—…ì²´']
        hosting = ''
        for col in possible_hosting_columns:
            if col in company_data and company_data[col] and str(company_data[col]).strip():
                hosting = str(company_data[col]).lower().strip()
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] {company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ë°œê²¬: '{col}' = '{hosting}'")
                break
        
        if not hosting:
            logger.warning(f"[ì‚¬ìš©ìë¬¸ì•ˆ] {company_name} í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ - CSVì— í˜¸ìŠ¤íŒ…ì‚¬ ì»´ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        
        is_self_hosted = 'ìì²´' in hosting or 'self' in hosting or 'ì§ì ‘' in hosting
        
        # sales_itemì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ê²°ì •
        sales_item = company_data.get('sales_item', '').lower().strip()
        services_to_generate = []
        if sales_item:
            if 'opi' in sales_item:
                # OPIëŠ” ìì²´êµ¬ì¶•ì¸ ê²½ìš°ì—ë§Œ ì œê³µ ê°€ëŠ¥
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity']
                    logger.info(f"âœ… [ì‚¬ìš©ìë¬¸ì•ˆ] OPI ì„œë¹„ìŠ¤ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
                else:
                    # ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconìœ¼ë¡œ ëŒ€ì²´
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.warning(f"âš ï¸ [ì‚¬ìš©ìë¬¸ì•ˆ] OPI ë¶ˆê°€ëŠ¥ (í˜¸ìŠ¤íŒ…: {hosting}) â†’ Recon(ì¬ë¬´ìë™í™”)ìœ¼ë¡œ ì „í™˜: {company_name}")
            elif 'recon' in sales_item or 'ì¬ë¬´' in sales_item:
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] Recon(ì¬ë¬´ìë™í™”) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            elif 'prism' in sales_item or 'í”„ë¦¬ì¦˜' in sales_item:
                services_to_generate = ['prism_professional', 'prism_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] Prism(ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            elif 'ps' in sales_item or 'í”Œë«í¼ì •ì‚°' in sales_item or 'íŒŒíŠ¸ë„ˆì •ì‚°' in sales_item:
                services_to_generate = ['ps_professional', 'ps_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] í”Œë«í¼ ì •ì‚°(íŒŒíŠ¸ë„ˆ ì •ì‚°+ì„¸ê¸ˆê³„ì‚°ì„œ+ì§€ê¸‰ëŒ€í–‰) ì„œë¹„ìŠ¤ ë¬¸ì•ˆë§Œ ìƒì„±: {company_name}")
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” sales_itemì¸ ê²½ìš°
                if is_self_hosted:
                    services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                else:
                    services_to_generate = ['finance_professional', 'finance_curiosity']
                    logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] ìì²´êµ¬ì¶• ì•„ë‹ˆë¯€ë¡œ Reconë§Œ ìƒì„±: {company_name}")
        else:
            # sales_itemì´ ì—†ìœ¼ë©´ í˜¸ìŠ¤íŒ…ì‚¬ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            if not hosting:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ì—†ìœ¼ë©´ 4ê°œ ëª¨ë‘ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ… ì •ë³´ ì—†ìŒ â†’ 4ê°œ ëª¨ë‘ ìƒì„±: {company_name}")
            elif is_self_hosted:
                # ìì²´êµ¬ì¶•ì´ë©´ 4ê°œ ìƒì„±
                services_to_generate = ['opi_professional', 'opi_curiosity', 'finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + ìì²´êµ¬ì¶• â†’ 4ê°œ ë¬¸ì•ˆ ìƒì„± (í˜¸ìŠ¤íŒ…: {hosting}): {company_name}")
            else:
                # í˜¸ìŠ¤íŒ… ì •ë³´ê°€ ìˆê³  ìì²´êµ¬ì¶•ì´ ì•„ë‹ˆë©´ Reconë§Œ
                services_to_generate = ['finance_professional', 'finance_curiosity']
                logger.info(f"[ì‚¬ìš©ìë¬¸ì•ˆ] sales_item ì—†ìŒ + í˜¸ìŠ¤íŒ…='{hosting}' (ìì²´êµ¬ì¶• ì•„ë‹˜) â†’ Reconë§Œ ìƒì„±: {company_name}")
        
        # CSV ë‰´ìŠ¤ ì œê³µ ì—¬ë¶€ í™•ì¸
        has_csv_news = "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)" in research_summary
        
        # ì‚¬ìš©ì ë¬¸ì•ˆ ëª¨ë“œ í”„ë¡¬í”„íŠ¸
        if has_csv_news:
            news_instruction_template = """**ğŸ¯ ìµœìš°ì„  ì§€ì‹œ: CSVì—ì„œ ì œê³µëœ 'ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬' ì„¹ì…˜ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì„œë¡ ì— í™œìš©í•˜ì„¸ìš”!**

ì´ ë‰´ìŠ¤ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì„ ì •í•œ ì¤‘ìš”í•œ ê¸°ì‚¬ì´ë¯€ë¡œ, ë‹¤ë¥¸ ì–´ë–¤ ë‰´ìŠ¤ë³´ë‹¤ ìš°ì„ ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.

**í•„ìˆ˜ ì‘ì„± ë°©ì‹:**
1. **ì„œë¡  (2-3ë¬¸ì¥)**: CSV ì œê³µ ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì¸ìš©í•˜ì—¬ í›„í‚¹í•˜ëŠ” ë„ì…ë¶€ ì‘ì„±
   - **ì‹œê¸‰ì„± + ê´€ë ¨ì„± + ê³µê°** 3ìš”ì†Œ ëª¨ë‘ í¬í•¨
   - ì˜ˆ: "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ì ìœ ì¹˜'ë¼ëŠ” ê¸°ì‚¬ë¥¼ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
   - ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
        else:
            news_instruction_template = """**í•„ìˆ˜ ì‘ì„± ë°©ì‹:**
1. **ì„œë¡  (2-3ë¬¸ì¥)**: ìœ„ì˜ ì¡°ì‚¬ ê²°ê³¼ì—ì„œ êµ¬ì²´ì ì¸ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì§ì ‘ ì¸ìš©í•˜ì—¬ í›„í‚¹í•˜ëŠ” ë„ì…ë¶€ ì‘ì„±
   - **ì‹œê¸‰ì„± + ê´€ë ¨ì„± + ê³µê°** 3ìš”ì†Œ ëª¨ë‘ í¬í•¨
   - ì˜ˆ: "ìµœê·¼ '{company_name}ê°€ 100ì–µì› íˆ¬ì ìœ ì¹˜' ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ì‚¬ì—… í™•ì¥ ì¤€ë¹„ë¡œ ë°”ì˜ì‹œê² ì§€ë§Œ, ê²°ì œ ì¸í”„ë¼ í™•ì¥ë„ ì§€ê¸ˆ ì¤€ë¹„í•´ì•¼ í•  ì‹œì ì´ ì•„ë‹ê¹Œìš”?"
   - ì˜ˆ: "'{company_name}ì˜ ë§¤ì¶œ 150% ì¦ê°€' ê¸°ì‚¬ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤. ê¸‰ì„±ì¥í•  ë•Œ ê²°ì œ ì‹œìŠ¤í…œ ë³‘ëª©ì´ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì¸ë°, ì§€ê¸ˆ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ê³„ì‹ ê°€ìš”?" """
        
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì „ë¬¸ ì„¸ì¼ì¦ˆ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.

**íƒ€ê²Ÿ íšŒì‚¬ ì •ë³´:**
{company_info}

**ğŸ”¥ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ (ì´ë©”ì¼ ì„œë¡ ì— ë°˜ë“œì‹œ í™œìš©):**
{research_summary}

**ğŸ¯ íŠ¹ë³„ ìš”ì²­ì‚¬í•­: ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ í™œìš©**

ì‚¬ìš©ìê°€ ì œê³µí•œ ë³¸ë¬¸ ë¬¸ì•ˆ:
---
{user_template}
---

**ğŸ¯ ìµœìš°ì„  ëª©í‘œ: B2B ì˜ì‚¬ê²°ì •ìê°€ "ì¦‰ì‹œ ë‹µì¥í•˜ê³  ì‹¶ë‹¤"ê³  ëŠë¼ëŠ” ë©”ì¼ ì‘ì„±**

ë‰´ìŠ¤ í›„í‚¹ ì„œë¡ ì´ ë‹¤ìŒ ë°˜ì‘ì„ ì´ëŒì–´ë‚´ì•¼ í•©ë‹ˆë‹¤:
- "ìš°ë¦¬ íšŒì‚¬ì˜ í˜„ì¬ ìƒí™©ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìˆë‹¤"
- "ë§¤ìš° ì‹œì˜ì ì ˆí•˜ê³  í•„ìš”í•œ ì œì•ˆ"
- "ì¦‰ì‹œ ë‹µì¥í•  ê°€ì¹˜ê°€ ìˆë‹¤"

**âš ï¸ ì¤‘ìš”**: ì´ë©”ì¼ ë³¸ë¬¸ ì‘ì„± ì‹œ "ì¦‰ì‹œ", "100%", "ì™„ë²½í•œ", "ì ˆëŒ€", "ë¬´ì¡°ê±´" ë“±ì˜ ê·¹ë‹¨ì  í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , í˜„ì‹¤ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í‘œí˜„ ì‚¬ìš© (ì˜ˆ: "ë¹ ë¥´ê²Œ", "90% ì´ìƒ", "ë†’ì€ ì •í™•ë„ë¡œ", "ëŒ€í­")

{news_instruction_template}

2. **ë³¸ë¬¸ (90%)**: ìœ„ì— ì œê³µëœ ì‚¬ìš©ì ë¬¸ì•ˆì„ **ê±°ì˜ ê·¸ëŒ€ë¡œ** ì‚¬ìš©í•˜ë˜, ë‹¤ìŒë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì¸í™”:
   - {{company_name}} íšŒì‚¬ëª…ì„ ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…
   - {{email_name}} ë‹´ë‹¹ìëª…ì„ ë§¥ë½ì— ë§ê²Œ ì¶”ê°€ ê°€ëŠ¥
   - ë¬¸ì¥ ìˆœì„œë‚˜ í•µì‹¬ ë‚´ìš©ì€ **ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ê²ƒ**
   - ë‹¨ì–´ ì„ íƒì´ë‚˜ ë¬¸ì²´ë„ **ìµœëŒ€í•œ ì›ë³¸ ìœ ì§€**

3. **ê³ ì • ê²°ë¡  (âš ï¸ í•„ìˆ˜!)**: 
   "<br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"
   
   â€¼ï¸ **CTAëŠ” ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤!** "ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´..."ì´ ë¹ ì§€ë©´ ì•ˆ ë©ë‹ˆë‹¤.

**ê³ ì • ì„œë¡  í˜•ì‹ (ì„œë¡  ì‹œì‘ ì „):**
"ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>"

**êµ¬ì¡°:**
- ì œëª©: "[PortOne] {{company_name}} {{email_name}}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤"
- ë³¸ë¬¸: ê³ ì • ì„œë¡  â†’ ë‰´ìŠ¤ í›„í‚¹ ì„œë¡ (2-3ë¬¸ì¥) â†’ ì‚¬ìš©ì ë¬¸ì•ˆ(90% ìœ ì§€) â†’ ê³ ì • ê²°ë¡ 

**ì¤‘ìš”**: ì–´ë–¤ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

**ìƒì„±í•  ì„œë¹„ìŠ¤**: {', '.join(services_to_generate)}

{{
  "opi_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "opi_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "finance_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_professional": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }},
  "prism_curiosity": {{
    "body": "<p>ì•ˆë…•í•˜ì„¸ìš”, {{company_name}} {{email_name}}.<br>PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.<br><br>[ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  2-3ë¬¸ì¥]<br><br>[ì‚¬ìš©ì ë¬¸ì•ˆ 90% ê·¸ëŒ€ë¡œ]</p><p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {{company_name}}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"
  }}
}}
"""
        
        # Gemini API í˜¸ì¶œ
        if not GEMINI_API_KEY:
            return {
                'success': False,
                'error': 'Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'timestamp': datetime.now().isoformat()
            }
        
        try:
            model = genai.GenerativeModel('gemini-2.5-pro')
            response = model.generate_content(context)
            
            if response.text:
                # JSON íŒŒì‹±
                clean_response = response.text.strip()
                if '```json' in clean_response:
                    json_start = clean_response.find('```json') + 7
                    json_end = clean_response.find('```', json_start)
                    if json_end != -1:
                        clean_response = clean_response[json_start:json_end]
                    else:
                        clean_response = clean_response[json_start:]
                elif '{' in clean_response and '}' in clean_response:
                    json_start = clean_response.find('{')
                    json_end = clean_response.rfind('}') + 1
                    clean_response = clean_response[json_start:json_end]
                
                clean_response = clean_response.strip()
                email_variations = json.loads(clean_response)
                
                # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
                def convert_markdown_to_html(text):
                    """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ HTMLë¡œ ë³€í™˜ (**ë³¼ë“œ**, *ì´íƒ¤ë¦­* ë“±)"""
                    import re
                    # **í…ìŠ¤íŠ¸** â†’ <strong>í…ìŠ¤íŠ¸</strong>
                    text = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', text)
                    # *í…ìŠ¤íŠ¸* â†’ <em>í…ìŠ¤íŠ¸</em> (ë³¼ë“œ ì²˜ë¦¬ í›„ ë‚¨ì€ ë‹¨ì¼ *)
                    text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
                    return text
                
                # í”Œë ˆì´ìŠ¤í™€ë” êµì²´
                def replace_placeholders(text, company_name, email_name, competitor_name=''):
                    result = text.replace('{company_name}', company_name).replace('{email_name}', email_name)
                    result = result.replace('{{company_name}}', company_name).replace('{{email_name}}', email_name)
                    if competitor_name:
                        result = result.replace('{competitor_name}', competitor_name).replace('{{competitor_name}}', competitor_name)
                    # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
                    result = result.replace('ì˜¤ì¤€í˜¸', user_name)
                    result = result.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
                    # ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì ìš©
                    result = convert_markdown_to_html(result)
                    return result
                
                formatted_variations = {}
                for service in services_to_generate:
                    if service in email_variations:
                        subject = f'[PortOne] {company_name} {email_name}ê»˜ ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤'
                        body = replace_placeholders(email_variations[service]['body'], company_name, email_name, competitor_name)
                        
                        formatted_variations[service] = {
                            'subject': subject,
                            'body': body
                        }
                
                # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
                logger.info(f"{company_name}: [ì‚¬ìš©ìë¬¸ì•ˆ] CTA ê²€ì¦ ì‹œì‘...")
                for service_key, email_content in formatted_variations.items():
                    if 'body' in email_content:
                        email_content['body'] = validate_and_fix_cta(
                            email_content['body'],
                            company_name
                        )
                
                return {
                    'success': True,
                    'variations': formatted_variations,
                    'services_generated': services_to_generate,
                    'sales_item': sales_item if sales_item else 'all',
                    'timestamp': datetime.now().isoformat(),
                    'model': 'gemini-2.5-pro-exp',
                    'mode': 'user_template'
                }
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ë¬¸ì•ˆ ì´ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì ë¬¸ì•ˆ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def generate_persuasive_reply(context, company_name, email_name, case_examples=""):
    """
    ê³ ê° ë°˜ë°•/ë¶€ì •ì  ë‹µë³€ì— ëŒ€í•œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
    
    Args:
        context: ê³ ê°ì˜ ë‹µë³€ ë˜ëŠ” ìƒí™© ì„¤ëª…
        company_name: íšŒì‚¬ëª…
        email_name: ë‹´ë‹¹ì í˜¸ì¹­
        case_examples: ê´€ë ¨ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
    
    Returns:
        dict: ìƒì„±ëœ ì¬ì„¤ë“ ë©”ì¼
    """
    try:
        logger.info(f"{company_name}: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹œì‘")
        
        # Gemini í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ìµœê³  ì˜ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ë¶€ì •ì  ë°˜ì‘ì´ë‚˜ ë°˜ë°•ì— ëŒ€ì‘í•˜ì—¬ ì¬ì„¤ë“í•˜ëŠ” ë©”ì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤.

**ê³ ê° ìƒí™©/ë‹µë³€:**
{context}

**íšŒì‚¬ ì •ë³´:**
- íšŒì‚¬ëª…: {company_name}
- ë‹´ë‹¹ì: {email_name}

**í¬íŠ¸ì› ì„œë¹„ìŠ¤ ì†Œê°œ, ì‹¤ì œ ì‚¬ë¡€ ë° ìµœì‹  ë¸”ë¡œê·¸ ì½˜í…ì¸ :**
{case_examples}

ğŸ’¡ **ìœ„ ì •ë³´ í™œìš© ë°©ë²•:**
- ì‹¤ì œ ê³ ê°ì‚¬ ì‚¬ë¡€ë¥¼ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ë„ ë†’ì´ê¸°
- ìµœì‹  ë¸”ë¡œê·¸ ì½˜í…ì¸ ì—ì„œ ê´€ë ¨ íŠ¸ë Œë“œë‚˜ ê¸°ìˆ  ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
- "ìµœê·¼ í¬íŠ¸ì› ë¸”ë¡œê·¸ì—ì„œë„..." ê°™ì€ ë°©ì‹ìœ¼ë¡œ í™œìš© ê°€ëŠ¥

**ğŸ¯ ëª©í‘œ: ê³ ê°ì˜ ìš°ë ¤ë¥¼ í•´ì†Œí•˜ê³  ì¬ë¯¸íŒ… ê¸°íšŒë¥¼ ë§Œë“œëŠ” ì„¤ë“ë ¥ ìˆëŠ” ë©”ì¼ ì‘ì„±**

**ë©”ì¼ ì‘ì„± ì „ëµ:**

1. **ê³µê° ë¨¼ì €**: ê³ ê°ì˜ ìš°ë ¤ë‚˜ ì˜ê²¬ì„ ë¨¼ì € ì¸ì •í•˜ê³  ê³µê°
   - "ë§ì”€í•˜ì‹  ìš°ë ¤ ì¶©ë¶„íˆ ì´í•´í•©ë‹ˆë‹¤"
   - "ì¢‹ì€ ì§€ì ì´ì‹­ë‹ˆë‹¤"
   
2. **ì˜¤í•´ í•´ì†Œ**: ê³ ê°ì´ ì˜ëª» ì´í•´í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë¶€ë“œëŸ½ê²Œ ì„¤ëª…
   - ê°•ì••ì ì´ì§€ ì•Šê²Œ
   - ë°ì´í„°ì™€ ì‚¬ë¡€ë¡œ ë’·ë°›ì¹¨

3. **êµ¬ì²´ì  ì‚¬ë¡€ + ìµœì‹  ì •ë³´ ì œì‹œ**: 
   - ìœ„ì˜ ì‹¤ì œ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ í™œìš©
   - ë¹„ìŠ·í•œ ìš°ë ¤ë¥¼ ê°€ì¡Œë˜ ë‹¤ë¥¸ ê³ ê°ì‚¬ ì‚¬ë¡€
   - ë„ì… í›„ ê²°ê³¼ ìˆ˜ì¹˜ ì œì‹œ
   - **í¬íŠ¸ì› ë¸”ë¡œê·¸ì˜ ìµœì‹  ì½˜í…ì¸ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰**í•˜ì—¬ ì „ë¬¸ì„±ê³¼ ìµœì‹ ì„± ê°•ì¡°
   - "{company_name}ë‹˜ê³¼ ë¹„ìŠ·í•œ ìƒí™©ì´ì—ˆë˜ [ê³ ê°ì‚¬ëª…]ë„..."

4. **ìƒˆë¡œìš´ ê°€ì¹˜ ì œì•ˆ**: ê³ ê°ì´ ë†“ì¹œ ë¶€ë¶„ ê°•ì¡°
   - ROI, ì‹œê°„ ì ˆì•½, ë¦¬ìŠ¤í¬ ê°ì†Œ ë“±
   - êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ì„¤ë“
   - ìµœì‹  íŠ¸ë Œë“œë‚˜ ì—…ê³„ ë™í–¥ ì–¸ê¸‰

5. **ë¶€ë‹´ ì—†ëŠ” ì¬ì œì•ˆ**: 
   - "ë‹¨ 15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹œë©´..."
   - "í•œ ë²ˆë§Œ ë°ëª¨ë¥¼ ë³´ì—¬ë“œë¦¬ë©´..."
   - "ë¬´ë£Œ ì»¨ì„¤íŒ…ìœ¼ë¡œ ê°€ëŠ¥ì„±ë§Œ í™•ì¸í•´ë³´ì‹œê² ìŠµë‹ˆê¹Œ?"

**ë°˜ë°• ìœ í˜•ë³„ ëŒ€ì‘ ì „ëµ:**

A. **"ë¹„ìš©ì´ ë¶€ë‹´ë©ë‹ˆë‹¤"**
   â†’ ROI ê³„ì‚°, ì¥ê¸°ì  ì ˆê° íš¨ê³¼, ë¬´ë£Œ ì²´í—˜ ì œì•ˆ

B. **"ì§€ê¸ˆì€ ë°”ë¹ ì„œ ì–´ë µìŠµë‹ˆë‹¤"**
   â†’ ê°„ë‹¨í•œ ë„ì… í”„ë¡œì„¸ìŠ¤ ê°•ì¡°, 2ì£¼ ë‚´ êµ¬ì¶• ê°€ëŠ¥, ìµœì†Œ ë¦¬ì†ŒìŠ¤

C. **"í˜„ì¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤"**
   â†’ ìˆ¨ê²¨ì§„ ë¹„íš¨ìœ¨ ì§€ì , í™•ì¥ì„± ë¬¸ì œ, ë¯¸ë˜ ì„±ì¥ ëŒ€ë¹„

D. **"ë‹¤ë¥¸ ì†”ë£¨ì…˜ê³¼ ë¹„êµ ì¤‘ì…ë‹ˆë‹¤"**
   â†’ ì°¨ë³„ì  ê°•ì¡°, ê³ ê°ì‚¬ ë§Œì¡±ë„, PGì‚¬ ë¹„êµ ê²¬ì  ì œê³µ

E. **"ë‚´ë¶€ ê²€í† ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤"**
   â†’ ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ìë£Œ ì œê³µ, ë ˆí¼ëŸ°ìŠ¤ ì—°ê²°, CTO ë¯¸íŒ… ì œì•ˆ

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ:**

1. **ì„œë¡ **: ì´ì „ ë©”ì¼ ê°ì‚¬ + ê³µê°
   "ì•ˆë…•í•˜ì„¸ìš”, {company_name} {email_name}.<br>PortOne {user_name}ì…ë‹ˆë‹¤.<br><br>
   ë°”ì˜ì‹  ì™€ì¤‘ì—ë„ ë‹µë³€ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."

2. **ë³¸ë¬¸**: 
   - ìš°ë ¤ì‚¬í•­ ê³µê° ë° í•´ì†Œ
   - ì‹¤ì œ ì‚¬ë¡€ 2-3ê°œ êµ¬ì²´ì  ì œì‹œ
   - ìˆ˜ì¹˜ ê¸°ë°˜ ì„¤ë“ (85% ì ˆê°, 2ì£¼ ë‚´ êµ¬ì¶• ë“±)
   - ìƒˆë¡œìš´ ê´€ì  ì œì‹œ

3. **CTA (í•„ìˆ˜!)**: 
   "<br>ê·¸ë˜ë„ í•œ ë²ˆë§Œ ê¸°íšŒë¥¼ ì£¼ì‹œë©´ {company_name}ì˜ ìƒí™©ì— ë§ëŠ”<br>
   êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ë³´ì—¬ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>
   ë‹¤ìŒ ì£¼ ì¤‘ 15ë¶„ë§Œ ì‹œê°„ ë‚´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?<br>
   ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.<br><br>
   ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼"

**í†¤ì•¤ë§¤ë„ˆ:**
- ì ˆëŒ€ ê°•ì••ì ì´ê±°ë‚˜ ê³µê²©ì ì´ì§€ ì•Šê²Œ
- ì§„ì •ì„± ìˆê²Œ, ê³ ê°ì˜ ì„±ê³µì„ ì§„ì‹¬ìœ¼ë¡œ ì›í•˜ëŠ” íŒŒíŠ¸ë„ˆë¡œ
- ì „ë¬¸ì ì´ì§€ë§Œ ì¹œê·¼í•˜ê²Œ
- ë°ì´í„°ì™€ ì‚¬ì‹¤ ê¸°ë°˜

**êµ¬ì¡°:**
ì œëª©: [PortOne] {company_name} {email_name} - ì¶”ê°€ ë§ì”€ ë“œë¦½ë‹ˆë‹¤

ë³¸ë¬¸: HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±
<p>ì„œë¡ </p>
<p>ë³¸ë¬¸ - ê³µê° + í•´ì†Œ</p>
<p>ë³¸ë¬¸ - ì‚¬ë¡€ ì œì‹œ</p>
<p>ë³¸ë¬¸ - ìƒˆë¡œìš´ ê°€ì¹˜</p>
<p>CTA</p>

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:**
{{
  "subject": "ì œëª©",
  "body": "HTML ë³¸ë¬¸",
  "strategy_used": "ì‚¬ìš©í•œ ì „ëµ ê°„ë‹¨ ì„¤ëª…",
  "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"]
}}
"""

        # Gemini API í˜¸ì¶œ
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        
        if not response or not response.text:
            raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # JSON íŒŒì‹±
        import re
        response_text = response.text.strip()
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        elif '{' in response_text and '}' in response_text:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text
        
        email_data = json.loads(json_str)
        
        # CTA ê²€ì¦
        if 'body' in email_data:
            email_data['body'] = validate_and_fix_cta(email_data['body'], company_name)
        
        logger.info(f"{company_name}: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì™„ë£Œ")
        
        return {
            'success': True,
            'email': email_data,
            'timestamp': datetime.now().isoformat(),
            'model': 'gemini-2.0-flash-exp'
        }
        
    except Exception as e:
        logger.error(f"{company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def validate_and_fix_cta(email_body, company_name):
    """
    ì´ë©”ì¼ ë³¸ë¬¸ì— CTA(Call-to-Action)ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
    
    Args:
        email_body: ì´ë©”ì¼ ë³¸ë¬¸ (HTML)
        company_name: íšŒì‚¬ëª…
    
    Returns:
        str: CTAê°€ í¬í•¨ëœ ì´ë©”ì¼ ë³¸ë¬¸
    """
    # CTA í‚¤ì›Œë“œ ì²´í¬
    cta_keywords = [
        'ë‹¤ìŒì£¼ ì¤‘', 'ë‹¤ìŒ ì£¼ ì¤‘', 'í¸í•˜ì‹  ì¼ì •', 'í¸í•˜ì‹  ì‹œê°„',
        'ê¸ì •ì ì¸ íšŒì‹ ', 'íšŒì‹  ë¶€íƒ', 'ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´',
        'ì‹œê°„ì„ ì•Œë ¤ì£¼ì‹œë©´', 'ë¯¸íŒ… ê°€ëŠ¥í•œ ì‹œê°„'
    ]
    
    # ë³¸ë¬¸ì— CTA í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
    has_cta = any(keyword in email_body for keyword in cta_keywords)
    
    if has_cta:
        logger.info(f"{company_name}: CTA ê²€ì¦ í†µê³¼ âœ“")
        return email_body
    
    # CTAê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
    logger.warning(f"{company_name}: âš ï¸  CTA ëˆ„ë½ ê°ì§€ - ìë™ ì¶”ê°€")
    
    # í‘œì¤€ CTA í…œí”Œë¦¿
    standard_cta = f"""<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ {company_name}ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{user_name} ë“œë¦¼</p>"""
    
    # ì„œëª… íŒ¨í„´ ì°¾ê¸°
    import re
    signature_patterns = [
        r'<p>\s*ê°ì‚¬í•©ë‹ˆë‹¤\.?<br>\s*ì˜¤ì¤€í˜¸\s*ë“œë¦¼\s*</p>',
        r'<p>\s*ì˜¤ì¤€í˜¸\s*Junho\s*Oh<br>\s*Sales\s*team.*?</p>',
        r'<p>\s*ì˜¤ì¤€í˜¸\s*ë“œë¦¼\s*</p>',
        r'ê°ì‚¬í•©ë‹ˆë‹¤[.\s]*$'
    ]
    
    # ì„œëª…ì´ ìˆìœ¼ë©´ ê·¸ ì•ì— CTA ì‚½ì…
    for pattern in signature_patterns:
        if re.search(pattern, email_body, re.DOTALL | re.IGNORECASE):
            email_body = re.sub(
                pattern,
                standard_cta,
                email_body,
                flags=re.DOTALL | re.IGNORECASE
            )
            logger.info(f"{company_name}: CTA ì¶”ê°€ ì™„ë£Œ (ì„œëª… ì•ì— ì‚½ì…)")
            return email_body
    
    # ì„œëª…ì´ ì—†ìœ¼ë©´ ë³¸ë¬¸ ëì— CTA ì¶”ê°€
    email_body = email_body.rstrip() + "\n\n" + standard_cta
    logger.info(f"{company_name}: CTA ì¶”ê°€ ì™„ë£Œ (ë³¸ë¬¸ ëì— ì¶”ê°€)")
    
    return email_body

def generate_email_with_gemini_and_cases(company_data, research_data, case_examples="", user_template=None, news_content=None, user_input_mode='template', user_info=None):
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ê°œì¸í™”ëœ ì´ë©”ì¼ ìƒì„± (ì‹¤ì œ ì‚¬ë¡€ í¬í•¨ ë²„ì „)
    
    Args:
        company_data: íšŒì‚¬ ì •ë³´ dict
        research_data: Perplexity ì¡°ì‚¬ ê²°ê³¼
        case_examples: ì„ íƒëœ ì‹¤ì œ ì‚¬ë¡€ í…ìŠ¤íŠ¸ (formatted)
        user_template: ì‚¬ìš©ì ì œê³µ ë¬¸ì•ˆ ë˜ëŠ” ìš”ì²­ì‚¬í•­ (ì˜µì…˜)
        news_content: ìŠ¤í¬ë˜í•‘ëœ ë‰´ìŠ¤ ë‚´ìš© (ì˜µì…˜)
        user_input_mode: 'request' (ìš”ì²­ì‚¬í•­ ëª¨ë“œ) ë˜ëŠ” 'template' (ë¬¸ì•ˆ ëª¨ë“œ)
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    
    Returns:
        dict: ìƒì„±ëœ ì´ë©”ì¼ variations
    """
    # ì‚¬ìš©ì ì…ë ¥ì´ ìˆìœ¼ë©´ ëª¨ë“œì— ë”°ë¼ ì²˜ë¦¬
    if user_template:
        if user_input_mode == 'request':
            logger.info(f"{company_data.get('íšŒì‚¬ëª…')}: ìš”ì²­ì‚¬í•­ ëª¨ë“œ - ê¸°ë³¸ ìƒì„± + ìš”ì²­ì‚¬í•­ ë°˜ì˜")
            return generate_email_with_user_request(company_data, research_data, user_template, case_examples, news_content, user_info)
        else:
            logger.info(f"{company_data.get('íšŒì‚¬ëª…')}: ë¬¸ì•ˆ ëª¨ë“œ - ë‰´ìŠ¤ í›„í‚¹ + ì‚¬ìš©ì ë³¸ë¬¸")
            return generate_email_with_user_template(company_data, research_data, user_template, case_examples, news_content, user_info)
    
    # ì‚¬ìš©ì ì…ë ¥ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ SSR ë°©ì‹ (4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨)
    logger.info(f"{company_data.get('íšŒì‚¬ëª…')}: SSR ëª¨ë“œ - 4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨")
    return generate_email_with_gemini(company_data, research_data, user_info)

def generate_email_with_user_request(company_data, research_data, user_request, case_examples="", news_content=None, user_info=None):
    """
    ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ê¸°ë°˜ ì´ë©”ì¼ ìƒì„± (2ë‹¨ê³„)
    
    1ë‹¨ê³„: ê¸°ë³¸ SSR ë°©ì‹ìœ¼ë¡œ 4ê°œ ë¬¸ì•ˆ ìƒì„± (Pain Point + í¬íŠ¸ì› í•´ê²°ì±… í¬í•¨)
    2ë‹¨ê³„: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜í•´ì„œ ê° ë¬¸ì•ˆ ê°œì„ 
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    try:
        company_name = company_data.get('íšŒì‚¬ëª…', 'Unknown')
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ 1ë‹¨ê³„ - ê¸°ë³¸ ë¬¸ì•ˆ ìƒì„± ì‹œì‘")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ SSR ëª¨ë“œë¡œ ë¬¸ì•ˆ ìƒì„±
        base_result = generate_email_with_gemini(company_data, research_data, user_info)
        
        if not base_result.get('success'):
            logger.error(f"{company_name}: ê¸°ë³¸ ë¬¸ì•ˆ ìƒì„± ì‹¤íŒ¨")
            return base_result
        
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ 2ë‹¨ê³„ - ìš”ì²­ì‚¬í•­ ë°˜ì˜ ê°œì„  ì‹œì‘")
        
        # 2ë‹¨ê³„: ê° ë¬¸ì•ˆì„ ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì— ë§ì¶° ê°œì„ 
        base_variations = base_result.get('variations', {})
        refined_variations = {}
        
        for service_key, email_content in base_variations.items():
            try:
                # ì›ë³¸ ì´ë©”ì¼
                original_subject = email_content.get('subject', '')
                original_body = email_content.get('body', '')
                
                # ìš”ì²­ì‚¬í•­ ë°˜ì˜í•´ì„œ ê°œì„ 
                refined_email = refine_email_with_user_request(
                    original_subject=original_subject,
                    original_body=original_body,
                    user_request=user_request,
                    company_data=company_data
                )
                
                if refined_email:
                    refined_variations[service_key] = refined_email
                else:
                    # ê°œì„  ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    refined_variations[service_key] = email_content
                    
            except Exception as e:
                logger.error(f"{company_name} {service_key} ê°œì„  ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ì‚¬ìš©
                refined_variations[service_key] = email_content
        
        # CTA ê²€ì¦ ë° ìë™ ìˆ˜ì •
        for service_key, email_content in refined_variations.items():
            if 'body' in email_content:
                email_content['body'] = validate_and_fix_cta(
                    email_content['body'],
                    company_name
                )
        
        logger.info(f"{company_name}: ìš”ì²­ëª¨ë“œ ì™„ë£Œ - {len(refined_variations)}ê°œ ë¬¸ì•ˆ ìƒì„±")
        
        return {
            'success': True,
            'variations': refined_variations,
            'services_generated': base_result.get('services_generated', []),
            'sales_item': base_result.get('sales_item', 'all'),
            'timestamp': datetime.now().isoformat(),
            'model': 'gemini-2.0-flash-exp',
            'mode': 'user_request'
        }
        
    except Exception as e:
        logger.error(f"ìš”ì²­ëª¨ë“œ ì˜¤ë¥˜: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

def refine_email_with_user_request(original_subject, original_body, user_request, company_data):
    """
    ìƒì„±ëœ ì´ë©”ì¼ì„ ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì— ë§ì¶° ê°œì„ 
    
    âš ï¸ í•µì‹¬: ì›ë³¸ ì´ë©”ì¼ì˜ Pain Point + í¬íŠ¸ì› í•´ê²°ì±…ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ë©´ì„œ
             ì‚¬ìš©ì ìš”ì²­ì‚¬í•­(í†¤, ê°•ì¡°ì , ì œëª© ìŠ¤íƒ€ì¼ ë“±)ë§Œ ë°˜ì˜
    """
    try:
        company_name = company_data.get('íšŒì‚¬ëª…', 'Unknown')
        
        # ìš”ì²­ì‚¬í•­ ê°œì„  í”„ë¡¬í”„íŠ¸
        context = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne) ì´ë©”ì¼ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì›ë³¸ ì´ë©”ì¼:**
ì œëª©: {original_subject}

ë³¸ë¬¸:
{original_body}

**ì‚¬ìš©ì ìš”ì²­ì‚¬í•­:**
{user_request}

**ğŸš¨ ì ˆëŒ€ ê·œì¹™ - MUST KEEP (ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•˜ëŠ” ë‚´ìš©):**

1. **Pain Point (ê³ ê° ê³¼ì œ) ë‚´ìš© 100% ìœ ì§€**
   - ì›ë³¸ì—ì„œ ì–¸ê¸‰í•œ íšŒì‚¬ì˜ ì–´ë ¤ì›€/ê³¼ì œëŠ” ì ˆëŒ€ ì‚­ì œ ë¶ˆê°€
   - ì˜ˆ: "ê±°ë˜ëŸ‰ ê¸‰ì¦", "ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ ë¶€ë‹´", "ì •ì‚° ì—…ë¬´ ë³µì¡ë„ ì¦ê°€" ë“±
   - í‘œí˜„ë§Œ ë‹¤ë“¬ì„ ìˆ˜ ìˆì§€ë§Œ, í•µì‹¬ ë©”ì‹œì§€ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€

2. **PortOne í•´ê²°ì±… 100% ìœ ì§€**
   - OPI/ì¬ë¬´ìë™í™” ë“± í¬íŠ¸ì› ì†”ë£¨ì…˜ ì„¤ëª…ì€ ì ˆëŒ€ ì‚­ì œ ë¶ˆê°€
   - êµ¬ì²´ì  ìˆ˜ì¹˜(85% ì ˆê°, 90% ë‹¨ì¶• ë“±)ëŠ” ë°˜ë“œì‹œ í¬í•¨
   - ì˜ˆ: "ë‹¨ í•˜ë‚˜ì˜ APIë¡œ êµ­ë‚´ì™¸ ì£¼ìš” PGì‚¬ ì—°ë™", "ì •ì‚° ì—…ë¬´ 90% ë‹¨ì¶•" ë“±

3. **ë‰´ìŠ¤ í›„í‚¹ ë‚´ìš© ìœ ì§€**
   - ì›ë³¸ì—ì„œ ì–¸ê¸‰í•œ íšŒì‚¬ ë‰´ìŠ¤/ì„±ì¥ ì´ì•¼ê¸°ëŠ” ìœ ì§€
   - íˆ¬ì ìœ ì¹˜, ì‚¬ì—… í™•ì¥ ë“± êµ¬ì²´ì  ë‚´ìš© ë³´ì¡´

**âœ… ë³€ê²½ ê°€ëŠ¥í•œ ë¶€ë¶„ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë°˜ì˜):**

1. **í†¤&ë§¤ë„ˆ ì¡°ì •**
   - ì¹œê·¼í•œ/ì „ë¬¸ì /ê²©ì‹ìˆëŠ” ë“± ìš”ì²­ëœ í†¤ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥
   - ì˜ˆ: "í˜¹ì‹œ ì´ëŸ° ê³ ë¯¼ ìˆìœ¼ì‹ ê°€ìš”?" â†” "ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì œë¥¼ ê²€í† í•˜ê³  ê³„ì‹¤ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤"

2. **ê°•ì¡°ì  ë³€ê²½**
   - ì‚¬ìš©ìê°€ ê°•ì¡° ìš”ì²­í•œ ë¶€ë¶„ì„ `<strong>` íƒœê·¸ë¡œ ê°•ì¡°
   - ë³¼ë“œ ì²˜ë¦¬ ìœ„ì¹˜ ì¡°ì • ê°€ëŠ¥

3. **ì œëª© ìˆ˜ì • (ì¡°ê±´ë¶€)**
   - âš ï¸ **ì‚¬ìš©ìê°€ ì œëª© ìˆ˜ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ** ì œëª© ë³€ê²½ ê°€ëŠ¥
   - ì˜ˆ: "ì œëª©ì„ ë” ì„íŒ©íŠ¸ìˆê²Œ", "ì œëª©ì— ROI ìˆ˜ì¹˜ í¬í•¨" ë“±ì˜ ëª…í™•í•œ ìš”ì²­ì´ ìˆì„ ë•Œë§Œ
   - **ì œëª© ê´€ë ¨ ìš”ì²­ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì œëª©({original_subject})ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©**

4. **êµ¬ì¡° ê°œì„  ë° í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆ**
   - ë¬¸ì¥ ìˆœì„œ ì¡°ì •, ë¬¸ë‹¨ ë‚˜ëˆ„ê¸° ë“±
   - **í•œêµ­ì–´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í˜¸í¡ì— ë§ì¶° ì¤„ë°”ê¿ˆ ë°°ì¹˜**:
     * ì£¼ì–´ê°€ ê¸´ ë¬¸ì¥: ì£¼ì–´ ë‹¤ìŒ ì¤„ë°”ê¿ˆ (`<br>`)
     * ì ‘ì†ì‚¬ ì „í›„: ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì— ì¤„ë°”ê¿ˆ
     * ì˜ë¯¸ ë‹¨ìœ„ êµ¬ë¶„: ê° ì˜ë¯¸ ë¸”ë¡ë§ˆë‹¤ ë¹ˆ ì¤„ (`<br><br>`)
     * ë¦¬ìŠ¤íŠ¸ë‚˜ ë‚˜ì—´: ê° í•­ëª©ë§ˆë‹¤ ì¤„ë°”ê¿ˆ
   - ì˜ˆì‹œ:
     ```
     ë‚˜ìœ ì¤„ë°”ê¿ˆ:
     "ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì €í¬ OPIëŠ”..."
     
     ì¢‹ì€ ì¤„ë°”ê¿ˆ:
     "ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤.<br>
     ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ<br>
     ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.<br><br>
     ì €í¬ í¬íŠ¸ì› OPIëŠ”..."
     ```

5. **ê¸¸ì´ ì¡°ì •**
   - ë” ê°„ê²°í•˜ê²Œ ë˜ëŠ” ë” ìƒì„¸í•˜ê²Œ (ë‹¨, Pain Point + í•´ê²°ì±…ì€ ìœ ì§€)

**âŒ ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- Pain Point ë‚´ìš©ì„ ì‚­ì œí•˜ê±°ë‚˜ ì¶•ì†Œ
- PortOne í•´ê²°ì±… ì„¤ëª…ì„ ì‚­ì œí•˜ê±°ë‚˜ ì¶”ìƒí™” ("ë„ì›€ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¡œë§Œ ëë‚´ê¸° ê¸ˆì§€)
- êµ¬ì²´ì  ìˆ˜ì¹˜ ì‚­ì œ
- ë‰´ìŠ¤ í›„í‚¹ ë‚´ìš© ì‚­ì œ

**ê°œì„  ì˜ˆì‹œ:**

ì›ë³¸:
"ìµœê·¼ íˆ¬ì ìœ ì¹˜ ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì„±ì¥ ì†ë„ë¥¼ ë³´ë‹ˆ ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ë¶€ë‹´ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 
ì €í¬ OPIëŠ” ë‹¨ í•˜ë‚˜ì˜ APIë¡œ ì£¼ìš” PGì‚¬ë¥¼ ì—°ë™í•˜ê³  ê°œë°œ ê¸°ê°„ì„ 85% ë‹¨ì¶•í•©ë‹ˆë‹¤."

ìš”ì²­ì‚¬í•­: "ë” ì¹œê·¼í•œ í†¤ìœ¼ë¡œ, ROI ìˆ˜ì¹˜ ê°•ì¡°"

ê°œì„ :
"'{company_name} íˆ¬ì ìœ ì¹˜' ì†Œì‹ ì •ë§ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! ğŸ˜Š
ì´ë ‡ê²Œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì‹œë‹¤ ë³´ë©´, ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ì´ ê°œë°œíŒ€ì— í° ë¶€ë‹´ ë˜ì§€ ì•Šìœ¼ì‹¤ê¹Œìš”?
ì €í¬ í¬íŠ¸ì› OPIëŠ” ë‹¨ í•˜ë‚˜ì˜ APIë¡œ êµ­ë‚´ì™¸ ì£¼ìš” PGì‚¬ë¥¼ ì—°ê²°í•˜ê³ , <strong>ê°œë°œ ê¸°ê°„ì„ 85% ë‹¨ì¶•</strong>í•´ë“œë¦½ë‹ˆë‹¤."

â†’ Pain Point(ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ ë¶€ë‹´) + í•´ê²°ì±…(OPI, 85% ë‹¨ì¶•) ëª¨ë‘ ìœ ì§€í•˜ë©´ì„œ, í†¤ë§Œ ì¹œê·¼í•˜ê²Œ ë³€ê²½

**ğŸ“¤ JSON ì¶œë ¥ í˜•ì‹:**

**ì¤‘ìš”**: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì—ì„œ ì œëª© ê´€ë ¨ ë‚´ìš©ì´ ì—†ìœ¼ë©´ subjectëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

{{
  "subject": "ì‚¬ìš©ìê°€ ì œëª© ìˆ˜ì •ì„ ìš”ì²­í–ˆë‹¤ë©´ ê°œì„ ëœ ì œëª©, ì•„ë‹ˆë©´ '{original_subject}' ê·¸ëŒ€ë¡œ",
  "body": "ê°œì„ ëœ ë³¸ë¬¸ (HTML í˜•ì‹, <p>, <br>, <strong> íƒœê·¸ ì‚¬ìš©, í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆ)"
}}

**ì¤„ë°”ê¿ˆ ì˜ˆì‹œ (ë³¸ë¬¸):**
```html
<p>ì•ˆë…•í•˜ì„¸ìš”, ABCíšŒì‚¬ ê¹€ì² ìˆ˜ ëŒ€í‘œë‹˜.<br>
PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ìµœê·¼ 'ABCíšŒì‚¬ ì‹œë¦¬ì¦ˆ A íˆ¬ì ìœ ì¹˜' ì†Œì‹ì„ ë´¤ìŠµë‹ˆë‹¤.<br>
ì •ë§ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤!</p>

<p>ì´ë ‡ê²Œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì‹œë‹¤ ë³´ë©´<br>
ê²°ì œ ì‹œìŠ¤í…œ í™•ì¥ê³¼ ê´€ë¦¬ê°€<br>
ê°œë°œíŒ€ì— í° ë¶€ë‹´ì´ ë˜ì§€ ì•Šìœ¼ì‹¤ê¹Œìš”?</p>

<p>ì €í¬ í¬íŠ¸ì› OPIëŠ”<br>
<strong>ë‹¨ í•˜ë‚˜ì˜ APIë¡œ êµ­ë‚´ì™¸ ì£¼ìš” PGì‚¬ë¥¼ ì—°ë™</strong>í•˜ê³ <br>
<strong>ê°œë°œ ê¸°ê°„ì„ 85% ë‹¨ì¶•</strong>í•´ë“œë¦½ë‹ˆë‹¤.</p>
```
"""
        
        payload = {
            "contents": [{"parts": [{"text": context}]}],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 2048,
                "responseMimeType": "application/json"
            }
        }
        
        gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={GEMINI_API_KEY}"
        
        response = requests.post(
            gemini_api_url,
            json=payload,
            headers={'Content-Type': 'application/json'},
            timeout=30
        )
        
        if response.status_code != 200:
            logger.error(f"{company_name} ê°œì„  API ì˜¤ë¥˜: {response.status_code}")
            return None
        
        result = response.json()
        generated_text = result['candidates'][0]['content']['parts'][0]['text']
        
        import json
        refined_email = json.loads(generated_text)
        
        return {
            'subject': refined_email.get('subject', original_subject),
            'body': refined_email.get('body', original_body)
        }
        
    except Exception as e:
        logger.error(f"ì´ë©”ì¼ ê°œì„  ì˜¤ë¥˜: {str(e)}")
        return None

def refine_email_with_gemini(current_email, refinement_request):
    """Gemini 2.5 Proë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë©”ì¼ ê°œì„ """
    try:
        # Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í´ë°± ì‘ë‹µ ìƒì„±
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            logger.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return f"""ì œëª©: ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆ - {refinement_request} ë°˜ì˜

ì•ˆë…•í•˜ì„¸ìš”!

ìš”ì²­í•´ì£¼ì‹  "{refinement_request}" ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

PortOneì˜ One Payment InfraëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤:

â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 80% ì ˆì•½
â€¢ 2ì£¼ ë‚´ ë¹ ë¥¸ ë„ì…
â€¢ ë¬´ë£Œ ì „ë¬¸ ì»¨ì„¤íŒ…
â€¢ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ

15ë¶„ ê°„ë‹¨í•œ ë°ëª¨ë¥¼ í†µí•´ êµ¬ì²´ì ì¸ í˜œíƒì„ ë³´ì—¬ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.

ì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?

ê°ì‚¬í•©ë‹ˆë‹¤.
PortOne ì˜ì—…íŒ€

(ì£¼ì˜: Gemini API í‚¤ ë¯¸ì„¤ì •ìœ¼ë¡œ ì¸í•œ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ)"""
        
        # URLì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ìŠ¤í¬ë˜í•‘
        article_context = ""
        import re
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, refinement_request)
        
        if urls:
            logger.info(f"ê°œì„  ìš”ì²­ì—ì„œ URL ë°œê²¬: {len(urls)}ê°œ")
            for url in urls[:3]:  # ìµœëŒ€ 3ê°œ URLê¹Œì§€ ì²˜ë¦¬
                try:
                    logger.info(f"URL ë‚´ìš© ìŠ¤í¬ë˜í•‘ ì‹œë„: {url}")
                    article_data = scrape_news_article(url)
                    
                    if article_data:
                        article_context += f"\n\n### ğŸ“° ì°¸ê³  ê¸°ì‚¬ ì •ë³´ (ì¶œì²˜: {url})\n"
                        article_context += f"**ì œëª©**: {article_data.get('title', 'ì œëª© ì—†ìŒ')}\n"
                        article_context += f"**ë³¸ë¬¸**: {article_data.get('content', '')[:1500]}\n"
                        logger.info(f"URL ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {article_data.get('title', '')[:50]}")
                    else:
                        logger.warning(f"URL ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {url}")
                        article_context += f"\n\n### âš ï¸ ê¸°ì‚¬ URL ì œê³µë¨: {url}\n(ìë™ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ - ìˆ˜ë™ìœ¼ë¡œ ë‚´ìš© í™•ì¸ í•„ìš”)\n"
                except Exception as e:
                    logger.error(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    article_context += f"\n\n### âš ï¸ ê¸°ì‚¬ URL: {url}\n(ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)})\n"
        
        prompt = f"""
ë‹¹ì‹ ì€ B2B SaaS ì„¸ì¼ì¦ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í•˜ëŠ” ì„ë¬´ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.

**í˜„ì¬ ì´ë©”ì¼:**
{current_email}

**ì‚¬ìš©ìì˜ ê°œì„  ìš”ì²­:**
{refinement_request}
{article_context}

---

## ğŸš¨ ì œí’ˆ ì„ íƒ ê·œì¹™

**ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”:**

### 1ï¸âƒ£ ë³µìˆ˜ ì œí’ˆ ìš”ì²­ ê°ì§€ (ìµœìš°ì„  í™•ì¸)
ì‚¬ìš©ìê°€ **ì—¬ëŸ¬ ì œí’ˆì„ í•¨ê»˜ ì–¸ê¸‰**í•˜ê±°ë‚˜ **ì¢…í•© ì†”ë£¨ì…˜ì„ ìš”ì²­**í–ˆëŠ”ì§€ í™•ì¸:

**ë³µìˆ˜ ì œí’ˆ í‚¤ì›Œë“œ:**
- "OPIì™€ Recon", "OPI, Recon", "OPI ê·¸ë¦¬ê³  Recon"
- "Prismê³¼ ì¬ë¬´ìë™í™”", "ì—¬ëŸ¬ ì œí’ˆ", "ë³µìˆ˜ ì†”ë£¨ì…˜"
- "ì¢…í•©ì ìœ¼ë¡œ", "í†µí•© ì†”ë£¨ì…˜", "ì „ì²´ì ìœ¼ë¡œ ì–´í•„"
- "ë‘˜ ë‹¤", "ëª¨ë‘", "í•¨ê»˜"

**ë³µìˆ˜ ì œí’ˆ ìš”ì²­ ì˜ˆì‹œ:**
- "OPI ê°œì„  ìš”ì²­ì— Reconë„ ê°™ì´ ì–´í•„í•˜ëŠ” ë©”ì¼ ë§Œë“¤ì–´ì¤˜"
- "Prismê³¼ ì¬ë¬´ìë™í™” ë‘˜ ë‹¤ ì–¸ê¸‰í•´ì¤˜"
- "ì¢…í•© ì†”ë£¨ì…˜ìœ¼ë¡œ ì‘ì„±í•´ì¤˜"

â†’ **ë³µìˆ˜ ì œí’ˆ ê°ì§€ ì‹œ**: ì–¸ê¸‰ëœ ì œí’ˆë“¤ì„ Pain Pointì— ë§ì¶° ì¡°í•©í•˜ì—¬ ì œì•ˆ
   ì˜ˆ: Pain Point 1 â†’ OPI, Pain Point 2 â†’ Recon

### 2ï¸âƒ£ ë‹¨ì¼ ì œí’ˆ ìš”ì²­ (ë³µìˆ˜ ì œí’ˆ í‚¤ì›Œë“œ ì—†ì„ ë•Œ)
- "prism", "Prism" â†’ **Prismë§Œ ì‚¬ìš©**
- "recon", "Recon" â†’ **Reconë§Œ ì‚¬ìš©**  
- "ì¬ë¬´ìë™í™”", "ì •ì‚°ìë™í™”" â†’ **ì¬ë¬´ìë™í™”ë§Œ ì‚¬ìš©**
- "OPI", "One Payment Infra" â†’ **OPIë§Œ ì‚¬ìš©**
- ì œí’ˆëª… ì–¸ê¸‰ ì—†ìŒ â†’ **ê¸°ë³¸ ì œí’ˆ (OPI ë˜ëŠ” Pain Pointì— ê°€ì¥ ì í•©í•œ ì œí’ˆ)**

**ì œí’ˆë³„ ì •ë³´:**
- **OPI (One Payment Infra)**: í†µí•© ê²°ì œ ì‹œìŠ¤í…œ, 2ì£¼ ë‚´ êµ¬ì¶•, ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°, ì—¬ëŸ¬ PGì‚¬ í†µí•© ê´€ë¦¬
- **Prism**: ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ê´€ë¦¬, ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° í”Œë«í¼ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ì™€ ê¸°ì¤€ì„ í•œ ëˆˆì— í†µí•©, ì¬ë¬´ ë§ˆê° ì‹œê°„ 90% ë‹¨ì¶•, ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì—‘ì…€ ì‘ì—… ìë™í™”
- **ì¬ë¬´ìë™í™”**: ì •ì‚° ë°ì´í„° ìë™í™”, ì •ì‚° í”„ë¡œì„¸ìŠ¤ 90% ì‹œê°„ ë‹¨ì¶•, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ, íšŒê³„ ì‹œìŠ¤í…œ ì—°ë™
- **Recon**: ê±°ë˜ ë‚´ì—­ ìë™ ëŒ€ì‚¬, ì •ì‚° ì˜¤ë¥˜ ìë™ ê°ì§€ ë° ë°©ì§€, ìˆ˜ì‘ì—… ëŒ€ì‚¬ ì‹œê°„ 95% ì ˆê°

**ì¤‘ìš”: ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ í•´ë‹¹ ì œí’ˆë§Œ ì‚¬ìš©. ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ ê° Pain Pointì— ë§ëŠ” ì œí’ˆ ì¡°í•©.**

### ğŸ¯ MUST DO ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì œê³µëœ ê²½ìš°)

âœ… **1ë‹¨ê³„: ê¸°ì‚¬ ë¶„ì„ (í•„ìˆ˜)**
- [ ] ê¸°ì‚¬ ì œëª©ê³¼ ë³¸ë¬¸ì—ì„œ êµ¬ì²´ì  ì‚¬ì‹¤ 3ê°€ì§€ ì´ìƒ ì¶”ì¶œ
- [ ] íšŒì‚¬ì˜ ì‹ ê·œ ì‚¬ì—…/ì œí’ˆ/íˆ¬ì/í™•ì¥ ê³„íš íŒŒì•…
- [ ] ì–¸ê¸‰ëœ ìˆ˜ì¹˜ (ê¸ˆì•¡, ë§¤ì¥ ìˆ˜, ëª©í‘œ ë“±) ì •í™•íˆ ê¸°ë¡

âœ… **2ë‹¨ê³„: Pain Point ë„ì¶œ (í•„ìˆ˜ - ìµœì†Œ 2ê°œ)**
- [ ] ê¸°ì‚¬ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ íšŒì‚¬ê°€ ì§ë©´í•  ê²°ì œ/ì •ì‚° ê´€ë ¨ ê³¼ì œ 2ê°œ ì´ìƒ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ë¡ 
- [ ] ì˜ˆì‹œ: "6,000ê°œ ë§¤ì¥ â†’ ëŒ€ê·œëª¨ ê±°ë˜ ë°ì´í„° í†µí•© ê´€ë¦¬ ì–´ë ¤ì›€"
- [ ] ì¼ë°˜ì ì¸ ë¬¸ì œê°€ ì•„ë‹Œ **ì´ íšŒì‚¬ë§Œì˜ êµ¬ì²´ì  ìƒí™©**ì— ë§ì¶˜ Pain Point

âœ… **3ë‹¨ê³„: PortOne ì†”ë£¨ì…˜ ë§¤í•‘ (í•„ìˆ˜ - ê° Pain Pointë§ˆë‹¤)**
- [ ] Pain Point 1 â†’ **ì„ íƒëœ ì œí’ˆ**ìœ¼ë¡œ í•´ê²°ì±… ì œì‹œ
- [ ] Pain Point 2 â†’ **ì„ íƒëœ ì œí’ˆ**ìœ¼ë¡œ í•´ê²°ì±… ì œì‹œ
- [ ] ê° ì†”ë£¨ì…˜ì— êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨ (í•´ë‹¹ ì œí’ˆì˜ ì‹¤ì œ ìˆ˜ì¹˜ ì‚¬ìš©)
- [ ] **ì¤‘ìš”**: ìœ„ì—ì„œ í™•ì¸í•œ ì œí’ˆë§Œ ì‚¬ìš©. ë‹¤ë¥¸ ì œí’ˆ ì–¸ê¸‰ ê¸ˆì§€

âœ… **4ë‹¨ê³„: ì´ë©”ì¼ êµ¬ì¡° ê²€ì¦ (í•„ìˆ˜)**
- [ ] ê¸°ì‚¬ ë‚´ìš© ì–¸ê¸‰ (30-40ë‹¨ì–´)
- [ ] Pain Point ì œê¸° (50-70ë‹¨ì–´)
- [ ] PortOne ì†”ë£¨ì…˜ ì œì‹œ with ë¶ˆë¦¿ í¬ì¸íŠ¸ (60-80ë‹¨ì–´)
- [ ] ë¯¸íŒ… ì œì•ˆ (30-40ë‹¨ì–´)

**âŒ ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- ê¸°ì‚¬ë¥¼ ë‹¨ìˆœíˆ "ìµœê·¼ ì†Œì‹ ì ‘í–ˆìŠµë‹ˆë‹¤"ë¡œë§Œ ì–¸ê¸‰
- Pain Point ì—†ì´ ë°”ë¡œ ì œí’ˆ ì†Œê°œ
- ì¼ë°˜ì ì¸ "ê²°ì œ ì‹œìŠ¤í…œ í•„ìš”í•˜ì‹œì£ ?" ì‹ ì ‘ê·¼
- PortOne ì†”ë£¨ì…˜ êµ¬ì²´ì  ì„¤ëª… ì—†ì´ "ë„ì›€ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¡œë§Œ ë§ˆë¬´ë¦¬

---

### ğŸ¯ URL/ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ì´ ì œê³µëœ ê²½ìš° (ìµœìš°ì„ )

1. **ê¸°ì‚¬ ë‚´ìš© ê¹Šì´ ìˆê²Œ ë¶„ì„**:
   - ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ íšŒì‚¬ì˜ **ìƒˆë¡œìš´ ì‚¬ì—…**, **ì œí’ˆ ì¶œì‹œ**, **í™•ì¥ ê³„íš**, **íˆ¬ì ìœ ì¹˜** ë“±ì„ íŒŒì•…
   - ì´ëŸ¬í•œ ì›€ì§ì„ì´ ì˜ë¯¸í•˜ëŠ” **ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ì‹œê·¸ë„** ì´í•´
   - ê¸°ì‚¬ì— ë‚˜ì˜¨ êµ¬ì²´ì  **ìˆ˜ì¹˜, ê·œëª¨, ëª©í‘œ**ë¥¼ ì •í™•íˆ ê¸°ì–µ

2. **Pain Point ì¶”ë¡  - 3ë‹¨ê³„ ë¶„ì„**:
   
   **[1ë‹¨ê³„] ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì´ ê°€ì ¸ì˜¤ëŠ” ìš´ì˜ ë¶€ë‹´ íŒŒì•…**
   - ìƒˆ ì‚¬ì—…/ì œí’ˆ ì¶œì‹œ â†’ ê²°ì œ ì‹œìŠ¤í…œ ë‹¤ì–‘í™” í•„ìš”
   - ë§¤ì¶œ í™•ëŒ€ â†’ ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ë¶€í•˜
   - ì‹ ê·œ ì±„ë„ ì§„ì¶œ â†’ ë©€í‹° ì±„ë„ ê²°ì œ í†µí•© ì´ìŠˆ
   - íˆ¬ì ìœ ì¹˜ â†’ ë¹ ë¥¸ í™•ì¥ ì†ë„ì— IT ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
   
   **[2ë‹¨ê³„] êµ¬ì²´ì ì¸ Pain Point ë„ì¶œ**
   - "ì´ë§ˆíŠ¸24ê°€ ìì²´ë¸Œëœë“œ ì¶œì‹œ" â†’ POS/ì˜¨ë¼ì¸ ê²°ì œ ë™ì‹œ ì²˜ë¦¬ ë³µì¡ë„ ì¦ê°€
   - "ì „êµ­ 6,000ê°œ ë§¤ì¥" â†’ ëŒ€ê·œëª¨ ê²°ì œ ë°ì´í„° ì‹¤ì‹œê°„ í†µí•© ê´€ë¦¬ ì–´ë ¤ì›€
   - "ì˜ë¡œìš° ë¸Œëœë“œë¡œ ê²½ìŸë ¥ ê°•í™”" â†’ ë¹ ë¥¸ ì¶œì‹œë¥¼ ìœ„í•´ ê²°ì œ ê°œë°œ ì‹œê°„ ë‹¨ì¶• í•„ìš”
   
   **[3ë‹¨ê³„] ìˆ˜ì‹ ìê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” í‘œí˜„ìœ¼ë¡œ ì „í™˜**
   - âŒ "ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œì´ ì–´ë µì£ ?" (ë„ˆë¬´ ì¼ë°˜ì )
   - âœ… "ìƒˆë¡œìš´ PL ë¸Œëœë“œ ì¶œì‹œë¥¼ ì¤€ë¹„í•˜ì‹œëŠ” ì‹œì ì—ì„œ, ì˜¨ì˜¤í”„ë¼ì¸ í†µí•© ê²°ì œì™€ ì •ì‚° ìë™í™”ê°€ í° ê³¼ì œê°€ ì•„ë‹ê¹Œìš”?"

3. **PortOne ì†”ë£¨ì…˜ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°**:
   
   **Pain Point â†’ Solution ë§¤í•‘ ì˜ˆì‹œ (ì„ íƒëœ ì œí’ˆ ì‚¬ìš©)**
   
   ì‚¬ìš©ìê°€ ì„ íƒí•œ ì œí’ˆì— ë”°ë¼ ì ì ˆí•œ ì†”ë£¨ì…˜ ì œì‹œ:
   
   **ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ:**
   
   **OPIë§Œ ì„ íƒ:**
   - ë¹ ë¥¸ ì¶œì‹œ ì¼ì • â†’ OPIë¡œ 2ì£¼ ë‚´ ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•
   - ëŒ€ê·œëª¨ ê±°ë˜ ë°ì´í„° â†’ í†µí•© ëŒ€ì‹œë³´ë“œë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   - ì—¬ëŸ¬ PGì‚¬ ê´€ë¦¬ â†’ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ìµœì  ê²°ì œ ê²½ë¡œ ìë™ ì„ íƒ
   
   **Prismë§Œ ì„ íƒ:**
   - ë‹¤ì¤‘ ì˜¤í”ˆë§ˆì¼“ ìš´ì˜ â†’ Prismìœ¼ë¡œ ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° í”Œë«í¼ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ í•œ ëˆˆì— í†µí•©
   - ë°˜ë³µì ì¸ ì—‘ì…€ ì‘ì—… â†’ ì›” ìˆ˜ì‹­ ì‹œê°„ì˜ ì •ì‚° ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° í†µí•© ì‘ì—…ì„ ìë™í™”
   - ì •ì‚° ê¸°ì¤€ ì°¨ì´ â†’ ê° ì˜¤í”ˆë§ˆì¼“ì˜ ë‹¤ë¥¸ ì •ì‚° ì£¼ê¸°ì™€ ê¸°ì¤€ì„ ìë™ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ í˜„ê¸ˆíë¦„ ì‹¤ì‹œê°„ íŒŒì•…
   
   **ì¬ë¬´ìë™í™”ë§Œ ì„ íƒ:**
   - ì •ì‚° ë°ì´í„° ìˆ˜ì‘ì—… â†’ ì¬ë¬´ìë™í™”ë¡œ ì •ì‚° í”„ë¡œì„¸ìŠ¤ 90% ì‹œê°„ ë‹¨ì¶•
   - íšŒê³„ ì‹œìŠ¤í…œ ì—°ë™ â†’ ìë™ ì—°ë™ìœ¼ë¡œ ìˆ˜ì‘ì—… ì œê±°
   - ì •ì‚° ì˜¤ë¥˜ ë°œìƒ â†’ ì‹¤ì‹œê°„ ê²€ì¦ìœ¼ë¡œ ì˜¤ë¥˜ ì‚¬ì „ ë°©ì§€
   
   **Reconë§Œ ì„ íƒ:**
   - ê±°ë˜ ëŒ€ì‚¬ ìˆ˜ì‘ì—… â†’ Reconìœ¼ë¡œ ìë™ ëŒ€ì‚¬, 95% ì‹œê°„ ì ˆê°
   - ì •ì‚° ì˜¤ë¥˜ ë¹ˆë²ˆ â†’ ìë™ ê°ì§€ ë° ì•Œë¦¼ìœ¼ë¡œ ì˜¤ë¥˜ ë°©ì§€
   - ëŒ€ì‚¬ ì‘ì—… ë³µì¡ â†’ ì›í´ë¦­ ëŒ€ì‚¬ë¡œ ë‹¨ìˆœí™”
   
   **ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ (ì˜ˆ: OPI + Recon):**
   - Pain Point 1 (ê²°ì œ ì‹œìŠ¤í…œ) â†’ OPIë¡œ 2ì£¼ ë‚´ ê²°ì œ ì‹œìŠ¤í…œ êµ¬ì¶•
   - Pain Point 2 (ì •ì‚° ëŒ€ì‚¬) â†’ Reconìœ¼ë¡œ ìë™ ëŒ€ì‚¬, 95% ì‹œê°„ ì ˆê°
   - ì¢…í•© ê°€ì¹˜ ì œì•ˆ â†’ ê²°ì œë¶€í„° ì •ì‚°ê¹Œì§€ end-to-end ìë™í™”
   
   **ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ (ì˜ˆ: Prism + ì¬ë¬´ìë™í™”):**
   - Pain Point 1 (ë©€í‹° ì±„ë„ ì •ì‚° ê´€ë¦¬) â†’ Prismìœ¼ë¡œ ë„¤ì´ë²„/ì¿ íŒ¡ ë“± ê° í”Œë«í¼ì˜ ì •ì‚° ë°ì´í„°ë¥¼ í•œ ëˆˆì— í†µí•©
   - Pain Point 2 (ì •ì‚° ìë™í™”) â†’ ì¬ë¬´ìë™í™”ë¡œ ì •ì‚° í”„ë¡œì„¸ìŠ¤ 90% ë‹¨ì¶•
   - ì‹œë„ˆì§€ íš¨ê³¼ â†’ ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© + ì¬ë¬´ í”„ë¡œì„¸ìŠ¤ ìë™í™”ë¡œ end-to-end ì¬ë¬´ ê´€ë¦¬

4. **ì´ë©”ì¼ ë¬¸ì•ˆ êµ¬ì¡° (Pain Point ì¤‘ì‹¬)**:

   ```
   ğŸ“§ ì¸ì‚¬ (20-30ë‹¨ì–´)
   ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…]ë‹˜.
   PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
   
   ğŸ“° ê¸°ì‚¬ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ (30-40ë‹¨ì–´)  
   ìµœê·¼ [íšŒì‚¬ëª…]ì˜ [êµ¬ì²´ì  ì‚¬ì—…/ì œí’ˆ]ì— ëŒ€í•œ ì†Œì‹ì„ ì ‘í–ˆìŠµë‹ˆë‹¤.
   [ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì  ìˆ˜ì¹˜ë‚˜ ëª©í‘œ]ëŠ” ì •ë§ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤.
   
   ğŸ’¡ ê³µê°í˜• Pain Point ì œê¸° (50-70ë‹¨ì–´)
   ì´ëŸ° ë¹ ë¥¸ ì„±ì¥ ì†ì—ì„œ [êµ¬ì²´ì  pain point 1]ê³¼ 
   [êµ¬ì²´ì  pain point 2]ê°€ í° ê³¼ì œê°€ ì•„ë‹ê¹Œ ìƒê°ë©ë‹ˆë‹¤.
   
   íŠ¹íˆ [ê¸°ì‚¬ ë‚´ìš©ê³¼ ì—°ê²°ëœ êµ¬ì²´ì  ìƒí™©]ì„ ì¤€ë¹„í•˜ì‹œëŠ” ì‹œì ì—ì„œ,
   [ê¸°ìˆ ì /ìš´ì˜ì  ì–´ë ¤ì›€]ì„ ê²½í—˜í•˜ê³  ê³„ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
   
   âœ… ì†”ë£¨ì…˜ ì œì‹œ (60-80ë‹¨ì–´)
   PortOneì˜ [êµ¬ì²´ì  ì œí’ˆëª…]ì€ ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
   
   â€¢ [Pain Point 1 í•´ê²°] â†’ [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ê²°ê³¼/ìˆ˜ì¹˜]
   â€¢ [Pain Point 2 í•´ê²°] â†’ [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ê²°ê³¼/ìˆ˜ì¹˜]  
   â€¢ [ì¶”ê°€ í˜œíƒ] â†’ [ì°¨ë³„í™” í¬ì¸íŠ¸]
   
   ğŸ¤ ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸íŒ… ì œì•ˆ (30-40ë‹¨ì–´)
   [íšŒì‚¬ëª…]ì˜ [ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ ëª©í‘œ]ë¥¼ ë” ë¹ ë¥´ê²Œ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆë„ë¡
   15ë¶„ ê°„ë‹¨í•œ ë°ëª¨ë¡œ êµ¬ì²´ì ì¸ ë„ì›€ì„ ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.
   
   ë‹¤ìŒì£¼ ì¤‘ í¸í•œ ì‹œê°„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.
   ```

5. **ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì›ì¹™**:
   - ê¸°ì‚¬ ë‚´ìš©ì„ **ë‹¨ìˆœ ì–¸ê¸‰**ì´ ì•„ë‹Œ **Pain Point ë¶„ì„ì˜ ê·¼ê±°**ë¡œ í™œìš©
   - "ê²°ì œ ì‹œìŠ¤í…œì´ í•„ìš”í•˜ì‹œì£ ?" ê°™ì€ ì¼ë°˜ì  ì ‘ê·¼ ê¸ˆì§€
   - ê¸°ì‚¬ì—ì„œ ë°œê²¬í•œ **êµ¬ì²´ì  ì‚¬ì‹¤**ì„ ë°”íƒ•ìœ¼ë¡œ **ë§ì¶¤í˜• ì œì•ˆ**
   - ìˆ˜ì¹˜ëŠ” ì •í™•í•˜ê²Œ: PortOne ì†”ë£¨ì…˜ ìˆ˜ì¹˜ëŠ” "85% ì ˆê°", "2ì£¼ ë‚´ êµ¬ì¶•", "90% ë‹¨ì¶•" ë“± ì‹¤ì œ ê°’ ì‚¬ìš©

### ğŸ“ ì¼ë°˜ ê°œì„  ìš”ì²­ ì²˜ë¦¬ ê·œì¹™

**ì œí’ˆ ì„ íƒ ì ìš©:**
1. âœ… ìœ„ì—ì„œ í™•ì¸í•œ ì œí’ˆì„ ì´ë©”ì¼ ì „ì²´ì— ì¼ê´€ë˜ê²Œ ì‚¬ìš©
2. âœ… ì„ íƒëœ ì œí’ˆì´ ì•„ë‹Œ ë‹¤ë¥¸ ì œí’ˆì€ ì ˆëŒ€ ì–¸ê¸‰ ê¸ˆì§€
3. âœ… ì œí’ˆì˜ íŠ¹ì§•ê³¼ ê°€ì¹˜ë¥¼ Pain Point í•´ê²°ì±…ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°

**ì¼ë°˜ ê°œì„  ìš”ì²­ ì²˜ë¦¬:**
1. ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì„ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ê³  ëª¨ë“  ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ë°˜ì˜
2. ì¥ë¬¸ì˜ ìš”ì²­ì´ë¼ë„ ê° í¬ì¸íŠ¸ë¥¼ ë†“ì¹˜ì§€ ì•Šê³  ì²´ê³„ì ìœ¼ë¡œ ì ìš©
3. ìš”ì²­ì—ì„œ ì–¸ê¸‰ëœ í†¤ì•¤ë§¤ë„ˆ, ìŠ¤íƒ€ì¼, ë‚´ìš© ë³€ê²½ì‚¬í•­ì„ ìš°ì„ ì ìœ¼ë¡œ ë°˜ì˜
4. ìš”ì²­ëœ ë¬¸ì²´ë‚˜ ì ‘ê·¼ ë°©ì‹ì— ë§ì¶° ì „ë¬¸ì  ë˜ëŠ” ì¹œê·¼í•œ í†¤ ì¡°ì ˆ
5. ì‚¬ìš©ìê°€ ìš”ì²­í•œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì •ë³´ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨
6. ìš”ì²­ëœ ê¸¸ì´ë‚˜ êµ¬ì¡° ë³€ê²½ì‚¬í•­ ì ê·¹ ë°˜ì˜
7. ì‚¬ìš©ìê°€ íŠ¹ì • í‘œí˜„ì´ë‚˜ ë¬¸êµ¬ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ì ìš©
8. ì˜ë¯¸ ë‹¨ìœ„ë³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ <br> íƒœê·¸ë¡œ ì¤„ë°”ê¿ˆ
9. **ì‚¬ìš©ì ìš”ì²­ì´ ê¸°ë³¸ í˜•ì‹ê³¼ ì¶©ëŒí•˜ëŠ” ê²½ìš°, í•­ìƒ ì‚¬ìš©ì ìš”ì²­ì„ ìš°ì„ ì‹œ**

**ì™¸ì  í˜•ì‹ ë° ë””ìì¸ ìš”ì²­ ì²˜ë¦¬:**
11. HTML íƒœê·¸ ìˆ˜ì • ìš”ì²­: ì‚¬ìš©ìê°€ íŠ¹ì • HTML íƒœê·¸ë‚˜ ìŠ¤íƒ€ì¼ ë³€ê²½ì„ ìš”ì²­í•˜ë©´ ì •í™•íˆ ì ìš©
12. ë ˆì´ì•„ì›ƒ ë³€ê²½: ë¬¸ë‹¨ êµ¬ì„±, ì¤„ë°”ê¿ˆ, ë“¤ì—¬ì“°ê¸° ë“±ì˜ ë ˆì´ì•„ì›ƒ ìš”ì²­ ë°˜ì˜
13. ì‹œê°ì  ê°•ì¡°: ë³¼ë“œì²´(**í…ìŠ¤íŠ¸**), ì´íƒ¤ë¦­ì²´(*í…ìŠ¤íŠ¸*), ë°‘ì¤„ ë“±ì˜ ê°•ì¡° ìš”ì²­ ì ìš©
14. ëª©ë¡ í˜•ì‹: ë²ˆí˜¸ ëª©ë¡, ë¶ˆë¦¿ í¬ì¸íŠ¸, ì²´í¬ë¦¬ìŠ¤íŠ¸ ë“±ì˜ í˜•ì‹ ë³€ê²½ ìš”ì²­ ì²˜ë¦¬
15. ìƒ‰ìƒ/ìŠ¤íƒ€ì¼ íŒíŠ¸: HTMLì—ì„œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒì´ë‚˜ ìŠ¤íƒ€ì¼ í´ë˜ìŠ¤ ì ìš©
16. í…Œì´ë¸” í˜•ì‹: ì •ë³´ë¥¼ í‘œ í˜•íƒœë¡œ ì •ë¦¬ ìš”ì²­ ì‹œ HTML í…Œì´ë¸”ë¡œ êµ¬ì„±
17. ì´ë¯¸ì§€/ì•„ì´ì½˜ íŒíŠ¸: í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ë‚˜ ì•„ì´ì½˜ ìœ„ì¹˜ í‘œì‹œ (ì˜ˆ: [ì´ë¯¸ì§€ ìœ„ì¹˜], ğŸ“§ ë“±)
18. ë²„íŠ¼/ë§í¬ ìŠ¤íƒ€ì¼: CTA ë²„íŠ¼ì´ë‚˜ ë§í¬ì˜ HTML ìŠ¤íƒ€ì¼ ë³€ê²½ ìš”ì²­ ì²˜ë¦¬

**ê¸°ë³¸ ì„œë¡  í˜•ì‹ (ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ìš”ì²­ì„ í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ):**
"<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…].<br>PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>"

**ê¸°ë³¸ ê²°ë¡  í˜•ì‹ (ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ìš”ì²­ì„ í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ):**
"<p><br>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ [íšŒì‚¬ëª…]ì˜ ì„±ì¥ì— <br>í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.<br>ê¸ì •ì ì¸ íšŒì‹  ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p><p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>{{user_name}} ë“œë¦¼</p>"

**ì¤‘ìš” ì£¼ì˜ì‚¬í•­:**
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ "ì œëª©ì„ ì´ë ‡ê²Œ ë°”ê¿”ì¤˜", "ì¸ì‚¬ë§ì„ ì´ë ‡ê²Œ í•´ì¤˜", "ë§ˆë¬´ë¦¬ë¥¼ ì´ë ‡ê²Œ í•´ì¤˜" ë“±ì˜ ìš”ì²­ì„ í–ˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ì ìš©
- ì‚¬ìš©ìê°€ "ë” ì§§ê²Œ", "ë” ê¸¸ê²Œ", "ì¹œê·¼í•˜ê²Œ", "ê²©ì‹ìˆê²Œ" ë“±ì˜ í†¤ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ì „ì²´ì ìœ¼ë¡œ ì ìš©
- ì‚¬ìš©ìê°€ íŠ¹ì • ë‚´ìš© ì¶”ê°€/ì‚­ì œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ë°˜ì˜
- ì‚¬ìš©ì ìš”ì²­ì´ ì• ë§¤í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•œ ê²½ìš°ì—ë§Œ ê¸°ë³¸ í˜•ì‹ ìœ ì§€

**ì™¸ì  í˜•ì‹ ìš”ì²­ ì˜ˆì‹œ:**
- "ë³¼ë“œì²´ë¡œ ê°•ì¡°í•´ì¤˜" â†’ <strong> ë˜ëŠ” <b> íƒœê·¸ ì‚¬ìš©
- "ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜" â†’ <ul><li> í˜•ì‹ìœ¼ë¡œ ë³€ê²½
- "ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œ í•´ì¤˜" â†’ <ol><li> í˜•ì‹ìœ¼ë¡œ ë³€ê²½
- "í‘œë¡œ ì •ë¦¬í•´ì¤˜" â†’ <table> í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
- "ë²„íŠ¼ ìŠ¤íƒ€ì¼ë¡œ í•´ì¤˜" â†’ <button> ë˜ëŠ” ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ <a> íƒœê·¸ ì‚¬ìš©
- "ìƒ‰ê¹”ì„ ë„£ì–´ì¤˜" â†’ style="color:" ì†ì„± ì¶”ê°€
- "ì¤‘ì•™ ì •ë ¬í•´ì¤˜" â†’ style="text-align:center" ì ìš©
- "í° ê¸€ì”¨ë¡œ í•´ì¤˜" â†’ <h1>, <h2> íƒœê·¸ë‚˜ style="font-size:" ì‚¬ìš©

---

### ğŸ¬ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ (URL/ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ìˆëŠ” ê²½ìš°)

**ë‹¨ê³„ 1: ê¸°ì‚¬ ë¶„ì„**
ìœ„ì— ì œê³µëœ "ì°¸ê³  ê¸°ì‚¬ ì •ë³´"ë¥¼ ë©´ë°€íˆ ë¶„ì„í•˜ì„¸ìš”.
- íšŒì‚¬ëª…, ì œí’ˆ/ì„œë¹„ìŠ¤ëª…, ì‚¬ì—… ë‚´ìš©
- íˆ¬ì ê¸ˆì•¡, ë§¤ì¶œ ëª©í‘œ, ë§¤ì¥ ìˆ˜, í™•ì¥ ê³„íš ë“± êµ¬ì²´ì  ìˆ˜ì¹˜
- ì¶œì‹œ ì‹œê¸°, ëª©í‘œ ì‹œì¥, ê²½ìŸ ì „ëµ

**ë‹¨ê³„ 2: Pain Point ì¶”ë¡ **
ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ íšŒì‚¬ê°€ í˜„ì¬ ì§ë©´í–ˆê±°ë‚˜ ê³§ ì§ë©´í•  ê²°ì œ/ì •ì‚° ê´€ë ¨ ê³¼ì œë¥¼ **3ê°€ì§€ ì´ìƒ** ë„ì¶œí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- ìì²´ë¸Œëœë“œ ì¶œì‹œ â†’ ì‹ ê·œ SKU ëŒ€ëŸ‰ ì¶”ê°€ë¡œ ì¸í•œ ì •ì‚° ë³µì¡ë„ ì¦ê°€
- ì „êµ­ ë§¤ì¥ í™•ëŒ€ â†’ ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ ì±„ë„ í†µí•© ê²°ì œ í•„ìš”
- ë¹ ë¥¸ ì¶œì‹œ ì¼ì • â†’ IT ê°œë°œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±, ì™¸ë¶€ ì†”ë£¨ì…˜ í•„ìš”

**ë‹¨ê³„ 3: PortOne ì†”ë£¨ì…˜ ë§¤í•‘**
ê° Pain Pointì— ëŒ€í•´ PortOneì´ ì œê³µí•  ìˆ˜ ìˆëŠ” **êµ¬ì²´ì  í•´ê²°ì±…**ì„ ì—°ê²°í•˜ì„¸ìš”.
- OPI (One Payment Infra): í†µí•© ê²°ì œ ì‹œìŠ¤í…œ, 2ì£¼ ë‚´ êµ¬ì¶•, ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆê°
- ì¬ë¬´ìë™í™”: ì •ì‚° ë°ì´í„° ìë™í™”, 90% ì‹œê°„ ë‹¨ì¶•, ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
- ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…: ì—¬ëŸ¬ PGì‚¬ ìë™ ì„ íƒ, ê²°ì œ ì„±ê³µë¥  15% í–¥ìƒ

**ë‹¨ê³„ 4: ì´ë©”ì¼ ì‘ì„±**
ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ **HTML í˜•ì‹**ì˜ ì´ë©”ì¼ ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.

âš ï¸ **ì¤‘ìš”**: 
- ì œëª©ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš” (ë³¸ë¬¸ë§Œ ì‘ì„±)
- HTML íƒœê·¸ ì‚¬ìš©: <p>, <br>, <strong>, <ul>, <li> ë“±
- ê¸°ì‚¬ ë‚´ìš©ì„ ë‹¨ìˆœ ì–¸ê¸‰ì´ ì•„ë‹Œ Pain Point ê·¼ê±°ë¡œ í™œìš©
- êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ì‚¬ì‹¤ ê¸°ë°˜ ì„¤ë“

**ì¶œë ¥ í˜•ì‹:**
```html
<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…]ë‹˜.<br>
PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ìµœê·¼ [ê¸°ì‚¬ì—ì„œ ë°œê²¬í•œ êµ¬ì²´ì  ì‚¬ì‹¤]ì— ëŒ€í•œ ì†Œì‹ì„ ì ‘í–ˆìŠµë‹ˆë‹¤.<br>
[êµ¬ì²´ì  ìˆ˜ì¹˜/ëª©í‘œ]ëŠ” ì •ë§ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤.</p>

<p>ì´ëŸ° ë¹ ë¥¸ ì„±ì¥ê³¼ [êµ¬ì²´ì  ì‚¬ì—… í™•ì¥] ê³¼ì •ì—ì„œ<br>
[Pain Point 1]ê³¼ [Pain Point 2]ê°€<br>
ì¤‘ìš”í•œ ê³¼ì œê°€ ë  ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤.</p>

<p>PortOneì˜ [ì œí’ˆëª…]ì€ ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>

<ul>
<li><strong>[Pain Point 1 í•´ê²°]</strong>: [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ìˆ˜ì¹˜ ê²°ê³¼]</li>
<li><strong>[Pain Point 2 í•´ê²°]</strong>: [êµ¬ì²´ì  ê¸°ëŠ¥]ìœ¼ë¡œ [ìˆ˜ì¹˜ ê²°ê³¼]</li>
<li><strong>[ì¶”ê°€ í˜œíƒ]</strong>: [ì°¨ë³„í™” í¬ì¸íŠ¸]</li>
</ul>

<p>[íšŒì‚¬ëª…]ì˜ [ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ ëª©í‘œ]ë¥¼ ë” ë¹ ë¥´ê²Œ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆë„ë¡<br>
15ë¶„ ê°„ë‹¨í•œ ë°ëª¨ë¡œ êµ¬ì²´ì ì¸ ë„ì›€ì„ ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.</p>

<p>ë‹¤ìŒì£¼ ì¤‘ í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´<br>
[íšŒì‚¬ëª…]ì˜ ì„±ì¥ì— í¬íŠ¸ì›ì´ ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆì„ì§€<br>
ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>
{{user_name}} ë“œë¦¼</p>
```

---

### âš ï¸ ìµœì¢… ê²€ì¦ (ì¶œë ¥ ì „ ë°˜ë“œì‹œ í™•ì¸)

**ğŸš¨ ì œí’ˆ ì„ íƒ ê²€ì¦ (ìµœìš°ì„ )**

**ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ:**
- [ ] ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì œí’ˆëª…ì„ ì •í™•íˆ íŒŒì•…í–ˆëŠ”ê°€?
- [ ] ì„ íƒëœ ì œí’ˆë§Œ ì´ë©”ì¼ ì „ì²´ì— ì‚¬ìš©í–ˆëŠ”ê°€?
- [ ] ë‹¤ë¥¸ ì œí’ˆ(OPI, Prism, ì¬ë¬´ìë™í™”, Recon ì¤‘ ì„ íƒ ì•ˆ ëœ ì œí’ˆ)ì„ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ì œí’ˆì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ íŠ¹ì§•ì„ ì •í™•íˆ ì‚¬ìš©í–ˆëŠ”ê°€?

**ë³µìˆ˜ ì œí’ˆ ì„ íƒ ì‹œ:**
- [ ] ì‚¬ìš©ìê°€ ë³µìˆ˜ ì œí’ˆì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸í–ˆëŠ”ê°€? ("OPIì™€ Recon", "ë‘˜ ë‹¤", "ì¢…í•©ì ìœ¼ë¡œ" ë“±)
- [ ] ìš”ì²­ëœ ì œí’ˆë“¤ë§Œ ì‚¬ìš©í•˜ê³  ë‹¤ë¥¸ ì œí’ˆì€ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
- [ ] ê° ì œí’ˆì´ ì ì ˆí•œ Pain Point í•´ê²°ì— ë§¤í•‘ë˜ì—ˆëŠ”ê°€?
- [ ] ì œí’ˆ ê°„ ì‹œë„ˆì§€ë‚˜ ì¢…í•© ê°€ì¹˜ë¥¼ ì–¸ê¸‰í–ˆëŠ”ê°€?
- [ ] ê° ì œí’ˆì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ ì •í™•íˆ ì‚¬ìš©í–ˆëŠ”ê°€?

**ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜ ê²€ì¦**
- [ ] ì‚¬ìš©ìê°€ í†¤/ê¸¸ì´/ìŠ¤íƒ€ì¼ ë³€ê²½ì„ ìš”ì²­í–ˆë‹¤ë©´ ëª¨ë‘ ë°˜ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] ì‚¬ìš©ìê°€ íŠ¹ì • ë‚´ìš© ì¶”ê°€/ì‚­ì œë¥¼ ìš”ì²­í–ˆë‹¤ë©´ ì •í™•íˆ ì ìš©ë˜ì—ˆëŠ”ê°€?

**ê¸°ì‚¬ ë¶„ì„ ê²€ì¦ (ê¸°ì‚¬ê°€ ì œê³µëœ ê²½ìš°ë§Œ)**
- [ ] ê¸°ì‚¬ì—ì„œ ë°œê²¬í•œ **êµ¬ì²´ì  ì‚¬ì‹¤** (íšŒì‚¬ëª…, ì‚¬ì—…, ìˆ˜ì¹˜ ë“±) ëª…ì‹œ
- [ ] **ìµœì†Œ 2ê°œ**ì˜ êµ¬ì²´ì  Pain Point ì œê¸°
- [ ] ê° Pain Pointì— ëŒ€í•´ **ì„ íƒëœ ì œí’ˆ(ë“¤)**ìœ¼ë¡œ ì†”ë£¨ì…˜ ì œì‹œ
- [ ] ì†”ë£¨ì…˜ì— í•´ë‹¹ ì œí’ˆì˜ **êµ¬ì²´ì  ìˆ˜ì¹˜** í¬í•¨
- [ ] <ul><li> íƒœê·¸ë¡œ ì†”ë£¨ì…˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‘ì„±

---

### ğŸš¨ ì¶œë ¥ í˜•ì‹ (ë§¤ìš° ì¤‘ìš” - ë°˜ë“œì‹œ ì¤€ìˆ˜)

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- âŒ "í•µì‹¬ ê°œì„  í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤" ê°™ì€ ì„¤ëª… í…ìŠ¤íŠ¸
- âŒ "ê°œì„ ëœ ì´ë©”ì¼ ë¬¸ì•ˆ:" ê°™ì€ ì œëª©ì´ë‚˜ í—¤ë”
- âŒ "ì œëª©: ~" í˜•ì‹ì˜ ì œëª© ìƒì„±
- âŒ ê°œì„  ì´ìœ ë‚˜ ë³€ê²½ ì‚¬í•­ ì„¤ëª…
- âŒ ì½”ë“œ ë¸”ë¡(```) ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹
- âŒ ê·¸ ì™¸ ì–´ë– í•œ ë¶€ê°€ ì„¤ëª…ì´ë‚˜ ì£¼ì„

**ë°˜ë“œì‹œ ì¶œë ¥:**
- âœ… HTML í˜•ì‹ì˜ ì´ë©”ì¼ **ë³¸ë¬¸ë§Œ** ì¶œë ¥
- âœ… <p>, <br>, <strong>, <ul>, <li> ë“± HTML íƒœê·¸ ì‚¬ìš©
- âœ… ì²« ì¤„ë¶€í„° ë°”ë¡œ "<p>ì•ˆë…•í•˜ì„¸ìš”..." ë¡œ ì‹œì‘

**ì¶œë ¥ ì˜ˆì‹œ:**
<p>ì•ˆë…•í•˜ì„¸ìš”, [íšŒì‚¬ëª…] [ë‹´ë‹¹ìëª…].<br>PortOne {{user_name}} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>
<p>ìµœê·¼ [ë‚´ìš©]...</p>
...

ì´ì œ ê°œì„ ëœ ì´ë©”ì¼ ë³¸ë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
"""
        
        # Gemini API í˜¸ì¶œ
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-2.5-pro')
        
        response = model.generate_content(
            prompt,
            generation_config={
                'temperature': 0.5,  # ë” ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì¶¤
                'max_output_tokens': 4096,
                'top_p': 0.9,
                'top_k': 40
            }
        )
        
        # Gemini ì‘ë‹µ ì•ˆì „ì„± ê²€ì¦
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 2:
                logger.warning("Gemini ì•ˆì „ í•„í„°ë¡œ ì¸í•œ ì‘ë‹µ ì°¨ë‹¨")
                raise Exception("ì½˜í…ì¸ ê°€ ì•ˆì „ ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
            elif hasattr(candidate, 'content') and candidate.content and candidate.content.parts:
                refined_content = candidate.content.parts[0].text.strip()
                logger.info(f"Gemini ì´ë©”ì¼ ê°œì„  ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(refined_content)} ë¬¸ì")
                return refined_content
            else:
                logger.warning("Gemini ì‘ë‹µì— ìœ íš¨í•œ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")
                raise Exception("ì‘ë‹µ ì½˜í…ì¸ ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ì‘ë‹µì´ ì—†ëŠ” ê²½ìš° í´ë°±
        logger.warning("Gemini ì‘ë‹µì´ ì—†ì–´ í´ë°± ì‘ë‹µ ìƒì„±")
        raise Exception("Gemini ì‘ë‹µ ì—†ìŒ")
        
    except Exception as e:
        logger.error(f"Gemini ì´ë©”ì¼ ê°œì„  ì˜¤ë¥˜: {str(e)}")
        return f"""ì œëª©: ê°œì„ ëœ ë©”ì¼ ë¬¸ì•ˆ - {refinement_request} ë°˜ì˜

ì•ˆë…•í•˜ì„¸ìš”!

ìš”ì²­í•´ì£¼ì‹  "{refinement_request}" ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ë©”ì¼ ë¬¸ì•ˆì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

PortOneì˜ One Payment InfraëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤:

â€¢ ê°œë°œ ë¦¬ì†ŒìŠ¤ 85% ì ˆì•½
â€¢ 2ì£¼ ë‚´ ë¹ ë¥¸ ë„ì…
â€¢ ë¬´ë£Œ ì „ë¬¸ ì»¨ì„¤íŒ…
â€¢ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ìœ¼ë¡œ ê²°ì œ ì„±ê³µë¥  í–¥ìƒ

15ë¶„ ê°„ë‹¨í•œ ë°ëª¨ë¥¼ í†µí•´ êµ¬ì²´ì ì¸ í˜œíƒì„ ë³´ì—¬ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.

ì–¸ì œ ì‹œê°„ì´ ë˜ì‹¤ì§€ìš”?

ê°ì‚¬í•©ë‹ˆë‹¤.
PortOne ì˜ì—…íŒ€

(ì£¼ì˜: Gemini API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ - {str(e)})"""

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
researcher = CompanyResearcher()
copywriter = EmailCopywriter()

@app.route('/api/research-company', methods=['POST'])
def research_company():
    """íšŒì‚¬ ì •ë³´ ì¡°ì‚¬ API"""
    try:
        data = request.json
        company_name = data.get('company_name')
        website = data.get('website')
        
        if not company_name:
            return jsonify({'error': 'íšŒì‚¬ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # Perplexityë¡œ íšŒì‚¬ ì •ë³´ ì¡°ì‚¬
        research_result = researcher.research_company(company_name, website)
        
        # íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥ (ë‰´ìŠ¤ ë¶„ì„ì—ì„œ ì¬ì‚¬ìš©)
        if research_result and research_result.get('success'):
            company_info = {
                'company_name': company_name,
                'industry': research_result.get('industry', ''),
                'business_description': research_result.get('business_description', ''),
                'company_size': research_result.get('company_size', ''),
                'special_notes': research_result.get('pain_points', ''),
                'website': website,
                'research_timestamp': datetime.now().isoformat()
            }
            save_company_info_cache(company_name, company_info)
        
        return jsonify(research_result)
        
    except Exception as e:
        return jsonify({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/api/generate-emails', methods=['POST'])
@login_required
def generate_emails():
    """ë©”ì¼ ë¬¸ì•ˆ ìƒì„± API (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        company_data = data.get('company_data', {})
        research_data = data.get('research_data', {})
        industry = data.get('industry')
        
        # ì—…ê³„ íŠ¸ë Œë“œ ì¡°ì‚¬ (ì„ íƒì‚¬í•­)
        industry_trends = None
        if industry:
            industry_trends = researcher.get_industry_trends(industry)
        
        # Geminië¡œ ë©”ì¼ ë¬¸ì•ˆ ìƒì„±
        if research_data:
            research_data['industry_trends'] = industry_trends
        else:
            research_data = {'industry_trends': industry_trends}
            
        email_result = generate_email_with_gemini(company_data, research_data)
        
        return jsonify({
            'email_result': email_result,
            'industry_trends': industry_trends,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': f'ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}'}), 500

def process_single_company(company, index, user_template=None, user_input_mode='template', user_info=None):
    """
    ë‹¨ì¼ íšŒì‚¬ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ ì‹¤í–‰ìš©) - SSR ìµœì í™” ë²„ì „
    
    ë‰´ìŠ¤ í›„í‚¹ + SSR ì ìš© (4ê°œ ìƒì„± â†’ ìµœì  1ê°œ ì¶”ì²œ) ë˜ëŠ” ì‚¬ìš©ì ë¬¸ì•ˆ/ìš”ì²­ì‚¬í•­ í™œìš©
    
    Args:
        user_info: ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ (name, email, company_nickname, phone)
    """
    try:
        company_name = company.get('íšŒì‚¬ëª…', '')
        
        # CSVì—ì„œ "ê´€ë ¨ë‰´ìŠ¤" ì—´ í™•ì¸
        news_url = company.get('ê´€ë ¨ë‰´ìŠ¤', '')
        news_content = None
        
        # ë‰´ìŠ¤ URLì´ ìˆìœ¼ë©´ ìŠ¤í¬ë˜í•‘
        if news_url and news_url.strip():
            logger.info(f"{company_name}: ê´€ë ¨ë‰´ìŠ¤ ë°œê²¬ - {news_url}")
            news_content = scrape_news_article(news_url.strip())
            if news_content:
                logger.info(f"{company_name}: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ - {news_content.get('title', '')}")
            else:
                logger.warning(f"{company_name}: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")
        
        # 1. íšŒì‚¬ ì •ë³´ ì¡°ì‚¬ (CSV ì¶”ê°€ ì •ë³´ í™œìš©)
        additional_info = {
            'ì‚¬ì—…ìë²ˆí˜¸': company.get('ì‚¬ì—…ìë²ˆí˜¸', ''),
            'ì—…ì¢…': company.get('ì—…ì¢…', ''),
            'ì„¸ì¼ì¦ˆí¬ì¸íŠ¸': company.get('ì„¸ì¼ì¦ˆí¬ì¸íŠ¸', ''),
            'ê·œëª¨': company.get('ê·œëª¨', ''),
            'ëŒ€í‘œìëª…': company.get('ëŒ€í‘œìëª…', ''),
            'ì´ë©”ì¼': company.get('ì´ë©”ì¼', '')
        }
        
        research_result = researcher.research_company(
            company_name, 
            company.get('í™ˆí˜ì´ì§€ë§í¬', ''),
            additional_info
        )
        
        # 2. ë©”ì¼ ë¬¸ì•ˆ ìƒì„± (Gemini ì‚¬ìš©)
        if research_result['success']:
            # ë‰´ìŠ¤ ë‚´ìš©ì„ research_resultì— ì¶”ê°€
            if news_content:
                news_title = news_content.get('title', '')
                news_text = news_content.get('content', '')
                logger.info(f"{company_name}: ê´€ë ¨ë‰´ìŠ¤ ë‚´ìš©ì„ researchì— ì¶”ê°€")
                research_result['company_info'] += f"\n\n## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ (CSV ì œê³µ)\n**ì œëª©:** {news_title}\n**ë‚´ìš©:** {news_text[:1000]}"
            
            # 2-1. ê´€ë ¨ ì‚¬ë¡€ ì„ íƒ (ì œì•ˆì„œ ê¸°ë°˜ ì‹¤ì œ ì‚¬ë¡€)
            relevant_case_keys = select_relevant_cases(
                company, 
                research_result.get('company_info', ''),
                max_cases=2
            )
            
            logger.info(f"{company_name} - ì„ íƒëœ ì‚¬ë¡€: {relevant_case_keys}")
            
            # ì‚¬ë¡€ ì •ë³´ í¬ë§·íŒ…
            case_examples = ""
            for case_key in relevant_case_keys:
                case_examples += format_case_for_email(case_key)
            
            # 2-2. Gemini APIë¥¼ ì‚¬ìš©í•œ ë©”ì¼ ìƒì„± (ë‰´ìŠ¤ ë‚´ìš©, ì‚¬ë¡€ ì •ë³´, ì‚¬ìš©ì ë¬¸ì•ˆ/ìš”ì²­ì‚¬í•­ í¬í•¨)
            email_result = generate_email_with_gemini_and_cases(
                company, research_result, case_examples, user_template=user_template, news_content=news_content, user_input_mode=user_input_mode, user_info=user_info
            )
            
            # 2-3. SSRë¡œ 4ê°œ ì´ë©”ì¼ í‰ê°€ ë° ìˆœìœ„ ë§¤ê¸°ê¸°
            if email_result.get('success') and email_result.get('variations'):
                try:
                    # 4ê°œ ì´ë©”ì¼ì„ SSRë¡œ í‰ê°€
                    all_emails = []
                    for key, variation in email_result['variations'].items():
                        all_emails.append({
                            'type': key,
                            'product': variation.get('product', 'PortOne'),
                            'subject': variation.get('subject', ''),
                            'body': variation.get('body', ''),
                            'cta': variation.get('cta', ''),
                            'tone': variation.get('tone', '')
                        })
                    
                    # SSR ìˆœìœ„ ë§¤ê¸°ê¸°
                    ranked_emails = rank_emails(all_emails, company)
                    
                    logger.info(f"{company.get('íšŒì‚¬ëª…')} SSR ì ìˆ˜: " + 
                              ", ".join([f"{e['type']}: {e.get('ssr_score', 0):.2f}" 
                                       for e in ranked_emails]))
                    
                    # ìµœê³  ì ìˆ˜ ì´ë©”ì¼
                    top_email = ranked_emails[0]
                    
                    # ê²°ê³¼ì— SSR ì •ë³´ ì¶”ê°€
                    email_result['recommended_email'] = top_email
                    email_result['all_ranked_emails'] = ranked_emails
                    email_result['ssr_enabled'] = True
                    
                except Exception as ssr_error:
                    logger.warning(f"SSR í‰ê°€ ì‹¤íŒ¨: {ssr_error}, ê¸°ë³¸ ìˆœì„œ ì‚¬ìš©")
                    email_result['ssr_enabled'] = False
            
            return {
                'company': company,
                'research': research_result,
                'emails': email_result,
                'selected_cases': relevant_case_keys,
                'index': index
            }
        else:
            return {
                'company': company,
                'error': research_result.get('error', 'ì¡°ì‚¬ ì‹¤íŒ¨'),
                'index': index
            }
            
    except Exception as e:
        logger.error(f"íšŒì‚¬ ì²˜ë¦¬ ì˜¤ë¥˜ ({company.get('íšŒì‚¬ëª…')}): {str(e)}")
        return {
            'company': company,
            'error': f'ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}',
            'index': index
        }

@app.route('/api/batch-process', methods=['POST'])
@login_required
def batch_process():
    """ì—¬ëŸ¬ íšŒì‚¬ ì¼ê´„ ì²˜ë¦¬ API - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        companies = data.get('companies', [])
        max_workers = data.get('max_workers', 3)  # ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (ê¸°ë³¸ 3ê°œë¡œ ê°ì†Œ)
        user_template = data.get('user_template', None)  # ì‚¬ìš©ì ë¬¸ì•ˆ ë˜ëŠ” ìš”ì²­ì‚¬í•­
        user_input_mode = data.get('user_input_mode', 'template')  # 'request' ë˜ëŠ” 'template'
        
        # ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ (ë³‘ë ¬ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)
        user_info = {
            'name': current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸",
            'email': current_user.email if current_user and current_user.is_authenticated else "ocean@portone.io",
            'company_nickname': current_user.company_nickname if current_user and current_user.is_authenticated else "PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €",
            'phone': current_user.phone if current_user and current_user.is_authenticated else "010-2580-2580"
        }
        logger.info(f"ğŸ“§ ë°°ì¹˜ ì²˜ë¦¬ ìš”ì²­ì: {user_info['name']} ({user_info['email']})")
        
        if not companies:
            return jsonify({'error': 'ì²˜ë¦¬í•  íšŒì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # âš ï¸ ëŒ€ëŸ‰ ì²˜ë¦¬ ì œí•œ: í•œ ë²ˆì— ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ
        MAX_BATCH_SIZE = 50
        if len(companies) > MAX_BATCH_SIZE:
            return jsonify({
                'error': f'í•œ ë²ˆì— ìµœëŒ€ {MAX_BATCH_SIZE}ê°œê¹Œì§€ë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. í˜„ì¬: {len(companies)}ê°œ',
                'suggestion': f'ë°ì´í„°ë¥¼ {MAX_BATCH_SIZE}ê°œì”© ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.'
            }), 400
        
        logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(companies)}ê°œ íšŒì‚¬, {max_workers}ê°œ ë™ì‹œ ì‘ì—…")
        if user_template:
            if user_input_mode == 'request':
                logger.info(f"ìš”ì²­ì‚¬í•­ ëª¨ë“œ: {len(user_template)}ì - ê¸°ë³¸ ìƒì„± + ìš”ì²­ì‚¬í•­ ë°˜ì˜")
            else:
                logger.info(f"ë¬¸ì•ˆ ëª¨ë“œ: {len(user_template)}ì - ë‰´ìŠ¤ í›„í‚¹ ì„œë¡  + ì‚¬ìš©ì ë³¸ë¬¸")
        else:
            logger.info("SSR ëª¨ë“œ: ë‰´ìŠ¤ í›„í‚¹ + 4ê°œ ìƒì„± + ì‚¬ë¡€ í¬í•¨ + AI ì¶”ì²œ")
        start_time = time.time()
        
        # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ê° íšŒì‚¬ì— ëŒ€í•´ ì²˜ë¦¬ ì‘ì—… ì œì¶œ (user_template, user_input_mode, user_info ì „ë‹¬)
            future_to_company = {
                executor.submit(process_single_company, company, i, user_template, user_input_mode, user_info): (company, i)
                for i, company in enumerate(companies)
            }
            
            results = []
            completed = 0
            total = len(companies)
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ ìˆ˜ì§‘
            for future in concurrent.futures.as_completed(future_to_company):
                company, index = future_to_company[future]
                try:
                    result = future.result()
                    results.append(result)
                    completed += 1
                    
                    logger.info(f"ì§„í–‰ë¥ : {completed}/{total} ({completed/total*100:.1f}%) - {company.get('íšŒì‚¬ëª…', 'Unknown')}")
                    
                except Exception as e:
                    logger.error(f"íšŒì‚¬ {company.get('íšŒì‚¬ëª…', 'Unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    results.append({
                        'company': company,
                        'error': f'ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}',
                        'index': index
                    })
                    completed += 1
        
        # ì¸ë±ìŠ¤ ìˆœì„œë¡œ ì •ë ¬
        results.sort(key=lambda x: x.get('index', 0))
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ, í‰ê·  {processing_time/len(companies):.2f}ì´ˆ/íšŒì‚¬")
        
        # ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥
        try:
            for result in results:
                if 'emails' in result and result['emails'].get('success'):
                    company = result.get('company', {})
                    company_name = company.get('íšŒì‚¬ëª…', 'Unknown')
                    company_email = company.get('ëŒ€í‘œì´ë©”ì¼', '')
                    
                    # ìƒì„±ëœ ê° ì´ë©”ì¼ íƒ€ì… ê¸°ë¡
                    variations = result['emails'].get('variations', {})
                    for email_type in variations.keys():
                        email_gen = EmailGeneration(
                            user_id=current_user.id,
                            company_name=company_name,
                            company_email=company_email,
                            email_type=email_type,
                            generation_mode='ssr' if not user_template else ('user_request' if user_input_mode == 'request' else 'user_template')
                        )
                        db.session.add(email_gen)
            
            db.session.commit()
            logger.info(f"ğŸ“Š {current_user.email}: {len(results)}ê°œ íšŒì‚¬, ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ìƒì„± ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
            # ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜
        
        return jsonify({
            'success': True,
            'results': results,
            'total_processed': len(results),
            'processing_time': round(processing_time, 2),
            'parallel_workers': max_workers,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ì¼ê´„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return jsonify({'error': f'ì¼ê´„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/api/refine-email', methods=['POST'])
@login_required
def refine_email():
    """ì´ë©”ì¼ ë¬¸ì•ˆ ê°œì„  (ë¡œê·¸ì¸ í•„ìš”)"""
    try:
        data = request.json
        current_email = data.get('current_email', '')
        refinement_request = data.get('refinement_request', '')
        
        if not current_email or not refinement_request:
            return jsonify({
                'success': False,
                'error': 'í˜„ì¬ ì´ë©”ì¼ ë‚´ìš©ê³¼ ê°œì„  ìš”ì²­ì‚¬í•­ì´ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # Gemini 2.5 Proë¡œ ì´ë©”ì¼ ê°œì„  ìš”ì²­
        refined_email = refine_email_with_gemini(current_email, refinement_request)
        
        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
        user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
        refined_email = refined_email.replace('{user_name}', user_name)
        refined_email = refined_email.replace('ì˜¤ì¤€í˜¸', user_name)
        refined_email = refined_email.replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
        
        return jsonify({
            'success': True,
            'refined_email': refined_email,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ì´ë©”ì¼ ê°œì„  ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/analyze-news', methods=['POST'])
def analyze_news():
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ë¥¼ ë¶„ì„í•˜ì—¬ í˜ì¸ í¬ì¸íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±"""
    try:
        data = request.json
        news_url = data.get('news_url', '')
        company_name = data.get('company_name', '')
        current_email = data.get('current_email', '')
        
        if not news_url:
            return jsonify({
                'success': False,
                'error': 'ë‰´ìŠ¤ ê¸°ì‚¬ URLì´ í•„ìš”í•©ë‹ˆë‹¤.'
            }), 400
        
        # URL ìœ íš¨ì„± ê²€ì‚¬
        if not is_valid_url(news_url):
            return jsonify({
                'success': False,
                'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤.'
            }), 400
        
        # ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš© ìŠ¤í¬ë˜í•‘
        logger.info(f"ë‰´ìŠ¤ ë¶„ì„ ìš”ì²­ - URL: {news_url}, íšŒì‚¬: {company_name}")
        article_content = scrape_news_article(news_url)
        
        if not article_content:
            logger.error(f"ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {news_url}")
            return jsonify({
                'success': False,
                'error': 'ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
            }), 400
        
        logger.info(f"ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì„±ê³µ - ì œëª©: {article_content.get('title', '')[:50]}..., ë³¸ë¬¸ ê¸¸ì´: {len(article_content.get('content', ''))}ì")
        
        # ê¸°ì‚¬ ë‚´ìš© ê´€ë ¨ì„± ê²€ì¦
        relevance_score = check_article_relevance(article_content, company_name)
        logger.info(f"ê¸°ì‚¬ ê´€ë ¨ì„± ì ìˆ˜: {relevance_score}/10")
        
        # íšŒì‚¬ ì •ë³´ ì¡°íšŒ (ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼ í™œìš©)
        company_info = get_existing_company_info(company_name)
        if company_info:
            logger.info(f"ê¸°ì¡´ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
        
        # ê¸°ì‚¬ ë‚´ìš© ê¸°ë°˜ í˜ì¸ í¬ì¸íŠ¸ ë¶„ì„ ë° ë©”ì¼ ìƒì„±
        analyzed_email = generate_email_from_news_analysis(
            article_content, 
            company_name, 
            current_email,
            news_url,
            company_info,
            relevance_score
        )
        
        return jsonify({
            'success': True,
            'analyzed_email': analyzed_email,
            'article_summary': article_content.get('summary', ''),
            'pain_points': article_content.get('pain_points', []),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def scrape_article_content(url):
    """
    ê°œë³„ ë¸”ë¡œê·¸ ê¸€ì˜ ìƒì„¸ ë‚´ìš© ìŠ¤í¬ë˜í•‘
    
    Args:
        url: ë¸”ë¡œê·¸ ê¸€ URL
    
    Returns:
        str: ê¸€ ë‚´ìš©
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # article íƒœê·¸ ì°¾ê¸°
        article = soup.find('article')
        if article:
            # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (HTML íƒœê·¸ ì œê±°)
            content = article.get_text(separator=' ', strip=True)
            return content[:5000]  # ìµœëŒ€ 5000ìë¡œ ì œí•œ
        
        return ''
    except Exception as e:
        logger.error(f"   ê¸€ ë‚´ìš© ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ({url}): {str(e)}")
        return ''

def scrape_portone_blog_category(category_url, category_name, max_pages=5):
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤í¬ë˜í•‘
    
    Args:
        category_url: ì¹´í…Œê³ ë¦¬ URL
        category_name: ì¹´í…Œê³ ë¦¬ëª… (OPI, Recon ë“±)
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
    
    Returns:
        list: ë¸”ë¡œê·¸ ê¸€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        
        logger.info(f"ğŸ“° [{category_name}] ìŠ¤í¬ë˜í•‘ ì‹œì‘: {category_url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        all_posts = []
        
        for page in range(1, max_pages + 1):
            # í˜ì´ì§€ URL êµ¬ì„±
            page_url = f"{category_url}&page={page}"
            logger.info(f"   í˜ì´ì§€ {page}/{max_pages} ìŠ¤í¬ë˜í•‘...")
            
            try:
                response = requests.get(page_url, headers=headers, timeout=15)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # h3 íƒœê·¸ë¡œ ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
                h3_tags = soup.find_all('h3', class_='group-hover:text-[#FC6B2D]')
                
                if not h3_tags:
                    logger.info(f"   í˜ì´ì§€ {page}ì— ë” ì´ìƒ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                for h3 in h3_tags:
                    try:
                        title = h3.get_text(strip=True)
                        
                        # ë§í¬ ì°¾ê¸° (h3ì˜ ë¶€ëª¨ë‚˜ í˜•ì œ ìš”ì†Œì—ì„œ)
                        link_elem = h3.find_parent('a') or h3.find('a')
                        if not link_elem:
                            # í˜•ì œ ìš”ì†Œì—ì„œ ë§í¬ ì°¾ê¸°
                            parent = h3.find_parent()
                            link_elem = parent.find('a') if parent else None
                        
                        if link_elem and link_elem.get('href'):
                            link = link_elem['href']
                            if not link.startswith('http'):
                                link = 'https://blog.portone.io' + link
                            
                            logger.info(f"      âœ… {title[:40]}...")
                            
                            # ìƒì„¸ ë‚´ìš© ìŠ¤í¬ë˜í•‘
                            content = scrape_article_content(link)
                            
                            # ìš”ì•½ì€ contentì˜ ì•ë¶€ë¶„
                            summary = content[:200] if content else ''
                            
                            all_posts.append({
                                'title': title,
                                'link': link,
                                'summary': summary,
                                'content': content,
                                'category': category_name
                            })
                            
                            # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€
                            import time
                            time.sleep(0.5)
                            
                    except Exception as e:
                        logger.error(f"      ê¸€ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                        continue
                
            except Exception as e:
                logger.error(f"   í˜ì´ì§€ {page} ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        logger.info(f"ğŸ“Š [{category_name}] ì´ {len(all_posts)}ê°œ ê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_posts
        
    except Exception as e:
        logger.error(f"[{category_name}] ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return []

def scrape_portone_blog_initial():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘
    - OPI (êµ­ë‚´ ê²°ì œ): 5í˜ì´ì§€
    - Recon (ë§¤ì¶œ ë§ˆê°): 1í˜ì´ì§€
    """
    try:
        from portone_blog_cache import save_blog_cache, extract_keywords_from_post
        
        logger.info("ğŸš€ í¬íŠ¸ì› ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹œì‘")
        
        all_posts = []
        
        # 1. OPI (êµ­ë‚´ ê²°ì œ) - 5í˜ì´ì§€
        opi_url = 'https://blog.portone.io/?filter=%EA%B5%AD%EB%82%B4%20%EA%B2%B0%EC%A0%9C'
        opi_posts = scrape_portone_blog_category(opi_url, 'OPI', max_pages=5)
        all_posts.extend(opi_posts)
        
        # 2. Recon (ë§¤ì¶œ ë§ˆê°) - 1í˜ì´ì§€
        recon_url = 'https://blog.portone.io/?filter=%EB%A7%A4%EC%B6%9C%20%EB%A7%88%EA%B0%90'
        recon_posts = scrape_portone_blog_category(recon_url, 'Recon', max_pages=1)
        all_posts.extend(recon_posts)
        
        # 3. PS (í”Œë«í¼ ì •ì‚°) - 3í˜ì´ì§€
        ps_url = 'https://blog.portone.io/category/news/?filter=%ED%94%8C%EB%9E%AB%ED%8F%BC%20%EC%A0%95%EC%82%B0'
        ps_posts = scrape_portone_blog_category(ps_url, 'PS', max_pages=3)
        all_posts.extend(ps_posts)
        
        # í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ
        logger.info("ğŸ” ë¸”ë¡œê·¸ ê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        for post in all_posts:
            keywords, industry_tags = extract_keywords_from_post(post)
            post['keywords'] = keywords
            post['industry_tags'] = industry_tags
        
        # DBì— ì €ì¥
        if all_posts:
            save_blog_cache(all_posts, replace_all=True)
            logger.info(f"âœ… ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: ì´ {len(all_posts)}ê°œ ê¸€")
            return all_posts
        else:
            logger.warning("âš ï¸ ìŠ¤í¬ë˜í•‘ëœ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤")
            return []
        
    except Exception as e:
        logger.error(f"ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return []

def get_blog_content_for_email():
    """
    ë©”ì¼ ìƒì„±ì— ì‚¬ìš©í•  ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ìš°ì„ )
    
    Returns:
        str: í¬ë§·íŒ…ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸ 
    """
    from portone_blog_cache import load_blog_cache, format_blog_content_for_email, get_blog_cache_age
    
    # ìºì‹œì—ì„œ ë¡œë“œ ì‹œë„
    cached_posts = load_blog_cache()
    
    if cached_posts:
        cache_age = get_blog_cache_age()
        if cache_age and cache_age < 24:  # 24ì‹œê°„ ì´ë‚´ë©´ ìºì‹œ ì‚¬ìš©
            logger.info(f"ğŸ“š ë¸”ë¡œê·¸ ìºì‹œ ì‚¬ìš© (ì—…ë°ì´íŠ¸ëœ ì§€ {cache_age:.1f}ì‹œê°„)")
            return format_blog_content_for_email(cached_posts)
        else:
            logger.info("â° ë¸”ë¡œê·¸ ìºì‹œê°€ ì˜¤ë˜ë¨ (24ì‹œê°„ ì´ìƒ)")
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ìŠ¤í¬ë˜í•‘
    logger.info("ğŸ”„ ë¸”ë¡œê·¸ ìƒˆë¡œ ìŠ¤í¬ë˜í•‘...")
    new_posts = scrape_portone_blog(max_posts=5)
    
    if new_posts:
        return format_blog_content_for_email(new_posts)
    elif cached_posts:
        # ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì˜¤ë˜ëœ ìºì‹œë¼ë„ ì‚¬ìš©
        logger.info("âš ï¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, ì˜¤ë˜ëœ ìºì‹œ ì‚¬ìš©")
        return format_blog_content_for_email(cached_posts)
    else:
        return ""

@app.route('/api/chat-reply', methods=['POST'])
@login_required
def chat_reply():
    """
    ììœ ë¡œìš´ ì±—ë´‡ - ê³ ê° ë‹µë³€/ë°˜ë°•ì— ëŒ€í•œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„± (ë¡œê·¸ì¸ í•„ìš”)
    
    ì‚¬ìš© ì‚¬ë¡€:
    1. ê³ ê°ì˜ ë¶€ì •ì  ë‹µë³€ì— ëŒ€í•œ ë°˜ë°• ë©”ì¼
    2. ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ë©”ì¼
    3. ììœ ë¡œìš´ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±
    """
    try:
        data = request.json
        user_context = data.get('context', '')  # ê³ ê° ë‹µë³€/ìƒí™© ì„¤ëª…
        company_name = data.get('company_name', '')
        email_name = data.get('email_name', 'ë‹´ë‹¹ìë‹˜')
        
        if not user_context:
            return jsonify({'error': 'ì»¨í…ìŠ¤íŠ¸(ê³ ê° ë‹µë³€ ë˜ëŠ” ìƒí™©)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
        
        logger.info(f"ğŸ’¬ ì±—ë´‡ ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹œì‘ - {company_name}")
        logger.info(f"   ì…ë ¥ ì»¨í…ìŠ¤íŠ¸: {user_context[:100]}...")
        
        # í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ìš°ì„ )
        blog_content = get_blog_content_for_email()
        logger.info(f"   ğŸ“š ë¸”ë¡œê·¸ ì½˜í…ì¸ : {'ì‚¬ìš©' if blog_content else 'ì—†ìŒ'}")
        
        # ì„œë¹„ìŠ¤ ì†Œê°œì„œ(ì¼€ì´ìŠ¤ ìŠ¤í„°ë””) ë¡œë“œ - ê¸°ë³¸ ì¼€ì´ìŠ¤ ì‚¬ìš©
        from case_database import PORTONE_CASES, format_case_for_email
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ ì¼€ì´ìŠ¤ ì„ íƒ
        context_lower = user_context.lower()
        selected_case_ids = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¼€ì´ìŠ¤ ì„ íƒ
        if 'pg' in context_lower or 'ê²°ì œ' in context_lower or 'ë¹„ìš©' in context_lower:
            selected_case_ids.append('development_resource_saving')
        if 'ì‹œê°„' in context_lower or 'ë°”ë¹ ' in context_lower or 'ê°œë°œ' in context_lower:
            selected_case_ids.append('quick_setup')
        if 'ì‹¤íŒ¨' in context_lower or 'ì˜¤ë¥˜' in context_lower:
            selected_case_ids.append('payment_failure_recovery')
        
        # ìµœì†Œ 2ê°œ ì¼€ì´ìŠ¤ ë³´ì¥
        if len(selected_case_ids) == 0:
            selected_case_ids = ['development_resource_saving', 'payment_failure_recovery']
        elif len(selected_case_ids) == 1:
            selected_case_ids.append('multi_pg_management')
        
        # ìµœëŒ€ 3ê°œë¡œ ì œí•œ
        selected_case_ids = selected_case_ids[:3]
        
        # ê° ì¼€ì´ìŠ¤ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ê²°í•©
        case_details = "\n".join([format_case_for_email(case_id) for case_id in selected_case_ids])
        
        # ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ì™€ ë¸”ë¡œê·¸ ì½˜í…ì¸  ê²°í•©
        full_context = case_details + blog_content
        
        # Geminië¡œ ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
        result = generate_persuasive_reply(
            context=user_context,
            company_name=company_name,
            email_name=email_name,
            case_examples=full_context
        )
        
        # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
        if result.get('success') and result.get('email', {}).get('body'):
            user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
            result['email']['body'] = result['email']['body'].replace('ì˜¤ì¤€í˜¸', user_name)
            result['email']['body'] = result['email']['body'].replace('PortOne ì˜¤ì¤€í˜¸ ë§¤ë‹ˆì €', f'PortOne {user_name} ë§¤ë‹ˆì €')
        
        if result.get('success'):
            logger.info(f"âœ… {company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì™„ë£Œ")
            return jsonify(result)
        else:
            logger.error(f"âŒ {company_name} ì¬ì„¤ë“ ë©”ì¼ ìƒì„± ì‹¤íŒ¨: {result.get('error')}")
            return jsonify(result), 500
            
    except Exception as e:
        logger.error(f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'error': f'ì±—ë´‡ ì˜¤ë¥˜: {str(e)}',
            'success': False
        }), 500

def classify_user_intent(user_message):
    """
    ì‚¬ìš©ì ìš”ì²­ì˜ ì˜ë„ë¥¼ Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
    
    Returns:
        dict: {
            'intent': ìš”ì²­ ìœ í˜•,
            'parameters': ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°,
            'confidence': ì‹ ë¢°ë„
        }
    """
    try:
        logger.info(f"ğŸ” ì‚¬ìš©ì ìš”ì²­ ë¶„ì„: {user_message[:100]}...")
        
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì´ë©”ì¼ ì±—ë´‡ ìš”ì²­ì…ë‹ˆë‹¤. ìš”ì²­ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

**ì‚¬ìš©ì ìš”ì²­:**
{user_message}

**ê°€ëŠ¥í•œ ìš”ì²­ ìœ í˜•:**
1. **regenerate_with_sales_change**: íŒë§¤ ìƒí’ˆì„ ë³€ê²½í•´ì„œ ë©”ì¼ ì¬ìƒì„±
   - ì˜ˆ: "OPIë¡œ ë‹¤ì‹œ ì¨ì¤˜", "ì¬ë¬´ìë™í™” ì œí’ˆìœ¼ë¡œ ë°”ê¿”ì¤˜", "recon ìƒí’ˆìœ¼ë¡œ ë³€ê²½", "prismìœ¼ë¡œ ì†Œê°œí•´ì¤˜"
   - íŒŒë¼ë¯¸í„°: sales_point (opi, recon, prism, ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê° ì¤‘ í•˜ë‚˜)

2. **change_tone**: í†¤ì´ë‚˜ ìŠ¤íƒ€ì¼ ë³€ê²½
   - ì˜ˆ: "ë” ì¹œê·¼í•˜ê²Œ", "ì „ë¬¸ì ìœ¼ë¡œ", "ìºì£¼ì–¼í•˜ê²Œ", "ê³µì†í•˜ê²Œ"
   - íŒŒë¼ë¯¸í„°: tone (casual, professional, friendly, formal)

3. **refine_content**: íŠ¹ì • ë¶€ë¶„ ê°œì„ 
   - ì˜ˆ: "ì œëª©ì„ ë” ì„íŒ©íŠ¸ìˆê²Œ", "ë³¸ë¬¸ ì§§ê²Œ", "ìˆ˜ì¹˜ ê°•ì¡°í•´ì¤˜"
   - íŒŒë¼ë¯¸í„°: refinement_request (êµ¬ì²´ì  ìš”ì²­ì‚¬í•­)

4. **persuasive_reply**: ê³ ê° ë°˜ë°•/ë¶€ì • ë‹µë³€ì— ëŒ€í•œ ì¬ì„¤ë“
   - ì˜ˆ: "ë¹„ìš©ì´ ë¶€ë‹´ëœë‹¤ê³  í–ˆì–´", "ì§€ê¸ˆì€ ë°”ë¹ ì„œ ì–´ë µëŒ€"
   - íŒŒë¼ë¯¸í„°: customer_response (ê³ ê° ë‹µë³€)

5. **question**: ì¼ë°˜ ì§ˆë¬¸ì´ë‚˜ ì •ë³´ ìš”ì²­
   - ì˜ˆ: "í¬íŠ¸ì›ì´ ë­ì•¼?", "OPIê°€ ë­”ì§€ ì„¤ëª…í•´ì¤˜"

6. **other**: ê¸°íƒ€ ìš”ì²­

**íšŒì‚¬ëª… ì¶”ì¶œ:**
- íšŒì‚¬ëª…ì´ ì–¸ê¸‰ë˜ë©´ ì¶”ì¶œ (ì˜ˆ: "í† ìŠ¤", "ì¿ íŒ¡", "ë„¤ì´ë²„" ë“±)

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:**
{{
  "intent": "ìš”ì²­ ìœ í˜• (ìœ„ 6ê°€ì§€ ì¤‘ í•˜ë‚˜)",
  "parameters": {{
    "sales_point": "opi/recon/prism/ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°/null",
    "tone": "í†¤ ì„¤ëª… ë˜ëŠ” null",
    "refinement_request": "ê°œì„  ìš”ì²­ì‚¬í•­ ë˜ëŠ” null",
    "customer_response": "ê³ ê° ë‹µë³€ ë˜ëŠ” null",
    "company_name": "íšŒì‚¬ëª… ë˜ëŠ” null"
  }},
  "confidence": 0.0-1.0,
  "reasoning": "íŒë‹¨ ê·¼ê±° ê°„ë‹¨íˆ"
}}
"""

        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        
        if not response or not response.text:
            raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # JSON íŒŒì‹±
        import re
        response_text = response.text.strip()
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        elif '{' in response_text and '}' in response_text:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text
        
        intent_data = json.loads(json_str)
        
        logger.info(f"âœ… ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent_data.get('intent')} (ì‹ ë¢°ë„: {intent_data.get('confidence')})")
        logger.info(f"   ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°: {intent_data.get('parameters')}")
        
        return intent_data
        
    except Exception as e:
        logger.error(f"ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        # Fallback: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­
        return fallback_intent_classification(user_message)

def fallback_intent_classification(user_message):
    """
    Gemini ì‹¤íŒ¨ ì‹œ í´ë°±: ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
    """
    message_lower = user_message.lower()
    
    # sales_point ë³€ê²½ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['opi', 'one payment infra', 'ê²°ì œ ì¸í”„ë¼']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'opi', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['recon', 'ì¬ë¬´ìë™í™”', 'ì¬ë¬´ ìë™í™”', 'ì •ì‚°']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'recon', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['prism', 'í”„ë¦¬ì¦˜', 'ì˜¤í”ˆë§ˆì¼“', 'ë©€í‹°ì±„ë„', 'ë‹¤ì¤‘ì±„ë„', 'ì •ì‚° í†µí•©', 'ì¿ íŒ¡', '11ë²ˆê°€']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'prism', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['ì¸ì•±ìˆ˜ìˆ˜ë£Œ', 'ê²Œì„', 'd2c', 'ì›¹ìƒì ']):
        return {
            'intent': 'regenerate_with_sales_change',
            'parameters': {'sales_point': 'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°', 'company_name': None},
            'confidence': 0.7,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # í†¤ ë³€ê²½ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ì¹œê·¼', 'ìºì£¼ì–¼', 'ë¶€ë“œëŸ½', 'í¸í•˜ê²Œ']):
        return {
            'intent': 'change_tone',
            'parameters': {'tone': 'friendly', 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    if any(keyword in message_lower for keyword in ['ì „ë¬¸ì ', 'í”„ë¡œí˜ì…”ë„', 'ê³µì‹ì ']):
        return {
            'intent': 'change_tone',
            'parameters': {'tone': 'professional', 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ì¬ì„¤ë“ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ë¹„ìš©', 'ë¶€ë‹´', 'ë°”ë¹ ', 'ê±°ì ˆ', 'ì•ˆëœë‹¤', 'ì–´ë µë‹¤']):
        return {
            'intent': 'persuasive_reply',
            'parameters': {'customer_response': user_message, 'company_name': None},
            'confidence': 0.6,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ê°œì„  ìš”ì²­ í‚¤ì›Œë“œ
    if any(keyword in message_lower for keyword in ['ê°œì„ ', 'ìˆ˜ì •', 'ë°”ê¿”', 'ë‹¤ì‹œ', 'ë”', 'ì§§ê²Œ', 'ê¸¸ê²Œ']):
        return {
            'intent': 'refine_content',
            'parameters': {'refinement_request': user_message, 'company_name': None},
            'confidence': 0.5,
            'reasoning': 'Keyword matching (fallback)'
        }
    
    # ê¸°ë³¸: ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜
    return {
        'intent': 'question',
        'parameters': {'company_name': None},
        'confidence': 0.3,
        'reasoning': 'Default fallback'
    }

@app.route('/api/smart-chat', methods=['POST'])
@login_required
def smart_chat():
    """
    í†µí•© ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ - ë‹¤ì–‘í•œ ì‚¬ìš©ì ìš”ì²­ì„ ì´í•´í•˜ê³  ì²˜ë¦¬
    
    ìš”ì²­ ìœ í˜•:
    - ë©”ì¼ ì¬ìƒì„± (sales_point ë³€ê²½)
    - í†¤/ìŠ¤íƒ€ì¼ ë³€ê²½
    - ë¬¸ì•ˆ ê°œì„ 
    - ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
    - ì¼ë°˜ ì§ˆë¬¸
    """
    try:
        data = request.json
        user_message = data.get('message', '')
        session_data = data.get('session_data', {})  # ì´ì „ ìƒì„± ê²°ê³¼ ë“±
        
        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
        
        logger.info(f"ğŸ’¬ ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ ìš”ì²­: {user_message[:100]}...")
        
        # 1ë‹¨ê³„: ì‚¬ìš©ì ì˜ë„ íŒŒì•…
        intent_result = classify_user_intent(user_message)
        intent = intent_result.get('intent')
        params = intent_result.get('parameters', {})
        
        logger.info(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼: {intent} (ì‹ ë¢°ë„: {intent_result.get('confidence')})")
        
        # 2ë‹¨ê³„: ì˜ë„ì— ë”°ë¼ ì²˜ë¦¬
        if intent == 'regenerate_with_sales_change':
            # íŒë§¤ ìƒí’ˆ ë³€ê²½í•´ì„œ ë©”ì¼ ì¬ìƒì„±
            sales_point = params.get('sales_point')
            company_data = session_data.get('company_data', {})
            
            if not company_data:
                return jsonify({
                    'success': False,
                    'error': 'ì´ì „ ìƒì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë©”ì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.',
                    'intent': intent
                }), 400
            
            # sales_item í•„ë“œ ì—…ë°ì´íŠ¸ (CSVì˜ sales_item ì»¬ëŸ¼)
            company_data['sales_item'] = sales_point
            logger.info(f"ğŸ”„ íŒë§¤ ìƒí’ˆ ë³€ê²½: {sales_point} (company_data['sales_item'] ì—…ë°ì´íŠ¸)")
            
            # ë©”ì¼ ì¬ìƒì„±
            # ê¸°ì¡´ research_data ì¬ì‚¬ìš©
            research_data = session_data.get('research_data', {})
            
            result = generate_email_with_gemini(company_data, research_data)
            
            # ì œí’ˆëª… í‘œì‹œ ê°œì„ 
            product_name_map = {
                'opi': 'OPI (One Payment Infra)',
                'recon': 'Recon (ì¬ë¬´ìë™í™”)',
                'prism': 'Prism (ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©)',
                'ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°': 'ê²Œì„ ì›¹ìƒì  (ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°)'
            }
            product_display_name = product_name_map.get(sales_point, sales_point.upper())
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': f'âœ… {product_display_name} ì œí’ˆìœ¼ë¡œ ë©”ì¼ì„ ì¬ìƒì„±í–ˆìŠµë‹ˆë‹¤!',
                'result': result,
                'sales_point': sales_point
            })
        
        elif intent == 'change_tone':
            # í†¤ ë³€ê²½
            tone = params.get('tone', '')
            current_email = session_data.get('current_email', {})
            
            if not current_email:
                return jsonify({
                    'success': False,
                    'error': 'ë³€ê²½í•  ì´ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            # í†¤ ë³€ê²½ ìš”ì²­ ìƒì„±
            refinement_request = f"ì´ë©”ì¼ì˜ í†¤ì„ {tone}ìœ¼ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”. ë‚´ìš©ì€ ìœ ì§€í•˜ë˜ í†¤ë§Œ ì¡°ì •í•©ë‹ˆë‹¤."
            
            # refine_email_with_user_request ì‚¬ìš©
            company_data = session_data.get('company_data', {})
            refined = refine_email_with_user_request(
                original_subject=current_email.get('subject', ''),
                original_body=current_email.get('body', ''),
                user_request=refinement_request,
                company_data=company_data
            )
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': f'âœ… í†¤ì„ {tone}ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤!',
                'result': refined
            })
        
        elif intent == 'refine_content':
            # ë¬¸ì•ˆ ê°œì„ 
            refinement_request = params.get('refinement_request', user_message)
            current_email = session_data.get('current_email', {})
            
            if not current_email:
                return jsonify({
                    'success': False,
                    'error': 'ê°œì„ í•  ì´ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            company_data = session_data.get('company_data', {})
            refined = refine_email_with_user_request(
                original_subject=current_email.get('subject', ''),
                original_body=current_email.get('body', ''),
                user_request=refinement_request,
                company_data=company_data
            )
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': 'âœ… ì´ë©”ì¼ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤!',
                'result': refined
            })
        
        elif intent == 'persuasive_reply':
            # ì¬ì„¤ë“ ë©”ì¼ ìƒì„±
            company_name = params.get('company_name', session_data.get('company_data', {}).get('íšŒì‚¬ëª…', ''))
            customer_response = params.get('customer_response', user_message)
            email_name = session_data.get('company_data', {}).get('ëŒ€í‘œìëª…', 'ë‹´ë‹¹ìë‹˜')
            
            if not company_name:
                return jsonify({
                    'success': False,
                    'error': 'íšŒì‚¬ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'intent': intent
                }), 400
            
            # í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
            blog_content = get_blog_content_for_email()
            
            # ì¼€ì´ìŠ¤ ìŠ¤í„°ë””
            from case_database import format_case_for_email
            selected_case_ids = ['development_resource_saving', 'payment_failure_recovery']
            case_details = "\n".join([format_case_for_email(case_id) for case_id in selected_case_ids])
            full_context = case_details + blog_content
            
            result = generate_persuasive_reply(
                context=customer_response,
                company_name=company_name,
                email_name=email_name,
                case_examples=full_context
            )
            
            # ì‚¬ìš©ì ì´ë¦„ ë™ì  ì¹˜í™˜
            if result.get('success') and result.get('email', {}).get('body'):
                user_name = current_user.name if current_user and current_user.is_authenticated else "ì˜¤ì¤€í˜¸"
                result['email']['body'] = result['email']['body'].replace('ì˜¤ì¤€í˜¸', user_name)
            
            return jsonify({
                'success': result.get('success'),
                'intent': intent,
                'message': 'âœ… ì¬ì„¤ë“ ë©”ì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!' if result.get('success') else 'âŒ ìƒì„± ì‹¤íŒ¨',
                'result': result
            })
        
        elif intent == 'question':
            # ì¼ë°˜ ì§ˆë¬¸ - Geminië¡œ ë‹µë³€ ìƒì„±
            answer = answer_general_question(user_message)
            
            return jsonify({
                'success': True,
                'intent': intent,
                'message': answer,
                'result': {'answer': answer}
            })
        
        else:
            # ê¸°íƒ€ ìš”ì²­
            return jsonify({
                'success': False,
                'intent': intent,
                'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?',
                'confidence': intent_result.get('confidence')
            })
    
    except Exception as e:
        logger.error(f"ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'error': f'ì±—ë´‡ ì˜¤ë¥˜: {str(e)}',
            'success': False
        }), 500

def answer_general_question(question):
    """
    ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
    """
    try:
        prompt = f"""
ë‹¹ì‹ ì€ í¬íŠ¸ì›(PortOne)ì˜ ì œí’ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

**ì§ˆë¬¸:** {question}

**í¬íŠ¸ì› ì œí’ˆ ì •ë³´:**
- One Payment Infra (OPI): ê²°ì œ ì‹œìŠ¤í…œ í†µí•© ê´€ë¦¬, PGì‚¬ í†µí•©, 85% ë¦¬ì†ŒìŠ¤ ì ˆê°
- Recon (ì¬ë¬´ìë™í™”): ì»¤ë¨¸ìŠ¤ ì¬ë¬´ ë§ˆê° ìë™í™”, ì •ì‚° ê´€ë¦¬
- Prism (ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•©): ë„¤ì´ë²„/ì¿ íŒ¡/11ë²ˆê°€ ë“± ê° í”Œë«í¼ì˜ ì„œë¡œ ë‹¤ë¥¸ ì •ì‚° ë°ì´í„°ë¥¼ í•œ ëˆˆì— í†µí•©, ì¬ë¬´ ë§ˆê° ì‹œê°„ 90% ë‹¨ì¶•
- ì¸ì•±ìˆ˜ìˆ˜ë£Œì ˆê°: ê²Œì„ ì›¹ìƒì  êµ¬ì¶•, ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ(30%) íšŒí”¼

**ë‹µë³€ í˜•ì‹:**
- ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ (3-5ë¬¸ì¥)
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì˜ˆì‹œ í¬í•¨
- ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤

ë‹µë³€ë§Œ ì‘ì„±í•˜ì„¸ìš” (ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ì •ë³´ ì—†ì´):
"""
        
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text.strip()
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route('/api/scrape-blog-initial', methods=['POST'])
def scrape_blog_initial():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘
    - OPI (êµ­ë‚´ ê²°ì œ): 5í˜ì´ì§€
    - Recon (ë§¤ì¶œ ë§ˆê°): 1í˜ì´ì§€
    """
    try:
        logger.info("ğŸš€ ë¸”ë¡œê·¸ ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ìš”ì²­")
        
        blog_posts = scrape_portone_blog_initial()
        
        if blog_posts:
            return jsonify({
                'success': True,
                'message': f'ì´ˆê¸° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ',
                'posts_count': len(blog_posts),
                'categories': {
                    'OPI': len([p for p in blog_posts if p.get('category') == 'OPI']),
                    'Recon': len([p for p in blog_posts if p.get('category') == 'Recon'])
                },
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨'
            }), 500
            
    except Exception as e:
        logger.error(f"ì´ˆê¸° ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/update-blog', methods=['POST'])
def update_blog():
    """
    í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸
    
    OPIì™€ Recon ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì—…ë°ì´íŠ¸
    """
    try:
        logger.info("ğŸ”„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ìš”ì²­")
        
        blog_posts = scrape_portone_blog_initial()
        
        if blog_posts:
            return jsonify({
                'success': True,
                'message': f'ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸ ì™„ë£Œ',
                'posts_count': len(blog_posts),
                'categories': {
                    'OPI': len([p for p in blog_posts if p.get('category') == 'OPI']),
                    'Recon': len([p for p in blog_posts if p.get('category') == 'Recon'])
                },
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨'
            }), 500
            
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/blog-cache-status', methods=['GET'])
def blog_cache_status():
    """
    ë¸”ë¡œê·¸ ìºì‹œ ìƒíƒœ í™•ì¸
    """
    try:
        from portone_blog_cache import load_blog_cache, get_blog_cache_age
        
        cached_posts = load_blog_cache()
        cache_age = get_blog_cache_age()
        
        return jsonify({
            'success': True,
            'has_cache': cached_posts is not None,
            'posts_count': len(cached_posts) if cached_posts else 0,
            'cache_age_hours': cache_age if cache_age else None,
            'cache_status': 'fresh' if cache_age and cache_age < 24 else 'stale' if cache_age else 'no_cache',
            'posts': cached_posts[:3] if cached_posts else [],  # ìµœê·¼ 3ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ìºì‹œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'service': 'email-generation',
        'timestamp': datetime.now().isoformat()
    })

# ë‰´ìŠ¤ ë¶„ì„ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ë¨¼ì € ì •ì˜
def is_valid_url(url):
    """URL ìœ íš¨ì„± ê²€ì‚¬"""
    import re
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pattern.match(url) is not None

def extract_content_from_soup(soup, url):
    """BeautifulSoup ê°ì²´ì—ì„œ ì œëª©ê³¼ ë³¸ë¬¸ ì¶”ì¶œ"""
    # í•œêµ­ ì£¼ìš” ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë³„ íŠ¹í™” ì„ íƒì
    site_specific_selectors = {
        'naver.com': {
            'title': ['h2#title', 'h3.tts_head', '.media_end_head_headline'],
            'content': ['#dic_area', '.go_trans._article_content', '#articleBodyContents']
        },
        'daum.net': {
            'title': ['.tit_view', '.txt_tit'],
            'content': ['.article_view', '.news_view']
        },
        'chosun.com': {
            'title': ['h1', 'title', '.article-header h1', '.news_title_text', '[property="og:title"]'],
            'content': ['#fusion-app article', '.story-news__article', '[data-type="article-body"]', '.par', '.news_text', 'article p', '.article-body']
        },
        'joins.com': {
            'title': ['.headline', '.article_title'],
            'content': ['#article_body', '.article_content']
        },
        'donga.com': {
            'title': ['.title', '.news_title'],
            'content': ['.news_view', '.article_txt']
        }
    }
    
    # ì¼ë°˜ì ì¸ ì„ íƒì (ëª¨ë“  ì‚¬ì´íŠ¸ ëŒ€ì‘)
    general_selectors = {
        'title': [
            'h1', 'h2', '.title', '.headline', '.article-title', '.news-title',
            '.post-title', '.entry-title', '[data-cy="article-headline"]',
            '.tit_view', '.news_ttl', '.article_head', '.news_headline'
        ],
        'content': [
            'article', '.article-content', '.news-content', '.post-content',
            '.entry-content', '.content', '#content', '.article-body',
            '.news-body', '.post-body', '.story-body', '.article-text',
            '[data-module="ArticleContent"]', '.article_body', '.news_content',
            '.view_txt', '.news_view', '.article_txt', '.par', '#newsContent'
        ]
    }
    
    title = ''
    content = ''
    
    # ì‚¬ì´íŠ¸ë³„ íŠ¹í™” ì„ íƒì ì‹œë„
    domain = url.lower()
    site_selectors = None
    for site, selectors in site_specific_selectors.items():
        if site in domain:
            site_selectors = selectors
            break
    
    # ì œëª© ì¶”ì¶œ - ë¨¼ì € meta íƒœê·¸ì—ì„œ ì‹œë„
    try:
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            title = og_title.get('content').strip()
            logger.info(f"OG íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ ì„±ê³µ: {title[:50]}...")
    except Exception as e:
        logger.debug(f"OG íƒœê·¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    # meta íƒœê·¸ì—ì„œ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ì„ íƒì ì‹œë„
    if not title:
        title_selectors = site_selectors['title'] if site_selectors else general_selectors['title']
        for selector in title_selectors:
            try:
                title_elem = soup.select_one(selector)
                if title_elem:
                    title = title_elem.get_text().strip()
                    if len(title) > 5:  # ì˜ë¯¸ìˆëŠ” ì œëª©ì¸ì§€ í™•ì¸
                        logger.info(f"ì œëª© ì¶”ì¶œ ì„±ê³µ: {title[:50]}...")
                        break
            except Exception as e:
                logger.debug(f"ì œëª© ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                continue
    
    # ë³¸ë¬¸ ì¶”ì¶œ - ì¡°ì„ ì¼ë³´ JSON ë°ì´í„°ì—ì„œ ë¨¼ì € ì‹œë„
    if 'chosun.com' in url.lower():
        try:
            # script íƒœê·¸ì—ì„œ Fusion.globalContent ì°¾ê¸°
            scripts = soup.find_all('script', id='fusion-metadata')
            for script in scripts:
                script_text = script.string
                if script_text and 'Fusion.globalContent' in script_text:
                    # JSON íŒŒì‹±
                    import json
                    import re
                    
                    # globalContent JSON ì¶”ì¶œ
                    match = re.search(r'Fusion\.globalContent=({.*?});', script_text, re.DOTALL)
                    if match:
                        json_str = match.group(1)
                        data = json.loads(json_str)
                        
                        # content_elementsì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ
                        if 'content_elements' in data:
                            content_parts = []
                            for elem in data['content_elements']:
                                if elem.get('type') == 'text' and elem.get('content'):
                                    content_parts.append(elem['content'])
                            
                            if content_parts:
                                content = ' '.join(content_parts)
                                logger.info(f"ì¡°ì„ ì¼ë³´ JSONì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ: {len(content)}ì")
        except Exception as e:
            logger.debug(f"ì¡°ì„ ì¼ë³´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì„ íƒìë¡œ ì‹œë„
    if not content or len(content) < 300:
        content_selectors = site_selectors['content'] if site_selectors else general_selectors['content']
        for selector in content_selectors:
            try:
                content_elem = soup.select_one(selector)
                if content_elem:
                    # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±° (ë” í¬ê´„ì )
                    unwanted_selectors = [
                        'script', 'style', 'nav', 'header', 'footer', 'aside',
                        '.ad', '.advertisement', '.social-share', '.related-articles',
                        '.comment', '.reply', '.share', '.tag', '.category',
                        '.author', '.date', '.source', '.copyright', '.ad_area',
                        '.related_news', '.more_news', '.sns_area', '.util_area'
                    ]
                    
                    for unwanted_selector in unwanted_selectors:
                        for unwanted in content_elem.select(unwanted_selector):
                            unwanted.decompose()
                    
                    content = content_elem.get_text().strip()
                    content = ' '.join(content.split())  # ê³µë°± ì •ë¦¬
                    
                    if len(content) > 300:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
                        logger.info(f"ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ: {len(content)}ì (ì„ íƒì: {selector})")
                        break
            except Exception as e:
                logger.debug(f"ë³¸ë¬¸ ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
                continue
    
    # ë³¸ë¬¸ì´ ì—¬ì „íˆ ì§§ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
    if len(content) < 300:
        logger.warning("ë³¸ë¬¸ì´ ì§§ì•„ì„œ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„")
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for unwanted_tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
            unwanted_tag.decompose()
        
        # ëª¨ë“  p íƒœê·¸ ë‚´ìš© ìˆ˜ì§‘
        paragraphs = soup.find_all('p')
        if paragraphs:
            content = ' '.join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 20])
        
        # ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸
        if len(content) < 300:
            content = soup.get_text()
            content = ' '.join(content.split())
    
    # ìµœì¢… ê²€ì¦
    if not title:
        # ë©”íƒ€ íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ ì‹œë„
        meta_title = soup.find('meta', property='og:title')
        if meta_title:
            title = meta_title.get('content', '').strip()
        else:
            title_tag = soup.find('title')
            if title_tag:
                title = title_tag.get_text().strip()
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê¸¸ì´ ì œí•œ
    content = content.replace('\n', ' ').replace('\t', ' ')
    content = ' '.join(content.split())  # ì¤‘ë³µ ê³µë°± ì œê±°
    
    logger.info(f"BeautifulSoup ìŠ¤í¬ë˜í•‘ ê²°ê³¼ - ì œëª©: {len(title)}ì, ë³¸ë¬¸: {len(content)}ì")
    
    return title, content

def scrape_news_article(url):
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš© ìŠ¤í¬ë˜í•‘ (Selenium í¬í•¨ ê°•í™”ëœ ë²„ì „)"""
    try:
        logger.info(f"ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {url}")
        
        # ë¨¼ì € ì¼ë°˜ requestsë¡œ ì‹œë„
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ ì‹œë„
        title, content = extract_content_from_soup(soup, url)
        
        # ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ Selenium ì‹œë„ (ì¡°ì„ ì¼ë³´ ë“± JavaScript ì‚¬ì´íŠ¸)
        if (not title or len(content) < 200) and ('chosun.com' in url or 'joins.com' in url):
            logger.info("ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨, Seleniumìœ¼ë¡œ ì¬ì‹œë„")
            title, content = scrape_with_selenium(url)
        
        if not title and len(content) < 100:
            logger.error("ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: ì œëª©ê³¼ ë³¸ë¬¸ ëª¨ë‘ ë¶€ì¡±")
            return None
            
        return {
            'title': title or 'ì œëª© ì—†ìŒ',
            'content': content[:3000],  # ìµœëŒ€ 3000ìë¡œ í™•ì¥
            'url': url,
            'scraped_length': len(content)
        }
        
    except requests.exceptions.RequestException as e:
        logger.error(f"HTTP ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return None

def scrape_with_selenium(url):
    """Seleniumì„ ì‚¬ìš©í•œ ë™ì  ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        import time
        
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        time.sleep(3)
        
        # ì¡°ì„ ì¼ë³´ íŠ¹í™” ì„ íƒì
        if 'chosun.com' in url:
            try:
                # ì œëª© ëŒ€ê¸° ë° ì¶”ì¶œ
                title_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1, .article-header h1, .news_title_text"))
                )
                title = title_element.text.strip()
                
                # ë³¸ë¬¸ ì¶”ì¶œ
                content_selectors = [
                    ".story-news__article",
                    ".article-body", 
                    ".news-article-memo",
                    "[data-type='article-body']",
                    ".par"
                ]
                
                content = ""
                for selector in content_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            content = " ".join([elem.text.strip() for elem in elements])
                            if len(content) > 200:
                                break
                    except:
                        continue
                
                # ì—¬ì „íˆ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ ëª¨ë“  p íƒœê·¸ ìˆ˜ì§‘
                if len(content) < 200:
                    p_elements = driver.find_elements(By.TAG_NAME, "p")
                    content = " ".join([p.text.strip() for p in p_elements if len(p.text.strip()) > 20])
                
            except Exception as e:
                logger.warning(f"Selenium ì¡°ì„ ì¼ë³´ íŠ¹í™” ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                # ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ í´ë°±
                title = driver.find_element(By.TAG_NAME, "h1").text.strip() if driver.find_elements(By.TAG_NAME, "h1") else ""
                content = driver.find_element(By.TAG_NAME, "body").text.strip()
        
        driver.quit()
        
        logger.info(f"Selenium ìŠ¤í¬ë˜í•‘ ì„±ê³µ - ì œëª©: {len(title)}ì, ë³¸ë¬¸: {len(content)}ì")
        return title, content
        
    except ImportError:
        logger.warning("Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install selenium ì‹¤í–‰ í•„ìš”")
        return "", ""
    except Exception as e:
        logger.error(f"Selenium ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
        return "", ""

def check_article_relevance(article_content, company_name):
    """ê¸°ì‚¬ ë‚´ìš©ê³¼ PortOne ì†”ë£¨ì…˜ì˜ ê´€ë ¨ì„± ê²€ì¦"""
    try:
        title = article_content.get('title', '')
        content = article_content.get('content', '')
        
        # PortOne ê´€ë ¨ í‚¤ì›Œë“œë“¤
        portone_keywords = [
            'ê²°ì œ', 'í˜ì´ë¨¼íŠ¸', 'í•€í…Œí¬', 'ì´ì»¤ë¨¸ìŠ¤', 'ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸ì‡¼í•‘', 
            'ì •ì‚°', 'ìˆ˜ìˆ˜ë£Œ', 'ë§¤ì¶œ', 'ìˆ˜ìµ', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ìŠ¤íƒ€íŠ¸ì—…', 'ê¸°ì—…',
            'ë””ì§€í„¸', 'í”Œë«í¼', 'ì„œë¹„ìŠ¤', 'ì‹œìŠ¤í…œ', 'ì¸í”„ë¼', 'ì†”ë£¨ì…˜',
            'ê¸€ë¡œë²Œ', 'í•´ì™¸ì§„ì¶œ', 'í™•ì¥', 'ì„±ì¥', 'íˆ¬ì', 'ìê¸ˆì¡°ë‹¬'
        ]
        
        # ê´€ë ¨ì„± ì—†ëŠ” í‚¤ì›Œë“œë“¤ (ê°ì  ìš”ì†Œ)
        irrelevant_keywords = [
            'ì—°ì˜ˆ', 'ë°©ì†¡', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ìŒì•…', 'ê²Œì„ì½˜í…ì¸ ', 'ì›¹íˆ°',
            'ìŠ¤í¬ì¸ ', 'ì •ì¹˜', 'ì‚¬íšŒ', 'ë¬¸í™”', 'ì˜ˆìˆ ', 'ì—¬í–‰', 'ìŒì‹'
        ]
        
        text = (title + ' ' + content).lower()
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        relevant_count = sum(1 for keyword in portone_keywords if keyword in text)
        irrelevant_count = sum(1 for keyword in irrelevant_keywords if keyword in text)
        
        # ê¸°ë³¸ ì ìˆ˜ 5ì ì—ì„œ ì‹œì‘
        score = 5
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ê°€ì  (ìµœëŒ€ 4ì )
        score += min(4, relevant_count * 0.5)
        
        # ë¹„ê´€ë ¨ í‚¤ì›Œë“œ ê°ì  (ìµœëŒ€ -3ì )
        score -= min(3, irrelevant_count * 1)
        
        # íšŒì‚¬ëª…ì´ ê¸°ì‚¬ì— ì§ì ‘ ì–¸ê¸‰ë˜ë©´ ê°€ì 
        if company_name.lower() in text:
            score += 2
        
        # 0-10 ë²”ìœ„ë¡œ ì œí•œ
        score = max(0, min(10, score))
        
        return round(score, 1)
        
    except Exception as e:
        logger.error(f"ê¸°ì‚¬ ê´€ë ¨ì„± ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return 5.0  # ê¸°ë³¸ê°’

def get_existing_company_info(company_name):
    """ê¸°ì¡´ íšŒì‚¬ ì¡°ì‚¬ ê²°ê³¼ ì¡°íšŒ"""
    try:
        # ë©”ëª¨ë¦¬ì—ì„œ íšŒì‚¬ ì •ë³´ ê²€ìƒ‰ (ê°„ë‹¨í•œ ìºì‹œ êµ¬í˜„)
        if hasattr(get_existing_company_info, 'cache'):
            if company_name in get_existing_company_info.cache:
                logger.info(f"ìºì‹œì—ì„œ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
                return get_existing_company_info.cache[company_name]
        
        # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ (ìµœê·¼ ì¡°ì‚¬ ê²°ê³¼)
        import os
        import json
        from datetime import datetime, timedelta
        
        cache_dir = "/tmp/company_cache"
        if not os.path.exists(cache_dir):
            return None
            
        cache_file = os.path.join(cache_dir, f"{company_name.replace(' ', '_')}.json")
        
        if os.path.exists(cache_file):
            # íŒŒì¼ì´ 24ì‹œê°„ ì´ë‚´ì— ìƒì„±ëœ ê²½ìš°ë§Œ ì‚¬ìš©
            file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_time < timedelta(hours=24):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    company_info = json.load(f)
                    logger.info(f"íŒŒì¼ ìºì‹œì—ì„œ íšŒì‚¬ ì •ë³´ ë°œê²¬: {company_name}")
                    return company_info
        
        return None
        
    except Exception as e:
        logger.error(f"ê¸°ì¡´ íšŒì‚¬ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None

def save_company_info_cache(company_name, company_info):
    """íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥"""
    try:
        import os
        import json
        
        # ë©”ëª¨ë¦¬ ìºì‹œ
        if not hasattr(get_existing_company_info, 'cache'):
            get_existing_company_info.cache = {}
        get_existing_company_info.cache[company_name] = company_info
        
        # íŒŒì¼ ìºì‹œ
        cache_dir = "/tmp/company_cache"
        os.makedirs(cache_dir, exist_ok=True)
        
        cache_file = os.path.join(cache_dir, f"{company_name.replace(' ', '_')}.json")
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(company_info, f, ensure_ascii=False, indent=2)
            
        logger.info(f"íšŒì‚¬ ì •ë³´ ìºì‹œ ì €ì¥: {company_name}")
        
    except Exception as e:
        logger.error(f"íšŒì‚¬ ì •ë³´ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

def generate_email_from_news_analysis(article_content, company_name, current_email, news_url, company_info=None, relevance_score=5.0):
    """ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ì„ í†µí•œ í˜ì¸ í¬ì¸íŠ¸ ê¸°ë°˜ ë©”ì¼ ìƒì„±"""
    try:
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            logger.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return generate_fallback_news_email(article_content, company_name, current_email, news_url)
        
        # íšŒì‚¬ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        company_context = ""
        if company_info:
            company_context = f"""
**íšŒì‚¬ ì •ë³´ (ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼):**
- íšŒì‚¬ëª…: {company_info.get('company_name', company_name)}
- ì—…ì¢…: {company_info.get('industry', 'ì •ë³´ ì—†ìŒ')}
- ì£¼ìš” ì‚¬ì—…: {company_info.get('business_description', 'ì •ë³´ ì—†ìŒ')}
- ê·œëª¨: {company_info.get('company_size', 'ì •ë³´ ì—†ìŒ')}
- íŠ¹ì´ì‚¬í•­: {company_info.get('special_notes', 'ì •ë³´ ì—†ìŒ')}
"""
        
        # Perplexityë¥¼ í†µí•œ ì¶”ê°€ ë¶„ì„ (ì„ íƒì )
        additional_context = ""
        try:
            perplexity_analysis = analyze_news_with_perplexity(article_content, company_name)
            if perplexity_analysis:
                additional_context = f"\n\n**Perplexity ì¶”ê°€ ë¶„ì„:**\n{perplexity_analysis}"
        except Exception as e:
            logger.warning(f"Perplexity ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ê´€ë ¨ì„±ì— ë”°ë¥¸ ì ‘ê·¼ ë°©ì‹ ê²°ì •
        if relevance_score < 4.0:
            approach_instruction = """
**âš ï¸ ë‚®ì€ ê´€ë ¨ì„± ê¸°ì‚¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ê¸°ì‚¬ ë‚´ìš©ì„ ì–µì§€ë¡œ PortOne ì†”ë£¨ì…˜ê³¼ ì—°ê²°í•˜ì§€ ë§ˆì„¸ìš”
- ëŒ€ì‹  ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë Œë“œë‚˜ ì‹œì¥ ë³€í™” ê´€ì ì—ì„œ ì ‘ê·¼
- "ìµœê·¼ ì—…ê³„ ë™í–¥ì„ ë³´ë©´..." ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘
- PortOne ì†”ë£¨ì…˜ì€ ê°„ëµí•˜ê²Œ ì†Œê°œí•˜ê³  ìƒë‹´ ì œì•ˆì— ì§‘ì¤‘
"""
        else:
            approach_instruction = """
**âœ… ë†’ì€ ê´€ë ¨ì„± ê¸°ì‚¬ ì²˜ë¦¬ ì§€ì¹¨:**
- ê¸°ì‚¬ ë‚´ìš©ê³¼ PortOne ì†”ë£¨ì…˜ì˜ ì—°ê´€ì„±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
- ê¸°ì‚¬ì—ì„œ ë„ì¶œí•œ Pain Pointë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì†”ë£¨ì…˜ ì œì•ˆ
- ìµœì‹ ì„±ê³¼ ì‹œê¸‰ì„±ì„ ê°•ì¡°í•˜ì—¬ ì„¤ë“ë ¥ ê°•í™”
"""
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ {company_name}ì—ê²Œ ë³´ë‚¼ ê°œì¸í™”ëœ ì˜ì—… ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ê¸°ì‚¬ ê´€ë ¨ì„± ì ìˆ˜: {relevance_score}/10**
{approach_instruction}

**ë‰´ìŠ¤ ê¸°ì‚¬ ì •ë³´:**
- ì œëª©: {article_content.get('title', '')}
- URL: {news_url}
- ë‚´ìš©: {article_content.get('content', '')}
- ë¶„ì„ ì‹œì : 2025ë…„ 9ì›” 17ì¼
{additional_context}

**í˜„ì¬ ë©”ì¼ ë¬¸ì•ˆ (ì°¸ê³ ìš©):**
{current_email}
{company_context}

**ë©”ì¼ ì‘ì„± ì§€ì¹¨:**
1. **ê´€ë ¨ì„± ê¸°ë°˜ ì ‘ê·¼**: 
   - ê´€ë ¨ì„± ì ìˆ˜ê°€ 4ì  ë¯¸ë§Œì´ë©´ ì–µì§€ ì—°ê²° ê¸ˆì§€
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë Œë“œ ê´€ì ì—ì„œ ì ‘ê·¼
   - ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ êµ¬ì²´ì  ì—°ê´€ì„± ì œì‹œ

2. **íšŒì‚¬ ì •ë³´ í™œìš©**: 
   - ê¸°ì¡´ ì¡°ì‚¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œìš©
   - íšŒì‚¬ì˜ ì—…ì¢…, ê·œëª¨, íŠ¹ì„±ì— ë§ì¶˜ ê°œì¸í™”
   - ì¼ë°˜ì ì¸ í…œí”Œë¦¿ ë©”ì¼ ì§€ì–‘

3. **Pain Point ì¤‘ì‹¬ êµ¬ì„±**: 
   - ì‹¤ì œ ì—…ê³„ ì´ìŠˆì—ì„œ ë„ì¶œí•œ êµ¬ì²´ì  ì–´ë ¤ì›€
   - "í˜¹ì‹œ ì´ëŸ° ë¬¸ì œë¡œ ê³ ë¯¼í•˜ê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?" ì‹ ê³µê° ì ‘ê·¼
   - ì–µì§€ìŠ¤ëŸ¬ìš´ ë¬¸ì œ ì œê¸° ê¸ˆì§€

4. **PortOne ì†”ë£¨ì…˜ ì œì•ˆ**:
   - OPI: 85% ë¦¬ì†ŒìŠ¤ ì ˆê°, 2ì£¼ êµ¬ì¶•
   - ì¬ë¬´ìë™í™”: 90% ì—…ë¬´ ì‹œê°„ ë‹¨ì¶•
   - ê²Œì„ ì›¹ìƒì : ì¸ì•±ê²°ì œ ìˆ˜ìˆ˜ë£Œ í•´ê²°
   - ìŠ¤ë§ˆíŠ¸ë¹Œë§: ê¸€ë¡œë²Œ ê²°ì œ ì§€ì›

5. **ì´ë©”ì¼ êµ¬ì¡°**:
   - ê°œì¸í™”ëœ ì¸ì‚¬ (30ë‹¨ì–´)
   - Pain Point ì œê¸° (60ë‹¨ì–´) 
   - í•´ê²°ì±… ì œì‹œ (80ë‹¨ì–´)
   - ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸íŒ… ì œì•ˆ (30ë‹¨ì–´)

**ì£¼ì˜ì‚¬í•­:**
- ì´ 200-250ë‹¨ì–´ ë‚´ì™¸
- ì œëª© 7ë‹¨ì–´/41ì ì´ë‚´
- HTML íƒœê·¸ ì‚¬ìš© (<br>, <strong>, <em>)
- ê´€ë ¨ì„±ì´ ë‚®ìœ¼ë©´ ê¸°ì‚¬ ë‚´ìš© ìµœì†Œ ì–¸ê¸‰

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì œëª©: [ê°œì¸í™”ëœ ì œëª©]

[HTML í˜•ì‹ì˜ ë©”ì¼ ë³¸ë¬¸]
"""
        
        # Gemini API í˜¸ì¶œ
        import google.generativeai as genai
        genai.configure(api_key=gemini_api_key)
        
        model = genai.GenerativeModel('gemini-2.5-pro')
        response = model.generate_content(prompt)
        
        if response and response.text:
            return response.text
        else:
            logger.error("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return generate_fallback_news_email(article_content, company_name, current_email, news_url)
            
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ê¸°ë°˜ ë©”ì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return generate_fallback_news_email(article_content, company_name, current_email, news_url)

def analyze_news_with_perplexity(article_content, company_name):
    """Perplexity AIë¥¼ í†µí•œ ë‰´ìŠ¤ ë¶„ì„ (ìµœì‹ ì„± ê°€ì¤‘ì¹˜ ì ìš©)"""
    try:
        perplexity_api_key = os.getenv('PERPLEXITY_API_KEY')
        if not perplexity_api_key:
            logger.warning("Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ìµœì‹ ì„± ê°•ì¡° í”„ë¡¬í”„íŠ¸
        current_date = "2025ë…„ 9ì›”"
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ {company_name}ê³¼ ê°™ì€ ê¸°ì—…ë“¤ì´ í˜„ì¬ ì§ë©´í•  ìˆ˜ ìˆëŠ” í˜ì¸ í¬ì¸íŠ¸ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€ (ìµœì‹ ì„± ìš°ì„ ):**
- í˜„ì¬ ì‹œì : {current_date}
- ìµœì‹  ì—…ê³„ ë™í–¥ê³¼ íŠ¸ë Œë“œ ìš°ì„  ë¶„ì„
- ê¸´ê¸‰ì„±ê³¼ ì‹œê¸‰ì„±ì´ ë†’ì€ ì´ìŠˆ ì¤‘ì‹¬ ê²€í† 

**ë‰´ìŠ¤ ê¸°ì‚¬:**
ì œëª©: {article_content.get('title', '')}
ë‚´ìš©: {article_content.get('content', '')}

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
1. **ìµœì‹  ì—…ê³„ ë™í–¥ ë¶„ì„**: {current_date} ê¸°ì¤€ìœ¼ë¡œ ì´ ë‰´ìŠ¤ê°€ ì—…ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
2. **í˜„ì¬ ì§„í–‰í˜• í˜ì¸ í¬ì¸íŠ¸**: ì§€ê¸ˆ ì´ ìˆœê°„ ê¸°ì—…ë“¤ì´ ê²ªê³  ìˆëŠ” êµ¬ì²´ì ì¸ ì–´ë ¤ì›€
3. **ì‹œê¸‰í•œ ëŒ€ì‘ í•„ìš”ì„±**: ë¹ ë¥¸ ì‹œì¼ ë‚´ í•´ê²°í•´ì•¼ í•  ê³¼ì œë“¤
4. **ê²°ì œ/í•€í…Œí¬ ì—°ê´€ì„±**: ê²°ì œ ì‹œìŠ¤í…œ, ì¬ë¬´ ìë™í™”, ì»¤ë¨¸ìŠ¤ ê´€ë ¨ ì´ìŠˆ
5. **ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ**: í˜„ì¬ ìƒí™©ì—ì„œ ë¹ ë¥´ê²Œ í™œìš© ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ ë‹ˆì¦ˆ

**ì‘ë‹µ í˜•ì‹:**
- 300ë‹¨ì–´ ë‚´ì™¸
- ìµœì‹ ì„±ê³¼ ê¸´ê¸‰ì„± ì¤‘ì‹¬ì˜ ë¶„ì„
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- "í˜„ì¬", "ì§€ê¸ˆ", "ìµœê·¼", "2025ë…„ ë“¤ì–´" ë“±ì˜ ì‹œê°„ì  í‘œí˜„ í™œìš©
"""
        
        headers = {
            'Authorization': f'Bearer {perplexity_api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.1-sonar-large-128k-online',
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'max_tokens': 500,
            'temperature': 0.3
        }
        
        response = requests.post(
            'https://api.perplexity.ai/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        
        return None
        
    except Exception as e:
        logger.error(f"Perplexity ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return None

def generate_fallback_news_email(article_content, company_name, current_email, news_url):
    """API ì‹¤íŒ¨ ì‹œ í´ë°± ë‰´ìŠ¤ ê¸°ë°˜ ë©”ì¼ ìƒì„± (ìµœì‹ ì„± ê°•ì¡°)"""
    title = article_content.get('title', 'ìµœì‹  ì—…ê³„ ë™í–¥')
    current_date = "2025ë…„ 9ì›”"
    
    return f"""ì œëª©: {company_name} ìµœì‹  ì—…ê³„ ë™í–¥ ëŒ€ì‘ ë°©ì•ˆ

<p>ì•ˆë…•í•˜ì„¸ìš”, {company_name} ë‹´ë‹¹ìë‹˜.<br>
PortOne {user_name} ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.</p>

<p>ë°©ê¸ˆ ì „ "<strong>{title}</strong>" ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë´¤ëŠ”ë°,<br>
{current_date} ë“¤ì–´ ì´ëŸ° ì—…ê³„ ë³€í™”ê°€ ê°€ì†í™”ë˜ê³  ìˆì–´<br>
{company_name}ì—ì„œë„ í˜„ì¬ ì´ëŸ° ê³ ë¯¼ì´ ìˆìœ¼ì‹¤ ê²ƒ ê°™ì•„ ì—°ë½ë“œë¦½ë‹ˆë‹¤.</p>

<p><strong>ì§€ê¸ˆ ì´ ì‹œì ì—ì„œ</strong> ë§ì€ ê¸°ì—…ë“¤ì´ ê²ªê³  ìˆëŠ” í˜„ì‹¤ì ì¸ ì–´ë ¤ì›€ë“¤:<br>
â€¢ ê¸‰ë³€í•˜ëŠ” ì‹œì¥ í™˜ê²½ì— ë¹ ë¥´ê²Œ ëŒ€ì‘í•´ì•¼ í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬ì¶• ì••ë°•<br>
â€¢ í˜„ì¬ ì§„í–‰í˜•ì¸ ê²°ì œ ì¸í”„ë¼ í˜„ëŒ€í™” ë° íš¨ìœ¨ì„± ê°œì„  í•„ìš”ì„±<br>
â€¢ ë‹¹ì¥ í•„ìš”í•œ ìš´ì˜ ë¹„ìš© ì ˆê°ê³¼ ì„œë¹„ìŠ¤ í’ˆì§ˆ í–¥ìƒì˜ ë”œë ˆë§ˆ</p>

<p><strong>PortOneì˜ One Payment Infra</strong>ë¡œ ì´ëŸ° ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:<br>
âœ… <strong>85% ë¦¬ì†ŒìŠ¤ ì ˆê°</strong> - ê°œë°œ ë° ìš´ì˜ ë¶€ë‹´ ëŒ€í­ ê°ì†Œ<br>
âœ… <strong>2ì£¼ ë‚´ êµ¬ì¶• ì™„ë£Œ</strong> - ì—…ê³„ ë³€í™” ì†ë„ì— ë§ì¶˜ ì‹ ì†í•œ ëŒ€ì‘<br>
âœ… <strong>100ë§Œì› ìƒë‹¹ ë¬´ë£Œ ì»¨ì„¤íŒ…</strong> - í˜„ì¬ ìƒí™© ë§ì¶¤ ì „ë¬¸ê°€ ë¶„ì„</p>

<p><strong>ì´ë²ˆ ì£¼ ì¤‘</strong> í¸í•˜ì‹  ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´<br>
{company_name}ì´ í˜„ì¬ ì§ë©´í•œ ê³¼ì œì— í¬íŠ¸ì›ì´<br>
ì–´ë–»ê²Œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ì§€ êµ¬ì²´ì ì¸ ë°©ì•ˆì„ ì œì•ˆí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</p>

<p>ê°ì‚¬í•©ë‹ˆë‹¤.<br>
{user_name} ë“œë¦¼</p>

<p><small>ì°¸ê³  ë‰´ìŠ¤ (9ì›” 17ì¼ í™•ì¸): <a href="{news_url}">{title}</a></small></p>"""

# ===== ì›¹ ì¸í„°í˜ì´ìŠ¤ ë¼ìš°íŠ¸ =====

@app.route('/')
@login_required
def index():
    """ë£¨íŠ¸ ê²½ë¡œ - index.html ì œê³µ (ì±—ë´‡ ìŠ¤íƒ€ì¼ UI) - ë¡œê·¸ì¸ í•„ìš”"""
    # ìºì‹œ ë²„ìŠ¤íŒ…ì„ ìœ„í•œ ë²„ì „ ë²ˆí˜¸ (í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„)
    import time
    cache_version = str(int(time.time()))
    return render_template('index.html', user=current_user, cache_version=cache_version)

@app.route('/script.js')
def serve_script():
    """script.js ì •ì  íŒŒì¼ ì œê³µ"""
    return send_from_directory('.', 'script.js')

@app.route('/api/send-email', methods=['POST'])
@login_required
def send_email():
    """
    ì´ë©”ì¼ ë°œì†¡ API
    ë¡œê·¸ì¸ëœ ì‚¬ìš©ìì˜ ì´ë©”ì¼ì„ ë°œì‹ ìë¡œ ì‚¬ìš©í•˜ê³ ,
    ì‚¬ìš©ìì˜ ì„œëª…ì„ ë³¸ë¬¸ ëì— ìë™ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    try:
        data = request.json
        to_email = data.get('to_email')
        to_name = data.get('to_name')
        subject = data.get('subject')
        body = data.get('body')
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if not all([to_email, subject, body]):
            return jsonify({
                'success': False,
                'error': 'í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 400
        
        # í˜„ì¬ ë¡œê·¸ì¸ëœ ì‚¬ìš©ì ì •ë³´
        from_email = current_user.email
        from_name = current_user.name
        user_signature = current_user.email_signature or ''  # ì„œëª… ê°€ì ¸ì˜¤ê¸°
        
        logger.info(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ìš”ì²­: {from_email} -> {to_email}")
        logger.info(f"   ì œëª©: {subject}")
        logger.info(f"   ë°›ëŠ” ì‚¬ëŒ: {to_name}")
        
        # ë³¸ë¬¸ì— ì„œëª… ì¶”ê°€
        if user_signature:
            # HTML ì„œëª…ì„ ë³¸ë¬¸ ëì— ì¶”ê°€
            full_body = f"{body}<br><br>{user_signature}"
            logger.info("âœï¸  ì‚¬ìš©ì ì„œëª… ì¶”ê°€ë¨")
        else:
            full_body = body
            logger.warning("âš ï¸  ì‚¬ìš©ì ì„œëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # SendGrid APIë¥¼ ì‚¬ìš©í•œ ì´ë©”ì¼ ë°œì†¡ (Railway í™˜ê²½ í˜¸í™˜)
        sendgrid_api_key = current_user.get_sendgrid_api_key()
        
        if sendgrid_api_key:
            # SendGrid API ì‚¬ìš© (Railwayì—ì„œ SMTP í¬íŠ¸ê°€ ì°¨ë‹¨ë˜ë¯€ë¡œ HTTP API ì‚¬ìš©)
            try:
                import requests
                
                logger.info(f"ğŸ“§ SendGrid APIë¡œ ì´ë©”ì¼ ë°œì†¡ ì¤‘...")
                
                # SendGrid API ìš”ì²­
                response = requests.post(
                    'https://api.sendgrid.com/v3/mail/send',
                    headers={
                        'Authorization': f'Bearer {sendgrid_api_key}',
                        'Content-Type': 'application/json'
                    },
                    json={
                        'personalizations': [{
                            'to': [{'email': to_email, 'name': to_name}]
                        }],
                        'from': {
                            'email': from_email,
                            'name': from_name
                        },
                        'subject': subject,
                        'content': [{
                            'type': 'text/html',
                            'value': full_body
                        }]
                    },
                    timeout=30
                )
                
                if response.status_code == 202:
                    logger.info(f"âœ… SendGrid API ë°œì†¡ ì„±ê³µ: {to_email}")
                    return jsonify({
                        'success': True,
                        'message': 'ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤ (SendGrid API).',
                        'from': from_email,
                        'to': to_email,
                        'signature_included': bool(user_signature),
                        'method': 'SendGrid API'
                    })
                elif response.status_code == 401:
                    # API í‚¤ ì¸ì¦ ì‹¤íŒ¨
                    logger.error(f"âŒ SendGrid API ì¸ì¦ ì‹¤íŒ¨ (401): {response.text}")
                    return jsonify({
                        'success': False,
                        'error': 'âŒ SendGrid API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nì„¤ì • í˜ì´ì§€ì—ì„œ ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nğŸ’¡ SendGrid ëŒ€ì‹œë³´ë“œì—ì„œ API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•˜ì„¸ìš”.\n(Settings â†’ API Keys)'
                    }), 401
                elif response.status_code == 403:
                    # ë°œì‹ ì ì¸ì¦ ë˜ëŠ” API í‚¤ ê¶Œí•œ ë¬¸ì œ
                    logger.error(f"âŒ SendGrid API 403 ì˜¤ë¥˜: {response.text}")
                    error_text = response.text.lower()
                    
                    if 'verified sender identity' in error_text or 'sender identity' in error_text:
                        # ë°œì‹ ì ì¸ì¦ ë¬¸ì œ
                        return jsonify({
                            'success': False,
                            'error': f'''âŒ ë°œì‹ ì ì´ë©”ì¼ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤!

SendGridì—ì„œ "{from_email}" ì£¼ì†Œë¥¼ ì¸ì¦í•´ì£¼ì„¸ìš”.

ğŸ“ ì¸ì¦ ë°©ë²•:
1. https://app.sendgrid.com/ ë¡œê·¸ì¸
2. Settings â†’ Sender Authentication
3. "Verify a Single Sender" í´ë¦­
4. ë°œì‹ ì ì •ë³´ ì…ë ¥ (From Email: {from_email})
5. ì¸ì¦ ì´ë©”ì¼ í™•ì¸ í›„ Verify ë²„íŠ¼ í´ë¦­

âœ… ì¸ì¦ ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!'''
                        }), 403
                    else:
                        # ê¸°íƒ€ ê¶Œí•œ ë¬¸ì œ
                        return jsonify({
                            'success': False,
                            'error': 'âŒ SendGrid API í‚¤ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n\nAPI í‚¤ë¥¼ "Full Access" ê¶Œí•œìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.'
                        }), 403
                else:
                    logger.error(f"âŒ SendGrid API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                    return jsonify({
                        'success': False,
                        'error': f'SendGrid API ì˜¤ë¥˜ ({response.status_code}): {response.text}'
                    }), 500
                    
            except Exception as e:
                logger.error(f"âŒ SendGrid API ë°œì†¡ ì‹¤íŒ¨: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': f'SendGrid API ë°œì†¡ ì‹¤íŒ¨: {str(e)}'
                }), 500
        
        # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ë¡œ SMTP ì‹œë„ (ë¡œì»¬ í™˜ê²½ìš©)
        gmail_app_password = current_user.get_gmail_app_password()
        
        if gmail_app_password:
            # ì‹¤ì œ Gmail SMTP ë°œì†¡ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
            import smtplib
            from email.mime.text import MIMEText
            from email.mime.multipart import MIMEMultipart
            
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = f"{from_name} <{from_email}>"
            msg['To'] = to_email
            
            # HTML ë³¸ë¬¸ ì¶”ê°€
            html_part = MIMEText(full_body, 'html', 'utf-8')
            msg.attach(html_part)
            
            # Railway í™˜ê²½ì—ì„œ ì—¬ëŸ¬ SMTP ë°©ë²• ì‹œë„
            smtp_methods = [
                # ë°©ë²• 1: SMTP_SSL (í¬íŠ¸ 465)
                {'name': 'SMTP_SSL 465', 'method': 'ssl', 'port': 465},
                # ë°©ë²• 2: SMTP with STARTTLS (í¬íŠ¸ 587)
                {'name': 'SMTP STARTTLS 587', 'method': 'starttls', 'port': 587},
            ]
            
            last_error = None
            for method_config in smtp_methods:
                try:
                    logger.info(f"ğŸ”„ {method_config['name']} ì‹œë„ ì¤‘...")
                    
                    if method_config['method'] == 'ssl':
                        # SSL ë°©ì‹ (í¬íŠ¸ 465)
                        with smtplib.SMTP_SSL('smtp.gmail.com', method_config['port'], timeout=30) as server:
                            server.login(from_email, gmail_app_password)
                            server.send_message(msg)
                    else:
                        # STARTTLS ë°©ì‹ (í¬íŠ¸ 587)
                        with smtplib.SMTP('smtp.gmail.com', method_config['port'], timeout=30) as server:
                            server.ehlo()
                            server.starttls()
                            server.ehlo()
                            server.login(from_email, gmail_app_password)
                            server.send_message(msg)
                    
                    logger.info(f"âœ… ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ ({method_config['name']}): {to_email}")
                    
                    return jsonify({
                        'success': True,
                        'message': f'ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤ ({method_config["name"]}).',
                        'from': from_email,
                        'to': to_email,
                        'signature_included': bool(user_signature),
                        'smtp_method': method_config['name']
                    })
                    
                except Exception as e:
                    last_error = str(e)
                    logger.warning(f"âš ï¸  {method_config['name']} ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
            logger.error(f"âŒ ëª¨ë“  SMTP ë°©ë²• ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
            return jsonify({
                'success': False,
                'error': f'ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: SMTP í¬íŠ¸ ì°¨ë‹¨ë¨.\n\nğŸ’¡ Railway í™˜ê²½ì—ì„œëŠ” SendGrid APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.\nê´€ë¦¬ìì—ê²Œ SENDGRID_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì„ ìš”ì²­í•˜ì„¸ìš”.'
            }), 500
        else:
            # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜
            logger.warning(f"âš ï¸  {from_email} ì‚¬ìš©ìì˜ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤")
            logger.info(f"ğŸ“§ [ì‹œë®¬ë ˆì´ì…˜] ë°œì†¡: {to_email}")
            logger.info(f"   ë³¸ë¬¸ ê¸¸ì´: {len(full_body)} ë¬¸ì")
            
            return jsonify({
                'success': False,
                'error': 'Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.',
                'from': from_email,
                'to': to_email,
                'signature_included': bool(user_signature)
            }), 400
        
    except Exception as e:
        logger.error(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


@app.route('/api/user/settings', methods=['GET', 'POST'])
@login_required
def user_settings():
    """
    ì‚¬ìš©ì ì„¤ì • API
    GET: í˜„ì¬ ì„¤ì • ì¡°íšŒ
    POST: ì„¤ì • ì—…ë°ì´íŠ¸ (Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ë“±)
    """
    if request.method == 'GET':
        return jsonify({
            'success': True,
            'user': {
                'email': current_user.email,
                'name': current_user.name,
                'name_en': current_user.name_en,
                'phone': current_user.phone,
                'has_gmail_password': bool(current_user.gmail_app_password),
                'has_sendgrid_api_key': bool(current_user.sendgrid_api_key),
                'has_signature': bool(current_user.email_signature)
            }
        })
    
    # POST - ì„¤ì • ì—…ë°ì´íŠ¸
    try:
        data = request.json
        gmail_password = data.get('gmail_app_password')
        sendgrid_key = data.get('sendgrid_api_key')
        
        updated = False
        messages = []
        
        if gmail_password:
            # Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì—…ë°ì´íŠ¸
            current_user.set_gmail_app_password(gmail_password.replace(' ', ''))  # ê³µë°± ì œê±°
            updated = True
            messages.append('Gmail ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
            logger.info(f"âœ… {current_user.email} Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì„¤ì • ì™„ë£Œ")
        
        if sendgrid_key:
            # SendGrid API í‚¤ ì—…ë°ì´íŠ¸
            current_user.set_sendgrid_api_key(sendgrid_key.strip())
            updated = True
            messages.append('SendGrid API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
            logger.info(f"âœ… {current_user.email} SendGrid API í‚¤ ì„¤ì • ì™„ë£Œ")
        
        if updated:
            db.session.commit()
            return jsonify({
                'success': True,
                'message': ' '.join(messages)
            })
        
        return jsonify({
            'success': False,
            'error': 'ì—…ë°ì´íŠ¸í•  ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.'
        }), 400
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ì • ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        db.session.rollback()
        return jsonify({
            'success': False,
            'error': f'ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500


@app.route('/api-docs')
def api_docs():
    """API ë¬¸ì„œ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>PortOne ì´ë©”ì¼ ìƒì„± API - ë¬¸ì„œ</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                max-width: 800px;
                margin: 50px auto;
                padding: 20px;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
            }
            .container {
                background: white;
                border-radius: 16px;
                padding: 40px;
                box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            }
            h1 { color: #4f46e5; margin-bottom: 10px; }
            h2 { color: #7c3aed; font-size: 1.5em; margin-top: 30px; }
            .info { background: #f0f9ff; padding: 15px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #4f46e5; }
            .endpoint { background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; }
            .method { display: inline-block; padding: 4px 12px; border-radius: 4px; font-weight: bold; font-size: 0.9em; margin-right: 10px; }
            .post { background: #10b981; color: white; }
            .get { background: #3b82f6; color: white; }
            code { background: #f1f5f9; padding: 2px 6px; border-radius: 4px; font-family: 'Courier New', monospace; }
            .test-form { background: #f8f9fa; padding: 20px; border-radius: 8px; margin-top: 20px; }
            input, textarea { width: 100%; padding: 10px; margin: 10px 0; border: 1px solid #ddd; border-radius: 4px; font-size: 14px; }
            button { background: #4f46e5; color: white; padding: 12px 24px; border: none; border-radius: 8px; cursor: pointer; font-size: 16px; font-weight: bold; }
            button:hover { background: #4338ca; }
            .result { background: white; border: 2px solid #4f46e5; padding: 15px; border-radius: 8px; margin-top: 20px; white-space: pre-wrap; font-family: monospace; max-height: 400px; overflow-y: auto; }
            .status { display: inline-block; width: 10px; height: 10px; border-radius: 50%; margin-right: 5px; }
            .status.ok { background: #10b981; }
            .status.error { background: #ef4444; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš€ PortOne ì´ë©”ì¼ ìƒì„± API</h1>
            <p style="color: #64748b;">AI ê¸°ë°˜ ê°œì¸í™” ì´ë©”ì¼ ë¬¸ì•ˆ ìƒì„± ì„œë¹„ìŠ¤</p>
            
            <div class="info">
                <strong>âœ… ì„œë²„ ìƒíƒœ:</strong> <span class="status ok"></span> ì‹¤í–‰ ì¤‘ (í¬íŠ¸: 5001)
            </div>
            
            <h2>ğŸ“¡ ì‚¬ìš© ê°€ëŠ¥í•œ API ì—”ë“œí¬ì¸íŠ¸</h2>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/health</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/research-company</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">Perplexityë¡œ íšŒì‚¬ ì •ë³´ ì¡°ì‚¬</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/generate-email</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">Geminië¡œ ì´ë©”ì¼ ë¬¸ì•ˆ 4ê°œ ìƒì„±</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/refine-email</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ê¸°ì¡´ ì´ë©”ì¼ ë¬¸ì•ˆ ê°œì„  (URL í¬í•¨ ê°€ëŠ¥)</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span>
                <strong>/api/analyze-news</strong>
                <p style="margin: 10px 0 0 0; color: #64748b;">ë‰´ìŠ¤ ê¸°ì‚¬ URL ë¶„ì„</p>
            </div>
            
            <h2>ğŸ§ª API í…ŒìŠ¤íŠ¸</h2>
            
            <div class="test-form">
                <h3>ì´ë©”ì¼ ê°œì„  í…ŒìŠ¤íŠ¸</h3>
                <label><strong>í˜„ì¬ ì´ë©”ì¼ ë³¸ë¬¸:</strong></label>
                <textarea id="currentEmail" rows="4" placeholder="ê°œì„ í•  ì´ë©”ì¼ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...">ì•ˆë…•í•˜ì„¸ìš”, ABC íšŒì‚¬ ë‹´ë‹¹ìë‹˜.

PortOneì˜ ê²°ì œ ì†”ë£¨ì…˜ì„ ì†Œê°œë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.</textarea>
                
                <label><strong>ê°œì„  ìš”ì²­ (URL í¬í•¨ ê°€ëŠ¥):</strong></label>
                <input type="text" id="refinementRequest" placeholder="ì˜ˆ: ë” ì¹œê·¼í•˜ê²Œ ë§Œë“¤ì–´ì¤˜ ë˜ëŠ” ë‰´ìŠ¤ URL">
                
                <button onclick="testRefine()">ğŸš€ AIë¡œ ê°œì„ í•˜ê¸°</button>
                
                <div id="result" style="display: none;"></div>
            </div>
            
            <div style="margin-top: 30px; padding: 20px; background: #fef3c7; border-radius: 8px; border-left: 4px solid #f59e0b;">
                <strong>ğŸ’¡ ì°¸ê³ :</strong> Google Apps Script ì—°ë™ì€ ë³„ë„ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                <br>Fì—´ì´ "claude ê°œì¸í™” ë©”ì¼"ì¸ ê²½ìš° ì´ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
            </div>
        </div>
        
        <script>
            async function testRefine() {
                const currentEmail = document.getElementById('currentEmail').value;
                const refinementRequest = document.getElementById('refinementRequest').value;
                
                if (!refinementRequest) {
                    alert('ê°œì„  ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!');
                    return;
                }
                
                const resultDiv = document.getElementById('result');
                resultDiv.style.display = 'block';
                resultDiv.innerHTML = '<div style="text-align: center; padding: 20px;"><strong>â³ AIê°€ ì´ë©”ì¼ì„ ê°œì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤...</strong></div>';
                resultDiv.className = 'result';
                
                try {
                    const response = await fetch('/api/refine-email', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            session_id: 'test_' + Date.now(),
                            current_email: currentEmail,
                            refinement_request: refinementRequest
                        })
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        resultDiv.innerHTML = '<strong style="color: #10b981;">âœ… ê°œì„  ì™„ë£Œ!</strong><br><br>' + 
                                            '<div style="background: white; padding: 15px; border-radius: 8px;">' + 
                                            result.refined_email.replace(/\\n/g, '<br>') + '</div>';
                    } else {
                        resultDiv.innerHTML = '<strong style="color: #ef4444;">âŒ ì˜¤ë¥˜ ë°œìƒ</strong><br><br>' + result.error;
                    }
                } catch (error) {
                    resultDiv.innerHTML = '<strong style="color: #ef4444;">âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜</strong><br><br>' + error.message;
                }
            }
        </script>
    </body>
    </html>
    """

def scheduled_blog_update():
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    í•˜ë£¨ 2ë²ˆ (ì˜¤ì „ 9ì‹œ, ì˜¤í›„ 6ì‹œ) ì‹¤í–‰ë¨
    """
    try:
        logger.info("â° ìŠ¤ì¼€ì¤„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        from portone_blog_cache import get_blog_cache_age
        
        # ìºì‹œ ë‚˜ì´ í™•ì¸ (12ì‹œê°„ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ì—…ë°ì´íŠ¸)
        cache_age = get_blog_cache_age()
        
        if cache_age is None or cache_age >= 12:
            logger.info(f"ğŸ“° ë¸”ë¡œê·¸ ìºì‹œ ì—…ë°ì´íŠ¸ í•„ìš” (ë‚˜ì´: {cache_age}ì‹œê°„)")
            blog_posts = scrape_portone_blog_initial()
            
            if blog_posts:
                logger.info(f"âœ… ìë™ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(blog_posts)}ê°œ ê¸€")
            else:
                logger.warning("âš ï¸ ìë™ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
        else:
            logger.info(f"âœ… ë¸”ë¡œê·¸ ìºì‹œ ìµœì‹  ìƒíƒœ (ë‚˜ì´: {cache_age:.1f}ì‹œê°„)")
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ ë¸”ë¡œê·¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

# ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
scheduler = BackgroundScheduler()

# í•˜ë£¨ 2ë²ˆ ì‹¤í–‰: ì˜¤ì „ 9ì‹œ, ì˜¤í›„ 6ì‹œ
scheduler.add_job(
    func=scheduled_blog_update,
    trigger=CronTrigger(hour='9,18', minute='0'),
    id='blog_update_job',
    name='ë¸”ë¡œê·¸ ìë™ ì—…ë°ì´íŠ¸',
    replace_existing=True
)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
scheduler.start()
logger.info("â° ë¸”ë¡œê·¸ ìë™ ì—…ë°ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨ (ë§¤ì¼ 9ì‹œ, 18ì‹œ ì‹¤í–‰)")

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ
atexit.register(lambda: scheduler.shutdown())

if __name__ == '__main__':
    # API í‚¤ í™•ì¸
    if not os.getenv('PERPLEXITY_API_KEY'):
        logger.warning("PERPLEXITY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if not os.getenv('GEMINI_API_KEY'):
        logger.warning("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    logger.info("ğŸš€ ì´ë©”ì¼ ìƒì„± ì±—ë´‡ ì„œë²„ ì‹œì‘")
    logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
    logger.info("- POST /api/research-company: íšŒì‚¬ ì¡°ì‚¬")
    logger.info("- POST /api/generate-email: ì´ë©”ì¼ ìƒì„±")
    logger.info("- POST /api/batch-process: ì¼ê´„ ì²˜ë¦¬")
    logger.info("- POST /api/refine-email: ì´ë©”ì¼ ê°œì„ ")
    logger.info("- POST /api/chat-reply: ì¬ì„¤ë“ ë©”ì¼ ìƒì„± (ì±—ë´‡)")
    logger.info("- POST /api/smart-chat: í†µí•© ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ (NEW! ğŸ¤–)")
    logger.info("  â†’ íŒë§¤ ìƒí’ˆ ë³€ê²½, í†¤ ë³€ê²½, ë¬¸ì•ˆ ê°œì„ , ì¬ì„¤ë“, ì§ˆë¬¸ ë‹µë³€")
    logger.info("- POST /api/analyze-news: ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„")
    logger.info("- POST /api/test-scraping: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    logger.info("- POST /api/update-blog: ë¸”ë¡œê·¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸")
    logger.info("- GET /api/blog-cache-status: ë¸”ë¡œê·¸ ìºì‹œ ìƒíƒœ í™•ì¸")
    logger.info("- GET /api/health: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸")
    
    # Flask ì„œë²„ ì‹œì‘
    app.run(host='0.0.0.0', port=8000, debug=True, use_reloader=False)
