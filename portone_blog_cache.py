"""
í¬íŠ¸ì› ë¸”ë¡œê·¸ ì½˜í…ì¸  ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ (PostgreSQL)
SQLite ëŒ€ì‹  PostgreSQLì„ ì‚¬ìš©í•˜ì—¬ Railwayì—ì„œ ì˜êµ¬ ì €ì¥
"""

from datetime import datetime
import logging
import json
from collections import Counter
from flask import has_app_context
import requests

logger = logging.getLogger(__name__)

def verify_url_exists(url, timeout=3):
    """
    URLì´ ì‹¤ì œë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸ (HEAD ìš”ì²­)
    
    Args:
        url: í™•ì¸í•  URL
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    
    Returns:
        bool: URLì´ ì ‘ê·¼ ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
    """
    try:
        response = requests.head(url, timeout=timeout, allow_redirects=True)
        if response.status_code == 200:
            return True
        # 404ë‚˜ ë‹¤ë¥¸ ì—ëŸ¬
        logger.warning(f"âŒ URL ì ‘ê·¼ ì‹¤íŒ¨ ({response.status_code}): {url}")
        return False
    except Exception as e:
        logger.warning(f"âŒ URL ì ‘ê·¼ ì˜¤ë¥˜: {url} - {str(e)}")
        return False

# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ import (app context ì²´í¬ í¬í•¨)
def get_db():
    """Flask appì˜ db ê°ì²´ ê°€ì ¸ì˜¤ê¸° (app context í•„ìˆ˜)"""
    if not has_app_context():
        raise RuntimeError("This function requires Flask app context. Call within 'with app.app_context():'")
    from models import db
    return db

def get_blog_post_model():
    """BlogPost ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (app context í•„ìˆ˜)"""
    if not has_app_context():
        raise RuntimeError("This function requires Flask app context. Call within 'with app.app_context():'")
    from models import BlogPost
    return BlogPost

def get_metadata_model():
    """BlogCacheMetadata ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (app context í•„ìˆ˜)"""
    if not has_app_context():
        raise RuntimeError("This function requires Flask app context. Call within 'with app.app_context():'")
    from models import BlogCacheMetadata
    return BlogCacheMetadata

def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (SQLAlchemyê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)"""
    # Flask app contextì—ì„œ db.create_all()ì´ í˜¸ì¶œë˜ë¯€ë¡œ
    # ì—¬ê¸°ì„œëŠ” íŠ¹ë³„í•œ ì‘ì—… ë¶ˆí•„ìš”
    logger.info("âœ… ë¸”ë¡œê·¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (PostgreSQL)")
    return True

def save_blog_cache(blog_posts, replace_all=True):
    """
    ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    
    Args:
        blog_posts: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (dict)
        replace_all: Trueë©´ ê¸°ì¡´ í¬ìŠ¤íŠ¸ ì „ì²´ ì‚­ì œ í›„ ì €ì¥, Falseë©´ ì¶”ê°€/ì—…ë°ì´íŠ¸ë§Œ
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        BlogCacheMetadata = get_metadata_model()
        
        # replace_allì´ Trueë©´ ê¸°ì¡´ í¬ìŠ¤íŠ¸ ì‚­ì œ
        if replace_all:
            db.session.query(BlogPost).delete()
            logger.info("ğŸ—‘ï¸ ê¸°ì¡´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì „ì²´ ì‚­ì œ")
        
        # ìƒˆ í¬ìŠ¤íŠ¸ ì‚½ì… ë˜ëŠ” ì—…ë°ì´íŠ¸
        inserted_count = 0
        updated_count = 0
        
        for post in blog_posts:
            link = post.get('link', '')
            if not link:
                continue
            
            # ê¸°ì¡´ í¬ìŠ¤íŠ¸ í™•ì¸ (linkë¡œ ì¤‘ë³µ ì²´í¬)
            existing_post = db.session.query(BlogPost).filter_by(link=link).first()
            
            if existing_post:
                # ì—…ë°ì´íŠ¸
                existing_post.title = post.get('title', '')
                existing_post.summary = post.get('summary', '')
                existing_post.content = post.get('content', '')
                existing_post.category = post.get('category', '')
                existing_post.keywords = post.get('keywords', '')
                existing_post.industry_tags = post.get('industry_tags', '')
                existing_post.updated_at = datetime.utcnow()
                updated_count += 1
            else:
                # ìƒˆ í¬ìŠ¤íŠ¸ ì‚½ì…
                new_post = BlogPost(
                    title=post.get('title', ''),
                    link=link,
                    summary=post.get('summary', ''),
                    content=post.get('content', ''),
                    category=post.get('category', ''),
                    keywords=post.get('keywords', ''),
                    industry_tags=post.get('industry_tags', ''),
                    created_at=datetime.utcnow(),
                    updated_at=datetime.utcnow()
                )
                db.session.add(new_post)
                inserted_count += 1
        
        # ì»¤ë°‹
        db.session.commit()
        
        # ì „ì²´ ê°œìˆ˜ í™•ì¸
        total_count = db.session.query(BlogPost).count()
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        metadata = db.session.query(BlogCacheMetadata).first()
        if metadata:
            metadata.last_updated = datetime.utcnow()
            metadata.posts_count = total_count
        else:
            metadata = BlogCacheMetadata(
                last_updated=datetime.utcnow(),
                posts_count=total_count
            )
            db.session.add(metadata)
        
        db.session.commit()
        
        logger.info(f"âœ… ë¸”ë¡œê·¸ DB ì €ì¥ ì™„ë£Œ: ì‹ ê·œ {inserted_count}ê°œ, ì—…ë°ì´íŠ¸ {updated_count}ê°œ, ì´ {total_count}ê°œ (PostgreSQL)")
        return True
        
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ DB ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        try:
            db.session.rollback()
        except:
            pass
        return False

def load_blog_cache():
    """
    PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¡œë“œ
    
    Returns:
        list: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (dict)
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        # ìµœì‹  ê¸€ë¶€í„° ì¡°íšŒ
        posts_query = db.session.query(BlogPost).order_by(BlogPost.created_at.desc()).all()
        
        if not posts_query:
            logger.info("ğŸ“ ë¸”ë¡œê·¸ DBì— ë°ì´í„° ì—†ìŒ (PostgreSQL)")
            return None
        
        # dict í˜•íƒœë¡œ ë³€í™˜
        posts = []
        for post in posts_query:
            posts.append({
                'title': post.title,
                'link': post.link,
                'summary': post.summary,
                'content': post.content,
                'category': post.category,
                'keywords': post.keywords,
                'industry_tags': post.industry_tags,
                'created_at': post.created_at.isoformat() if post.created_at else None
            })
        
        logger.info(f"ğŸ“š ë¸”ë¡œê·¸ DB ë¡œë“œ ì™„ë£Œ: {len(posts)}ê°œ ê¸€ (PostgreSQL)")
        return posts
        
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ DB ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

def get_blog_cache_age():
    """
    ë°ì´í„°ë² ì´ìŠ¤ì˜ ì—…ë°ì´íŠ¸ ì‹œê°„ í™•ì¸
    
    Returns:
        float: ìºì‹œ ë‚˜ì´ (ì‹œê°„ ë‹¨ìœ„) ë˜ëŠ” None
    """
    try:
        db = get_db()
        BlogCacheMetadata = get_metadata_model()
        
        metadata = db.session.query(BlogCacheMetadata).first()
        
        if not metadata or not metadata.last_updated:
            return None
        
        age_hours = (datetime.utcnow() - metadata.last_updated).total_seconds() / 3600
        return age_hours
        
    except Exception as e:
        logger.error(f"ìºì‹œ ì‹œê°„ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return None

# ğŸ†• ì•Œë ¤ì§„ ê³ ê°ì‚¬ â†’ ì—…ì¢… ë§¤í•‘ (ë¸”ë¡œê·¸ ì‚¬ë¡€ì—ì„œ ì¶”ì¶œ)
KNOWN_CUSTOMER_INDUSTRIES = {
    # ê²Œì„
    'ë„¥ìŠ¨': 'ê²Œì„', 'ì—”ì”¨ì†Œí”„íŠ¸': 'ê²Œì„', 'nc': 'ê²Œì„', 'ë„·ë§ˆë¸”': 'ê²Œì„', 'í¬ë˜í”„í†¤': 'ê²Œì„',
    'ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ': 'ê²Œì„', 'ìŠ¤ë§ˆì¼ê²Œì´íŠ¸': 'ê²Œì„', 'í„ì–´ë¹„ìŠ¤': 'ê²Œì„', 'ì»´íˆ¬ìŠ¤': 'ê²Œì„',
    'ë°ë¸Œì‹œìŠ¤í„°ì¦ˆ': 'ê²Œì„', 'ì¿ í‚¤ëŸ°': 'ê²Œì„', 'ìŠˆí¼ì…€': 'ê²Œì„', 'ë¼ì´ì—‡': 'ê²Œì„',
    
    # ì´ì»¤ë¨¸ìŠ¤/ì‡¼í•‘
    'ë¬´ì‹ ì‚¬': 'íŒ¨ì…˜', '29cm': 'íŒ¨ì…˜', 'wì»¨ì…‰': 'íŒ¨ì…˜', 'ì§€ê·¸ì¬ê·¸': 'íŒ¨ì…˜', 'ì—ì´ë¸”ë¦¬': 'íŒ¨ì…˜',
    'ë¸Œëœë””': 'íŒ¨ì…˜', 'í•˜ì´ë²„': 'íŒ¨ì…˜', 'ì˜¤ëŠ˜ì˜ì§‘': 'ì´ì»¤ë¨¸ìŠ¤', 'ë§ˆì¼“ì»¬ë¦¬': 'í‘¸ë“œ', 'ì»¬ë¦¬': 'í‘¸ë“œ',
    'ì¿ íŒ¡': 'ì´ì»¤ë¨¸ìŠ¤', '11ë²ˆê°€': 'ì´ì»¤ë¨¸ìŠ¤', 'ssg': 'ì´ì»¤ë¨¸ìŠ¤', 'ë¡¯ë°ì˜¨': 'ì´ì»¤ë¨¸ìŠ¤',
    'í‹°ëª¬': 'ì´ì»¤ë¨¸ìŠ¤', 'ìœ„ë©”í”„': 'ì´ì»¤ë¨¸ìŠ¤', 'ì¸í„°íŒŒí¬': 'ì´ì»¤ë¨¸ìŠ¤',
    
    # ë·°í‹°
    'ì˜¬ë¦¬ë¸Œì˜': 'ë·°í‹°', 'ì•„ëª¨ë ˆí¼ì‹œí”½': 'ë·°í‹°', 'lgìƒí™œê±´ê°•': 'ë·°í‹°', 'ì´ë‹ˆìŠ¤í”„ë¦¬': 'ë·°í‹°',
    'ì—ë›°ë“œ': 'ë·°í‹°', 'í† ë‹ˆëª¨ë¦¬': 'ë·°í‹°', 'ë¯¸ìƒ¤': 'ë·°í‹°', 'ë”í˜ì´ìŠ¤ìƒµ': 'ë·°í‹°',
    'í™”í•´': 'ë·°í‹°', 'ê¸€ë¡œìš°í”½': 'ë·°í‹°',
    
    # ìë™ì°¨/ëª¨ë¹Œë¦¬í‹°
    'í˜„ëŒ€ìë™ì°¨': 'ìë™ì°¨', 'ê¸°ì•„': 'ìë™ì°¨', 'í˜„ëŒ€ì°¨': 'ìë™ì°¨', 'ì œë„¤ì‹œìŠ¤': 'ìë™ì°¨',
    'ì˜ì¹´': 'ìë™ì°¨', 'íƒ€ë‹¤': 'ìë™ì°¨', 'ì¹´ì¹´ì˜¤ëª¨ë¹Œë¦¬í‹°': 'ìë™ì°¨', 'í‹°ë§µëª¨ë¹Œë¦¬í‹°': 'ìë™ì°¨',
    
    # ì—¬í–‰
    'ì•¼ë†€ì': 'ì—¬í–‰', 'ì—¬ê¸°ì–´ë•Œ': 'ì—¬í–‰', 'ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½': 'ì—¬í–‰', 'í´ë£©': 'ì—¬í–‰',
    'ì¸í„°íŒŒí¬íˆ¬ì–´': 'ì—¬í–‰', 'í•˜ë‚˜íˆ¬ì–´': 'ì—¬í–‰', 'ëª¨ë‘íˆ¬ì–´': 'ì—¬í–‰', 'íŠ¸ë¦½ë‹·ì»´': 'ì—¬í–‰',
    'ì•„ê³ ë‹¤': 'ì—¬í–‰', 'ì—ì–´ë¹„ì•¤ë¹„': 'ì—¬í–‰', 'ìµìŠ¤í”¼ë””ì•„': 'ì—¬í–‰',
    
    # êµìœ¡
    'ë©”ê°€ìŠ¤í„°ë””': 'êµìœ¡', 'ëŒ€ì„±ë§ˆì´ë§¥': 'êµìœ¡', 'ì—ë“€ìœŒ': 'êµìœ¡', 'í´ë˜ìŠ¤101': 'êµìœ¡',
    'íƒˆì‰': 'êµìœ¡', 'í¬ëª½': 'êµìœ¡', 'íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤': 'êµìœ¡', 'ì¸í”„ëŸ°': 'êµìœ¡',
    'ë…¸ë§ˆë“œì½”ë”': 'êµìœ¡', 'ì½”ë“œì‡': 'êµìœ¡',
    
    # ê¸ˆìœµ
    'í† ìŠ¤': 'ê¸ˆìœµ', 'ì¹´ì¹´ì˜¤ë±…í¬': 'ê¸ˆìœµ', 'ì¼€ì´ë±…í¬': 'ê¸ˆìœµ', 'ë±…í¬ìƒëŸ¬ë“œ': 'ê¸ˆìœµ',
    'í•€ë‹¤': 'ê¸ˆìœµ', 'ë Œë”§': 'ê¸ˆìœµ', '8í¼ì„¼íŠ¸': 'ê¸ˆìœµ', 'í”¼í”Œí€ë“œ': 'ê¸ˆìœµ',
    
    # ë¯¸ë””ì–´/ì½˜í…ì¸ 
    'ì™“ì± ': 'ë¯¸ë””ì–´', 'ì›¨ì´ë¸Œ': 'ë¯¸ë””ì–´', 'í‹°ë¹™': 'ë¯¸ë””ì–´', 'ì‹œì¦Œ': 'ë¯¸ë””ì–´',
    'ë©œë¡ ': 'ë¯¸ë””ì–´', 'ì§€ë‹ˆë®¤ì§': 'ë¯¸ë””ì–´', 'í”Œë¡œ': 'ë¯¸ë””ì–´', 'ë°€ë¦¬ì˜ì„œì¬': 'ë¯¸ë””ì–´',
    'ë¦¬ë””ë¶ìŠ¤': 'ë¯¸ë””ì–´', 'ë¦¬ë””': 'ë¯¸ë””ì–´',
    
    # SaaS/B2B
    'í† ìŠ¤í˜ì´ë¨¼ì¸ ': 'SaaS', 'ì±„ë„í†¡': 'SaaS', 'ì„¼ë“œë²„ë“œ': 'SaaS', 'ìŠ¤í‹°ë¹„': 'SaaS',
    'ë…¸ì…˜': 'SaaS', 'ìŠ¬ë™': 'SaaS', 'ì”ë””': 'SaaS', 'í”Œë ‰ìŠ¤': 'SaaS', 'ì‹œí”„í‹°': 'SaaS',
    
    # ë¬¼ë¥˜/ë°°ë‹¬
    'ë°°ë‹¬ì˜ë¯¼ì¡±': 'í‘¸ë“œ', 'ìš”ê¸°ìš”': 'í‘¸ë“œ', 'ì¿ íŒ¡ì´ì¸ ': 'í‘¸ë“œ',
    'cjëŒ€í•œí†µìš´': 'ë¬¼ë¥˜', 'í•œì§„': 'ë¬¼ë¥˜', 'ë¡¯ë°íƒë°°': 'ë¬¼ë¥˜', 'ë¡œì  íƒë°°': 'ë¬¼ë¥˜',
    
    # í”Œë«í¼
    'ì¹´ì¹´ì˜¤': 'í”Œë«í¼', 'ë„¤ì´ë²„': 'í”Œë«í¼', 'ë¼ì¸': 'í”Œë«í¼', 'ë‹¹ê·¼ë§ˆì¼“': 'í”Œë«í¼',
    'ë²ˆê°œì¥í„°': 'ë¦¬ì…€', 'ì¤‘ê³ ë‚˜ë¼': 'ë¦¬ì…€', 'í¬ë¦¼': 'ë¦¬ì…€',
    
    # í—¬ìŠ¤ì¼€ì–´
    'êµ¿ë‹¥': 'í—¬ìŠ¤ì¼€ì–´', 'ë˜‘ë‹¥': 'í—¬ìŠ¤ì¼€ì–´', 'ë‹¥í„°ë‚˜ìš°': 'í—¬ìŠ¤ì¼€ì–´', 'íœ´ë ˆì´í¬ì§€í‹°ë¸Œ': 'í—¬ìŠ¤ì¼€ì–´',
    
    # ë¶€ë™ì‚°
    'ì§ë°©': 'ë¶€ë™ì‚°', 'ë‹¤ë°©': 'ë¶€ë™ì‚°', 'í˜¸ê°±ë…¸ë…¸': 'ë¶€ë™ì‚°', 'ì§‘í† ìŠ¤': 'ë¶€ë™ì‚°',
}


def extract_case_companies_from_blog(content, title=''):
    """
    ë¸”ë¡œê·¸ ë‚´ìš©ì—ì„œ ê³ ê°ì‚¬ë¡€ë¡œ ì–¸ê¸‰ëœ íšŒì‚¬ëª…ê³¼ ì—…ì¢…ì„ ì¶”ì¶œ
    
    Args:
        content: ë¸”ë¡œê·¸ ë³¸ë¬¸
        title: ë¸”ë¡œê·¸ ì œëª©
        
    Returns:
        list: [{'company': 'íšŒì‚¬ëª…', 'industry': 'ì—…ì¢…'}, ...]
    """
    found_companies = []
    text = (title + ' ' + content).lower()
    
    for company, industry in KNOWN_CUSTOMER_INDUSTRIES.items():
        if company.lower() in text:
            found_companies.append({
                'company': company,
                'industry': industry
            })
    
    return found_companies


def extract_keywords_from_post(post):
    """
    ë¸”ë¡œê·¸ ê¸€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê·œì¹™ ê¸°ë°˜ + ê³ ê°ì‚¬ë¡€ ë¶„ì„)
    
    Args:
        post: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ dict
    
    Returns:
        tuple: (keywords, industry_tags)
    """
    try:
        content = post.get('content', '')
        title = post.get('title', '')
        
        if not content or len(content) < 50:
            return '', ''
        
        # í‚¤ì›Œë“œ ì´ˆê¸°í™”
        keywords = []
        industry_tags = []
        
        # ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì°¾ê¸°
        text_lower = (title + ' ' + content[:2000]).lower()
        
        # ğŸ†• ê³ ê°ì‚¬ë¡€ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ â†’ ì—…ì¢… íŒŒì•…
        case_companies = extract_case_companies_from_blog(content, title)
        if case_companies:
            keywords.append('ê³ ê°ì‚¬ë¡€')
            for case in case_companies:
                if case['industry'] not in industry_tags:
                    industry_tags.append(case['industry'])
            logger.debug(f"ë¸”ë¡œê·¸ì—ì„œ ê³ ê°ì‚¬ ë°œê²¬: {[c['company'] for c in case_companies]}")
        
        # ì—…ì¢… ê´€ë ¨ í‚¤ì›Œë“œ (í™•ì¥)
        industry_mapping = {
            'ê²Œì„': ['ê²Œì„', 'game', 'ì¸ì•±ê²°ì œ', 'd2c', 'ì›¹ìƒì ', 'ì•±ìŠ¤í† ì–´', 'êµ¬ê¸€í”Œë ˆì´'],
            'ì´ì»¤ë¨¸ìŠ¤': ['ì´ì»¤ë¨¸ìŠ¤', 'eì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘ëª°', 'commerce', 'ì˜¨ë¼ì¸ëª°', 'ë§ˆì¼“í”Œë ˆì´ìŠ¤', 'ì»¤ë¨¸ìŠ¤', 'ë¦¬í…Œì¼'],
            'ì—¬í–‰': ['ì—¬í–‰', 'travel', 'í•­ê³µ', 'í˜¸í…”', 'ìˆ™ë°•', 'ì˜ˆì•½', 'ota'],
            'êµìœ¡': ['êµìœ¡', 'education', 'ì—ë“€í…Œí¬', 'í•™ì›', 'ê°•ì˜', 'ì˜¨ë¼ì¸êµìœ¡'],
            'ê¸ˆìœµ': ['ê¸ˆìœµ', 'fintech', 'í•€í…Œí¬', 'ë³´í—˜', 'ëŒ€ì¶œ', 'íˆ¬ì'],
            'ë¯¸ë””ì–´': ['ë¯¸ë””ì–´', 'media', 'ì½˜í…ì¸ ', 'ott', 'ìŠ¤íŠ¸ë¦¬ë°', 'êµ¬ë…'],
            'SaaS': ['saas', 'êµ¬ë…ì„œë¹„ìŠ¤', 'subscription', 'ì†Œí”„íŠ¸ì›¨ì–´', 'b2b'],
            'ë¬¼ë¥˜': ['ë¬¼ë¥˜', 'logistics', 'ë°°ì†¡', 'ë°°ë‹¬', 'í’€í•„ë¨¼íŠ¸'],
            'í”Œë«í¼': ['í”Œë«í¼', 'platform', 'ì¤‘ê°œ', 'ë§ˆì¼“', 'íŒŒíŠ¸ë„ˆì •ì‚°'],
            'íŒ¨ì…˜': ['íŒ¨ì…˜', 'fashion', 'ì˜ë¥˜', 'ë¸Œëœë“œ', 'ë¦¬ì…€'],
            'í‘¸ë“œ': ['ìŒì‹', 'food', 'ì‹í’ˆ', 'f&b', 'ë ˆìŠ¤í† ë‘', 'ë°°ë‹¬'],
            'ìë™ì°¨': ['ìë™ì°¨', 'ì°¨ëŸ‰', 'automotive', 'ëª¨ë¹Œë¦¬í‹°'],
            'ë·°í‹°': ['ë·°í‹°', 'í™”ì¥í’ˆ', 'ì½”ìŠ¤ë©”í‹±', 'beauty', 'ìŠ¤í‚¨ì¼€ì–´'],
            'í—¬ìŠ¤ì¼€ì–´': ['ì˜ë£Œ', 'ë³‘ì›', 'í—¬ìŠ¤', 'ê±´ê°•', 'ì œì•½'],
            'ë¶€ë™ì‚°': ['ë¶€ë™ì‚°', 'ê±´ë¬¼', 'ì„ëŒ€', 'ë¶„ì–‘'],
            'ë¦¬ì…€': ['ë¦¬ì…€', 'ì¤‘ê³ ', 'ì„¸ì»¨í•¸ë“œ', 'ë¹ˆí‹°ì§€']
        }
        
        for industry, keywords_list in industry_mapping.items():
            if any(kw in text_lower for kw in keywords_list):
                if industry not in industry_tags:
                    industry_tags.append(industry)
        
        # ê¸°ëŠ¥/í˜œíƒ ê´€ë ¨ í‚¤ì›Œë“œ (í™•ì¥)
        benefit_mapping = {
            'ìˆ˜ìˆ˜ë£Œì ˆê°': ['ìˆ˜ìˆ˜ë£Œ', 'ë¹„ìš©ì ˆê°', 'ì ˆê°', 'í• ì¸', 'ì €ë ´', '15%', '30%'],
            'ê²°ì œì—°ë™': ['ê²°ì œ', 'payment', 'pgì—°ë™', 'api', 'sdk'],
            'ì •ì‚°ìë™í™”': ['ì •ì‚°', 'ë§¤ì¶œ', 'ëŒ€ì‚¬', 'ìë™í™”', 'ì¬ë¬´', 'ë§ˆê°'],
            'PGí†µí•©': ['pg', 'ê°„í¸ê²°ì œ', 'ë©€í‹°pg', 'ë³µìˆ˜pg', '25ê°œ'],
            'ê¸€ë¡œë²Œ': ['í•´ì™¸', 'global', 'ê¸€ë¡œë²Œ', 'í•´ì™¸ê²°ì œ', 'í™˜ìœ¨'],
            'ì •ê¸°ê²°ì œ': ['ì •ê¸°ê²°ì œ', 'subscription', 'ë¹Œë§í‚¤', 'êµ¬ë…ê²°ì œ'],
            'ë¦¬ìŠ¤í¬ê´€ë¦¬': ['ì¥ì• ', 'ë°±ì—…', 'ë¼ìš°íŒ…', 'ë¦¬ìŠ¤í¬', 'ì•ˆì •ì„±'],
            'ê°œë°œíš¨ìœ¨': ['ê°œë°œ', 'ë¦¬ì†ŒìŠ¤', '2ì£¼', '85%', 'íš¨ìœ¨']
        }
        
        for benefit, keywords_list in benefit_mapping.items():
            if any(kw in text_lower for kw in keywords_list):
                keywords.append(benefit)
        
        # ê³ ê°ì‚¬ë¡€ ì—¬ë¶€ í™•ì¸ (ì´ë¯¸ ìœ„ì—ì„œ ì²´í¬í–ˆì§€ë§Œ, í‚¤ì›Œë“œ ê¸°ë°˜ë„ ì¶”ê°€)
        if 'ê³ ê°ì‚¬ë¡€' not in keywords:
            if any(kw in text_lower for kw in ['ê³ ê°ì‚¬', 'ë„ì…ì‚¬ë¡€', 'ì„±ê³µì‚¬ë¡€', 'ì¸í„°ë·°', 'ì¼€ì´ìŠ¤']):
                keywords.append('ê³ ê°ì‚¬ë¡€')
        
        # êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨ ì—¬ë¶€
        import re
        if re.search(r'\d+%|\d+ì–µ|\d+ë§Œì›|\d+ë°°', text_lower):
            keywords.append('ì •ëŸ‰ì íš¨ê³¼')
        
        return ','.join(keywords), ','.join(industry_tags)
        
    except Exception as e:
        logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return '', ''


def analyze_blog_with_ai(post, gemini_model=None):
    """
    Gemini AIë¡œ ë¸”ë¡œê·¸ ë‚´ìš© ì‹¬ì¸µ ë¶„ì„ (ì„ íƒì  ì‚¬ìš©)
    
    Args:
        post: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ dict
        gemini_model: Gemini ëª¨ë¸ ê°ì²´
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ (target_industry, benefits, case_company, summary)
    """
    if not gemini_model:
        return None
    
    try:
        content = post.get('content', '')[:3000]
        title = post.get('title', '')
        
        prompt = f"""ë‹¤ìŒ í¬íŠ¸ì› ë¸”ë¡œê·¸ ê¸€ì„ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

ì œëª©: {title}
ë‚´ìš©: {content}

ë¶„ì„ í•­ëª©:
1. target_industry: ì´ ê¸€ì´ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” ì—…ì¢… (ê²Œì„, ì´ì»¤ë¨¸ìŠ¤, ì—¬í–‰, êµìœ¡, ê¸ˆìœµ, SaaS, ë¬¼ë¥˜, í”Œë«í¼, ì¼ë°˜ ì¤‘ íƒ1)
2. main_benefit: ì£¼ìš” í˜œíƒ/ê°€ì¹˜ (ìˆ˜ìˆ˜ë£Œì ˆê°, ê°œë°œíš¨ìœ¨, ì •ì‚°ìë™í™”, ê¸€ë¡œë²Œì§„ì¶œ, ì•ˆì •ì„± ì¤‘ íƒ1)
3. case_company: ì–¸ê¸‰ëœ ê³ ê°ì‚¬ ì´ë¦„ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
4. one_line_summary: í•œ ì¤„ ìš”ì•½ (30ì ì´ë‚´)
5. quantitative_results: ì •ëŸ‰ì  ì„±ê³¼ ìˆ˜ì¹˜ (ì˜ˆ: "ìˆ˜ìˆ˜ë£Œ 15% ì ˆê°", ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{"target_industry": "", "main_benefit": "", "case_company": "", "one_line_summary": "", "quantitative_results": ""}}
"""
        
        response = gemini_model.generate_content(prompt)
        result = response.text.strip()
        
        # JSON íŒŒì‹±
        import json
        if result.startswith('```'):
            result = result.split('```')[1]
            if result.startswith('json'):
                result = result[4:]
        
        return json.loads(result)
        
    except Exception as e:
        logger.error(f"AI ë¸”ë¡œê·¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return None


def reanalyze_all_blog_tags():
    """
    ê¸°ì¡´ ë¸”ë¡œê·¸ ë°ì´í„°ì˜ ì—…ì¢…íƒœê·¸ì™€ í‚¤ì›Œë“œë¥¼ ì¬ë¶„ì„í•˜ì—¬ ì—…ë°ì´íŠ¸
    ì—…ì¢…íƒœê·¸ê°€ ë¹„ì–´ìˆëŠ” ë¸”ë¡œê·¸ì— ëŒ€í•´ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ íƒœê·¸ ì¶”ì¶œ
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        all_posts = db.session.query(BlogPost).all()
        updated_count = 0
        
        for post in all_posts:
            # í˜„ì¬ ë°ì´í„°ë¡œ ì¬ë¶„ì„
            post_data = {
                'title': post.title or '',
                'content': post.content or '',
                'summary': post.summary or ''
            }
            
            # í‚¤ì›Œë“œì™€ ì—…ì¢…íƒœê·¸ ì¬ì¶”ì¶œ
            new_keywords, new_industry_tags = extract_keywords_from_post(post_data)
            
            # ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
            needs_update = False
            
            # ì—…ì¢…íƒœê·¸ê°€ ë¹„ì–´ìˆëŠ”ë° ìƒˆë¡œ ì¶”ì¶œëœ íƒœê·¸ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
            if not post.industry_tags and new_industry_tags:
                post.industry_tags = new_industry_tags
                needs_update = True
            
            # í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆê±°ë‚˜ ë” í’ë¶€í•´ì§€ë©´ ì—…ë°ì´íŠ¸
            if new_keywords and (not post.keywords or len(new_keywords) > len(post.keywords or '')):
                post.keywords = new_keywords
                needs_update = True
            
            if needs_update:
                updated_count += 1
                logger.info(f"ğŸ“ ë¸”ë¡œê·¸ íƒœê·¸ ì—…ë°ì´íŠ¸: {post.title[:30]}... â†’ ì—…ì¢…: {post.industry_tags}, í‚¤ì›Œë“œ: {post.keywords}")
        
        db.session.commit()
        logger.info(f"âœ… ë¸”ë¡œê·¸ íƒœê·¸ ì¬ë¶„ì„ ì™„ë£Œ: {updated_count}/{len(all_posts)}ê°œ ì—…ë°ì´íŠ¸ë¨")
        return updated_count
        
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ íƒœê·¸ ì¬ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return 0


def get_relevant_blog_posts_by_industry(company_info, max_posts=3, service_type=None, pain_points=None):
    """
    íšŒì‚¬ ì •ë³´ì™€ Pain Pointë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¸”ë¡œê·¸ ê¸€ ì¡°íšŒ (PostgreSQL)
    
    Args:
        company_info: íšŒì‚¬ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        max_posts: ìµœëŒ€ ë°˜í™˜ ê¸€ ìˆ˜
        service_type: ì„œë¹„ìŠ¤ íƒ€ì… ('OPI', 'Recon', 'Prism', 'PS' ë“±)
        pain_points: Pain Point í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['êµ¬ë…ê²°ì œ', 'PGê´€ë¦¬', 'ì •ì‚°'])
    
    Returns:
        list: ê´€ë ¨ ë¸”ë¡œê·¸ ê¸€ ë¦¬ìŠ¤íŠ¸
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        # íšŒì‚¬ ì •ë³´ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
        industry = company_info.get('industry', '')
        category = company_info.get('category', '')
        description = company_info.get('description', '')
        
        search_terms = []
        if industry:
            search_terms.append(industry)
        if category:
            search_terms.append(category)
        
        # Pain Point í‚¤ì›Œë“œ ì¶”ê°€ (ìµœìš°ì„ )
        pain_point_terms = []
        if pain_points:
            pain_point_terms.extend(pain_points)
            logger.info(f"ğŸ¯ Pain Point í‚¤ì›Œë“œ: {', '.join(pain_points)}")
        
        # ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if description:
            desc_lower = description.lower()
            for keyword in ['ê²Œì„', 'game', 'ì´ì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘ëª°', 'ì—¬í–‰', 'travel', 'êµìœ¡', 'education', 'ê¸ˆìœµ', 'fintech']:
                if keyword in desc_lower:
                    search_terms.append(keyword)
        
        from sqlalchemy import or_
        
        # ë‘ ë‹¨ê³„ ê²€ìƒ‰: 1) Pain Point ë§¤ì¹­ ìš°ì„  2) ì—…ì¢… ë§¤ì¹­
        all_posts = []
        seen_ids = set()
        
        # 1ë‹¨ê³„: Pain Point í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (ìµœìš°ì„ )
        if pain_point_terms:
            pain_query = db.session.query(BlogPost)
            if service_type:
                pain_query = pain_query.filter(BlogPost.category == service_type)
            
            pain_pattern = f"%{'%'.join(pain_point_terms)}%"
            pain_query = pain_query.filter(
                or_(
                    BlogPost.keywords.like(pain_pattern),
                    BlogPost.title.like(pain_pattern),
                    BlogPost.content.like(pain_pattern)
                )
            )
            
            pain_posts = pain_query.order_by(BlogPost.created_at.desc()).limit(max_posts).all()
            for post in pain_posts:
                if post.id not in seen_ids:
                    all_posts.append(post)
                    seen_ids.add(post.id)
                    logger.info(f"  âœ… Pain Point ë§¤ì¹­: {post.title[:50]}...")
        
        # 2ë‹¨ê³„: ì—…ì¢… í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (Pain Point ë§¤ì¹­ í›„ ë¶€ì¡±í•˜ë©´ ì±„ìš°ê¸°)
        remaining_count = max_posts - len(all_posts)
        if remaining_count > 0 and search_terms:
            industry_query = db.session.query(BlogPost)
            if service_type:
                industry_query = industry_query.filter(BlogPost.category == service_type)
            
            search_pattern = f"%{'%'.join(search_terms)}%"
            industry_query = industry_query.filter(
                or_(
                    BlogPost.industry_tags.like(search_pattern),
                    BlogPost.keywords.like(search_pattern),
                    BlogPost.title.like(search_pattern),
                    BlogPost.content.like(search_pattern)
                )
            )
            
            industry_posts = industry_query.order_by(BlogPost.created_at.desc()).limit(remaining_count).all()
            for post in industry_posts:
                if post.id not in seen_ids:
                    all_posts.append(post)
                    seen_ids.add(post.id)
        
        posts_query = all_posts
        
        service_label = f"[{service_type}] " if service_type else ""
        
        if not posts_query:
            if search_terms:
                logger.info(f"ğŸ” {service_label}'{', '.join(search_terms)}' ê´€ë ¨ ë¸”ë¡œê·¸ ê¸€ ì—†ìŒ")
            else:
                logger.info(f"ğŸ” {service_label}ë¸”ë¡œê·¸ ê¸€ ì—†ìŒ")
            return []
        
        # dict í˜•íƒœë¡œ ë³€í™˜
        posts = []
        for post in posts_query:
            posts.append({
                'title': post.title,
                'link': post.link,
                'summary': post.summary,
                'content': post.content,
                'category': post.category,
                'keywords': post.keywords,
                'industry_tags': post.industry_tags
            })
        
        if search_terms:
            logger.info(f"âœ… {service_label}'{', '.join(search_terms)}' ê´€ë ¨ ë¸”ë¡œê·¸ ê¸€ {len(posts)}ê°œ ì¡°íšŒ (PostgreSQL)")
        else:
            logger.info(f"âœ… {service_label}ë¸”ë¡œê·¸ ê¸€ {len(posts)}ê°œ ì¡°íšŒ (PostgreSQL)")
        
        return posts
        
    except Exception as e:
        logger.error(f"ì—…ì¢…ë³„ ë¸”ë¡œê·¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return []

def get_best_blog_for_email_mention(company_info, research_data=None, max_check=50, competitors=None, service_type=None):
    """
    ì´ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰í•  ê°€ì¥ ì í•©í•œ ë¸”ë¡œê·¸ 1ê°œ ì„ íƒ
    
    ì„ íƒ ê¸°ì¤€ (ìš°ì„ ìˆœìœ„):
    1. ê²½ìŸì‚¬ ì‚¬ë¡€ ë¸”ë¡œê·¸ (ê°€ì¥ ì„¤ë“ë ¥ ìˆìŒ)
    2. ë™ì¼ ì—…ì¢…ì˜ ìœ ì‚¬ ê¸°ì—… ì‚¬ë¡€
    3. ê´€ë ¨ ì‚°ì—…ì˜ í•´ê²° ì‚¬ë¡€
    4. ë°›ì„ ìˆ˜ ìˆëŠ” í˜œíƒ(ìˆ˜ìˆ˜ë£Œ ì ˆê°, ìë™í™” ë“±)ê³¼ ê´€ë ¨ëœ ì •ë³´
    
    Args:
        company_info: íšŒì‚¬ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        research_data: ì¡°ì‚¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (pain_points ë“±)
        max_check: í™•ì¸í•  ìµœëŒ€ ë¸”ë¡œê·¸ ìˆ˜
        competitors: ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
        service_type: ì„œë¹„ìŠ¤ ìœ í˜• ('OPI', 'PS', 'Recon' ë“±) - í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë¸”ë¡œê·¸ë§Œ ë§¤ì¹­
    
    Returns:
        dict or None: ì„ íƒëœ ë¸”ë¡œê·¸ ì •ë³´ (title, link, summary, match_reason)
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        # íšŒì‚¬ ì •ë³´ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
        industry = company_info.get('industry', '') or ''
        category = company_info.get('category', '') or ''
        description = company_info.get('description', '') or ''
        company_name = company_info.get('company_name', '') or company_info.get('íšŒì‚¬ëª…', '') or ''
        
        # research_dataì—ì„œ pain_points, company_info ì¶”ì¶œ
        pain_points = ''
        research_company_info = ''
        if research_data:
            pain_points = research_data.get('pain_points', '') or ''
            research_company_info = research_data.get('company_info', '') or ''
        
        # ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        competitor_list = []
        if competitors:
            if isinstance(competitors, str):
                # ì‰¼í‘œ, ìŠ¬ë˜ì‹œ, ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
                import re
                competitor_list = [c.strip().lower() for c in re.split(r'[,/\s]+', competitors) if c.strip() and len(c.strip()) > 1]
            elif isinstance(competitors, list):
                competitor_list = [c.lower() for c in competitors if c and len(c) > 1]
        
        logger.info(f"ğŸ” ë¸”ë¡œê·¸ ë§¤ì¹­ - ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸: {competitor_list}")
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì¹˜ê¸° (ë‰´ìŠ¤ ê¸°ì‚¬ í¬í•¨)
        news_content = research_data.get('news_summary', '') or research_data.get('news', '') or '' if research_data else ''
        all_text = f"{company_name} {industry} {category} {description} {pain_points} {research_company_info} {news_content}".lower()
        
        # ğŸ†• ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ íšŒì‚¬ì˜ 'ì˜ë„/ê³„íš' íŒŒì•… â†’ ì‹œë‚˜ë¦¬ì˜¤ ë§¤ì¹­
        # âš ï¸ ì˜ë„ ë§¤ì¹­ì€ ìµœìš°ì„ ! ì ìˆ˜ë¥¼ í¬ê²Œ ë†’ì—¬ í™•ì‹¤íˆ ì„ íƒë˜ë„ë¡ í•¨
        intent_scenarios = {
            'ê¸€ë¡œë²Œì§„ì¶œ': {
                'keywords': ['í•´ì™¸ì§„ì¶œ', 'ì¼ë³¸ì§„ì¶œ', 'ê¸€ë¡œë²Œ', 'í•´ì™¸ì‹œì¥', 'ìˆ˜ì¶œ', 'ë¯¸êµ­ì§„ì¶œ', 'ë™ë‚¨ì•„', 'ì¤‘êµ­ì§„ì¶œ', 'í¬ë¡œìŠ¤ë³´ë”', 'í˜„ì§€í™”', 'í•´ì™¸ë§¤ì¶œ', 'ê¸€ë¡œë²Œí™•ì¥', 'uae', 'ë² íŠ¸ë‚¨', 'íƒœêµ­', 'ì¸ë„ë„¤ì‹œì•„', 'ì‹±ê°€í¬ë¥´', 'í•´ì™¸', 'ë‹¤êµ­ê°€'],
                'blog_keywords': ['ê¸€ë¡œë²Œ', 'í•´ì™¸', 'global', 'ì¼ë³¸', 'í¬ë¡œìŠ¤ë³´ë”', 'ìš°ì»¤ë¨¸ìŠ¤', 'woocommerce'],
                'score': 100  # ğŸ”¥ ì˜ë„ ë§¤ì¹­ì€ ìµœìš°ì„  (ë‹¤ë¥¸ ë§¤ì¹­ë³´ë‹¤ í™•ì‹¤íˆ ë†’ê²Œ)
            },
            'êµ¬ë…ì„œë¹„ìŠ¤': {
                'keywords': ['êµ¬ë…', 'ì •ê¸°ê²°ì œ', 'ë©¤ë²„ì‹­', 'saas', 'ott', 'ì›”ì •ì•¡', 'êµ¬ë…ëª¨ë¸', 'ì •ê¸°ë°°ì†¡', 'êµ¬ë…ê²½ì œ'],
                'blog_keywords': ['ë¹Œë§í‚¤', 'êµ¬ë…', 'ì •ê¸°ê²°ì œ', 'subscription'],
                'score': 100
            },
            'ì •ì‚°ê°œì„ ': {
                'keywords': ['ì •ì‚°', 'ë§¤ì¶œê´€ë¦¬', 'ì¬ë¬´', 'íšŒê³„', 'ëŒ€ì‚¬', 'ë§ˆê°', 'erp', 'ìë™í™”', 'íš¨ìœ¨í™”'],
                'blog_keywords': ['ì •ì‚°', 'ë§¤ì¶œ', 'ìë™í™”', 'ëŒ€ì‚¬', 'ë§ˆê°'],
                'score': 100
            },
            'ê²°ì œì—°ë™': {
                'keywords': ['ê²°ì œë„ì…', 'pgì—°ë™', 'ê²°ì œì‹œìŠ¤í…œ', 'ê²°ì œìˆ˜ë‹¨', 'ê°„í¸ê²°ì œ', 'í˜ì´', 'ê²°ì œì†”ë£¨ì…˜'],
                'blog_keywords': ['ê²°ì œ', 'pg', 'ì—°ë™', 'api'],
                'score': 80
            },
            'ë¹„ìš©ì ˆê°': {
                'keywords': ['ìˆ˜ìˆ˜ë£Œ', 'ë¹„ìš©ì ˆê°', 'ì›ê°€', 'íš¨ìœ¨', 'ì¸ì•±ê²°ì œ', 'ìˆ˜ìˆ˜ë£Œì¸í•˜'],
                'blog_keywords': ['ìˆ˜ìˆ˜ë£Œ', 'ì ˆê°', '30%', 'ë¹„ìš©'],
                'score': 80
            }
        }
        
        # ë‰´ìŠ¤ì—ì„œ íŒŒì•…ëœ ì˜ë„ ì°¾ê¸°
        detected_intents = []
        for intent_name, intent_info in intent_scenarios.items():
            for kw in intent_info['keywords']:
                if kw in all_text:
                    detected_intents.append(intent_name)
                    break
        
        if detected_intents:
            logger.info(f"ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ íŒŒì•…ëœ íšŒì‚¬ ì˜ë„: {detected_intents}")
        
        # ğŸ†• í™•ì¥ëœ ì‚°ì—… í‚¤ì›Œë“œ ë§¤ì¹­ (ë” ì„¸ë¶„í™”)
        industry_keywords = {
            # IT/í…Œí¬
            'ê²Œì„': ['ê²Œì„', 'game', 'ì¸ì•±ê²°ì œ', 'd2c', 'ì›¹ìƒì ', 'ì•±ìŠ¤í† ì–´', 'êµ¬ê¸€í”Œë ˆì´', 'ìŠ¤íŒ€'],
            'SaaS': ['saas', 'b2b', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í´ë¼ìš°ë“œ', 'ì†”ë£¨ì…˜', 'í”Œë«í¼ì„œë¹„ìŠ¤'],
            'ITì„œë¹„ìŠ¤': ['it', 'í…Œí¬', 'tech', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ê°œë°œ', 'ìŠ¤íƒ€íŠ¸ì—…'],
            
            # ì»¤ë¨¸ìŠ¤
            'ì´ì»¤ë¨¸ìŠ¤': ['ì´ì»¤ë¨¸ìŠ¤', 'eì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘ëª°', 'ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸ëª°', 'ë§ˆì¼“í”Œë ˆì´ìŠ¤', 'ì˜¨ë¼ì¸ì‡¼í•‘'],
            'ë¦¬ì…€/ì¤‘ê³ ': ['ë¦¬ì…€', 'ì¤‘ê³ ', 'ì„¸ì»¨í•¸ë“œ', 'ë¹ˆí‹°ì§€', 'ë²ˆê°œì¥í„°', 'ë‹¹ê·¼'],
            'íŒ¨ì…˜': ['íŒ¨ì…˜', 'fashion', 'ì˜ë¥˜', 'ë¸Œëœë“œ', 'ì˜·', 'ì‹ ë°œ', 'ì•¡ì„¸ì„œë¦¬'],
            'ë·°í‹°': ['ë·°í‹°', 'í™”ì¥í’ˆ', 'ì½”ìŠ¤ë©”í‹±', 'beauty', 'ìŠ¤í‚¨ì¼€ì–´', 'ë©”ì´í¬ì—…'],
            
            # ì—¬í–‰/ìˆ™ë°•
            'ì—¬í–‰': ['ì—¬í–‰', 'travel', 'í•­ê³µ', 'í˜¸í…”', 'ìˆ™ë°•', 'ì˜ˆì•½', 'ota', 'íˆ¬ì–´'],
            
            # êµìœ¡
            'êµìœ¡': ['êµìœ¡', 'education', 'ì—ë“€í…Œí¬', 'í•™ì›', 'ê°•ì˜', 'ì˜¨ë¼ì¸ê°•ì˜', 'ì´ëŸ¬ë‹'],
            
            # ê¸ˆìœµ
            'ê¸ˆìœµ': ['ê¸ˆìœµ', 'fintech', 'í•€í…Œí¬', 'ë³´í—˜', 'ëŒ€ì¶œ', 'íˆ¬ì', 'ì¦ê¶Œ', 'ì€í–‰'],
            
            # ë¯¸ë””ì–´/ì½˜í…ì¸ 
            'ë¯¸ë””ì–´': ['ë¯¸ë””ì–´', 'media', 'ì½˜í…ì¸ ', 'ott', 'ìŠ¤íŠ¸ë¦¬ë°', 'ì˜ìƒ', 'ë‰´ìŠ¤'],
            'ì—”í„°í…Œì¸ë¨¼íŠ¸': ['ì—”í„°', 'ì—°ì˜ˆ', 'ê³µì—°', 'í‹°ì¼“', 'ì½˜ì„œíŠ¸', 'ì˜í™”'],
            
            # ë¬¼ë¥˜/ë°°ì†¡
            'ë¬¼ë¥˜': ['ë¬¼ë¥˜', 'logistics', 'ë°°ì†¡', 'ë°°ë‹¬', 'í’€í•„ë¨¼íŠ¸', 'íƒë°°'],
            'í‘¸ë“œ': ['ìŒì‹', 'food', 'ì‹í’ˆ', 'f&b', 'ë ˆìŠ¤í† ë‘', 'ë°°ë‹¬', 'ì‹ìì¬'],
            
            # í”Œë«í¼
            'í”Œë«í¼': ['í”Œë«í¼', 'platform', 'ì¤‘ê°œ', 'ë§ˆì¼“', 'íŒŒíŠ¸ë„ˆì •ì‚°'],
            
            # ì œì¡°/ì‚°ì—…
            'ìë™ì°¨': ['ìë™ì°¨', 'ì°¨ëŸ‰', 'automotive', 'ëª¨ë¹Œë¦¬í‹°', 'ì¹´', 'ì˜¤í† '],
            'ì œì¡°': ['ì œì¡°', 'manufacturing', 'ê³µì¥', 'ìƒì‚°', 'ë¶€í’ˆ'],
            
            # í—¬ìŠ¤ì¼€ì–´
            'í—¬ìŠ¤ì¼€ì–´': ['ì˜ë£Œ', 'ë³‘ì›', 'í—¬ìŠ¤', 'ê±´ê°•', 'ì œì•½', 'ë°”ì´ì˜¤'],
            
            # ë¶€ë™ì‚°
            'ë¶€ë™ì‚°': ['ë¶€ë™ì‚°', 'ê±´ë¬¼', 'ì„ëŒ€', 'ë¶„ì–‘', 'ì¤‘ê°œ'],
            
            # ê¸€ë¡œë²Œ
            'ê¸€ë¡œë²Œ': ['í•´ì™¸', 'ê¸€ë¡œë²Œ', 'global', 'ìˆ˜ì¶œ', 'í•´ì™¸ì§„ì¶œ', 'í¬ë¡œìŠ¤ë³´ë”']
        }
        
        # ğŸ†• ìƒí˜¸ ë°°íƒ€ì  ì—…ì¢… ê·¸ë£¹ (ì´ ê·¸ë£¹ ë‚´ ë‹¤ë¥¸ ì—…ì¢… ë¸”ë¡œê·¸ëŠ” ì¶”ì²œ ì•ˆí•¨)
        exclusive_groups = [
            ['ìë™ì°¨', 'ì œì¡°'],  # ì œì¡°ì—…
            ['ë·°í‹°', 'íŒ¨ì…˜'],     # ì†Œë¹„ì¬
            ['í—¬ìŠ¤ì¼€ì–´'],         # ì˜ë£Œ
            ['ë¶€ë™ì‚°'],           # ë¶€ë™ì‚°
            ['ê¸ˆìœµ'],             # ê¸ˆìœµ
        ]
        
        # í˜œíƒ í‚¤ì›Œë“œ ë§¤ì¹­ (ì„¸ì¼ì¦ˆ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°•í™”)
        benefit_keywords = {
            # ğŸŒ ê¸€ë¡œë²Œ ì§„ì¶œ ì‹œë‚˜ë¦¬ì˜¤
            'ê¸€ë¡œë²Œ': ['í•´ì™¸', 'ê¸€ë¡œë²Œ', 'global', 'í•´ì™¸ê²°ì œ', 'í™˜ìœ¨', 'í¬ë¡œìŠ¤ë³´ë”', 'ì¼ë³¸', 'ë™ë‚¨ì•„', 'ë¯¸êµ­', 'ì¤‘êµ­', 'paypay', 'alipay', 'ì§„ì¶œ', 'ìˆ˜ì¶œ'],
            # ğŸ”„ êµ¬ë… ì„œë¹„ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤
            'êµ¬ë…': ['êµ¬ë…', 'saas', 'ë©¤ë²„ì‹­', 'ì •ê¸°ê²°ì œ', 'ë¹Œë§í‚¤', 'ë¹Œë§', 'ott', 'ì •ê¸°ë°°ì†¡', 'ì›”ì •ì•¡', 'ì—°ê°„êµ¬ë…'],
            # 1ï¸âƒ£ ë‹¨ì¼/ë³µìˆ˜ PG ì‹œë‚˜ë¦¬ì˜¤
            'ìˆ˜ìˆ˜ë£Œì ˆê°': ['ìˆ˜ìˆ˜ë£Œ', 'ë¹„ìš©', 'ì ˆê°', 'í• ì¸', 'ì €ë ´', '15%', '30%', 'ë‹¨ì¼pg', 'ë©€í‹°pg', 'ë³µìˆ˜pg'],
            'ì •ì‚°': ['ì •ì‚°', 'ë§¤ì¶œ', 'ì¬ë¬´', 'íšŒê³„', 'ëŒ€ì‚¬', 'ëŒ€ì‹œë³´ë“œ', 'í†µí•©ê´€ë¦¬', 'ìë™ëŒ€ì‚¬'],
            # ê³µí†µ
            'ìë™í™”': ['ìë™í™”', 'ìë™', 'íš¨ìœ¨', 'ë¦¬ì†ŒìŠ¤', 'ì‹œê°„ì ˆì•½', '90%', 'ë‹¨ì¶•'],
            'ì•ˆì •ì„±': ['ì•ˆì •', 'ì¥ì• ', 'ë¦¬ìŠ¤í¬', 'ë°±ì—…', 'ë¼ìš°íŒ…', 'ìŠ¤ë§ˆíŠ¸ë¼ìš°íŒ…', 'ìë™ì „í™˜', 'ì´íƒˆë¥ '],
            'ê°œë°œíš¨ìœ¨': ['ê°œë°œ', 'api', 'sdk', 'ì—°ë™', '2ì£¼', '85%', 'êµ¬ì¶•']
        }
        
        # íšŒì‚¬ì— í•´ë‹¹í•˜ëŠ” ì‚°ì—… ì°¾ê¸°
        matched_industries = []
        for ind, keywords in industry_keywords.items():
            for kw in keywords:
                if kw in all_text:
                    matched_industries.append(ind)
                    break
        
        # ê´€ì‹¬ í˜œíƒ ì°¾ê¸°
        matched_benefits = []
        for benefit, keywords in benefit_keywords.items():
            for kw in keywords:
                if kw in all_text:
                    matched_benefits.append(benefit)
                    break
        
        logger.info(f"ğŸ¯ ë¸”ë¡œê·¸ ì„ íƒ - íšŒì‚¬: {company_name}, ë§¤ì¹­ëœ ì‚°ì—…: {matched_industries}, í˜œíƒ: {matched_benefits}")
        
        # ğŸ†• íšŒì‚¬ì˜ ë°°íƒ€ì  ê·¸ë£¹ ì°¾ê¸°
        company_exclusive_group = None
        for group in exclusive_groups:
            if any(ind in matched_industries for ind in group):
                company_exclusive_group = group
                break
        
        from sqlalchemy import or_
        
        # ğŸ†• ì„œë¹„ìŠ¤ ìœ í˜•ë³„ ë¸”ë¡œê·¸ URL íŒ¨í„´ í•„í„°ë§
        # OPI: ê²°ì œ ì—°ë™/PG ê´€ë ¨
        # PS: í”Œë«í¼ ì •ì‚° (íŒŒíŠ¸ë„ˆ ì •ì‚°) - /ps_ ê²½ë¡œ
        # Recon: ë§¤ì¶œ ë§ˆê°/ì •ì‚° ì¡°íšŒ - /co- ê²½ë¡œ (Company ì‚¬ë¡€)
        service_url_patterns = {
            # OPI: ê²°ì œ ì—°ë™/PG ê´€ë ¨ + ê¸€ë¡œë²Œ ê²°ì œ
            'OPI': ['/opi_', '/payment_', '/pgcompare', '/onboarding', '/easypayment', '/billing-pay', '/case_', '/fitpet', '/v2-open', '/multi-pg', '/blue-garage', '/game', '/codemshop', '/global', '/woocommerce'],
            'PS': ['/ps_'],  # í”Œë«í¼ ì •ì‚° ì „ìš© (ps_odin, ps_news, ps_tech-lead) - âš ï¸ ì ˆëŒ€ OPI ë©”ì¼ì— ë„£ì§€ ë§ê²ƒ
            'Recon': ['/co-', '/recon_', '/analytics']  # ë§¤ì¶œ ë§ˆê° (co-sabang, co-drg, co-skin1004)
        }
        
        # ë¸”ë¡œê·¸ ê²€ìƒ‰ (ìµœì‹ ìˆœ)
        query = db.session.query(BlogPost).order_by(BlogPost.created_at.desc())
        
        # ì„œë¹„ìŠ¤ ìœ í˜•ì´ ì§€ì •ë˜ë©´ í•´ë‹¹ íŒ¨í„´ë§Œ í•„í„°ë§
        if service_type and service_type.upper() in service_url_patterns:
            patterns = service_url_patterns[service_type.upper()]
            # OR ì¡°ê±´ìœ¼ë¡œ íŒ¨í„´ ë§¤ì¹­
            pattern_filters = [BlogPost.link.like(f'%{p}%') for p in patterns]
            query = query.filter(or_(*pattern_filters))
            logger.info(f"ğŸ” {service_type} ë¸”ë¡œê·¸ë§Œ ê²€ìƒ‰ (íŒ¨í„´: {patterns})")
        
        all_posts = query.limit(max_check).all()
        
        if not all_posts:
            logger.info(f"ğŸ“ ë¸”ë¡œê·¸ DBì— {service_type or 'ì „ì²´'} ë°ì´í„° ì—†ìŒ")
            return None
        
        best_match = None
        best_score = 0
        best_reason = ''
        industry_matched = False
        best_case_company = None  # ë¸”ë¡œê·¸ì— ì–¸ê¸‰ëœ ê³ ê°ì‚¬ëª…
        
        for post in all_posts:
            score = 0
            reasons = []
            this_industry_matched = False
            case_company_name = None  # ë¸”ë¡œê·¸ì— ì–¸ê¸‰ëœ ê³ ê°ì‚¬ëª…
            
            post_text = f"{post.title} {post.summary} {post.content} {post.industry_tags} {post.keywords}".lower()
            
            # ğŸ†• ë¸”ë¡œê·¸ì—ì„œ ê³ ê°ì‚¬ë¡€ íšŒì‚¬ ì¶”ì¶œ â†’ ì—…ì¢… íŒŒì•… (ê°€ì¥ ì •í™•)
            case_companies = extract_case_companies_from_blog(post.content or '', post.title or '')
            blog_industries = []
            
            if case_companies:
                for case in case_companies:
                    if case['industry'] not in blog_industries:
                        blog_industries.append(case['industry'])
                case_company_name = case_companies[0]['company']  # ì²« ë²ˆì§¸ ê³ ê°ì‚¬ëª… ì €ì¥
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì—…ì¢…ë„ ì¶”ê°€
            for ind, keywords in industry_keywords.items():
                for kw in keywords:
                    if kw in post_text:
                        if ind not in blog_industries:
                            blog_industries.append(ind)
                        break
            
            # ğŸ†• ë°°íƒ€ì  ê·¸ë£¹ ì²´í¬ - íšŒì‚¬ê°€ ìë™ì°¨ì¸ë° ë¸”ë¡œê·¸ê°€ ë·°í‹°ë©´ ì œì™¸
            if company_exclusive_group:
                blog_in_exclusive = False
                for group in exclusive_groups:
                    if any(ind in blog_industries for ind in group):
                        if group != company_exclusive_group:
                            # ë‹¤ë¥¸ ë°°íƒ€ì  ê·¸ë£¹ì˜ ë¸”ë¡œê·¸ëŠ” ìŠ¤í‚µ
                            blog_in_exclusive = True
                            break
                if blog_in_exclusive:
                    continue
            
            # ğŸ¯ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ íŒŒì•…ëœ ì˜ë„ì™€ ë¸”ë¡œê·¸ ë§¤ì¹­ (ìµœìš°ì„ !)
            title_lower = (post.title or '').lower()
            for intent_name in detected_intents:
                intent_info = intent_scenarios.get(intent_name, {})
                blog_kws = intent_info.get('blog_keywords', [])
                intent_score = intent_info.get('score', 30)
                
                # ë¸”ë¡œê·¸ ì œëª©ì— ì˜ë„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìµœê³  ì ìˆ˜
                if any(bk in title_lower for bk in blog_kws):
                    score += intent_score
                    this_industry_matched = True  # ì—…ì¢… ë¶ˆì¼ì¹˜ íŒ¨ë„í‹° ë°©ì§€
                    reasons.insert(0, f"ğŸ“° {intent_name} ê´€ë ¨ ì „ë¬¸ ì‚¬ë¡€")
                    break
                # ë¸”ë¡œê·¸ ë³¸ë¬¸ì— ì˜ë„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
                elif any(bk in post_text for bk in blog_kws):
                    score += intent_score // 2
                    reasons.insert(0, f"{intent_name} ê´€ë ¨")
            
            # ğŸ† ê²½ìŸì‚¬ ë§¤ì¹­ (ìµœê³  ì ìˆ˜ - ê°€ì¥ ì„¤ë“ë ¥ ìˆìŒ!)
            competitor_matched = False
            if competitor_list:
                for comp in competitor_list:
                    if comp in post_text:
                        score += 25  # ê²½ìŸì‚¬ ì–¸ê¸‰ ì‹œ ìµœê³  ì ìˆ˜
                        competitor_matched = True
                        reasons.insert(0, f"ê²½ìŸì‚¬ '{comp}' ì‚¬ë¡€")
                        logger.info(f"ğŸ† ê²½ìŸì‚¬ ë§¤ì¹­! '{comp}' in blog: {post.title[:30]}...")
                        break
                    # ë¸”ë¡œê·¸ì—ì„œ ì¶”ì¶œí•œ ê³ ê°ì‚¬ê°€ ê²½ìŸì‚¬ì¸ ê²½ìš°
                    if case_companies:
                        for case in case_companies:
                            if comp in case['company'].lower():
                                score += 25
                                competitor_matched = True
                                reasons.insert(0, f"ê²½ìŸì‚¬ '{case['company']}' ì‚¬ë¡€")
                                case_company_name = case['company']
                                break
                        if competitor_matched:
                            break
            
            # ì‚°ì—… ë§¤ì¹­ ì ìˆ˜ (ë†’ì€ ê°€ì¤‘ì¹˜)
            for ind in matched_industries:
                if ind in blog_industries:
                    score += 15  # ì •í™•íˆ ê°™ì€ ì—…ì¢…
                    this_industry_matched = True
                    # ğŸ†• ê³ ê°ì‚¬ëª…ì´ ìˆìœ¼ë©´ ë” êµ¬ì²´ì ì¸ ì´ìœ  í‘œì‹œ
                    if case_company_name and f"{ind}" not in str(reasons):
                        reasons.append(f"{case_company_name}({ind})")
                    elif f"{ind} ì—…ì¢…" not in [r for r in reasons]:
                        reasons.append(f"{ind} ì—…ì¢… ì‚¬ë¡€")
                else:
                    # í‚¤ì›Œë“œë¡œ ë¶€ë¶„ ë§¤ì¹­
                    for kw in industry_keywords.get(ind, []):
                        if kw in post_text:
                            score += 5
                            this_industry_matched = True
                            if f"{ind}" not in str(reasons):
                                reasons.append(f"{ind} ê´€ë ¨")
                            break
            
            # í˜œíƒ ë§¤ì¹­ ì ìˆ˜
            for benefit in matched_benefits:
                for kw in benefit_keywords.get(benefit, []):
                    if kw in post_text:
                        score += 5
                        if benefit not in str(reasons):
                            reasons.append(f"{benefit}")
                        break
            
            # ì¼ë°˜ í˜œíƒ í‚¤ì›Œë“œ (íšŒì‚¬ ë§¤ì¹­ ì—†ì–´ë„)
            general_benefits = ['ìˆ˜ìˆ˜ë£Œ', 'ì ˆê°', 'ìë™í™”', 'íš¨ìœ¨', 'ì„±ê³µì‚¬ë¡€', 'ë„ì…ì‚¬ë¡€']
            for gb in general_benefits:
                if gb in post_text:
                    score += 1
            
            # ğŸ†• ì—…ì¢… ë§¤ì¹­ì´ ìˆëŠ” ë¸”ë¡œê·¸ ìš°ì„  (ì—…ì¢… ë§¤ì¹­ ì—†ìœ¼ë©´ ì ìˆ˜ ê°ì )
            if not this_industry_matched and matched_industries:
                score = score // 2  # ì—…ì¢… ë¶ˆì¼ì¹˜ ì‹œ ì ìˆ˜ ë°˜ê°
            
            # URLì´ ìœ íš¨í•œì§€ í™•ì¸
            if score > best_score and post.link:
                best_score = score
                best_match = post
                best_reason = ', '.join(reasons[:2]) if reasons else 'í¬íŠ¸ì› ë„ì… íš¨ê³¼'
                industry_matched = this_industry_matched
                best_case_company = case_company_name  # ê³ ê°ì‚¬ëª… ì €ì¥
        
        # ğŸ†• ìµœì†Œ ì ìˆ˜ ê¸°ì¤€ ì™„í™”: ë¸”ë¡œê·¸ ì–¸ê¸‰ì„ ë” ì ê·¹ì ìœ¼ë¡œ í•˜ê¸° ìœ„í•´
        # ì—…ì¢… ë§¤ì¹­ ìˆìœ¼ë©´ 3ì , ì—†ìœ¼ë©´ 5ì  ì´ìƒì´ë©´ OK
        min_score = 3 if industry_matched else 5
        
        if best_match and best_score >= min_score:
            logger.info(f"âœ… ë¸”ë¡œê·¸ ì„ íƒ: {best_match.title[:40]}... (ì ìˆ˜: {best_score}, ì´ìœ : {best_reason}, ì—…ì¢…ë§¤ì¹­: {industry_matched}, ê³ ê°ì‚¬: {best_case_company})")
            return {
                'title': best_match.title,
                'link': best_match.link,
                'summary': best_match.summary[:200] if best_match.summary else '',
                'match_reason': best_reason,
                'industry_matched': industry_matched,
                'case_company': best_case_company  # ë¸”ë¡œê·¸ì— ì–¸ê¸‰ëœ ê³ ê°ì‚¬ëª…
            }
        else:
            logger.info(f"ğŸ“ ì í•©í•œ ë¸”ë¡œê·¸ ì—†ìŒ (ìµœê³  ì ìˆ˜: {best_score}, ìµœì†Œ ê¸°ì¤€: {min_score})")
            return None
            
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ ì„ íƒ ì˜¤ë¥˜: {str(e)}")
        return None


def format_blog_mention_for_email(blog_info, company_name=''):
    """
    ì´ë©”ì¼ì— ì‚½ì…í•  ë¸”ë¡œê·¸ ì–¸ê¸‰ ë¬¸êµ¬ ìƒì„±
    
    "3,000ì—¬ê°œ ê³ ê°ì‚¬ê°€..." ëŒ€ì‹  ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¬¸êµ¬
    
    Args:
        blog_info: get_best_blog_for_email_mention() ê²°ê³¼
        company_name: íšŒì‚¬ëª…
    
    Returns:
        dict: {
            'mention_text': ë³¸ë¬¸ì— ì‚½ì…í•  í…ìŠ¤íŠ¸,
            'blog_link': ë¸”ë¡œê·¸ ë§í¬,
            'blog_title': ë¸”ë¡œê·¸ ì œëª©
        }
    """
    if not blog_info:
        return None
    
    title = blog_info.get('title', '')
    link = blog_info.get('link', '')
    reason = blog_info.get('match_reason', '')
    
    # ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…í•  ë¬¸êµ¬
    mention_text = f"""
ì‹¤ì œë¡œ {reason}ë¥¼ ê³ ë¯¼í•˜ì…¨ë˜ ê³ ê°ì‚¬ì—ì„œ í¬íŠ¸ì› ë„ì… í›„ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ëŠ”ë°ìš”,
ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê¸€ì—ì„œ í™•ì¸í•´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ‘‰ [{title}]({link})
"""
    
    return {
        'mention_text': mention_text.strip(),
        'blog_link': link,
        'blog_title': title,
        'match_reason': reason
    }


def format_relevant_blog_for_email(blog_posts, company_name='', service_type=''):
    """
    ì—…ì¢…ë³„ ê´€ë ¨ ë¸”ë¡œê·¸ ê¸€ì„ RAG ë°©ì‹ìœ¼ë¡œ í¬ë§·íŒ…
    
    Args:
        blog_posts: ë¸”ë¡œê·¸ ê¸€ ë¦¬ìŠ¤íŠ¸
        company_name: íšŒì‚¬ëª…
        service_type: ì„œë¹„ìŠ¤ íƒ€ì…
    
    Returns:
        str: í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if not blog_posts:
        return ''
    
    service_label = service_type if service_type else 'í¬íŠ¸ì›'
    
    content = f"\n\n**ğŸ“š {service_label} ê´€ë ¨ ì°¸ê³  ì •ë³´ (RAG - Pain Point ë§¤ì¹­ ì‚¬ë¡€ ìš°ì„ !):**\n\n"
    content += "âš ï¸ **ì¤‘ìš” ì§€ì¹¨**: ì•„ë˜ ì •ë³´ëŠ” ì´ë©”ì¼ ë³¸ë¬¸ì˜ ì„¤ë“ë ¥ì„ ë†’ì´ê¸° ìœ„í•œ ì°¸ê³  ìë£Œì…ë‹ˆë‹¤.\n"
    content += "- ë¸”ë¡œê·¸ ê¸€ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš” (\"ìµœê·¼ í¬íŠ¸ì› ë¸”ë¡œê·¸ì—ì„œ...\" âŒ)\n"
    content += "- **ì•„ë˜ ë¸”ë¡œê·¸ëŠ” {company_name}ì˜ Pain Pointì™€ ìœ ì‚¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•œ ê¸°ì¡´ ê³ ê° ì‚¬ë¡€ì…ë‹ˆë‹¤**\n"
    content += "- **ì°¸ê³ ìë£Œ 1ë²ˆì´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì‚¬ë¡€**ì´ë¯€ë¡œ ìš°ì„  í™œìš©í•˜ì„¸ìš”\n"
    content += "- ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì—¬ \"{company_name}ë‹˜ë„ ì´ëŸ° ë¬¸ì œ ê²ªìœ¼ì‹œì£ ?\"ë¼ëŠ” ê³µê°ëŒ€ í˜•ì„±\n"
    content += "- ìˆ˜ì¹˜, íŠ¸ë Œë“œ, ì‚¬ë¡€ ë“±ì„ ìì‹ ì˜ ë§ë¡œ ë…¹ì—¬ì„œ ì‚¬ìš©í•˜ì„¸ìš”\n\n"
    content += "---\n\n"
    
    for i, post in enumerate(blog_posts[:3], 1):
        content += f"**ì°¸ê³ ìë£Œ {i}:**\n"
        content += f"ì£¼ì œ: {post['title']}\n"
        content += f"ğŸ”— **ì›ë³¸ ë§í¬ (ì´ë©”ì¼ ì¶œì²˜ë¡œ ì‚¬ìš© ì‹œ ì´ URLì„ ì •í™•íˆ ë³µì‚¬)**: {post.get('link', '')}\n\n"
        
        summary = post.get('summary', '')
        full_content = post.get('content', '')
        
        if summary:
            content += f"í•µì‹¬ ë‚´ìš©:\n{summary}\n\n"
        
        if full_content and len(full_content) > len(summary):
            additional = full_content[len(summary):min(len(summary)+300, len(full_content))]
            content += f"ì¶”ê°€ ì •ë³´:\n{additional}...\n\n"
        
        content += "---\n\n"
    
    content += f"ğŸ’¡ **Pain Point ë§¤ì¹­ ì‚¬ë¡€ í™œìš©ë²•**: \n"
    content += f"- ìœ„ ë¸”ë¡œê·¸ëŠ” {company_name}ì™€ ìœ ì‚¬í•œ Pain Pointë¥¼ ê²ªì€ ê¸°ì¡´ ê³ ê°ì˜ ì„±ê³µ ì‚¬ë¡€ì…ë‹ˆë‹¤\n"
    content += f"- ì´ë©”ì¼ì—ì„œ \"{company_name}ë‹˜ë„ ì´ëŸ° ì–´ë ¤ì›€ ê²ªê³  ê³„ì‹œì§€ ì•Šë‚˜ìš”?\"ë¼ëŠ” ê³µê°ìœ¼ë¡œ ì‹œì‘\n"
    content += f"- ê¸°ì¡´ ê³ ê°ì´ ì–´ë–»ê²Œ ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ì§€ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì–¸ê¸‰\n"
    content += f"- ì˜ˆ: \"ìœ ì‚¬í•œ ì—…ì¢…ì˜ Xì‚¬ëŠ” í¬íŠ¸ì› ë„ì… í›„ Y% ê°œì„  íš¨ê³¼ë¥¼ ë³´ì•˜ìŠµë‹ˆë‹¤\"\n"
    content += f"- ì¶œì²˜ë¥¼ ëª…ì‹œí•  ê²½ìš° ì´ë©”ì¼ í•˜ë‹¨ì— [ì°¸ê³ ] í˜•ì‹ìœ¼ë¡œë§Œ í‘œê¸°\n"
    
    return content

def get_service_knowledge(service_type=''):
    """
    ì„œë¹„ìŠ¤ ì†Œê°œì„œì™€ ë¸”ë¡œê·¸ ì „ì²´ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ RAG ì§€ì‹ë² ì´ìŠ¤ ìƒì„±
    
    Args:
        service_type: 'OPI', 'Recon', 'Prism', 'PS'
    
    Returns:
        str: í†µí•©ëœ ì§€ì‹ë² ì´ìŠ¤ í…ìŠ¤íŠ¸
    """
    knowledge = ""
    
    # 1. ì„œë¹„ìŠ¤ ì†Œê°œì„œ ë¡œë“œ
    service_files = {
        'OPI': 'opi_service_info.txt',
        'Recon': 'recon_service_info.txt',
        'Prism': 'prism_service_info.txt',
        'PS': 'ps_service_info.txt'
    }
    
    service_names = {
        'OPI': 'One Payment Infra (OPI)',
        'Recon': 'ì¬ë¬´ìë™í™” ì†”ë£¨ì…˜ (Recon)',
        'Prism': 'ë©€í‹° ì˜¤í”ˆë§ˆì¼“ ì •ì‚° í†µí•© ì†”ë£¨ì…˜ (Prism)',
        'PS': 'í”Œë«í¼ ì •ì‚° ìë™í™”'
    }
    
    if service_type in service_files:
        try:
            with open(service_files[service_type], 'r', encoding='utf-8') as f:
                service_doc = f.read()
            knowledge += f"\n\n**ğŸ“– {service_names[service_type]} ì„œë¹„ìŠ¤ ì†Œê°œ:**\n\n"
            knowledge += f"{service_doc[:3000]}...\n\n"
            logger.info(f"âœ… {service_type} ì„œë¹„ìŠ¤ ì†Œê°œì„œ ë¡œë“œ ì™„ë£Œ")
        except:
            logger.warning(f"âš ï¸ {service_type} ì„œë¹„ìŠ¤ ì†Œê°œì„œ íŒŒì¼ ì—†ìŒ")
    
    # 2. ë¸”ë¡œê·¸ ì „ì²´ ìš”ì•½ (PostgreSQLì—ì„œ ì¡°íšŒ)
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        posts_query = db.session.query(BlogPost).filter_by(category=service_type).order_by(BlogPost.created_at.desc()).all()
        
        if posts_query:
            knowledge += f"\n\n**ğŸ“š {service_type} ê´€ë ¨ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ({len(posts_query)}ê°œ ê¸€):**\n\n"
            knowledge += f"ë‹¤ìŒì€ í¬íŠ¸ì› ê³µì‹ ë¸”ë¡œê·¸ì—ì„œ {service_type} ê´€ë ¨ {len(posts_query)}ê°œ ê¸€ì˜ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤.\n"
            knowledge += "ì´ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì—…ê³„ íŠ¸ë Œë“œ, Pain Point, ì‚¬ë¡€ ë“±ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.\n\n"
            
            # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            all_keywords = []
            for post in posts_query:
                if post.keywords:
                    keywords = post.keywords.split(',')
                    all_keywords.extend(keywords)
            
            if all_keywords:
                keyword_freq = Counter(all_keywords)
                top_keywords = [k for k, v in keyword_freq.most_common(10)]
                knowledge += f"**ì£¼ìš” í‚¤ì›Œë“œ**: {', '.join(top_keywords)}\n\n"
            
            # ëŒ€í‘œ ê¸€ 5ê°œ ìš”ì•½
            knowledge += f"**ëŒ€í‘œ ì¸ì‚¬ì´íŠ¸:**\n\n"
            for i, post in enumerate(posts_query[:5], 1):
                knowledge += f"{i}. {post.title}\n"
                knowledge += f"   ğŸ”— **ì›ë³¸ ë§í¬**: {post.link}\n"
                if post.summary:
                    knowledge += f"   â†’ {post.summary[:150]}...\n\n"
            
            logger.info(f"âœ… {service_type} ë¸”ë¡œê·¸ {len(posts_query)}ê°œ ìš”ì•½ ì™„ë£Œ (PostgreSQL)")
            
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ ìš”ì•½ ì˜¤ë¥˜: {str(e)}")
    
    # 3. RAG í™œìš© ì§€ì¹¨
    knowledge += f"\n\n**ğŸ’¡ ì§€ì‹ í™œìš© ê°€ì´ë“œ:**\n"
    knowledge += "- ìœ„ ì„œë¹„ìŠ¤ ì†Œê°œì„œì™€ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ê¹Šì´ ì´í•´í•˜ê³  í™œìš©í•˜ì„¸ìš”\n"
    knowledge += "- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ê¸°ëŠ¥, íš¨ê³¼ë¥¼ ì •í™•í•˜ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”\n"
    knowledge += "- ì—…ê³„ íŠ¸ë Œë“œë‚˜ Pain PointëŠ” 'ì—…ê³„ì—ì„œëŠ”...', 'ë§ì€ ê¸°ì—…ë“¤ì´...' í˜•íƒœë¡œ ìì—°ìŠ¤ëŸ½ê²Œ\n"
    knowledge += "- ê²½ìŸë ¥ ìˆëŠ” ì°¨ë³„ì ê³¼ í•µì‹¬ ê°€ì¹˜ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ì„¸ìš”\n"
    knowledge += f"- {service_type} ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì „ë¬¸ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë³´ì—¬ì£¼ì„¸ìš”\n"
    
    return knowledge

def get_existing_blog_links():
    """
    DBì— ì´ë¯¸ ì €ì¥ëœ ë¸”ë¡œê·¸ ë§í¬ ëª©ë¡ ì¡°íšŒ
    
    Returns:
        set: ê¸°ì¡´ ë¸”ë¡œê·¸ ë§í¬ ì§‘í•©
    """
    try:
        db = get_db()
        BlogPost = get_blog_post_model()
        
        # ëª¨ë“  ë§í¬ ì¡°íšŒ
        posts = db.session.query(BlogPost.link).all()
        existing_links = {post.link for post in posts if post.link}
        
        logger.info(f"ğŸ“‹ DBì— ì €ì¥ëœ ë¸”ë¡œê·¸: {len(existing_links)}ê°œ")
        return existing_links
        
    except Exception as e:
        logger.error(f"ê¸°ì¡´ ë§í¬ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return set()

def check_for_new_posts(category_url, existing_links, max_check_pages=2):
    """
    ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒˆë¡œìš´ í¬ìŠ¤íŠ¸ë§Œ í™•ì¸
    
    Args:
        category_url: ì¹´í…Œê³ ë¦¬ URL
        existing_links: ê¸°ì¡´ ë¸”ë¡œê·¸ ë§í¬ ì§‘í•©
        max_check_pages: í™•ì¸í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ 2í˜ì´ì§€)
    
    Returns:
        list: ìƒˆë¡œìš´ í¬ìŠ¤íŠ¸ ë§í¬ ëª©ë¡
    """
    try:
        from bs4 import BeautifulSoup
        import requests
        
        new_post_links = []
        
        for page in range(1, max_check_pages + 1):
            page_url = f"{category_url}&page={page}" if page > 1 else category_url
            
            response = requests.get(page_url, timeout=10)
            if response.status_code != 200:
                logger.warning(f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {page_url}")
                break
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all('article', class_='post')
            
            if not articles:
                logger.info(f"ë” ì´ìƒ ê¸€ì´ ì—†ìŒ (í˜ì´ì§€ {page})")
                break
            
            found_existing = False
            for article in articles:
                link_tag = article.find('a', href=True)
                if link_tag:
                    link = f"https://blog.portone.io{link_tag['href']}"
                    
                    # ê¸°ì¡´ DBì— ì—†ëŠ” ìƒˆë¡œìš´ ê¸€ë§Œ ì¶”ê°€
                    if link not in existing_links:
                        new_post_links.append(link)
                    else:
                        found_existing = True
            
            # ê¸°ì¡´ ê¸€ì„ ë°œê²¬í•˜ë©´ ë” ì´ìƒ í™•ì¸ ë¶ˆí•„ìš”
            if found_existing:
                logger.info(f"ê¸°ì¡´ ê¸€ ë°œê²¬ - {page}í˜ì´ì§€ì—ì„œ í™•ì¸ ì¤‘ë‹¨")
                break
        
        return new_post_links
        
    except Exception as e:
        logger.error(f"ìƒˆ í¬ìŠ¤íŠ¸ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return []
